{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> ", "gt": "if self . n_cpu == <NUM_LIT> :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> ", "gt": "return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) )"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) <EOL> plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> plot_title ( \"<STR_LIT>\" + \"<STR_LIT>\" + audio_file . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> plot_spectrogram ( y , sr , stft , duration ) <EOL> plot_waveform ( y , sr , duration ) <EOL> plot_features ( librosa . times_like ( cent ) , cent , bw , rolloff , duration ) <EOL> plt . tight_layout ( ) <EOL> if save_plot_path : <EOL> plt . savefig ( save_plot_path , bbox_inches = \"<STR_LIT>\" , dpi = <NUM_LIT> ) <EOL> ", "gt": "plt . close ( )"}
{"input": "import os <EOL> import torch <EOL> def change_info ( path , info , name ) : <EOL> try : <EOL> ckpt = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> ckpt [ \"<STR_LIT>\" ] = info <EOL> ", "gt": "if name == \"<STR_LIT>\" :"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) <EOL> gen_losses . append ( l ) <EOL> loss += l <EOL> return loss , gen_losses <EOL> def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : <EOL> z_p = z_p . float ( ) <EOL> logs_q = logs_q . float ( ) <EOL> m_p = m_p . float ( ) <EOL> logs_p = logs_p . float ( ) <EOL> z_mask = z_mask . float ( ) <EOL> kl = logs_p - logs_q - <NUM_LIT> <EOL> kl += <NUM_LIT> * ( ( z_p - m_p ) ** <NUM_LIT> ) * torch . exp ( - <NUM_LIT> * logs_p ) <EOL> kl = torch . sum ( kl * z_mask ) <EOL> ", "gt": "l = kl / torch . sum ( z_mask )"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> ", "gt": "start_time = int ( start_time )"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ", "gt": ")"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> audio_input_path , <EOL> audio_output_path , <EOL> model_path , <EOL> index_path , <EOL> split_audio , <EOL> f0autotune , <EOL> clean_audio , <EOL> clean_strength , <EOL> export_format , <EOL> ) : <EOL> global tgt_sr , net_g , vc , cpt <EOL> get_vc ( model_path , <NUM_LIT> ) <EOL> try : <EOL> start_time = time . time ( ) <EOL> vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = audio_input_path , <EOL> f0_up_key = f0up_key , <EOL> f0_file = None , <EOL> f0_method = f0method , <EOL> file_index = index_path , <EOL> index_rate = index_rate , <EOL> rms_mix_rate = rms_mix_rate , <EOL> protect = protect , <EOL> hop_length = hop_length , <EOL> output_path = audio_output_path , <EOL> split_audio = split_audio , <EOL> f0autotune = f0autotune , <EOL> filter_radius = filter_radius , <EOL> ) <EOL> if clean_audio == \"<STR_LIT>\" : <EOL> cleaned_audio = remove_audio_noise ( audio_output_path , clean_strength ) <EOL> if cleaned_audio is not None : <EOL> sf . write ( audio_output_path , cleaned_audio , tgt_sr , format = \"<STR_LIT>\" ) <EOL> output_path_format = audio_output_path . replace ( <EOL> \"<STR_LIT>\" , f\"<STR_LIT>\" <EOL> ) <EOL> audio_output_path = convert_audio_format ( <EOL> audio_output_path , output_path_format , export_format <EOL> ) <EOL> end_time = time . time ( ) <EOL> elapsed_time = end_time - start_time <EOL> ", "gt": "print ("}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> ", "gt": "value = loadThemes . read_json ( ) ,"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> ", "gt": "return {"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> ", "gt": "global mel_basis"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> self . enc = WN ( <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = p_dropout , <EOL> gin_channels = gin_channels , <EOL> ) <EOL> self . post = nn . Conv1d ( hidden_channels , self . half_channels * ( <NUM_LIT> - mean_only ) , <NUM_LIT> ) <EOL> self . post . weight . data . zero_ ( ) <EOL> self . post . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask , g = None , reverse = False ) : <EOL> x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> h = self . pre ( x0 ) * x_mask <EOL> h = self . enc ( h , x_mask , g = g ) <EOL> stats = self . post ( h ) * x_mask <EOL> if not self . mean_only : <EOL> m , logs = torch . split ( stats , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> ", "gt": "else :"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> ", "gt": "for path , idx0 in infos :"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> ) <EOL> model_view_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> ", "gt": "model_view_button . click ("}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> \"<STR_LIT>\" : feats . to ( device ) , <EOL> \"<STR_LIT>\" : padding_mask . to ( device ) , <EOL> \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , <EOL> } <EOL> with torch . no_grad ( ) : <EOL> logits = model . extract_features ( ** inputs ) <EOL> feats = ( <EOL> model . final_proj ( logits [ <NUM_LIT> ] ) <EOL> if version == \"<STR_LIT>\" <EOL> else logits [ <NUM_LIT> ] <EOL> ) <EOL> feats = feats . squeeze ( <NUM_LIT> ) . float ( ) . cpu ( ) . numpy ( ) <EOL> if np . isnan ( feats ) . sum ( ) == <NUM_LIT> : <EOL> np . save ( out_file_path , feats , allow_pickle = False ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pbar . set_description ( f\"<STR_LIT>\" ) <EOL> except Exception as error : <EOL> ", "gt": "print ( error )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( <EOL> f\"<STR_LIT>\" <EOL> ", "gt": ")"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) ) <EOL> torch . save ( <EOL> replace_keys_in_dict ( <EOL> replace_keys_in_dict ( <EOL> model , \"<STR_LIT>\" , \"<STR_LIT>\" <EOL> ) , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> pth_file_old_version_path , <EOL> ", "gt": ")"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ) <EOL> melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) <EOL> melspec = spectral_normalize_torch ( melspec ) <EOL> return melspec <EOL> def mel_spectrogram_torch ( <EOL> y , n_fft , num_mels , sampling_rate , hop_size , win_size , fmin , fmax , center = False <EOL> ) : <EOL> ", "gt": "spec = spectrogram_torch ( y , n_fft , hop_size , win_size , center )"}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> pitch_guidance = \"<STR_LIT>\" if f0 == <NUM_LIT> else \"<STR_LIT>\" <EOL> return ( <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> ", "gt": "f\"<STR_LIT>\""}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> ", "gt": "fs = self . sampling_rate ,"}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> model_information_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> model_information_button . click ( <EOL> run_model_information_script , <EOL> ", "gt": "[ model_name ] ,"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> ", "gt": "self . enc = WN ("}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> ", "gt": "\"<STR_LIT>\" : \"<STR_LIT>\" ,"}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> raise RuntimeError ( f\"<STR_LIT>\" ) <EOL> return np . frombuffer ( out , np . float32 ) . flatten ( ) <EOL> def format_title ( title ) : <EOL> formatted_title = ( <EOL> unicodedata . normalize ( \"<STR_LIT>\" , title ) . encode ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . decode ( \"<STR_LIT>\" ) <EOL> ) <EOL> formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title ) <EOL> ", "gt": "formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> self . enc = WN ( <EOL> ", "gt": "hidden_channels ,"}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> pass <EOL> python = sys . executable <EOL> os . execl ( python , python , * sys . argv ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def restart_tab ( ) : <EOL> ", "gt": "with gr . Row ( ) :"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . activation = activation <EOL> self . causal = causal <EOL> if causal : <EOL> self . padding = self . _causal_padding <EOL> else : <EOL> self . padding = self . _same_padding <EOL> ", "gt": "self . conv_1 = nn . Conv1d ( in_channels , filter_channels , kernel_size )"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> ", "gt": "return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ]"}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> raise RuntimeError ( f\"<STR_LIT>\" ) <EOL> return np . frombuffer ( out , np . float32 ) . flatten ( ) <EOL> ", "gt": "def format_title ( title ) :"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> self . rpc . update ( <EOL> state = \"<STR_LIT>\" , <EOL> ", "gt": "details = \"<STR_LIT>\" ,"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> ", "gt": "l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> )"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> ", "gt": "self . running = False"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> ", "gt": "n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> ", "gt": "with torch . no_grad ( ) :"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> ", "gt": "hparams . total_epoch = args . total_epoch"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> ", "gt": "f0 = self . mncrepe ( f0_method , x , p_len , hop_length )"}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> pitch_guidance = \"<STR_LIT>\" if f0 == <NUM_LIT> else \"<STR_LIT>\" <EOL> ", "gt": "return ("}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> pitch_guidance = \"<STR_LIT>\" if f0 == <NUM_LIT> else \"<STR_LIT>\" <EOL> return ( <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> ", "gt": "f\"<STR_LIT>\""}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ", "gt": "info = i18n ("}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> ", "gt": "destination_path = os . path . join ( local_folder , file )"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> ", "gt": "download_files ( models_list )"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ) <EOL> melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) <EOL> melspec = spectral_normalize_torch ( melspec ) <EOL> return melspec <EOL> ", "gt": "def mel_spectrogram_torch ("}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> return tag_name <EOL> except requests . exceptions . RequestException as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "return None"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> ", "gt": "temp_filename = save_base64_video ( returned_string )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> self . enc = WN ( <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = p_dropout , <EOL> gin_channels = gin_channels , <EOL> ) <EOL> self . post = nn . Conv1d ( hidden_channels , self . half_channels * ( <NUM_LIT> - mean_only ) , <NUM_LIT> ) <EOL> self . post . weight . data . zero_ ( ) <EOL> self . post . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask , g = None , reverse = False ) : <EOL> x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> h = self . pre ( x0 ) * x_mask <EOL> h = self . enc ( h , x_mask , g = g ) <EOL> stats = self . post ( h ) * x_mask <EOL> if not self . mean_only : <EOL> m , logs = torch . split ( stats , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> else : <EOL> m = stats <EOL> logs = torch . zeros_like ( m ) <EOL> if not reverse : <EOL> x1 = m + x1 * torch . exp ( logs ) * x_mask <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) <EOL> logdet = torch . sum ( logs , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return x , logdet <EOL> else : <EOL> x1 = ( x1 - m ) * torch . exp ( - logs ) * x_mask <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> self . enc . remove_weight_norm ( ) <EOL> class ConvFlow ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> num_bins = <NUM_LIT> , <EOL> tail_bound = <NUM_LIT> , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . num_bins = num_bins <EOL> self . tail_bound = tail_bound <EOL> self . half_channels = in_channels // <NUM_LIT> <EOL> self . pre = nn . Conv1d ( self . half_channels , filter_channels , <NUM_LIT> ) <EOL> self . convs = DDSConv ( filter_channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) <EOL> self . proj = nn . Conv1d ( <EOL> filter_channels , self . half_channels * ( num_bins * <NUM_LIT> - <NUM_LIT> ) , <NUM_LIT> <EOL> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask , g = None , reverse = False ) : <EOL> x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> h = self . pre ( x0 ) <EOL> h = self . convs ( h , x_mask , g = g ) <EOL> h = self . proj ( h ) * x_mask <EOL> b , c , t = x0 . shape <EOL> h = h . reshape ( b , c , - <NUM_LIT> , t ) . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> unnormalized_widths = h [ ... , : self . num_bins ] / math . sqrt ( self . filter_channels ) <EOL> unnormalized_heights = h [ ... , self . num_bins : <NUM_LIT> * self . num_bins ] / math . sqrt ( <EOL> self . filter_channels <EOL> ) <EOL> unnormalized_derivatives = h [ ... , <NUM_LIT> * self . num_bins : ] <EOL> x1 , logabsdet = piecewise_rational_quadratic_transform ( <EOL> x1 , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = reverse , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = self . tail_bound , <EOL> ", "gt": ")"}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> pitch_guidance = \"<STR_LIT>\" if f0 == <NUM_LIT> else \"<STR_LIT>\" <EOL> return ( <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> ", "gt": ")"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> hparams . total_epoch = args . total_epoch <EOL> hparams . pretrainG = args . pretrainG <EOL> hparams . pretrainD = args . pretrainD <EOL> hparams . version = args . version <EOL> hparams . gpus = args . gpus <EOL> hparams . train . batch_size = args . batch_size <EOL> hparams . sample_rate = args . sample_rate <EOL> hparams . if_f0 = args . if_f0 <EOL> hparams . if_latest = args . if_latest <EOL> hparams . save_every_weights = args . save_every_weights <EOL> hparams . if_cache_data_in_gpu = args . if_cache_data_in_gpu <EOL> hparams . data . training_files = f\"<STR_LIT>\" <EOL> hparams . overtraining_detector = args . overtraining_detector <EOL> hparams . overtraining_threshold = args . overtraining_threshold <EOL> return hparams <EOL> class HParams : <EOL> def __init__ ( self , ** kwargs ) : <EOL> for k , v in kwargs . items ( ) : <EOL> if type ( v ) == dict : <EOL> v = HParams ( ** v ) <EOL> self [ k ] = v <EOL> def keys ( self ) : <EOL> ", "gt": "return self . __dict__ . keys ( )"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> elif \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> try : <EOL> now_dir . encode ( \"<STR_LIT>\" ) <EOL> except UnicodeEncodeError : <EOL> ", "gt": "raise InstallationError ("}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> elif \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) <EOL> gen_losses . append ( l ) <EOL> loss += l <EOL> return loss , gen_losses <EOL> def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : <EOL> z_p = z_p . float ( ) <EOL> logs_q = logs_q . float ( ) <EOL> m_p = m_p . float ( ) <EOL> logs_p = logs_p . float ( ) <EOL> z_mask = z_mask . float ( ) <EOL> kl = logs_p - logs_q - <NUM_LIT> <EOL> kl += <NUM_LIT> * ( ( z_p - m_p ) ** <NUM_LIT> ) * torch . exp ( - <NUM_LIT> * logs_p ) <EOL> kl = torch . sum ( kl * z_mask ) <EOL> l = kl / torch . sum ( z_mask ) <EOL> ", "gt": "return l"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> ", "gt": "return f0_coarse"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> self . rpc . update ( <EOL> state = \"<STR_LIT>\" , <EOL> details = \"<STR_LIT>\" , <EOL> buttons = [ <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> ", "gt": "{ \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } ,"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( )"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> ", "gt": "hop_length ,"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> ", "gt": "else :"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> \"<STR_LIT>\" : feats . to ( device ) , <EOL> \"<STR_LIT>\" : padding_mask . to ( device ) , <EOL> \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , <EOL> } <EOL> with torch . no_grad ( ) : <EOL> logits = model . extract_features ( ** inputs ) <EOL> feats = ( <EOL> model . final_proj ( logits [ <NUM_LIT> ] ) <EOL> if version == \"<STR_LIT>\" <EOL> ", "gt": "else logits [ <NUM_LIT> ]"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> ", "gt": "raise ValueError ( \"<STR_LIT>\" )"}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> ", "gt": "raise RuntimeError ( f\"<STR_LIT>\" )"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> ", "gt": "audio_segments = [ ]"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if pretraineds_v2 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v2_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "wget . download ( url , out = destination_path )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> ", "gt": "padding = get_padding ( kernel_size , <NUM_LIT> ) ,"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> ", "gt": "if pretraineds_v1 == \"<STR_LIT>\" :"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> ", "gt": "tmp_audio . astype ( np . float32 ) ,"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( \"<STR_LIT>\" ) <EOL> print ( e ) <EOL> def load_config_flask ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> ", "gt": "def save_config ( value ) :"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> indices = [ ] <EOL> if self . shuffle : <EOL> for bucket in self . buckets : <EOL> indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) <EOL> else : <EOL> for bucket in self . buckets : <EOL> indices . append ( list ( range ( len ( bucket ) ) ) ) <EOL> batches = [ ] <EOL> for i in range ( len ( self . buckets ) ) : <EOL> bucket = self . buckets [ i ] <EOL> len_bucket = len ( bucket ) <EOL> ", "gt": "ids_bucket = indices [ i ]"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> ", "gt": "gr . Info ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> ", "gt": "[ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> ", "gt": "plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" )"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) <EOL> gen_losses . append ( l ) <EOL> loss += l <EOL> return loss , gen_losses <EOL> def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : <EOL> z_p = z_p . float ( ) <EOL> logs_q = logs_q . float ( ) <EOL> m_p = m_p . float ( ) <EOL> logs_p = logs_p . float ( ) <EOL> z_mask = z_mask . float ( ) <EOL> kl = logs_p - logs_q - <NUM_LIT> <EOL> kl += <NUM_LIT> * ( ( z_p - m_p ) ** <NUM_LIT> ) * torch . exp ( - <NUM_LIT> * logs_p ) <EOL> ", "gt": "kl = torch . sum ( kl * z_mask )"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ", "gt": "try :"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> ", "gt": "x = torch . arange ( max_length , dtype = length . dtype , device = length . device )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> ", "gt": "if x_mask is not None :"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> opt_path2 + \"<STR_LIT>\" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> np . save ( <EOL> opt_path2 , <EOL> feature_pit , <EOL> ", "gt": "allow_pickle = False ,"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) <EOL> path = path . view ( b , t_x , t_y ) <EOL> path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] <EOL> path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask <EOL> return path <EOL> def clip_grad_value_ ( parameters , clip_value , norm_type = <NUM_LIT> ) : <EOL> if isinstance ( parameters , torch . Tensor ) : <EOL> parameters = [ parameters ] <EOL> parameters = list ( filter ( lambda p : p . grad is not None , parameters ) ) <EOL> norm_type = float ( norm_type ) <EOL> if clip_value is not None : <EOL> clip_value = float ( clip_value ) <EOL> total_norm = <NUM_LIT> <EOL> for p in parameters : <EOL> param_norm = p . grad . data . norm ( norm_type ) <EOL> total_norm += param_norm . item ( ) ** norm_type <EOL> if clip_value is not None : <EOL> ", "gt": "p . grad . data . clamp_ ( min = - clip_value , max = clip_value )"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( \"<STR_LIT>\" ) <EOL> ", "gt": "print ( e )"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> try : <EOL> infos = [ <EOL> ( f\"<STR_LIT>\" , idx ) <EOL> for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) <EOL> ] <EOL> processes = [ ] <EOL> for i in range ( num_processes ) : <EOL> p = multiprocessing . Process ( <EOL> target = self . process_audio_multiprocessing , <EOL> args = ( infos [ i : : num_processes ] , ) , <EOL> ) <EOL> processes . append ( p ) <EOL> p . start ( ) <EOL> for i in range ( num_processes ) : <EOL> processes [ i ] . join ( ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def preprocess_training_set ( input_root , sr , num_processes , exp_dir , per ) : <EOL> pp = PreProcess ( sr , exp_dir , per ) <EOL> print ( \"<STR_LIT>\" ) <EOL> pp . process_audio_multiprocessing_input_directory ( input_root , num_processes ) <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( <EOL> ", "gt": "f\"<STR_LIT>\""}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> ", "gt": "required = True ,"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> ", "gt": "<NUM_LIT> ,"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ", "gt": ")"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> ", "gt": "label = i18n ( \"<STR_LIT>\" ) ,"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ) . half ( ) <EOL> opt [ \"<STR_LIT>\" ] = cfg <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> opt [ \"<STR_LIT>\" ] = cfg_f0 <EOL> opt [ \"<STR_LIT>\" ] = cfg_version <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> torch . save ( opt , os . path . join ( \"<STR_LIT>\" , \"<STR_LIT>\" % name ) ) <EOL> print ( message ) <EOL> ", "gt": "return message , os . path . join ( \"<STR_LIT>\" , \"<STR_LIT>\" % name )"}
{"input": "import gradio as gr <EOL> import tabs . extra . processing . processing as processing <EOL> import tabs . extra . analyzer . analyzer as analyzer <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def extra_tab ( ) : <EOL> gr . Markdown ( <EOL> ", "gt": "value = i18n ("}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> ", "gt": "label = i18n ( \"<STR_LIT>\" ) ,"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> ", "gt": "center = center ,"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> ", "gt": "plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" )"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> with gr . Column ( ) : <EOL> selected_language = gr . Dropdown ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> value = get_language_settings ( ) , <EOL> choices = [ \"<STR_LIT>\" ] <EOL> + i18n . _get_available_languages ( ) , <EOL> interactive = True , <EOL> ) <EOL> ", "gt": "selected_language . change ("}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) <EOL> c = - input_delta * ( inputs - input_cumheights ) <EOL> discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c <EOL> assert ( discriminant >= <NUM_LIT> ) . all ( ) <EOL> root = ( <NUM_LIT> * c ) / ( - b - torch . sqrt ( discriminant ) ) <EOL> outputs = root * input_bin_widths + input_cumwidths <EOL> theta_one_minus_theta = root * ( <NUM_LIT> - root ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> * theta_one_minus_theta <EOL> ) <EOL> derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( <EOL> input_derivatives_plus_one * root . pow ( <NUM_LIT> ) <EOL> + <NUM_LIT> * input_delta * theta_one_minus_theta <EOL> + input_derivatives * ( <NUM_LIT> - root ) . pow ( <NUM_LIT> ) <EOL> ", "gt": ")"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> ", "gt": "config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] = step"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" <EOL> def load_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> module = importlib . import_module ( selected_file [ : - <NUM_LIT> ] ) <EOL> obtained_class = getattr ( module , class_name ) <EOL> instance = obtained_class ( ) <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> ", "gt": "* cpt [ \"<STR_LIT>\" ] , is_half = config . is_half"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> with gr . Column ( ) : <EOL> selected_language = gr . Dropdown ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ", "gt": ") ,"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> with gr . Column ( ) : <EOL> ", "gt": "selected_language = gr . Dropdown ("}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> ", "gt": "input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> ", "gt": "right = <NUM_LIT> ,"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> \"<STR_LIT>\" : feats . to ( device ) , <EOL> \"<STR_LIT>\" : padding_mask . to ( device ) , <EOL> \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , <EOL> } <EOL> with torch . no_grad ( ) : <EOL> logits = model . extract_features ( ** inputs ) <EOL> ", "gt": "feats = ("}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> return x_pad , x_query , x_center , x_max <EOL> def max_vram_gpu ( gpu ) : <EOL> if torch . cuda . is_available ( ) : <EOL> gpu_properties = torch . cuda . get_device_properties ( gpu ) <EOL> total_memory_gb = round ( gpu_properties . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> ) <EOL> return total_memory_gb <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> def get_gpu_info ( ) : <EOL> ", "gt": "ngpu = torch . cuda . device_count ( )"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> ", "gt": "def get_vc ( weight_root , sid ) :"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> ", "gt": "b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ("}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> raise RuntimeError ( f\"<STR_LIT>\" ) <EOL> return np . frombuffer ( out , np . float32 ) . flatten ( ) <EOL> def format_title ( title ) : <EOL> formatted_title = ( <EOL> unicodedata . normalize ( \"<STR_LIT>\" , title ) . encode ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . decode ( \"<STR_LIT>\" ) <EOL> ", "gt": ")"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> ", "gt": "\"<STR_LIT>\" : self . get_dio ,"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" <EOL> def load_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> module = importlib . import_module ( selected_file [ : - <NUM_LIT> ] ) <EOL> obtained_class = getattr ( module , class_name ) <EOL> instance = obtained_class ( ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return instance <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> return None <EOL> except Exception as e : <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> ) <EOL> model_view_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> model_view_button . click ( <EOL> run_model_information_script , <EOL> [ model_view_model_path ] , <EOL> model_view_output_info , <EOL> ", "gt": "api_name = \"<STR_LIT>\" ,"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> ", "gt": ". tril ( self . block_length )"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> ", "gt": "for _ in range ( <NUM_LIT> ) :"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> ", "gt": "} ,"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> ", "gt": "assert ("}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> return tag_name <EOL> except requests . exceptions . RequestException as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def compare_version ( ) : <EOL> local_version = load_local_version ( ) <EOL> online_version = obtain_tag_name ( ) <EOL> ", "gt": "elements_online_version = list ( map ( int , online_version . split ( \"<STR_LIT>\" ) ) )"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> ", "gt": "fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT>"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> ", "gt": "if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape :"}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> ", "gt": "tag_name = data [ \"<STR_LIT>\" ]"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ", "gt": ") ,"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> with gr . Column ( ) : <EOL> selected_language = gr . Dropdown ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> value = get_language_settings ( ) , <EOL> choices = [ \"<STR_LIT>\" ] <EOL> + i18n . _get_available_languages ( ) , <EOL> interactive = True , <EOL> ) <EOL> selected_language . change ( <EOL> fn = save_lang_settings , <EOL> inputs = [ selected_language ] , <EOL> ", "gt": "outputs = [ ] ,"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> ", "gt": "index_rate ,"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> ", "gt": "except Exception as e :"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> ", "gt": "silence = AudioSegment . silent ( duration = silence_duration )"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False <EOL> ", "gt": ")"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ", "gt": "ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> ", "gt": "hidden_channels ,"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def fake_gpu_tab ( ) : <EOL> ", "gt": "with gr . Row ( ) :"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> ", "gt": "min_bin_height = DEFAULT_MIN_BIN_HEIGHT ,"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> ", "gt": "filename , start_time = match . groups ( )"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) <EOL> plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> plot_title ( \"<STR_LIT>\" + \"<STR_LIT>\" + audio_file . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> plot_spectrogram ( y , sr , stft , duration ) <EOL> plot_waveform ( y , sr , duration ) <EOL> plot_features ( librosa . times_like ( cent ) , cent , bw , rolloff , duration ) <EOL> ", "gt": "plt . tight_layout ( )"}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ", "gt": "creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> ", "gt": "if returned_string . startswith ( \"<STR_LIT>\" ) :"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] [ key ] = ("}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ", "gt": ")"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> fn = toggle , <EOL> inputs = [ flask_checkbox ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> if load_config_flask ( ) == True : <EOL> start_flask ( ) <EOL> else : <EOL> try : <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> except requests . exceptions . ConnectionError : <EOL> ", "gt": "pass"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "print ( e )"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> ", "gt": "hps . model . kernel_size ,"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> indices = [ ] <EOL> if self . shuffle : <EOL> for bucket in self . buckets : <EOL> indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) <EOL> else : <EOL> for bucket in self . buckets : <EOL> indices . append ( list ( range ( len ( bucket ) ) ) ) <EOL> batches = [ ] <EOL> for i in range ( len ( self . buckets ) ) : <EOL> bucket = self . buckets [ i ] <EOL> len_bucket = len ( bucket ) <EOL> ids_bucket = indices [ i ] <EOL> num_samples_bucket = self . num_samples_per_bucket [ i ] <EOL> rem = num_samples_bucket - len_bucket <EOL> ids_bucket = ( <EOL> ids_bucket <EOL> + ids_bucket * ( rem // len_bucket ) <EOL> + ids_bucket [ : ( rem % len_bucket ) ] <EOL> ) <EOL> ids_bucket = ids_bucket [ self . rank : : self . num_replicas ] <EOL> for j in range ( len ( ids_bucket ) // self . batch_size ) : <EOL> batch = [ <EOL> bucket [ idx ] <EOL> for idx in ids_bucket [ <EOL> j * self . batch_size : ( j + <NUM_LIT> ) * self . batch_size <EOL> ] <EOL> ] <EOL> batches . append ( batch ) <EOL> if self . shuffle : <EOL> batch_ids = torch . randperm ( len ( batches ) , generator = g ) . tolist ( ) <EOL> batches = [ batches [ i ] for i in batch_ids ] <EOL> self . batches = batches <EOL> assert len ( self . batches ) * self . batch_size == self . num_samples <EOL> return iter ( self . batches ) <EOL> def _bisect ( self , x , lo = <NUM_LIT> , hi = None ) : <EOL> if hi is None : <EOL> hi = len ( self . boundaries ) - <NUM_LIT> <EOL> if hi > lo : <EOL> ", "gt": "mid = ( hi + lo ) // <NUM_LIT>"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> ", "gt": "if \"<STR_LIT>\" in now_dir :"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ", "gt": ")"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> self . rpc . update ( <EOL> state = \"<STR_LIT>\" , <EOL> details = \"<STR_LIT>\" , <EOL> buttons = [ <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> ] , <EOL> large_image = \"<STR_LIT>\" , <EOL> large_text = \"<STR_LIT>\" , <EOL> start = dt . datetime . now ( ) . timestamp ( ) , <EOL> ) <EOL> def stop_presence ( self ) : <EOL> ", "gt": "self . running = False"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> return x_pad , x_query , x_center , x_max <EOL> def max_vram_gpu ( gpu ) : <EOL> if torch . cuda . is_available ( ) : <EOL> gpu_properties = torch . cuda . get_device_properties ( gpu ) <EOL> total_memory_gb = round ( gpu_properties . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> ) <EOL> return total_memory_gb <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> def get_gpu_info ( ) : <EOL> ngpu = torch . cuda . device_count ( ) <EOL> gpu_infos = [ ] <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> for i in range ( ngpu ) : <EOL> gpu_name = torch . cuda . get_device_name ( i ) <EOL> ", "gt": "mem = int ("}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> audio_segments . append ( audio ) <EOL> last_end_time = start_time + len ( audio ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> merged_audio = sum ( audio_segments ) <EOL> ", "gt": "merged_audio_np = np . array ( merged_audio . get_array_of_samples ( ) )"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> ", "gt": "return pad_shape"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> ", "gt": "slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT>"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] = epoch"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> ", "gt": "fs = self . sampling_rate ,"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> ", "gt": "x_pad = <NUM_LIT>"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ", "gt": ")"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> ", "gt": "parser . add_argument ("}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> return tag_name <EOL> ", "gt": "except requests . exceptions . RequestException as e :"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> ", "gt": "dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device )"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> \"<STR_LIT>\" : feats . to ( device ) , <EOL> \"<STR_LIT>\" : padding_mask . to ( device ) , <EOL> \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , <EOL> ", "gt": "}"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> ", "gt": "librosa . display . waveshow ( y , sr = sr )"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> ", "gt": "selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ]"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ) <EOL> melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) <EOL> melspec = spectral_normalize_torch ( melspec ) <EOL> return melspec <EOL> def mel_spectrogram_torch ( <EOL> y , n_fft , num_mels , sampling_rate , hop_size , win_size , fmin , fmax , center = False <EOL> ) : <EOL> spec = spectrogram_torch ( y , n_fft , hop_size , win_size , center ) <EOL> melspec = spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) <EOL> ", "gt": "return melspec"}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = False , <EOL> ) <EOL> version_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> version_button . click ( <EOL> fn = compare_version , <EOL> ", "gt": "inputs = [ ] ,"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] [ key ] = ("}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = False , <EOL> ) <EOL> version_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> ", "gt": "version_button . click ("}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> pass <EOL> python = sys . executable <EOL> os . execl ( python , python , * sys . argv ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def restart_tab ( ) : <EOL> with gr . Row ( ) : <EOL> ", "gt": "with gr . Column ( ) :"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( \"<STR_LIT>\" ) <EOL> print ( e ) <EOL> def load_config_flask ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> ", "gt": "with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file :"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) <EOL> path = path . view ( b , t_x , t_y ) <EOL> path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] <EOL> path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask <EOL> return path <EOL> def clip_grad_value_ ( parameters , clip_value , norm_type = <NUM_LIT> ) : <EOL> if isinstance ( parameters , torch . Tensor ) : <EOL> parameters = [ parameters ] <EOL> parameters = list ( filter ( lambda p : p . grad is not None , parameters ) ) <EOL> norm_type = float ( norm_type ) <EOL> if clip_value is not None : <EOL> clip_value = float ( clip_value ) <EOL> total_norm = <NUM_LIT> <EOL> for p in parameters : <EOL> param_norm = p . grad . data . norm ( norm_type ) <EOL> total_norm += param_norm . item ( ) ** norm_type <EOL> if clip_value is not None : <EOL> p . grad . data . clamp_ ( min = - clip_value , max = clip_value ) <EOL> total_norm = total_norm ** ( <NUM_LIT> / norm_type ) <EOL> ", "gt": "return total_norm"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ", "gt": ") ,"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ", "gt": "visible = True ,"}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> ", "gt": "except Exception as error :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ", "gt": ")"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> return x_pad , x_query , x_center , x_max <EOL> def max_vram_gpu ( gpu ) : <EOL> if torch . cuda . is_available ( ) : <EOL> gpu_properties = torch . cuda . get_device_properties ( gpu ) <EOL> total_memory_gb = round ( gpu_properties . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> ) <EOL> return total_memory_gb <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> def get_gpu_info ( ) : <EOL> ngpu = torch . cuda . device_count ( ) <EOL> gpu_infos = [ ] <EOL> ", "gt": "if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> :"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> ", "gt": "try :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> ", "gt": "frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate ,"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> hparams . total_epoch = args . total_epoch <EOL> hparams . pretrainG = args . pretrainG <EOL> hparams . pretrainD = args . pretrainD <EOL> hparams . version = args . version <EOL> ", "gt": "hparams . gpus = args . gpus"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> ", "gt": "local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" )"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> opt_path2 + \"<STR_LIT>\" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> np . save ( <EOL> opt_path2 , <EOL> feature_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> coarse_pit = self . coarse_f0 ( feature_pit ) <EOL> np . save ( <EOL> opt_path1 , <EOL> coarse_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> pbar . update ( <NUM_LIT> ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> feature_input = FeatureInput ( ) <EOL> paths = [ ] <EOL> input_root = f\"<STR_LIT>\" <EOL> output_root1 = f\"<STR_LIT>\" <EOL> output_root2 = f\"<STR_LIT>\" <EOL> os . makedirs ( output_root1 , exist_ok = True ) <EOL> os . makedirs ( output_root2 , exist_ok = True ) <EOL> for name in sorted ( list ( os . listdir ( input_root ) ) ) : <EOL> input_path = f\"<STR_LIT>\" <EOL> if \"<STR_LIT>\" in input_path : <EOL> continue <EOL> output_path1 = f\"<STR_LIT>\" <EOL> output_path2 = f\"<STR_LIT>\" <EOL> paths . append ( [ input_path , output_path1 , output_path2 ] ) <EOL> processes = [ ] <EOL> print ( \"<STR_LIT>\" + f0_method ) <EOL> ", "gt": "for i in range ( num_processes ) :"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> ", "gt": "padded_relative_embeddings = F . pad ("}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> ) <EOL> ", "gt": "model_view_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" )"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ", "gt": ")"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> ", "gt": "f0_ceil = self . f0_max ,"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> if not gpu_available ( ) : <EOL> fake_gpu_tab ( ) <EOL> theme_tab ( ) <EOL> version_tab ( ) <EOL> lang_tab ( ) <EOL> restart_tab ( ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> port = <NUM_LIT> <EOL> if \"<STR_LIT>\" in sys . argv : <EOL> ", "gt": "port_index = sys . argv . index ( \"<STR_LIT>\" ) + <NUM_LIT>"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) ) <EOL> torch . save ( <EOL> replace_keys_in_dict ( <EOL> replace_keys_in_dict ( <EOL> model , \"<STR_LIT>\" , \"<STR_LIT>\" <EOL> ) , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> pth_file_old_version_path , <EOL> ) <EOL> os . remove ( model_dir ) <EOL> os . rename ( pth_file_old_version_path , model_dir ) <EOL> except Exception as error : <EOL> ", "gt": "print ( error )"}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> return tag_name <EOL> except requests . exceptions . RequestException as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def compare_version ( ) : <EOL> local_version = load_local_version ( ) <EOL> online_version = obtain_tag_name ( ) <EOL> elements_online_version = list ( map ( int , online_version . split ( \"<STR_LIT>\" ) ) ) <EOL> elements_local_version = list ( map ( int , local_version . split ( \"<STR_LIT>\" ) ) ) <EOL> for online , local in zip ( elements_online_version , elements_local_version ) : <EOL> ", "gt": "if local < online :"}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> ", "gt": "label = i18n ( \"<STR_LIT>\" ) ,"}
{"input": "import sys <EOL> import asyncio <EOL> import edge_tts <EOL> async def main ( ) : <EOL> text = sys . argv [ <NUM_LIT> ] <EOL> voice = sys . argv [ <NUM_LIT> ] <EOL> output_file = sys . argv [ <NUM_LIT> ] <EOL> await edge_tts . Communicate ( text , voice ) . save ( output_file ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "if __name__ == \"<STR_LIT>\" :"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False <EOL> ) <EOL> model_fusion_button . click ( <EOL> fn = run_model_blender_script , <EOL> inputs = [ <EOL> model_fusion_name , <EOL> model_fusion_a , <EOL> model_fusion_b , <EOL> alpha_a , <EOL> ] , <EOL> outputs = [ model_fusion_output_info , model_fusion_pth_output ] , <EOL> ) <EOL> model_fusion_a_dropbox . upload ( <EOL> fn = update_model_fusion , <EOL> inputs = model_fusion_a_dropbox , <EOL> outputs = [ model_fusion_a , model_fusion_a_dropbox ] , <EOL> ) <EOL> model_fusion_b_dropbox . upload ( <EOL> fn = update_model_fusion , <EOL> ", "gt": "inputs = model_fusion_b_dropbox ,"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( \"<STR_LIT>\" ) <EOL> print ( e ) <EOL> ", "gt": "def load_config_flask ( ) :"}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ", "gt": "interactive = False ,"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> ", "gt": "self . n_cpu = os . cpu_count ( )"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> hparams . total_epoch = args . total_epoch <EOL> hparams . pretrainG = args . pretrainG <EOL> hparams . pretrainD = args . pretrainD <EOL> hparams . version = args . version <EOL> hparams . gpus = args . gpus <EOL> ", "gt": "hparams . train . batch_size = args . batch_size"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> ", "gt": "torch . cuda . get_device_properties ( i_device ) . total_memory"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> ", "gt": "[ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> ", "gt": "info = i18n ( \"<STR_LIT>\" ) ,"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> ", "gt": "value = load_config_presence ( ) ,"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "for line in lines :"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ", "gt": "]"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" <EOL> def load_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> ", "gt": "module = importlib . import_module ( selected_file [ : - <NUM_LIT> ] )"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ) <EOL> melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) <EOL> melspec = spectral_normalize_torch ( melspec ) <EOL> return melspec <EOL> def mel_spectrogram_torch ( <EOL> y , n_fft , num_mels , sampling_rate , hop_size , win_size , fmin , fmax , center = False <EOL> ", "gt": ") :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> ", "gt": "source [ source < <NUM_LIT> ] = np . nan"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Video ( <EOL> value = temp_filename , interactive = False <EOL> ) <EOL> start_button . click ( <EOL> toggle_button_label , <EOL> ", "gt": "start_button ,"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) <EOL> c = - input_delta * ( inputs - input_cumheights ) <EOL> discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c <EOL> assert ( discriminant >= <NUM_LIT> ) . all ( ) <EOL> root = ( <NUM_LIT> * c ) / ( - b - torch . sqrt ( discriminant ) ) <EOL> outputs = root * input_bin_widths + input_cumwidths <EOL> theta_one_minus_theta = root * ( <NUM_LIT> - root ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> ", "gt": "* theta_one_minus_theta"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> ", "gt": "extra_tab ( )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> ", "gt": "loadThemes . get_list ( ) ,"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ", "gt": "if version == \"<STR_LIT>\" :"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> audio_input_path , <EOL> audio_output_path , <EOL> model_path , <EOL> index_path , <EOL> ", "gt": "split_audio ,"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if pretraineds_v2 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v2_list : <EOL> ", "gt": "local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" )"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "gr . Info ( f\"<STR_LIT>\" )"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> ", "gt": "for file_name in file_list :"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> ", "gt": "script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> ", "gt": "gr . Markdown ("}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ", "gt": ")"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> indices = [ ] <EOL> if self . shuffle : <EOL> for bucket in self . buckets : <EOL> indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) <EOL> else : <EOL> ", "gt": "for bucket in self . buckets :"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False <EOL> ) <EOL> model_fusion_button . click ( <EOL> fn = run_model_blender_script , <EOL> inputs = [ <EOL> model_fusion_name , <EOL> model_fusion_a , <EOL> model_fusion_b , <EOL> alpha_a , <EOL> ] , <EOL> outputs = [ model_fusion_output_info , model_fusion_pth_output ] , <EOL> ", "gt": ")"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> fn = toggle , <EOL> inputs = [ flask_checkbox ] , <EOL> ", "gt": "outputs = [ ] ,"}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = False , <EOL> ) <EOL> version_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> version_button . click ( <EOL> fn = compare_version , <EOL> inputs = [ ] , <EOL> ", "gt": "outputs = [ version_check ] ,"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) <EOL> c = - input_delta * ( inputs - input_cumheights ) <EOL> discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c <EOL> assert ( discriminant >= <NUM_LIT> ) . all ( ) <EOL> root = ( <NUM_LIT> * c ) / ( - b - torch . sqrt ( discriminant ) ) <EOL> outputs = root * input_bin_widths + input_cumwidths <EOL> theta_one_minus_theta = root * ( <NUM_LIT> - root ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> * theta_one_minus_theta <EOL> ) <EOL> derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( <EOL> input_derivatives_plus_one * root . pow ( <NUM_LIT> ) <EOL> + <NUM_LIT> * input_delta * theta_one_minus_theta <EOL> + input_derivatives * ( <NUM_LIT> - root ) . pow ( <NUM_LIT> ) <EOL> ) <EOL> logabsdet = torch . log ( derivative_numerator ) - <NUM_LIT> * torch . log ( denominator ) <EOL> return outputs , - logabsdet <EOL> else : <EOL> theta = ( inputs - input_cumwidths ) / input_bin_widths <EOL> theta_one_minus_theta = theta * ( <NUM_LIT> - theta ) <EOL> numerator = input_heights * ( <EOL> input_delta * theta . pow ( <NUM_LIT> ) + input_derivatives * theta_one_minus_theta <EOL> ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> * theta_one_minus_theta <EOL> ", "gt": ")"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> ", "gt": "except Exception as e :"}
{"input": "import sys <EOL> import asyncio <EOL> import edge_tts <EOL> async def main ( ) : <EOL> text = sys . argv [ <NUM_LIT> ] <EOL> ", "gt": "voice = sys . argv [ <NUM_LIT> ]"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> ", "gt": "return {"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> ", "gt": "if not gpu_available ( ) :"}
{"input": "import os <EOL> import torch <EOL> def change_info ( path , info , name ) : <EOL> try : <EOL> ckpt = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> ckpt [ \"<STR_LIT>\" ] = info <EOL> if name == \"<STR_LIT>\" : <EOL> name = os . path . basename ( path ) <EOL> torch . save ( ckpt , f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" <EOL> ", "gt": "except Exception as error :"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> ", "gt": "class_found = get_class ( full_path )"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> ", "gt": "def generate_path ( duration , mask ) :"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> ", "gt": "else :"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> ", "gt": "except Exception as e :"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ", "gt": ") ,"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> ", "gt": "x_center = <NUM_LIT>"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> ", "gt": "else :"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) ) <EOL> torch . save ( <EOL> replace_keys_in_dict ( <EOL> replace_keys_in_dict ( <EOL> model , \"<STR_LIT>\" , \"<STR_LIT>\" <EOL> ", "gt": ") ,"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) <EOL> path = path . view ( b , t_x , t_y ) <EOL> path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] <EOL> path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask <EOL> return path <EOL> def clip_grad_value_ ( parameters , clip_value , norm_type = <NUM_LIT> ) : <EOL> if isinstance ( parameters , torch . Tensor ) : <EOL> parameters = [ parameters ] <EOL> parameters = list ( filter ( lambda p : p . grad is not None , parameters ) ) <EOL> norm_type = float ( norm_type ) <EOL> if clip_value is not None : <EOL> ", "gt": "clip_value = float ( clip_value )"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> ", "gt": "self . normalize_and_write ( tmp_audio , idx0 , idx1 )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> ", "gt": "class ElementwiseAffine ( nn . Module ) :"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) <EOL> c = - input_delta * ( inputs - input_cumheights ) <EOL> discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c <EOL> assert ( discriminant >= <NUM_LIT> ) . all ( ) <EOL> root = ( <NUM_LIT> * c ) / ( - b - torch . sqrt ( discriminant ) ) <EOL> outputs = root * input_bin_widths + input_cumwidths <EOL> theta_one_minus_theta = root * ( <NUM_LIT> - root ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> * theta_one_minus_theta <EOL> ) <EOL> derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( <EOL> input_derivatives_plus_one * root . pow ( <NUM_LIT> ) <EOL> + <NUM_LIT> * input_delta * theta_one_minus_theta <EOL> + input_derivatives * ( <NUM_LIT> - root ) . pow ( <NUM_LIT> ) <EOL> ) <EOL> logabsdet = torch . log ( derivative_numerator ) - <NUM_LIT> * torch . log ( denominator ) <EOL> return outputs , - logabsdet <EOL> else : <EOL> theta = ( inputs - input_cumwidths ) / input_bin_widths <EOL> theta_one_minus_theta = theta * ( <NUM_LIT> - theta ) <EOL> numerator = input_heights * ( <EOL> input_delta * theta . pow ( <NUM_LIT> ) + input_derivatives * theta_one_minus_theta <EOL> ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> ", "gt": "* theta_one_minus_theta"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ", "gt": "ckpt2 = ckpt2 [ \"<STR_LIT>\" ]"}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> raise RuntimeError ( f\"<STR_LIT>\" ) <EOL> return np . frombuffer ( out , np . float32 ) . flatten ( ) <EOL> def format_title ( title ) : <EOL> formatted_title = ( <EOL> unicodedata . normalize ( \"<STR_LIT>\" , title ) . encode ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . decode ( \"<STR_LIT>\" ) <EOL> ) <EOL> formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title ) <EOL> formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title ) <EOL> formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title ) <EOL> ", "gt": "return formatted_title"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> ", "gt": "or \"<STR_LIT>\" in self . gpu_name"}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ", "gt": "version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" )"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> ", "gt": "y , sr = librosa . load ( audio_file )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> if not gpu_available ( ) : <EOL> fake_gpu_tab ( ) <EOL> theme_tab ( ) <EOL> ", "gt": "version_tab ( )"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> opt_path2 + \"<STR_LIT>\" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> np . save ( <EOL> opt_path2 , <EOL> feature_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> coarse_pit = self . coarse_f0 ( feature_pit ) <EOL> np . save ( <EOL> opt_path1 , <EOL> coarse_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> pbar . update ( <NUM_LIT> ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> feature_input = FeatureInput ( ) <EOL> paths = [ ] <EOL> input_root = f\"<STR_LIT>\" <EOL> output_root1 = f\"<STR_LIT>\" <EOL> ", "gt": "output_root2 = f\"<STR_LIT>\""}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ", "gt": ") ,"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> ", "gt": "phone = row [ <NUM_LIT> ]"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> try : <EOL> file_path = Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" <EOL> with open ( file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> return json . load ( file ) <EOL> except FileNotFoundError : <EOL> raise FileNotFoundError ( <EOL> ", "gt": "f\"<STR_LIT>\""}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> ", "gt": "assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ("}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) <EOL> path = path . view ( b , t_x , t_y ) <EOL> path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] <EOL> path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask <EOL> return path <EOL> def clip_grad_value_ ( parameters , clip_value , norm_type = <NUM_LIT> ) : <EOL> if isinstance ( parameters , torch . Tensor ) : <EOL> ", "gt": "parameters = [ parameters ]"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> ", "gt": "last_value = data [ i ]"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> ", "gt": "dtype = spec . dtype , device = spec . device"}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> return tag_name <EOL> except requests . exceptions . RequestException as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> ", "gt": "def compare_version ( ) :"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> if not gpu_available ( ) : <EOL> fake_gpu_tab ( ) <EOL> theme_tab ( ) <EOL> version_tab ( ) <EOL> lang_tab ( ) <EOL> restart_tab ( ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> port = <NUM_LIT> <EOL> ", "gt": "if \"<STR_LIT>\" in sys . argv :"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ", "gt": ")"}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> pass <EOL> python = sys . executable <EOL> ", "gt": "os . execl ( python , python , * sys . argv )"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> ", "gt": "if fmax_dtype_device not in mel_basis :"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) <EOL> c = - input_delta * ( inputs - input_cumheights ) <EOL> discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c <EOL> assert ( discriminant >= <NUM_LIT> ) . all ( ) <EOL> root = ( <NUM_LIT> * c ) / ( - b - torch . sqrt ( discriminant ) ) <EOL> outputs = root * input_bin_widths + input_cumwidths <EOL> theta_one_minus_theta = root * ( <NUM_LIT> - root ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> * theta_one_minus_theta <EOL> ) <EOL> derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( <EOL> input_derivatives_plus_one * root . pow ( <NUM_LIT> ) <EOL> ", "gt": "+ <NUM_LIT> * input_delta * theta_one_minus_theta"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ", "gt": ") ,"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> ", "gt": "phone_padded ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> ", "gt": "f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate )"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> ", "gt": "if selected_file is not None and class_name :"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> ", "gt": "label = i18n ( \"<STR_LIT>\" ) ,"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False <EOL> ) <EOL> model_fusion_button . click ( <EOL> fn = run_model_blender_script , <EOL> inputs = [ <EOL> model_fusion_name , <EOL> model_fusion_a , <EOL> model_fusion_b , <EOL> alpha_a , <EOL> ] , <EOL> outputs = [ model_fusion_output_info , model_fusion_pth_output ] , <EOL> ) <EOL> model_fusion_a_dropbox . upload ( <EOL> fn = update_model_fusion , <EOL> inputs = model_fusion_a_dropbox , <EOL> outputs = [ model_fusion_a , model_fusion_a_dropbox ] , <EOL> ) <EOL> model_fusion_b_dropbox . upload ( <EOL> ", "gt": "fn = update_model_fusion ,"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if pretraineds_v2 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v2_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> ", "gt": "os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True )"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ", "gt": "value = \"<STR_LIT>\" ,"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> ", "gt": "def update_presence ( self ) :"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> visible = True , <EOL> ) <EOL> ", "gt": "themes_select . change ("}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> if not gpu_available ( ) : <EOL> fake_gpu_tab ( ) <EOL> theme_tab ( ) <EOL> version_tab ( ) <EOL> lang_tab ( ) <EOL> restart_tab ( ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> port = <NUM_LIT> <EOL> if \"<STR_LIT>\" in sys . argv : <EOL> port_index = sys . argv . index ( \"<STR_LIT>\" ) + <NUM_LIT> <EOL> ", "gt": "if port_index < len ( sys . argv ) :"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ", "gt": ")"}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> ", "gt": "return tag_name"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> ", "gt": "def get_labels ( self , phone ) :"}
{"input": "import os <EOL> import torch <EOL> def change_info ( path , info , name ) : <EOL> try : <EOL> ckpt = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> ckpt [ \"<STR_LIT>\" ] = info <EOL> if name == \"<STR_LIT>\" : <EOL> name = os . path . basename ( path ) <EOL> torch . save ( ckpt , f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" <EOL> except Exception as error : <EOL> ", "gt": "print ( error )"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> ", "gt": "def get_dio ( self , x ) :"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> ", "gt": "hps . model . resblock ,"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> ", "gt": "spec = spec [ : , : len_min ]"}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) <EOL> ", "gt": "else :"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> ", "gt": "for _ in range ( <NUM_LIT> ) :"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> self . enc = WN ( <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = p_dropout , <EOL> gin_channels = gin_channels , <EOL> ) <EOL> self . post = nn . Conv1d ( hidden_channels , self . half_channels * ( <NUM_LIT> - mean_only ) , <NUM_LIT> ) <EOL> self . post . weight . data . zero_ ( ) <EOL> self . post . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask , g = None , reverse = False ) : <EOL> x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> h = self . pre ( x0 ) * x_mask <EOL> h = self . enc ( h , x_mask , g = g ) <EOL> stats = self . post ( h ) * x_mask <EOL> if not self . mean_only : <EOL> m , logs = torch . split ( stats , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> else : <EOL> m = stats <EOL> logs = torch . zeros_like ( m ) <EOL> if not reverse : <EOL> x1 = m + x1 * torch . exp ( logs ) * x_mask <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) <EOL> logdet = torch . sum ( logs , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return x , logdet <EOL> else : <EOL> x1 = ( x1 - m ) * torch . exp ( - logs ) * x_mask <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> self . enc . remove_weight_norm ( ) <EOL> class ConvFlow ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> num_bins = <NUM_LIT> , <EOL> ", "gt": "tail_bound = <NUM_LIT> ,"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> ", "gt": "f0nsf_dir = f\"<STR_LIT>\""}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> ", "gt": "options . append ("}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) <EOL> plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> plot_title ( \"<STR_LIT>\" + \"<STR_LIT>\" + audio_file . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> plot_spectrogram ( y , sr , stft , duration ) <EOL> ", "gt": "plot_waveform ( y , sr , duration )"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( \"<STR_LIT>\" ) <EOL> print ( e ) <EOL> def load_config_flask ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> ", "gt": "with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file :"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "import sys <EOL> import asyncio <EOL> import edge_tts <EOL> async def main ( ) : <EOL> text = sys . argv [ <NUM_LIT> ] <EOL> voice = sys . argv [ <NUM_LIT> ] <EOL> output_file = sys . argv [ <NUM_LIT> ] <EOL> ", "gt": "await edge_tts . Communicate ( text , voice ) . save ( output_file )"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ", "gt": "ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) )"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> ", "gt": "self . process_audio ( path , idx0 )"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) ) <EOL> ", "gt": "torch . save ("}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> ", "gt": "url = f\"<STR_LIT>\""}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) <EOL> path = path . view ( b , t_x , t_y ) <EOL> path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] <EOL> path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask <EOL> return path <EOL> def clip_grad_value_ ( parameters , clip_value , norm_type = <NUM_LIT> ) : <EOL> if isinstance ( parameters , torch . Tensor ) : <EOL> parameters = [ parameters ] <EOL> parameters = list ( filter ( lambda p : p . grad is not None , parameters ) ) <EOL> norm_type = float ( norm_type ) <EOL> if clip_value is not None : <EOL> clip_value = float ( clip_value ) <EOL> total_norm = <NUM_LIT> <EOL> for p in parameters : <EOL> param_norm = p . grad . data . norm ( norm_type ) <EOL> total_norm += param_norm . item ( ) ** norm_type <EOL> if clip_value is not None : <EOL> p . grad . data . clamp_ ( min = - clip_value , max = clip_value ) <EOL> ", "gt": "total_norm = total_norm ** ( <NUM_LIT> / norm_type )"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> ", "gt": "normalized = False ,"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> ", "gt": "mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ("}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> ", "gt": "return class_name"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ", "gt": ")"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> audio_segments . append ( audio ) <EOL> last_end_time = start_time + len ( audio ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> merged_audio = sum ( audio_segments ) <EOL> merged_audio_np = np . array ( merged_audio . get_array_of_samples ( ) ) <EOL> return merged_audio . frame_rate , merged_audio_np <EOL> except Exception as e : <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False <EOL> ) <EOL> model_fusion_button . click ( <EOL> fn = run_model_blender_script , <EOL> ", "gt": "inputs = ["}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> ", "gt": "xt = c1 ( xt )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ", "gt": "i18n ("}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . activation = activation <EOL> self . causal = causal <EOL> if causal : <EOL> self . padding = self . _causal_padding <EOL> else : <EOL> self . padding = self . _same_padding <EOL> self . conv_1 = nn . Conv1d ( in_channels , filter_channels , kernel_size ) <EOL> self . conv_2 = nn . Conv1d ( filter_channels , out_channels , kernel_size ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> def forward ( self , x , x_mask ) : <EOL> x = self . conv_1 ( self . padding ( x * x_mask ) ) <EOL> if self . activation == \"<STR_LIT>\" : <EOL> x = x * torch . sigmoid ( <NUM_LIT> * x ) <EOL> else : <EOL> x = torch . relu ( x ) <EOL> x = self . drop ( x ) <EOL> x = self . conv_2 ( self . padding ( x * x_mask ) ) <EOL> return x * x_mask <EOL> def _causal_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> pad_l = self . kernel_size - <NUM_LIT> <EOL> pad_r = <NUM_LIT> <EOL> padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] <EOL> x = F . pad ( x , commons . convert_pad_shape ( padding ) ) <EOL> return x <EOL> def _same_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> pad_l = ( self . kernel_size - <NUM_LIT> ) // <NUM_LIT> <EOL> pad_r = self . kernel_size // <NUM_LIT> <EOL> padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] <EOL> x = F . pad ( x , commons . convert_pad_shape ( padding ) ) <EOL> ", "gt": "return x"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> audio_input_path , <EOL> audio_output_path , <EOL> model_path , <EOL> index_path , <EOL> split_audio , <EOL> f0autotune , <EOL> clean_audio , <EOL> clean_strength , <EOL> export_format , <EOL> ) : <EOL> global tgt_sr , net_g , vc , cpt <EOL> get_vc ( model_path , <NUM_LIT> ) <EOL> try : <EOL> start_time = time . time ( ) <EOL> vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = audio_input_path , <EOL> f0_up_key = f0up_key , <EOL> f0_file = None , <EOL> f0_method = f0method , <EOL> file_index = index_path , <EOL> index_rate = index_rate , <EOL> rms_mix_rate = rms_mix_rate , <EOL> protect = protect , <EOL> hop_length = hop_length , <EOL> output_path = audio_output_path , <EOL> split_audio = split_audio , <EOL> ", "gt": "f0autotune = f0autotune ,"}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> ", "gt": "return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> )"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> ", "gt": "with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file :"}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> model_information_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> model_information_button . click ( <EOL> run_model_information_script , <EOL> [ model_name ] , <EOL> ", "gt": "model_information_output_info ,"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> ", "gt": "\"<STR_LIT>\" : ("}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> model_information_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> model_information_button . click ( <EOL> ", "gt": "run_model_information_script ,"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> ", "gt": "os . path . dirname ( new_dir_path ) ,"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> ", "gt": "set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] )"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> opt_path2 + \"<STR_LIT>\" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> np . save ( <EOL> opt_path2 , <EOL> feature_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> coarse_pit = self . coarse_f0 ( feature_pit ) <EOL> np . save ( <EOL> opt_path1 , <EOL> coarse_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> pbar . update ( <NUM_LIT> ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> feature_input = FeatureInput ( ) <EOL> paths = [ ] <EOL> input_root = f\"<STR_LIT>\" <EOL> output_root1 = f\"<STR_LIT>\" <EOL> output_root2 = f\"<STR_LIT>\" <EOL> os . makedirs ( output_root1 , exist_ok = True ) <EOL> os . makedirs ( output_root2 , exist_ok = True ) <EOL> for name in sorted ( list ( os . listdir ( input_root ) ) ) : <EOL> input_path = f\"<STR_LIT>\" <EOL> if \"<STR_LIT>\" in input_path : <EOL> continue <EOL> output_path1 = f\"<STR_LIT>\" <EOL> output_path2 = f\"<STR_LIT>\" <EOL> paths . append ( [ input_path , output_path1 , output_path2 ] ) <EOL> processes = [ ] <EOL> print ( \"<STR_LIT>\" + f0_method ) <EOL> for i in range ( num_processes ) : <EOL> p = Process ( <EOL> ", "gt": "target = feature_input . process_paths ,"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . activation = activation <EOL> self . causal = causal <EOL> if causal : <EOL> self . padding = self . _causal_padding <EOL> else : <EOL> self . padding = self . _same_padding <EOL> self . conv_1 = nn . Conv1d ( in_channels , filter_channels , kernel_size ) <EOL> self . conv_2 = nn . Conv1d ( filter_channels , out_channels , kernel_size ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> def forward ( self , x , x_mask ) : <EOL> x = self . conv_1 ( self . padding ( x * x_mask ) ) <EOL> if self . activation == \"<STR_LIT>\" : <EOL> x = x * torch . sigmoid ( <NUM_LIT> * x ) <EOL> else : <EOL> x = torch . relu ( x ) <EOL> ", "gt": "x = self . drop ( x )"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "wget . download ( url , out = destination_path )"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> ", "gt": "plt . title ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> ", "gt": "if os . path . exists ( out_file_path ) :"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> ", "gt": "start = int ( self . sr * ( self . per - self . overlap ) * i )"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> ", "gt": "hash_input = f\"<STR_LIT>\""}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) <EOL> ", "gt": "plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) )"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" <EOL> def load_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> module = importlib . import_module ( selected_file [ : - <NUM_LIT> ] ) <EOL> obtained_class = getattr ( module , class_name ) <EOL> instance = obtained_class ( ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return instance <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> ", "gt": "return None"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> hparams . total_epoch = args . total_epoch <EOL> hparams . pretrainG = args . pretrainG <EOL> hparams . pretrainD = args . pretrainD <EOL> hparams . version = args . version <EOL> hparams . gpus = args . gpus <EOL> hparams . train . batch_size = args . batch_size <EOL> hparams . sample_rate = args . sample_rate <EOL> hparams . if_f0 = args . if_f0 <EOL> hparams . if_latest = args . if_latest <EOL> hparams . save_every_weights = args . save_every_weights <EOL> hparams . if_cache_data_in_gpu = args . if_cache_data_in_gpu <EOL> hparams . data . training_files = f\"<STR_LIT>\" <EOL> hparams . overtraining_detector = args . overtraining_detector <EOL> hparams . overtraining_threshold = args . overtraining_threshold <EOL> return hparams <EOL> class HParams : <EOL> def __init__ ( self , ** kwargs ) : <EOL> for k , v in kwargs . items ( ) : <EOL> if type ( v ) == dict : <EOL> v = HParams ( ** v ) <EOL> self [ k ] = v <EOL> def keys ( self ) : <EOL> return self . __dict__ . keys ( ) <EOL> def items ( self ) : <EOL> return self . __dict__ . items ( ) <EOL> def values ( self ) : <EOL> return self . __dict__ . values ( ) <EOL> def __len__ ( self ) : <EOL> return len ( self . __dict__ ) <EOL> def __getitem__ ( self , key ) : <EOL> return getattr ( self , key ) <EOL> def __setitem__ ( self , key , value ) : <EOL> ", "gt": "return setattr ( self , key , value )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> ", "gt": "with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) :"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> ", "gt": "parser . add_argument ("}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> indices = [ ] <EOL> if self . shuffle : <EOL> for bucket in self . buckets : <EOL> indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) <EOL> else : <EOL> for bucket in self . buckets : <EOL> indices . append ( list ( range ( len ( bucket ) ) ) ) <EOL> batches = [ ] <EOL> ", "gt": "for i in range ( len ( self . buckets ) ) :"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> hparams . total_epoch = args . total_epoch <EOL> ", "gt": "hparams . pretrainG = args . pretrainG"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> self . rpc . update ( <EOL> state = \"<STR_LIT>\" , <EOL> details = \"<STR_LIT>\" , <EOL> buttons = [ <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> ] , <EOL> large_image = \"<STR_LIT>\" , <EOL> large_text = \"<STR_LIT>\" , <EOL> ", "gt": "start = dt . datetime . now ( ) . timestamp ( ) ,"}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ", "gt": ")"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> ", "gt": "if not hasattr ( self , \"<STR_LIT>\" ) :"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> ", "gt": "x = load_audio ( path , self . fs )"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) ) <EOL> torch . save ( <EOL> replace_keys_in_dict ( <EOL> replace_keys_in_dict ( <EOL> model , \"<STR_LIT>\" , \"<STR_LIT>\" <EOL> ) , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ", "gt": ") ,"}
{"input": "import sys <EOL> import asyncio <EOL> import edge_tts <EOL> async def main ( ) : <EOL> text = sys . argv [ <NUM_LIT> ] <EOL> voice = sys . argv [ <NUM_LIT> ] <EOL> ", "gt": "output_file = sys . argv [ <NUM_LIT> ]"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ) . half ( ) <EOL> opt [ \"<STR_LIT>\" ] = cfg <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> opt [ \"<STR_LIT>\" ] = cfg_f0 <EOL> opt [ \"<STR_LIT>\" ] = cfg_version <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] = message"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "def read_json ( ) :"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> ", "gt": "self . device = self . instead = \"<STR_LIT>\""}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . activation = activation <EOL> self . causal = causal <EOL> if causal : <EOL> self . padding = self . _causal_padding <EOL> else : <EOL> self . padding = self . _same_padding <EOL> self . conv_1 = nn . Conv1d ( in_channels , filter_channels , kernel_size ) <EOL> self . conv_2 = nn . Conv1d ( filter_channels , out_channels , kernel_size ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> def forward ( self , x , x_mask ) : <EOL> x = self . conv_1 ( self . padding ( x * x_mask ) ) <EOL> if self . activation == \"<STR_LIT>\" : <EOL> x = x * torch . sigmoid ( <NUM_LIT> * x ) <EOL> else : <EOL> x = torch . relu ( x ) <EOL> x = self . drop ( x ) <EOL> x = self . conv_2 ( self . padding ( x * x_mask ) ) <EOL> return x * x_mask <EOL> def _causal_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> pad_l = self . kernel_size - <NUM_LIT> <EOL> pad_r = <NUM_LIT> <EOL> padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] <EOL> x = F . pad ( x , commons . convert_pad_shape ( padding ) ) <EOL> return x <EOL> def _same_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> ", "gt": "pad_l = ( self . kernel_size - <NUM_LIT> ) // <NUM_LIT>"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ) . half ( ) <EOL> opt [ \"<STR_LIT>\" ] = cfg <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> opt [ \"<STR_LIT>\" ] = cfg_f0 <EOL> opt [ \"<STR_LIT>\" ] = cfg_version <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> torch . save ( opt , os . path . join ( \"<STR_LIT>\" , \"<STR_LIT>\" % name ) ) <EOL> ", "gt": "print ( message )"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> ) <EOL> model_view_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> model_view_button . click ( <EOL> run_model_information_script , <EOL> [ model_view_model_path ] , <EOL> ", "gt": "model_view_output_info ,"}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ", "gt": ")"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> ", "gt": "x_query = <NUM_LIT>"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ", "gt": ")"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> ", "gt": "for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) :"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> ", "gt": "subprocess . Popen ("}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) <EOL> path = path . view ( b , t_x , t_y ) <EOL> path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] <EOL> path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask <EOL> return path <EOL> def clip_grad_value_ ( parameters , clip_value , norm_type = <NUM_LIT> ) : <EOL> if isinstance ( parameters , torch . Tensor ) : <EOL> parameters = [ parameters ] <EOL> parameters = list ( filter ( lambda p : p . grad is not None , parameters ) ) <EOL> norm_type = float ( norm_type ) <EOL> if clip_value is not None : <EOL> clip_value = float ( clip_value ) <EOL> total_norm = <NUM_LIT> <EOL> for p in parameters : <EOL> ", "gt": "param_norm = p . grad . data . norm ( norm_type )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> ", "gt": "return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ("}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> ", "gt": "<NUM_LIT> ,"}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> pitch_guidance = \"<STR_LIT>\" if f0 == <NUM_LIT> else \"<STR_LIT>\" <EOL> return ( <EOL> f\"<STR_LIT>\" <EOL> ", "gt": "f\"<STR_LIT>\""}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> opt_path2 + \"<STR_LIT>\" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> ", "gt": "np . save ("}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> ", "gt": "def download_files ( file_list ) :"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_presence ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> ", "gt": "outputs = [ ] ,"}
{"input": "import gradio as gr <EOL> import tabs . extra . processing . processing as processing <EOL> import tabs . extra . analyzer . analyzer as analyzer <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def extra_tab ( ) : <EOL> gr . Markdown ( <EOL> value = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> ", "gt": "with gr . TabItem ( i18n ( \"<STR_LIT>\" ) ) :"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> ", "gt": "\"<STR_LIT>\" : \"<STR_LIT>\" ,"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> ) <EOL> model_view_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> model_view_button . click ( <EOL> run_model_information_script , <EOL> [ model_view_model_path ] , <EOL> model_view_output_info , <EOL> api_name = \"<STR_LIT>\" , <EOL> ", "gt": ")"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> ", "gt": "hps . data . sampling_rate ,"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> if not gpu_available ( ) : <EOL> fake_gpu_tab ( ) <EOL> theme_tab ( ) <EOL> version_tab ( ) <EOL> ", "gt": "lang_tab ( )"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> ", "gt": "plt . title ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> ", "gt": "return gr . Button ( value = \"<STR_LIT>\" ) , None"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> ", "gt": "return x_pad , x_query , x_center , x_max"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> ", "gt": "return \"<STR_LIT>\""}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> ", "gt": "model_information_button = gr . Button ( i18n ( \"<STR_LIT>\" ) )"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( \"<STR_LIT>\" ) <EOL> print ( e ) <EOL> def load_config_flask ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> ", "gt": "config [ \"<STR_LIT>\" ] = value"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ", "gt": "value = \"<STR_LIT>\" ,"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> self . enc = WN ( <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = p_dropout , <EOL> gin_channels = gin_channels , <EOL> ) <EOL> self . post = nn . Conv1d ( hidden_channels , self . half_channels * ( <NUM_LIT> - mean_only ) , <NUM_LIT> ) <EOL> self . post . weight . data . zero_ ( ) <EOL> ", "gt": "self . post . bias . data . zero_ ( )"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> ", "gt": "if file . endswith ( \"<STR_LIT>\" ) :"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> ", "gt": "model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( )"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ", "gt": ")"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> ", "gt": "def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) :"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> ", "gt": "wave_padded . zero_ ( )"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> try : <EOL> file_path = Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" <EOL> with open ( file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> return json . load ( file ) <EOL> except FileNotFoundError : <EOL> raise FileNotFoundError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> def _get_available_languages ( self ) : <EOL> language_files = [ path . stem for path in Path ( self . LANGUAGE_PATH ) . glob ( \"<STR_LIT>\" ) ] <EOL> return language_files <EOL> def _language_exists ( self , language ) : <EOL> ", "gt": "return ( Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" ) . exists ( )"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> ", "gt": "\"<STR_LIT>\" : ("}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> ", "gt": "alpha_a = gr . Slider ("}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> ", "gt": "def process_audio ( self , path , idx0 ) :"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> ", "gt": "placeholder = i18n ( \"<STR_LIT>\" ) ,"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> ", "gt": "self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\""}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> ", "gt": "def resize_f0 ( self , x , target_len ) :"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> opt_path2 + \"<STR_LIT>\" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> np . save ( <EOL> opt_path2 , <EOL> feature_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> coarse_pit = self . coarse_f0 ( feature_pit ) <EOL> np . save ( <EOL> opt_path1 , <EOL> coarse_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> pbar . update ( <NUM_LIT> ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> feature_input = FeatureInput ( ) <EOL> paths = [ ] <EOL> input_root = f\"<STR_LIT>\" <EOL> output_root1 = f\"<STR_LIT>\" <EOL> output_root2 = f\"<STR_LIT>\" <EOL> os . makedirs ( output_root1 , exist_ok = True ) <EOL> os . makedirs ( output_root2 , exist_ok = True ) <EOL> for name in sorted ( list ( os . listdir ( input_root ) ) ) : <EOL> input_path = f\"<STR_LIT>\" <EOL> if \"<STR_LIT>\" in input_path : <EOL> continue <EOL> output_path1 = f\"<STR_LIT>\" <EOL> output_path2 = f\"<STR_LIT>\" <EOL> ", "gt": "paths . append ( [ input_path , output_path1 , output_path2 ] )"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> ", "gt": "value = \"<STR_LIT>\" ,"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> ", "gt": "else :"}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ", "gt": "max_lines = <NUM_LIT> ,"}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ", "gt": ") ,"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def fake_gpu_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_fake_gpu ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> ", "gt": "restart_applio ( )"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> pitch_guidance = \"<STR_LIT>\" if f0 == <NUM_LIT> else \"<STR_LIT>\" <EOL> return ( <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> ", "gt": "f\"<STR_LIT>\""}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> ", "gt": "subprocess . Popen ("}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> ", "gt": "model . eval ( )"}
{"input": "import gradio as gr <EOL> import tabs . extra . processing . processing as processing <EOL> import tabs . extra . analyzer . analyzer as analyzer <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def extra_tab ( ) : <EOL> gr . Markdown ( <EOL> value = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . TabItem ( i18n ( \"<STR_LIT>\" ) ) : <EOL> ", "gt": "processing . processing ( )"}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return \"<STR_LIT>\" , <NUM_LIT> <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> ", "gt": "def shutdown ( ) :"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_presence ( ) , <EOL> ) <EOL> ", "gt": "presence . change ("}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = False , <EOL> ) <EOL> version_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> version_button . click ( <EOL> fn = compare_version , <EOL> inputs = [ ] , <EOL> outputs = [ version_check ] , <EOL> ", "gt": ")"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> ", "gt": "self . in_channels = in_channels"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> ", "gt": "help = \"<STR_LIT>\" ,"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_presence ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> if load_config_presence ( ) == True : <EOL> try : <EOL> ", "gt": "RPCManager . start_presence ( )"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> ", "gt": "x_query = <NUM_LIT>"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> \"<STR_LIT>\" : feats . to ( device ) , <EOL> \"<STR_LIT>\" : padding_mask . to ( device ) , <EOL> \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , <EOL> } <EOL> with torch . no_grad ( ) : <EOL> logits = model . extract_features ( ** inputs ) <EOL> feats = ( <EOL> model . final_proj ( logits [ <NUM_LIT> ] ) <EOL> if version == \"<STR_LIT>\" <EOL> else logits [ <NUM_LIT> ] <EOL> ", "gt": ")"}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> raise RuntimeError ( f\"<STR_LIT>\" ) <EOL> return np . frombuffer ( out , np . float32 ) . flatten ( ) <EOL> def format_title ( title ) : <EOL> formatted_title = ( <EOL> unicodedata . normalize ( \"<STR_LIT>\" , title ) . encode ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . decode ( \"<STR_LIT>\" ) <EOL> ) <EOL> formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title ) <EOL> formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title ) <EOL> ", "gt": "formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title )"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> ", "gt": "continue"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> ", "gt": "np . arange ( <NUM_LIT> , len ( source ) ) ,"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ", "gt": ") . half ( )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ", "gt": "]"}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ", "gt": "model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" )"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> ", "gt": "if class_found :"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> ", "gt": "return"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> ", "gt": "widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> ", "gt": "with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) :"}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = False , <EOL> ) <EOL> version_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> version_button . click ( <EOL> ", "gt": "fn = compare_version ,"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> ", "gt": "return spec"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) ) <EOL> torch . save ( <EOL> ", "gt": "replace_keys_in_dict ("}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> ", "gt": "signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] )"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> ", "gt": "win_length = win_size ,"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> indices = [ ] <EOL> if self . shuffle : <EOL> for bucket in self . buckets : <EOL> indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) <EOL> else : <EOL> for bucket in self . buckets : <EOL> indices . append ( list ( range ( len ( bucket ) ) ) ) <EOL> batches = [ ] <EOL> for i in range ( len ( self . buckets ) ) : <EOL> bucket = self . buckets [ i ] <EOL> ", "gt": "len_bucket = len ( bucket )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Video ( <EOL> value = temp_filename , interactive = False <EOL> ) <EOL> start_button . click ( <EOL> toggle_button_label , <EOL> start_button , <EOL> [ start_button , video_component ] , <EOL> js = record_button_js , <EOL> ", "gt": ")"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> audio_segments . append ( audio ) <EOL> last_end_time = start_time + len ( audio ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "merged_audio = sum ( audio_segments )"}
{"input": "import os <EOL> import torch <EOL> def change_info ( path , info , name ) : <EOL> try : <EOL> ckpt = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> ckpt [ \"<STR_LIT>\" ] = info <EOL> if name == \"<STR_LIT>\" : <EOL> name = os . path . basename ( path ) <EOL> ", "gt": "torch . save ( ckpt , f\"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> \"<STR_LIT>\" : feats . to ( device ) , <EOL> \"<STR_LIT>\" : padding_mask . to ( device ) , <EOL> \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , <EOL> } <EOL> with torch . no_grad ( ) : <EOL> logits = model . extract_features ( ** inputs ) <EOL> feats = ( <EOL> model . final_proj ( logits [ <NUM_LIT> ] ) <EOL> if version == \"<STR_LIT>\" <EOL> else logits [ <NUM_LIT> ] <EOL> ) <EOL> feats = feats . squeeze ( <NUM_LIT> ) . float ( ) . cpu ( ) . numpy ( ) <EOL> if np . isnan ( feats ) . sum ( ) == <NUM_LIT> : <EOL> np . save ( out_file_path , feats , allow_pickle = False ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pbar . set_description ( f\"<STR_LIT>\" ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> pbar . update ( <NUM_LIT> ) <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> ", "gt": "info = i18n ("}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> ", "gt": "s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] )"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> ", "gt": "buckets . pop ( i )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> ", "gt": "scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> if not gpu_available ( ) : <EOL> fake_gpu_tab ( ) <EOL> theme_tab ( ) <EOL> version_tab ( ) <EOL> lang_tab ( ) <EOL> restart_tab ( ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> port = <NUM_LIT> <EOL> if \"<STR_LIT>\" in sys . argv : <EOL> port_index = sys . argv . index ( \"<STR_LIT>\" ) + <NUM_LIT> <EOL> if port_index < len ( sys . argv ) : <EOL> port = int ( sys . argv [ port_index ] ) <EOL> Applio . launch ( <EOL> ", "gt": "favicon_path = \"<STR_LIT>\" ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> ", "gt": "wav . astype ( np . double ) ,"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> ", "gt": "try :"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> ", "gt": "parser . add_argument ("}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> ", "gt": "plt . legend ( )"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> audio_segments . append ( audio ) <EOL> last_end_time = start_time + len ( audio ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> merged_audio = sum ( audio_segments ) <EOL> merged_audio_np = np . array ( merged_audio . get_array_of_samples ( ) ) <EOL> return merged_audio . frame_rate , merged_audio_np <EOL> ", "gt": "except Exception as e :"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> ", "gt": "with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f :"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> ", "gt": "f0up_key ,"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) <EOL> gen_losses . append ( l ) <EOL> loss += l <EOL> return loss , gen_losses <EOL> def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : <EOL> z_p = z_p . float ( ) <EOL> logs_q = logs_q . float ( ) <EOL> m_p = m_p . float ( ) <EOL> logs_p = logs_p . float ( ) <EOL> z_mask = z_mask . float ( ) <EOL> ", "gt": "kl = logs_p - logs_q - <NUM_LIT>"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> fn = toggle , <EOL> inputs = [ flask_checkbox ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> if load_config_flask ( ) == True : <EOL> start_flask ( ) <EOL> else : <EOL> try : <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> ", "gt": "except requests . exceptions . ConnectionError :"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> ", "gt": "def plot_features ( times , cent , bw , rolloff , duration ) :"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> elif \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> try : <EOL> now_dir . encode ( \"<STR_LIT>\" ) <EOL> except UnicodeEncodeError : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ", "gt": ")"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> opt_path2 + \"<STR_LIT>\" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> np . save ( <EOL> opt_path2 , <EOL> feature_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> coarse_pit = self . coarse_f0 ( feature_pit ) <EOL> np . save ( <EOL> opt_path1 , <EOL> coarse_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> pbar . update ( <NUM_LIT> ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> feature_input = FeatureInput ( ) <EOL> paths = [ ] <EOL> input_root = f\"<STR_LIT>\" <EOL> output_root1 = f\"<STR_LIT>\" <EOL> output_root2 = f\"<STR_LIT>\" <EOL> os . makedirs ( output_root1 , exist_ok = True ) <EOL> os . makedirs ( output_root2 , exist_ok = True ) <EOL> for name in sorted ( list ( os . listdir ( input_root ) ) ) : <EOL> ", "gt": "input_path = f\"<STR_LIT>\""}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> return tag_name <EOL> except requests . exceptions . RequestException as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def compare_version ( ) : <EOL> local_version = load_local_version ( ) <EOL> ", "gt": "online_version = obtain_tag_name ( )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> ", "gt": "logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] )"}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> return tag_name <EOL> except requests . exceptions . RequestException as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def compare_version ( ) : <EOL> local_version = load_local_version ( ) <EOL> online_version = obtain_tag_name ( ) <EOL> elements_online_version = list ( map ( int , online_version . split ( \"<STR_LIT>\" ) ) ) <EOL> elements_local_version = list ( map ( int , local_version . split ( \"<STR_LIT>\" ) ) ) <EOL> ", "gt": "for online , local in zip ( elements_online_version , elements_local_version ) :"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ", "gt": ")"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> ", "gt": "frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate ,"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> ", "gt": "try :"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> try : <EOL> file_path = Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" <EOL> with open ( file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> return json . load ( file ) <EOL> except FileNotFoundError : <EOL> raise FileNotFoundError ( <EOL> f\"<STR_LIT>\" <EOL> ", "gt": ")"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False <EOL> ) <EOL> model_fusion_button . click ( <EOL> fn = run_model_blender_script , <EOL> inputs = [ <EOL> ", "gt": "model_fusion_name ,"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> try : <EOL> infos = [ <EOL> ( f\"<STR_LIT>\" , idx ) <EOL> for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) <EOL> ] <EOL> processes = [ ] <EOL> for i in range ( num_processes ) : <EOL> p = multiprocessing . Process ( <EOL> target = self . process_audio_multiprocessing , <EOL> args = ( infos [ i : : num_processes ] , ) , <EOL> ) <EOL> processes . append ( p ) <EOL> p . start ( ) <EOL> for i in range ( num_processes ) : <EOL> ", "gt": "processes [ i ] . join ( )"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> elif \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> try : <EOL> now_dir . encode ( \"<STR_LIT>\" ) <EOL> ", "gt": "except UnicodeEncodeError :"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ", "gt": ")"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> try : <EOL> file_path = Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" <EOL> with open ( file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> return json . load ( file ) <EOL> except FileNotFoundError : <EOL> raise FileNotFoundError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> def _get_available_languages ( self ) : <EOL> language_files = [ path . stem for path in Path ( self . LANGUAGE_PATH ) . glob ( \"<STR_LIT>\" ) ] <EOL> return language_files <EOL> ", "gt": "def _language_exists ( self , language ) :"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) <EOL> plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> plot_title ( \"<STR_LIT>\" + \"<STR_LIT>\" + audio_file . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> ", "gt": "plot_spectrogram ( y , sr , stft , duration )"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> ", "gt": "silence_duration = max ( start_time - last_end_time , <NUM_LIT> )"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ) . half ( ) <EOL> opt [ \"<STR_LIT>\" ] = cfg <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] = message"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> ", "gt": "f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate )"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> ", "gt": "plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> )"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> ", "gt": "self . language_map = self . _load_language_list ( )"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def fake_gpu_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_fake_gpu ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> ", "gt": "inputs = [ presence ] ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ", "gt": ")"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> indices = [ ] <EOL> if self . shuffle : <EOL> for bucket in self . buckets : <EOL> indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) <EOL> else : <EOL> for bucket in self . buckets : <EOL> indices . append ( list ( range ( len ( bucket ) ) ) ) <EOL> batches = [ ] <EOL> for i in range ( len ( self . buckets ) ) : <EOL> bucket = self . buckets [ i ] <EOL> len_bucket = len ( bucket ) <EOL> ids_bucket = indices [ i ] <EOL> num_samples_bucket = self . num_samples_per_bucket [ i ] <EOL> rem = num_samples_bucket - len_bucket <EOL> ids_bucket = ( <EOL> ids_bucket <EOL> + ids_bucket * ( rem // len_bucket ) <EOL> + ids_bucket [ : ( rem % len_bucket ) ] <EOL> ) <EOL> ids_bucket = ids_bucket [ self . rank : : self . num_replicas ] <EOL> for j in range ( len ( ids_bucket ) // self . batch_size ) : <EOL> batch = [ <EOL> bucket [ idx ] <EOL> for idx in ids_bucket [ <EOL> j * self . batch_size : ( j + <NUM_LIT> ) * self . batch_size <EOL> ] <EOL> ] <EOL> batches . append ( batch ) <EOL> if self . shuffle : <EOL> batch_ids = torch . randperm ( len ( batches ) , generator = g ) . tolist ( ) <EOL> batches = [ batches [ i ] for i in batch_ids ] <EOL> self . batches = batches <EOL> assert len ( self . batches ) * self . batch_size == self . num_samples <EOL> return iter ( self . batches ) <EOL> def _bisect ( self , x , lo = <NUM_LIT> , hi = None ) : <EOL> if hi is None : <EOL> hi = len ( self . boundaries ) - <NUM_LIT> <EOL> if hi > lo : <EOL> mid = ( hi + lo ) // <NUM_LIT> <EOL> if self . boundaries [ mid ] < x and x <= self . boundaries [ mid + <NUM_LIT> ] : <EOL> return mid <EOL> ", "gt": "elif x <= self . boundaries [ mid ] :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> ", "gt": "if p_len is None :"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> try : <EOL> infos = [ <EOL> ( f\"<STR_LIT>\" , idx ) <EOL> for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) <EOL> ] <EOL> processes = [ ] <EOL> for i in range ( num_processes ) : <EOL> p = multiprocessing . Process ( <EOL> target = self . process_audio_multiprocessing , <EOL> ", "gt": "args = ( infos [ i : : num_processes ] , ) ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> ", "gt": "def resize_f0 ( self , x , target_len ) :"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> ", "gt": "raise InstallationError ("}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> ", "gt": "pass"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> ", "gt": "padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False )"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> audio_input_path , <EOL> audio_output_path , <EOL> model_path , <EOL> index_path , <EOL> split_audio , <EOL> f0autotune , <EOL> clean_audio , <EOL> clean_strength , <EOL> export_format , <EOL> ) : <EOL> global tgt_sr , net_g , vc , cpt <EOL> get_vc ( model_path , <NUM_LIT> ) <EOL> try : <EOL> start_time = time . time ( ) <EOL> vc_single ( <EOL> ", "gt": "sid = <NUM_LIT> ,"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> ", "gt": "self . boundaries . pop ( i + <NUM_LIT> )"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> fn = toggle , <EOL> ", "gt": "inputs = [ flask_checkbox ] ,"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> try : <EOL> ", "gt": "file_path = Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\""}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> ", "gt": "heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ]"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> ", "gt": "for i in range ( len ( ids_sorted_decreasing ) ) :"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> with gr . Column ( ) : <EOL> selected_language = gr . Dropdown ( <EOL> ", "gt": "label = i18n ( \"<STR_LIT>\" ) ,"}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> ", "gt": "os . remove ( pid_file_path )"}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> ", "gt": "if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) :"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> elif \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> try : <EOL> ", "gt": "now_dir . encode ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> shuffle ( options ) <EOL> ", "gt": "with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> ", "gt": "for index , pitch in enumerate ( f0 ) :"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> ", "gt": "if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) :"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) <EOL> plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> ", "gt": "plot_title ( \"<STR_LIT>\" + \"<STR_LIT>\" + audio_file . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] )"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> ", "gt": "torch . save ( opt , model_dir )"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if pretraineds_v2 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v2_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> ", "gt": "for file in file_list :"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> audio_segments . append ( audio ) <EOL> ", "gt": "last_end_time = start_time + len ( audio )"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> \"<STR_LIT>\" : feats . to ( device ) , <EOL> \"<STR_LIT>\" : padding_mask . to ( device ) , <EOL> \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , <EOL> } <EOL> with torch . no_grad ( ) : <EOL> logits = model . extract_features ( ** inputs ) <EOL> feats = ( <EOL> model . final_proj ( logits [ <NUM_LIT> ] ) <EOL> if version == \"<STR_LIT>\" <EOL> else logits [ <NUM_LIT> ] <EOL> ) <EOL> feats = feats . squeeze ( <NUM_LIT> ) . float ( ) . cpu ( ) . numpy ( ) <EOL> if np . isnan ( feats ) . sum ( ) == <NUM_LIT> : <EOL> np . save ( out_file_path , feats , allow_pickle = False ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pbar . set_description ( f\"<STR_LIT>\" ) <EOL> ", "gt": "except Exception as error :"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] = { }"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> ", "gt": "def fake_gpu_tab ( ) :"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def fake_gpu_tab ( ) : <EOL> with gr . Row ( ) : <EOL> ", "gt": "with gr . Column ( ) :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> ", "gt": "for index , pitch in enumerate ( f0 ) :"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) <EOL> gen_losses . append ( l ) <EOL> loss += l <EOL> return loss , gen_losses <EOL> def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : <EOL> z_p = z_p . float ( ) <EOL> logs_q = logs_q . float ( ) <EOL> ", "gt": "m_p = m_p . float ( )"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> ", "gt": "help = \"<STR_LIT>\" ,"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) <EOL> plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> plot_title ( \"<STR_LIT>\" + \"<STR_LIT>\" + audio_file . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> plot_spectrogram ( y , sr , stft , duration ) <EOL> plot_waveform ( y , sr , duration ) <EOL> plot_features ( librosa . times_like ( cent ) , cent , bw , rolloff , duration ) <EOL> plt . tight_layout ( ) <EOL> ", "gt": "if save_plot_path :"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> fn = toggle , <EOL> inputs = [ flask_checkbox ] , <EOL> outputs = [ ] , <EOL> ) <EOL> ", "gt": "def toggle ( checkbox ) :"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> ", "gt": "else :"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ", "gt": "]"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> ", "gt": "f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate )"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> ", "gt": "json . dump ( config , file , indent = <NUM_LIT> )"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ) . half ( ) <EOL> opt [ \"<STR_LIT>\" ] = cfg <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> opt [ \"<STR_LIT>\" ] = cfg_f0 <EOL> opt [ \"<STR_LIT>\" ] = cfg_version <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> ", "gt": "torch . save ( opt , os . path . join ( \"<STR_LIT>\" , \"<STR_LIT>\" % name ) )"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> ", "gt": "min_bin_width = DEFAULT_MIN_BIN_WIDTH ,"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> ", "gt": "names = ("}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> ", "gt": "hps . model . spk_embed_dim ,"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> elif \"<STR_LIT>\" in now_dir : <EOL> ", "gt": "raise InstallationError ("}
{"input": "import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) <EOL> return date_time_obj . strftime ( \"<STR_LIT>\" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> pitch_guidance = \"<STR_LIT>\" if f0 == <NUM_LIT> else \"<STR_LIT>\" <EOL> return ( <EOL> f\"<STR_LIT>\" <EOL> f\"<STR_LIT>\" <EOL> ", "gt": "f\"<STR_LIT>\""}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_presence ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> ", "gt": "save_config ( bool ( checkbox ) )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> ", "gt": "voice_blender_tab ( )"}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = False , <EOL> ", "gt": ")"}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = False , <EOL> ) <EOL> ", "gt": "version_button = gr . Button ( i18n ( \"<STR_LIT>\" ) )"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> ", "gt": "if output_path is not None :"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> ", "gt": "torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> ", "gt": "if len ( audio_segment [ start : ] ) > self . tail * self . sr :"}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> ", "gt": "else :"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> hparams . total_epoch = args . total_epoch <EOL> hparams . pretrainG = args . pretrainG <EOL> hparams . pretrainD = args . pretrainD <EOL> hparams . version = args . version <EOL> hparams . gpus = args . gpus <EOL> hparams . train . batch_size = args . batch_size <EOL> hparams . sample_rate = args . sample_rate <EOL> hparams . if_f0 = args . if_f0 <EOL> hparams . if_latest = args . if_latest <EOL> hparams . save_every_weights = args . save_every_weights <EOL> hparams . if_cache_data_in_gpu = args . if_cache_data_in_gpu <EOL> hparams . data . training_files = f\"<STR_LIT>\" <EOL> hparams . overtraining_detector = args . overtraining_detector <EOL> hparams . overtraining_threshold = args . overtraining_threshold <EOL> return hparams <EOL> class HParams : <EOL> def __init__ ( self , ** kwargs ) : <EOL> for k , v in kwargs . items ( ) : <EOL> if type ( v ) == dict : <EOL> v = HParams ( ** v ) <EOL> self [ k ] = v <EOL> def keys ( self ) : <EOL> return self . __dict__ . keys ( ) <EOL> def items ( self ) : <EOL> return self . __dict__ . items ( ) <EOL> def values ( self ) : <EOL> return self . __dict__ . values ( ) <EOL> def __len__ ( self ) : <EOL> return len ( self . __dict__ ) <EOL> def __getitem__ ( self , key ) : <EOL> return getattr ( self , key ) <EOL> ", "gt": "def __setitem__ ( self , key , value ) :"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> self . rpc . update ( <EOL> state = \"<STR_LIT>\" , <EOL> details = \"<STR_LIT>\" , <EOL> buttons = [ <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> ] , <EOL> large_image = \"<STR_LIT>\" , <EOL> large_text = \"<STR_LIT>\" , <EOL> start = dt . datetime . now ( ) . timestamp ( ) , <EOL> ) <EOL> def stop_presence ( self ) : <EOL> self . running = False <EOL> if self . rpc : <EOL> self . rpc . close ( ) <EOL> self . rpc = None <EOL> ", "gt": "RPCManager = RichPresenceManager ( )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> ", "gt": "report_tab ( )"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> ", "gt": "start : start + int ( self . per * self . sr )"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_presence ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> if load_config_presence ( ) == True : <EOL> ", "gt": "try :"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Video ( <EOL> value = temp_filename , interactive = False <EOL> ) <EOL> start_button . click ( <EOL> toggle_button_label , <EOL> start_button , <EOL> [ start_button , video_component ] , <EOL> ", "gt": "js = record_button_js ,"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "with tqdm . tqdm ( total = len ( todo ) ) as pbar :"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def fake_gpu_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> ", "gt": "presence = gr . Checkbox ("}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> ", "gt": "return \"<STR_LIT>\" , <NUM_LIT>"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> ", "gt": "scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) )"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> ", "gt": "target = np . interp ("}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . activation = activation <EOL> self . causal = causal <EOL> if causal : <EOL> self . padding = self . _causal_padding <EOL> else : <EOL> self . padding = self . _same_padding <EOL> self . conv_1 = nn . Conv1d ( in_channels , filter_channels , kernel_size ) <EOL> self . conv_2 = nn . Conv1d ( filter_channels , out_channels , kernel_size ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> def forward ( self , x , x_mask ) : <EOL> x = self . conv_1 ( self . padding ( x * x_mask ) ) <EOL> if self . activation == \"<STR_LIT>\" : <EOL> x = x * torch . sigmoid ( <NUM_LIT> * x ) <EOL> else : <EOL> x = torch . relu ( x ) <EOL> x = self . drop ( x ) <EOL> x = self . conv_2 ( self . padding ( x * x_mask ) ) <EOL> return x * x_mask <EOL> def _causal_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> pad_l = self . kernel_size - <NUM_LIT> <EOL> pad_r = <NUM_LIT> <EOL> padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] <EOL> x = F . pad ( x , commons . convert_pad_shape ( padding ) ) <EOL> return x <EOL> def _same_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> pad_l = ( self . kernel_size - <NUM_LIT> ) // <NUM_LIT> <EOL> pad_r = self . kernel_size // <NUM_LIT> <EOL> padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] <EOL> ", "gt": "x = F . pad ( x , commons . convert_pad_shape ( padding ) )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . activation = activation <EOL> self . causal = causal <EOL> if causal : <EOL> self . padding = self . _causal_padding <EOL> else : <EOL> self . padding = self . _same_padding <EOL> self . conv_1 = nn . Conv1d ( in_channels , filter_channels , kernel_size ) <EOL> self . conv_2 = nn . Conv1d ( filter_channels , out_channels , kernel_size ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> def forward ( self , x , x_mask ) : <EOL> x = self . conv_1 ( self . padding ( x * x_mask ) ) <EOL> if self . activation == \"<STR_LIT>\" : <EOL> x = x * torch . sigmoid ( <NUM_LIT> * x ) <EOL> else : <EOL> x = torch . relu ( x ) <EOL> x = self . drop ( x ) <EOL> x = self . conv_2 ( self . padding ( x * x_mask ) ) <EOL> return x * x_mask <EOL> def _causal_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> pad_l = self . kernel_size - <NUM_LIT> <EOL> pad_r = <NUM_LIT> <EOL> padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] <EOL> x = F . pad ( x , commons . convert_pad_shape ( padding ) ) <EOL> return x <EOL> def _same_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> ", "gt": "return x"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> ", "gt": "class ResidualCouplingLayer ( nn . Module ) :"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> ", "gt": "return loss , r_losses , g_losses"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> ", "gt": "value = load_config_flask ( ) ,"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> ", "gt": "model = model . half ( )"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> return x_pad , x_query , x_center , x_max <EOL> def max_vram_gpu ( gpu ) : <EOL> if torch . cuda . is_available ( ) : <EOL> gpu_properties = torch . cuda . get_device_properties ( gpu ) <EOL> total_memory_gb = round ( gpu_properties . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> ) <EOL> return total_memory_gb <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> def get_gpu_info ( ) : <EOL> ngpu = torch . cuda . device_count ( ) <EOL> gpu_infos = [ ] <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> ", "gt": "for i in range ( ngpu ) :"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) <EOL> c = - input_delta * ( inputs - input_cumheights ) <EOL> discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c <EOL> assert ( discriminant >= <NUM_LIT> ) . all ( ) <EOL> root = ( <NUM_LIT> * c ) / ( - b - torch . sqrt ( discriminant ) ) <EOL> outputs = root * input_bin_widths + input_cumwidths <EOL> theta_one_minus_theta = root * ( <NUM_LIT> - root ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> * theta_one_minus_theta <EOL> ) <EOL> derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( <EOL> input_derivatives_plus_one * root . pow ( <NUM_LIT> ) <EOL> + <NUM_LIT> * input_delta * theta_one_minus_theta <EOL> + input_derivatives * ( <NUM_LIT> - root ) . pow ( <NUM_LIT> ) <EOL> ) <EOL> ", "gt": "logabsdet = torch . log ( derivative_numerator ) - <NUM_LIT> * torch . log ( denominator )"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> fn = toggle , <EOL> inputs = [ flask_checkbox ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> if load_config_flask ( ) == True : <EOL> ", "gt": "start_flask ( )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ", "gt": ")"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_presence ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> ", "gt": "if load_config_presence ( ) == True :"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> ", "gt": "else :"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> ", "gt": "rms_mix_rate ,"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False <EOL> ) <EOL> model_fusion_button . click ( <EOL> fn = run_model_blender_script , <EOL> inputs = [ <EOL> model_fusion_name , <EOL> model_fusion_a , <EOL> model_fusion_b , <EOL> alpha_a , <EOL> ] , <EOL> outputs = [ model_fusion_output_info , model_fusion_pth_output ] , <EOL> ) <EOL> model_fusion_a_dropbox . upload ( <EOL> fn = update_model_fusion , <EOL> inputs = model_fusion_a_dropbox , <EOL> outputs = [ model_fusion_a , model_fusion_a_dropbox ] , <EOL> ) <EOL> ", "gt": "model_fusion_b_dropbox . upload ("}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> try : <EOL> infos = [ <EOL> ( f\"<STR_LIT>\" , idx ) <EOL> for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) <EOL> ] <EOL> processes = [ ] <EOL> for i in range ( num_processes ) : <EOL> p = multiprocessing . Process ( <EOL> target = self . process_audio_multiprocessing , <EOL> args = ( infos [ i : : num_processes ] , ) , <EOL> ", "gt": ")"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( \"<STR_LIT>\" ) <EOL> print ( e ) <EOL> def load_config_flask ( ) : <EOL> ", "gt": "with open ( config_file , \"<STR_LIT>\" ) as file :"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> ", "gt": "\"<STR_LIT>\" : ("}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return \"<STR_LIT>\" , <NUM_LIT> <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def shutdown ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> os . kill ( os . getpid ( ) , signal . SIGTERM ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> ", "gt": "app . run ( host = \"<STR_LIT>\" , port = <NUM_LIT> )"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> ", "gt": "plt . ylabel ( \"<STR_LIT>\" )"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> ", "gt": "idx1 += <NUM_LIT>"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> ", "gt": "n_channels_int = n_channels [ <NUM_LIT> ]"}
{"input": "import sys <EOL> import asyncio <EOL> import edge_tts <EOL> async def main ( ) : <EOL> text = sys . argv [ <NUM_LIT> ] <EOL> voice = sys . argv [ <NUM_LIT> ] <EOL> output_file = sys . argv [ <NUM_LIT> ] <EOL> await edge_tts . Communicate ( text , voice ) . save ( output_file ) <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> ", "gt": "opt_path2 + \"<STR_LIT>\""}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> ", "gt": "info = i18n ("}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> ", "gt": "x = self . conv_o ( x )"}
{"input": "import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = \"<STR_LIT>\" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( \"<STR_LIT>\" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if \"<STR_LIT>\" in now_dir : <EOL> raise InstallationError ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ", "gt": "elif \"<STR_LIT>\" in now_dir :"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> ", "gt": "options . append ("}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> with gr . Column ( ) : <EOL> selected_language = gr . Dropdown ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> value = get_language_settings ( ) , <EOL> choices = [ \"<STR_LIT>\" ] <EOL> ", "gt": "+ i18n . _get_available_languages ( ) ,"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> ", "gt": "flask_server_tab ( )"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ) . half ( ) <EOL> opt [ \"<STR_LIT>\" ] = cfg <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> opt [ \"<STR_LIT>\" ] = cfg_f0 <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] = cfg_version"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> if not gpu_available ( ) : <EOL> fake_gpu_tab ( ) <EOL> theme_tab ( ) <EOL> version_tab ( ) <EOL> lang_tab ( ) <EOL> restart_tab ( ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> port = <NUM_LIT> <EOL> if \"<STR_LIT>\" in sys . argv : <EOL> port_index = sys . argv . index ( \"<STR_LIT>\" ) + <NUM_LIT> <EOL> if port_index < len ( sys . argv ) : <EOL> port = int ( sys . argv [ port_index ] ) <EOL> Applio . launch ( <EOL> favicon_path = \"<STR_LIT>\" , <EOL> share = \"<STR_LIT>\" in sys . argv , <EOL> ", "gt": "inbrowser = \"<STR_LIT>\" in sys . argv ,"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> ", "gt": "except Exception as e :"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> ", "gt": "def merge_audio ( timestamps_file ) :"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> ", "gt": "if min_bin_width * num_bins > <NUM_LIT> :"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ", "gt": "]"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> try : <EOL> file_path = Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" <EOL> with open ( file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> return json . load ( file ) <EOL> except FileNotFoundError : <EOL> ", "gt": "raise FileNotFoundError ("}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def fake_gpu_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_fake_gpu ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> outputs = [ ] , <EOL> ) <EOL> ", "gt": "def toggle ( checkbox ) :"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> self . enc = WN ( <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = p_dropout , <EOL> gin_channels = gin_channels , <EOL> ", "gt": ")"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" <EOL> def load_json ( ) : <EOL> ", "gt": "try :"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> ", "gt": "maximum = <NUM_LIT> ,"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> ", "gt": "path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype )"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> audio_segments . append ( audio ) <EOL> last_end_time = start_time + len ( audio ) <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> ", "gt": "input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) <EOL> gen_losses . append ( l ) <EOL> loss += l <EOL> return loss , gen_losses <EOL> def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : <EOL> z_p = z_p . float ( ) <EOL> logs_q = logs_q . float ( ) <EOL> m_p = m_p . float ( ) <EOL> logs_p = logs_p . float ( ) <EOL> z_mask = z_mask . float ( ) <EOL> kl = logs_p - logs_q - <NUM_LIT> <EOL> ", "gt": "kl += <NUM_LIT> * ( ( z_p - m_p ) ** <NUM_LIT> ) * torch . exp ( - <NUM_LIT> * logs_p )"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ", "gt": ") ,"}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> raise RuntimeError ( f\"<STR_LIT>\" ) <EOL> return np . frombuffer ( out , np . float32 ) . flatten ( ) <EOL> def format_title ( title ) : <EOL> formatted_title = ( <EOL> unicodedata . normalize ( \"<STR_LIT>\" , title ) . encode ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . decode ( \"<STR_LIT>\" ) <EOL> ) <EOL> ", "gt": "formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title )"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> self . rpc . update ( <EOL> state = \"<STR_LIT>\" , <EOL> details = \"<STR_LIT>\" , <EOL> buttons = [ <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , <EOL> ", "gt": "] ,"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> ", "gt": "return_complex = True ,"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> ", "gt": "if models == \"<STR_LIT>\" :"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> ", "gt": "window = hann_window [ wnsize_dtype_device ] ,"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> try : <EOL> infos = [ <EOL> ( f\"<STR_LIT>\" , idx ) <EOL> for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) <EOL> ] <EOL> processes = [ ] <EOL> for i in range ( num_processes ) : <EOL> p = multiprocessing . Process ( <EOL> target = self . process_audio_multiprocessing , <EOL> args = ( infos [ i : : num_processes ] , ) , <EOL> ) <EOL> processes . append ( p ) <EOL> p . start ( ) <EOL> for i in range ( num_processes ) : <EOL> processes [ i ] . join ( ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def preprocess_training_set ( input_root , sr , num_processes , exp_dir , per ) : <EOL> pp = PreProcess ( sr , exp_dir , per ) <EOL> print ( \"<STR_LIT>\" ) <EOL> pp . process_audio_multiprocessing_input_directory ( input_root , num_processes ) <EOL> print ( \"<STR_LIT>\" ) <EOL> ", "gt": "if __name__ == \"<STR_LIT>\" :"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> ", "gt": "kernel_size ,"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ", "gt": ")"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> ", "gt": "x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ]"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> audio_input_path , <EOL> audio_output_path , <EOL> model_path , <EOL> index_path , <EOL> split_audio , <EOL> f0autotune , <EOL> clean_audio , <EOL> clean_strength , <EOL> export_format , <EOL> ) : <EOL> global tgt_sr , net_g , vc , cpt <EOL> get_vc ( model_path , <NUM_LIT> ) <EOL> try : <EOL> start_time = time . time ( ) <EOL> vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = audio_input_path , <EOL> f0_up_key = f0up_key , <EOL> f0_file = None , <EOL> f0_method = f0method , <EOL> file_index = index_path , <EOL> index_rate = index_rate , <EOL> rms_mix_rate = rms_mix_rate , <EOL> protect = protect , <EOL> hop_length = hop_length , <EOL> output_path = audio_output_path , <EOL> split_audio = split_audio , <EOL> f0autotune = f0autotune , <EOL> filter_radius = filter_radius , <EOL> ) <EOL> if clean_audio == \"<STR_LIT>\" : <EOL> cleaned_audio = remove_audio_noise ( audio_output_path , clean_strength ) <EOL> if cleaned_audio is not None : <EOL> sf . write ( audio_output_path , cleaned_audio , tgt_sr , format = \"<STR_LIT>\" ) <EOL> output_path_format = audio_output_path . replace ( <EOL> \"<STR_LIT>\" , f\"<STR_LIT>\" <EOL> ", "gt": ")"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> with gr . Column ( ) : <EOL> selected_language = gr . Dropdown ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> value = get_language_settings ( ) , <EOL> choices = [ \"<STR_LIT>\" ] <EOL> + i18n . _get_available_languages ( ) , <EOL> interactive = True , <EOL> ) <EOL> selected_language . change ( <EOL> ", "gt": "fn = save_lang_settings ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> ", "gt": "def compute_f0_uv ( self , wav , p_len = None ) :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> ", "gt": "f0 , t = pyworld . dio ("}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> ", "gt": "\"<STR_LIT>\" ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> ", "gt": "f0_ceil = self . f0_max ,"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> visible = True , <EOL> ) <EOL> themes_select . change ( <EOL> fn = loadThemes . select_theme , <EOL> inputs = themes_select , <EOL> outputs = [ ] , <EOL> ", "gt": ")"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> ", "gt": "n_layers ,"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> ", "gt": "minimum = <NUM_LIT> ,"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ", "gt": ")"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> ", "gt": "else :"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> ", "gt": "self . lengths = dataset . lengths"}
{"input": "import gradio as gr <EOL> import tabs . extra . processing . processing as processing <EOL> import tabs . extra . analyzer . analyzer as analyzer <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def extra_tab ( ) : <EOL> gr . Markdown ( <EOL> value = i18n ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "import gradio as gr <EOL> import tabs . extra . processing . processing as processing <EOL> import tabs . extra . analyzer . analyzer as analyzer <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def extra_tab ( ) : <EOL> gr . Markdown ( <EOL> value = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . TabItem ( i18n ( \"<STR_LIT>\" ) ) : <EOL> processing . processing ( ) <EOL> ", "gt": "with gr . TabItem ( i18n ( \"<STR_LIT>\" ) ) :"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> ", "gt": "relative_embeddings ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> ", "gt": "f0_floor = self . f0_min ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> ", "gt": "target = np . interp ("}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> ", "gt": "signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> visible = True , <EOL> ) <EOL> themes_select . change ( <EOL> ", "gt": "fn = loadThemes . select_theme ,"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ) . half ( ) <EOL> opt [ \"<STR_LIT>\" ] = cfg <EOL> opt [ \"<STR_LIT>\" ] = message <EOL> ", "gt": "opt [ \"<STR_LIT>\" ] = cfg_f0"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> ", "gt": "options . append ( f\"<STR_LIT>\" )"}
{"input": "import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> try : <EOL> file_path = Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" <EOL> with open ( file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> return json . load ( file ) <EOL> except FileNotFoundError : <EOL> raise FileNotFoundError ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> ", "gt": "def _get_available_languages ( self ) :"}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ) <EOL> melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) <EOL> ", "gt": "melspec = spectral_normalize_torch ( melspec )"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> ", "gt": "f0 = ("}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return \"<STR_LIT>\" , <NUM_LIT> <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def shutdown ( ) : <EOL> ", "gt": "print ( \"<STR_LIT>\" )"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> ", "gt": "with gr . Column ( ) :"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> ", "gt": "hps . model . resblock_kernel_sizes ,"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> ", "gt": "plt . xlabel ( \"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ", "gt": "interactive = True ,"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) <EOL> gen_losses . append ( l ) <EOL> loss += l <EOL> return loss , gen_losses <EOL> def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : <EOL> ", "gt": "z_p = z_p . float ( )"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> ", "gt": "download_tab ( )"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> ", "gt": "wav . astype ( np . double ) ,"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Video ( <EOL> value = temp_filename , interactive = False <EOL> ) <EOL> start_button . click ( <EOL> toggle_button_label , <EOL> start_button , <EOL> ", "gt": "[ start_button , video_component ] ,"}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f\"<STR_LIT>\" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( <EOL> opt_path2 + \"<STR_LIT>\" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> np . save ( <EOL> opt_path2 , <EOL> feature_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> coarse_pit = self . coarse_f0 ( feature_pit ) <EOL> np . save ( <EOL> opt_path1 , <EOL> coarse_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> ", "gt": "pbar . update ( <NUM_LIT> )"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> indices = [ ] <EOL> if self . shuffle : <EOL> for bucket in self . buckets : <EOL> indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) <EOL> else : <EOL> for bucket in self . buckets : <EOL> indices . append ( list ( range ( len ( bucket ) ) ) ) <EOL> batches = [ ] <EOL> for i in range ( len ( self . buckets ) ) : <EOL> bucket = self . buckets [ i ] <EOL> len_bucket = len ( bucket ) <EOL> ids_bucket = indices [ i ] <EOL> num_samples_bucket = self . num_samples_per_bucket [ i ] <EOL> rem = num_samples_bucket - len_bucket <EOL> ids_bucket = ( <EOL> ids_bucket <EOL> + ids_bucket * ( rem // len_bucket ) <EOL> ", "gt": "+ ids_bucket [ : ( rem % len_bucket ) ]"}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) ) <EOL> torch . save ( <EOL> replace_keys_in_dict ( <EOL> replace_keys_in_dict ( <EOL> ", "gt": "model , \"<STR_LIT>\" , \"<STR_LIT>\""}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ) <EOL> melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) <EOL> melspec = spectral_normalize_torch ( melspec ) <EOL> return melspec <EOL> def mel_spectrogram_torch ( <EOL> y , n_fft , num_mels , sampling_rate , hop_size , win_size , fmin , fmax , center = False <EOL> ) : <EOL> spec = spectrogram_torch ( y , n_fft , hop_size , win_size , center ) <EOL> ", "gt": "melspec = spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax )"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> ", "gt": "\"<STR_LIT>\" : ("}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( \"<STR_LIT>\" ) <EOL> print ( e ) <EOL> def load_config_flask ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" ) as file : <EOL> ", "gt": "config = json . load ( file )"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> ", "gt": "else :"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ", "gt": ") ,"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> ", "gt": "self . kernel_size = kernel_size"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Video ( <EOL> value = temp_filename , interactive = False <EOL> ) <EOL> ", "gt": "start_button . click ("}
{"input": "import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f\"<STR_LIT>\" ) <EOL> pth_file = f\"<STR_LIT>\" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f\"<STR_LIT>\" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key <EOL> } <EOL> ) <EOL> opt [ \"<STR_LIT>\" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ \"<STR_LIT>\" ] = epoch <EOL> opt [ \"<STR_LIT>\" ] = step <EOL> opt [ \"<STR_LIT>\" ] = sr <EOL> opt [ \"<STR_LIT>\" ] = if_f0 <EOL> opt [ \"<STR_LIT>\" ] = version <EOL> opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f\"<STR_LIT>\" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ \"<STR_LIT>\" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> ", "gt": "model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) )"}
{"input": "import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> host = \"<STR_LIT>\" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> print ( \"<STR_LIT>\" ) <EOL> sock . close ( ) <EOL> requests . post ( \"<STR_LIT>\" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> ", "gt": "sock . close ( )"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> ", "gt": "f0_floor = self . f0_min ,"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> fn = toggle , <EOL> inputs = [ flask_checkbox ] , <EOL> outputs = [ ] , <EOL> ", "gt": ")"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ", "gt": "+ ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) )"}
{"input": "import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def fake_gpu_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ", "gt": "interactive = True ,"}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> pass <EOL> python = sys . executable <EOL> os . execl ( python , python , * sys . argv ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> ", "gt": "def restart_tab ( ) :"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) <EOL> c = - input_delta * ( inputs - input_cumheights ) <EOL> ", "gt": "discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> ", "gt": "chunk_file = os . path . join ( timestamps_dir , prefix , filename )"}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> ", "gt": "indices = [ ]"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) <EOL> path = path . view ( b , t_x , t_y ) <EOL> path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] <EOL> path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask <EOL> ", "gt": "return path"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> ", "gt": "f0_ceil = self . f0_max ,"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" <EOL> def load_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> ", "gt": "if selected_file is not None and class_name :"}
{"input": "import os <EOL> import wget <EOL> url_base = \"<STR_LIT>\" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> \"<STR_LIT>\" , <EOL> [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> folder_mapping_list = { <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" : \"<STR_LIT>\" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == \"<STR_LIT>\" : <EOL> download_files ( models_list ) <EOL> if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if pretraineds_v2 == \"<STR_LIT>\" : <EOL> for remote_folder , file_list in pretraineds_v2_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f\"<STR_LIT>\" <EOL> ", "gt": "if not os . path . exists ( destination_path ) :"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> hparams . total_epoch = args . total_epoch <EOL> hparams . pretrainG = args . pretrainG <EOL> hparams . pretrainD = args . pretrainD <EOL> hparams . version = args . version <EOL> hparams . gpus = args . gpus <EOL> hparams . train . batch_size = args . batch_size <EOL> hparams . sample_rate = args . sample_rate <EOL> hparams . if_f0 = args . if_f0 <EOL> hparams . if_latest = args . if_latest <EOL> hparams . save_every_weights = args . save_every_weights <EOL> hparams . if_cache_data_in_gpu = args . if_cache_data_in_gpu <EOL> hparams . data . training_files = f\"<STR_LIT>\" <EOL> hparams . overtraining_detector = args . overtraining_detector <EOL> hparams . overtraining_threshold = args . overtraining_threshold <EOL> return hparams <EOL> class HParams : <EOL> def __init__ ( self , ** kwargs ) : <EOL> for k , v in kwargs . items ( ) : <EOL> if type ( v ) == dict : <EOL> v = HParams ( ** v ) <EOL> self [ k ] = v <EOL> def keys ( self ) : <EOL> return self . __dict__ . keys ( ) <EOL> def items ( self ) : <EOL> return self . __dict__ . items ( ) <EOL> def values ( self ) : <EOL> return self . __dict__ . values ( ) <EOL> def __len__ ( self ) : <EOL> return len ( self . __dict__ ) <EOL> def __getitem__ ( self , key ) : <EOL> return getattr ( self , key ) <EOL> def __setitem__ ( self , key , value ) : <EOL> return setattr ( self , key , value ) <EOL> def __contains__ ( self , key ) : <EOL> return key in self . __dict__ <EOL> def __repr__ ( self ) : <EOL> ", "gt": "return self . __dict__ . __repr__ ( )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . activation = activation <EOL> self . causal = causal <EOL> if causal : <EOL> ", "gt": "self . padding = self . _causal_padding"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( \"<STR_LIT>\" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( \"<STR_LIT>\" ) : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> ", "gt": "return gr . Button ( value = \"<STR_LIT>\" ) , gr . Video ("}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> ", "gt": "else :"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> ", "gt": "info = i18n ( \"<STR_LIT>\" ) ,"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> ", "gt": "try :"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> ", "gt": "return acts"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> audio_segments . append ( audio ) <EOL> last_end_time = start_time + len ( audio ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> merged_audio = sum ( audio_segments ) <EOL> merged_audio_np = np . array ( merged_audio . get_array_of_samples ( ) ) <EOL> ", "gt": "return merged_audio . frame_rate , merged_audio_np"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == \"<STR_LIT>\" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( \"<STR_LIT>\" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) <EOL> tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> elif version == \"<STR_LIT>\" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> audio_input_path , <EOL> audio_output_path , <EOL> model_path , <EOL> index_path , <EOL> split_audio , <EOL> f0autotune , <EOL> clean_audio , <EOL> clean_strength , <EOL> export_format , <EOL> ) : <EOL> global tgt_sr , net_g , vc , cpt <EOL> get_vc ( model_path , <NUM_LIT> ) <EOL> ", "gt": "try :"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> ", "gt": "np . arange ( <NUM_LIT> , len ( source ) ) ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> ", "gt": "source ,"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> self . rpc . update ( <EOL> state = \"<STR_LIT>\" , <EOL> details = \"<STR_LIT>\" , <EOL> buttons = [ <EOL> ", "gt": "{ \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> ", "gt": "f0_floor = self . f0_min ,"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> ", "gt": "f\"<STR_LIT>\""}
{"input": "import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ", "gt": "interactive = True ,"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ", "gt": ") . half ( )"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , \"<STR_LIT>\" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , \"<STR_LIT>\" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> ", "gt": "output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t )"}
{"input": "import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def obtain_tag_name ( ) : <EOL> url = \"<STR_LIT>\" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ \"<STR_LIT>\" ] <EOL> return tag_name <EOL> except requests . exceptions . RequestException as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def compare_version ( ) : <EOL> local_version = load_local_version ( ) <EOL> online_version = obtain_tag_name ( ) <EOL> elements_online_version = list ( map ( int , online_version . split ( \"<STR_LIT>\" ) ) ) <EOL> ", "gt": "elements_local_version = list ( map ( int , local_version . split ( \"<STR_LIT>\" ) ) )"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> try : <EOL> infos = [ <EOL> ( f\"<STR_LIT>\" , idx ) <EOL> for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) <EOL> ] <EOL> processes = [ ] <EOL> for i in range ( num_processes ) : <EOL> p = multiprocessing . Process ( <EOL> target = self . process_audio_multiprocessing , <EOL> args = ( infos [ i : : num_processes ] , ) , <EOL> ) <EOL> processes . append ( p ) <EOL> p . start ( ) <EOL> for i in range ( num_processes ) : <EOL> processes [ i ] . join ( ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def preprocess_training_set ( input_root , sr , num_processes , exp_dir , per ) : <EOL> pp = PreProcess ( sr , exp_dir , per ) <EOL> print ( \"<STR_LIT>\" ) <EOL> pp . process_audio_multiprocessing_input_directory ( input_root , num_processes ) <EOL> print ( \"<STR_LIT>\" ) <EOL> if __name__ == \"<STR_LIT>\" : <EOL> preprocess_training_set ( <EOL> input_root , sampling_rate , num_processes , experiment_directory , percentage <EOL> ", "gt": ")"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> ", "gt": "print ( f\"<STR_LIT>\" )"}
{"input": "import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) <EOL> saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> \"<STR_LIT>\" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( \"<STR_LIT>\" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f\"<STR_LIT>\" ) <EOL> if hasattr ( model , \"<STR_LIT>\" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> \"<STR_LIT>\" : state_dict , <EOL> \"<STR_LIT>\" : iteration , <EOL> \"<STR_LIT>\" : optimizer . state_dict ( ) , <EOL> \"<STR_LIT>\" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : <EOL> with open ( filename , encoding = \"<STR_LIT>\" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = str , <EOL> default = \"<STR_LIT>\" , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> required = True , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> parser . add_argument ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = \"<STR_LIT>\" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) <EOL> with open ( config_save_path , \"<STR_LIT>\" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> ", "gt": "hparams . save_every_epoch = args . save_every_epoch"}
{"input": "import os <EOL> import torch <EOL> def change_info ( path , info , name ) : <EOL> try : <EOL> ckpt = torch . load ( path , map_location = \"<STR_LIT>\" ) <EOL> ckpt [ \"<STR_LIT>\" ] = info <EOL> if name == \"<STR_LIT>\" : <EOL> name = os . path . basename ( path ) <EOL> torch . save ( ckpt , f\"<STR_LIT>\" ) <EOL> ", "gt": "return \"<STR_LIT>\""}
{"input": "import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> raise RuntimeError ( f\"<STR_LIT>\" ) <EOL> ", "gt": "return np . frombuffer ( out , np . float32 ) . flatten ( )"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> ", "gt": "with gr . Row ( ) :"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> ", "gt": "names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ("}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> ", "gt": "prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" )"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ \"<STR_LIT>\" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> config [ \"<STR_LIT>\" ] = value <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_presence ( ) , <EOL> ", "gt": ")"}
{"input": "import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if \"<STR_LIT>\" in line : <EOL> found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + \"<STR_LIT>\" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file <EOL> config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> gr . Info ( f\"<STR_LIT>\" ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> ", "gt": "return \"<STR_LIT>\""}
{"input": "import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> \"<STR_LIT>\" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> ", "gt": "def get_audio ( self , filename ) :"}
{"input": "import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ \"<STR_LIT>\" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in a . keys ( ) : <EOL> if \"<STR_LIT>\" in key : <EOL> continue <EOL> opt [ \"<STR_LIT>\" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f\"<STR_LIT>\" <EOL> ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) <EOL> ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) <EOL> cfg = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] <EOL> cfg_version = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ \"<STR_LIT>\" ] <EOL> if \"<STR_LIT>\" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ \"<STR_LIT>\" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return \"<STR_LIT>\" <EOL> opt = OrderedDict ( ) <EOL> opt [ \"<STR_LIT>\" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ \"<STR_LIT>\" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> ", "gt": "else :"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( \"<STR_LIT>\" , recorder_js ) <EOL> . replace ( \"<STR_LIT>\" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( \"<STR_LIT>\" ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> i18n ( <EOL> ", "gt": "\"<STR_LIT>\""}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return \"<STR_LIT>\" , <NUM_LIT> <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def shutdown ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> os . kill ( os . getpid ( ) , signal . SIGTERM ) <EOL> ", "gt": "if __name__ == \"<STR_LIT>\" :"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> return x_pad , x_query , x_center , x_max <EOL> def max_vram_gpu ( gpu ) : <EOL> if torch . cuda . is_available ( ) : <EOL> gpu_properties = torch . cuda . get_device_properties ( gpu ) <EOL> total_memory_gb = round ( gpu_properties . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> ) <EOL> return total_memory_gb <EOL> else : <EOL> return \"<STR_LIT>\" <EOL> def get_gpu_info ( ) : <EOL> ngpu = torch . cuda . device_count ( ) <EOL> gpu_infos = [ ] <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> for i in range ( ngpu ) : <EOL> gpu_name = torch . cuda . get_device_name ( i ) <EOL> mem = int ( <EOL> ", "gt": "torch . cuda . get_device_properties ( i ) . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT>"}
{"input": "import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> ) <EOL> model_view_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> model_view_button . click ( <EOL> ", "gt": "run_model_information_script ,"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> ", "gt": "& set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] )"}
{"input": "from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) <EOL> chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> f . write ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , new_dir_path <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return \"<STR_LIT>\" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f\"<STR_LIT>\" ) <EOL> for line in lines : <EOL> match = re . search ( r\"<STR_LIT>\" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> ", "gt": "audio_segments . append ( audio )"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> ", "gt": "shuffle ( options )"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> ", "gt": "f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs )"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> ", "gt": "x_max = <NUM_LIT>"}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> ", "gt": "except :"}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> ", "gt": "b , channels , length = x . size ( )"}
{"input": "import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> ", "gt": "loss = <NUM_LIT>"}
{"input": "import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = \"<STR_LIT>\" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name . upper ( ) <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> or \"<STR_LIT>\" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( \"<STR_LIT>\" ) <EOL> self . device = self . instead = \"<STR_LIT>\" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> ", "gt": "x_pad = <NUM_LIT>"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> ", "gt": "f0 , t = pyworld . harvest ("}
{"input": "import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> ", "gt": "def convert_pad_shape ( pad_shape ) :"}
{"input": "import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , \"<STR_LIT>\" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = \"<STR_LIT>\" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> self . enc = WN ( <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = p_dropout , <EOL> gin_channels = gin_channels , <EOL> ) <EOL> self . post = nn . Conv1d ( hidden_channels , self . half_channels * ( <NUM_LIT> - mean_only ) , <NUM_LIT> ) <EOL> self . post . weight . data . zero_ ( ) <EOL> self . post . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask , g = None , reverse = False ) : <EOL> x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> h = self . pre ( x0 ) * x_mask <EOL> h = self . enc ( h , x_mask , g = g ) <EOL> stats = self . post ( h ) * x_mask <EOL> if not self . mean_only : <EOL> m , logs = torch . split ( stats , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> else : <EOL> m = stats <EOL> logs = torch . zeros_like ( m ) <EOL> if not reverse : <EOL> x1 = m + x1 * torch . exp ( logs ) * x_mask <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) <EOL> logdet = torch . sum ( logs , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return x , logdet <EOL> else : <EOL> x1 = ( x1 - m ) * torch . exp ( - logs ) * x_mask <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> self . enc . remove_weight_norm ( ) <EOL> class ConvFlow ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> num_bins = <NUM_LIT> , <EOL> tail_bound = <NUM_LIT> , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . num_bins = num_bins <EOL> self . tail_bound = tail_bound <EOL> self . half_channels = in_channels // <NUM_LIT> <EOL> self . pre = nn . Conv1d ( self . half_channels , filter_channels , <NUM_LIT> ) <EOL> self . convs = DDSConv ( filter_channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) <EOL> self . proj = nn . Conv1d ( <EOL> filter_channels , self . half_channels * ( num_bins * <NUM_LIT> - <NUM_LIT> ) , <NUM_LIT> <EOL> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask , g = None , reverse = False ) : <EOL> x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> h = self . pre ( x0 ) <EOL> h = self . convs ( h , x_mask , g = g ) <EOL> h = self . proj ( h ) * x_mask <EOL> b , c , t = x0 . shape <EOL> h = h . reshape ( b , c , - <NUM_LIT> , t ) . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> unnormalized_widths = h [ ... , : self . num_bins ] / math . sqrt ( self . filter_channels ) <EOL> unnormalized_heights = h [ ... , self . num_bins : <NUM_LIT> * self . num_bins ] / math . sqrt ( <EOL> self . filter_channels <EOL> ) <EOL> unnormalized_derivatives = h [ ... , <NUM_LIT> * self . num_bins : ] <EOL> x1 , logabsdet = piecewise_rational_quadratic_transform ( <EOL> x1 , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = reverse , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = self . tail_bound , <EOL> ) <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) * x_mask <EOL> logdet = torch . sum ( logabsdet * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> if not reverse : <EOL> return x , logdet <EOL> else : <EOL> ", "gt": "return x"}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> model_information_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> model_information_button . click ( <EOL> run_model_information_script , <EOL> [ model_name ] , <EOL> model_information_output_info , <EOL> ", "gt": "api_name = \"<STR_LIT>\" ,"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> try : <EOL> infos = [ <EOL> ( f\"<STR_LIT>\" , idx ) <EOL> for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) <EOL> ] <EOL> processes = [ ] <EOL> for i in range ( num_processes ) : <EOL> p = multiprocessing . Process ( <EOL> target = self . process_audio_multiprocessing , <EOL> args = ( infos [ i : : num_processes ] , ) , <EOL> ) <EOL> processes . append ( p ) <EOL> p . start ( ) <EOL> for i in range ( num_processes ) : <EOL> processes [ i ] . join ( ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def preprocess_training_set ( input_root , sr , num_processes , exp_dir , per ) : <EOL> ", "gt": "pp = PreProcess ( sr , exp_dir , per )"}
{"input": "import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ \"<STR_LIT>\" ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != \"<STR_LIT>\" : <EOL> print ( f\"<STR_LIT>\" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f\"<STR_LIT>\" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( \"<STR_LIT>\" ) <EOL> . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == \"<STR_LIT>\" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == \"<STR_LIT>\" : <EOL> return \"<STR_LIT>\" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) <EOL> ) <EOL> if dir_path != \"<STR_LIT>\" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( \"<STR_LIT>\" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f\"<STR_LIT>\" <EOL> print ( \"<STR_LIT>\" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f\"<STR_LIT>\" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> ", "gt": "filter_radius ,"}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> pass <EOL> ", "gt": "python = sys . executable"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> ", "gt": "plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" )"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> ", "gt": "f0_ceil = self . f0_max ,"}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ", "gt": ")"}
{"input": "def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> \"<STR_LIT>\" : { <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> \"<STR_LIT>\" : ( <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ) , <EOL> } , <EOL> ", "gt": "}"}
{"input": "import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = \"<STR_LIT>\" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == \"<STR_LIT>\" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> ", "gt": "bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ]"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> ", "gt": "\"<STR_LIT>\" : feats . to ( device ) ,"}
{"input": "import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == \"<STR_LIT>\" : <EOL> if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) <EOL> else : <EOL> ", "gt": "return \"<STR_LIT>\""}
{"input": "import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = \"<STR_LIT>\" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ) <EOL> melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) <EOL> melspec = spectral_normalize_torch ( melspec ) <EOL> ", "gt": "return melspec"}
{"input": "import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> ", "gt": "fn = toggle ,"}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> pass <EOL> python = sys . executable <EOL> os . execl ( python , python , * sys . argv ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> ", "gt": "i18n = I18nAuto ( )"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> options . append ( f\"<STR_LIT>\" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f\"<STR_LIT>\" <EOL> ) <EOL> shuffle ( options ) <EOL> with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : <EOL> ", "gt": "f . write ( \"<STR_LIT>\" . join ( options ) )"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> \"<STR_LIT>\" : feats . to ( device ) , <EOL> \"<STR_LIT>\" : padding_mask . to ( device ) , <EOL> \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , <EOL> } <EOL> with torch . no_grad ( ) : <EOL> ", "gt": "logits = model . extract_features ( ** inputs )"}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> ", "gt": "if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] :"}
{"input": "import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = \"<STR_LIT>\" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = \"<STR_LIT>\" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . ylabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) <EOL> plt . xlabel ( \"<STR_LIT>\" ) <EOL> plt . title ( \"<STR_LIT>\" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> ", "gt": "stft , duration , cent , bw , rolloff = calculate_features ( y , sr )"}
{"input": "from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f\"<STR_LIT>\" <EOL> self . wavs16k_dir = f\"<STR_LIT>\" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f\"<STR_LIT>\" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f\"<STR_LIT>\" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ", "gt": "]"}
{"input": "import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : <EOL> config_path = f\"<STR_LIT>\" <EOL> else : <EOL> config_path = f\"<STR_LIT>\" <EOL> config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( \"<STR_LIT>\" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f\"<STR_LIT>\" <EOL> feature_dir = ( <EOL> f\"<STR_LIT>\" <EOL> if rvc_version == \"<STR_LIT>\" <EOL> else f\"<STR_LIT>\" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f\"<STR_LIT>\" <EOL> f0nsf_dir = f\"<STR_LIT>\" <EOL> names = ( <EOL> set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> ", "gt": "options = [ ]"}
{"input": "import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> interactive = True , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False <EOL> ) <EOL> ", "gt": "model_fusion_button . click ("}
{"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> ", "gt": "p_len = wav . shape [ <NUM_LIT> ] // self . hop_length"}
{"input": "from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = \"<STR_LIT>\" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f\"<STR_LIT>\" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> ", "gt": "self . rpc . update ("}
{"input": "import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f\"<STR_LIT>\" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( \"<STR_LIT>\" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( \"<STR_LIT>\" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == \"<STR_LIT>\" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> \"<STR_LIT>\" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ \"<STR_LIT>\" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = \"<STR_LIT>\" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> \"<STR_LIT>\" : self . get_pm , <EOL> \"<STR_LIT>\" : self . get_harvest , <EOL> \"<STR_LIT>\" : self . get_dio , <EOL> \"<STR_LIT>\" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == \"<STR_LIT>\" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == \"<STR_LIT>\" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( \"<STR_LIT>\" ) <EOL> return <EOL> ", "gt": "with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar :"}
{"input": "import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def restart_applio ( ) : <EOL> if os . name != \"<STR_LIT>\" : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> else : <EOL> os . system ( \"<STR_LIT>\" ) <EOL> try : <EOL> with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> pass <EOL> python = sys . executable <EOL> os . execl ( python , python , * sys . argv ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def restart_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> restart_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> restart_button . click ( <EOL> fn = restart_applio , <EOL> inputs = [ ] , <EOL> outputs = [ ] , <EOL> ", "gt": ")"}
{"input": "import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> logging . getLogger ( \"<STR_LIT>\" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( \"<STR_LIT>\" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = \"<STR_LIT>\" <EOL> with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : <EOL> gr . Markdown ( \"<STR_LIT>\" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : <EOL> extra_tab ( ) <EOL> ", "gt": "with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) :"}
{"input": "import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> placeholder = i18n ( \"<STR_LIT>\" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( \"<STR_LIT>\" ) , <EOL> value = \"<STR_LIT>\" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> model_information_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) <EOL> ", "gt": "model_information_button . click ("}
{"input": "import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = \"<STR_LIT>\" <EOL> wav_path = f\"<STR_LIT>\" <EOL> out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( \"<STR_LIT>\" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = \"<STR_LIT>\" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> \"<STR_LIT>\" <EOL> ) <EOL> else : <EOL> print ( f\"<STR_LIT>\" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( \"<STR_LIT>\" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> ", "gt": "out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) )"}
{"input": "import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> label = i18n ( \"<STR_LIT>\" ) , <EOL> info = i18n ( <EOL> \"<STR_LIT>\" <EOL> ) , <EOL> visible = True , <EOL> ) <EOL> themes_select . change ( <EOL> fn = loadThemes . select_theme , <EOL> ", "gt": "inputs = themes_select ,"}
{"input": "import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : <EOL> return \"<STR_LIT>\" <EOL> else : <EOL> return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == \"<STR_LIT>\" : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False <EOL> else : <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True <EOL> config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language <EOL> gr . Info ( \"<STR_LIT>\" ) <EOL> with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> ", "gt": "def lang_tab ( ) :"}
