<s> import os , sys <EOL> import gradio as gr <EOL> import regex as re <EOL> import shutil <EOL> import datetime <EOL> import random <EOL> from core import ( <EOL> run_infer_script , <EOL> run_batch_infer_script , <EOL> ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from rvc . lib . utils import format_title <EOL> i18n = I18nAuto ( ) <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> model_root = os . path . join ( now_dir , "<STR_LIT>" ) <EOL> audio_root = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> model_root_relative = os . path . relpath ( model_root , now_dir ) <EOL> audio_root_relative = os . path . relpath ( audio_root , now_dir ) <EOL> sup_audioext = { <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> } <EOL> names = [ <EOL> os . path . join ( root , file ) <EOL> for root , _ , files in os . walk ( model_root_relative , topdown = False ) <EOL> for file in files <EOL> if ( <EOL> file . endswith ( ( "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> and not ( file . startswith ( "<STR_LIT>" ) or file . startswith ( "<STR_LIT>" ) ) <EOL> ) <EOL> ] <EOL> indexes_list = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( model_root_relative , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( "<STR_LIT>" ) and "<STR_LIT>" not in name <EOL> ] <EOL> audio_paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( audio_root_relative , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( tuple ( sup_audioext ) ) <EOL> and root == audio_root_relative <EOL> and "<STR_LIT>" not in name <EOL> ] <EOL> def output_path_fn ( input_audio_path ) : <EOL> original_name_without_extension = os . path . basename ( input_audio_path ) . rsplit ( "<STR_LIT>" , <NUM_LIT> ) [ <EOL> <NUM_LIT> <EOL> ] <EOL> new_name = original_name_without_extension + "<STR_LIT>" <EOL> output_path = os . path . join ( os . path . dirname ( input_audio_path ) , new_name ) <EOL> return output_path <EOL> def change_choices ( ) : <EOL> names = [ <EOL> os . path . join ( root , file ) <EOL> for root , _ , files in os . walk ( model_root_relative , topdown = False ) <EOL> for file in files <EOL> if ( <EOL> file . endswith ( ( "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> and not ( file . startswith ( "<STR_LIT>" ) or file . startswith ( "<STR_LIT>" ) ) <EOL> ) <EOL> ] <EOL> indexes_list = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( model_root_relative , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( "<STR_LIT>" ) and "<STR_LIT>" not in name <EOL> ] <EOL> audio_paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( audio_root_relative , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( tuple ( sup_audioext ) ) <EOL> and root == audio_root_relative <EOL> and "<STR_LIT>" not in name <EOL> ] <EOL> return ( <EOL> { "<STR_LIT>" : sorted ( names ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : sorted ( indexes_list ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : sorted ( audio_paths ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> ) <EOL> def get_indexes ( ) : <EOL> indexes_list = [ <EOL> os . path . join ( dirpath , filename ) <EOL> for dirpath , _ , filenames in os . walk ( model_root_relative ) <EOL> for filename in filenames <EOL> if filename . endswith ( "<STR_LIT>" ) and "<STR_LIT>" not in filename <EOL> ] <EOL> return indexes_list if indexes_list else "<STR_LIT>" <EOL> def save_to_wav ( record_button ) : <EOL> if record_button is None : <EOL> pass <EOL> else : <EOL> path_to_file = record_button <EOL> new_name = datetime . datetime . now ( ) . strftime ( "<STR_LIT>" ) + "<STR_LIT>" <EOL> target_path = os . path . join ( audio_root_relative , os . path . basename ( new_name ) ) <EOL> shutil . move ( path_to_file , target_path ) <EOL> return target_path , output_path_fn ( target_path ) <EOL> def save_to_wav2 ( upload_audio ) : <EOL> file_path = upload_audio <EOL> formated_name = format_title ( os . path . basename ( file_path ) ) <EOL> target_path = os . path . join ( audio_root_relative , formated_name ) <EOL> if os . path . exists ( target_path ) : <EOL> os . remove ( target_path ) <EOL> shutil . copy ( file_path , target_path ) <EOL> return target_path , output_path_fn ( target_path ) <EOL> def delete_outputs ( ) : <EOL> gr . Info ( f"<STR_LIT>" ) <EOL> for root , _ , files in os . walk ( audio_root_relative , topdown = False ) : <EOL> for name in files : <EOL> if name . endswith ( tuple ( sup_audioext ) ) and name . __contains__ ( "<STR_LIT>" ) : <EOL> os . remove ( os . path . join ( root , name ) ) <EOL> def match_index ( model_file_value ) : <EOL> if model_file_value : <EOL> model_folder = os . path . dirname ( model_file_value ) <EOL> index_files = get_indexes ( ) <EOL> for index_file in index_files : <EOL> if os . path . dirname ( index_file ) == model_folder : <EOL> return index_file <EOL> return "<STR_LIT>" <EOL> def inference_tab ( ) : <EOL> default_weight = random . choice ( names ) if names else None <EOL> with gr . Row ( ) : <EOL> with gr . Row ( ) : <EOL> model_file = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = sorted ( names , key = lambda path : os . path . getsize ( path ) ) , <EOL> interactive = True , <EOL> value = default_weight , <EOL> allow_custom_value = True , <EOL> ) <EOL> index_file = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = get_indexes ( ) , <EOL> value = match_index ( default_weight ) if default_weight else "<STR_LIT>" , <EOL> interactive = True , <EOL> allow_custom_value = True , <EOL> ) <EOL> with gr . Column ( ) : <EOL> refresh_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> unload_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> unload_button . click ( <EOL> fn = lambda : ( <EOL> { "<STR_LIT>" : "<STR_LIT>" , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : "<STR_LIT>" , "<STR_LIT>" : "<STR_LIT>" } , <EOL> ) , <EOL> inputs = [ ] , <EOL> outputs = [ model_file , index_file ] , <EOL> ) <EOL> model_file . select ( <EOL> fn = lambda model_file_value : match_index ( model_file_value ) , <EOL> inputs = [ model_file ] , <EOL> outputs = [ index_file ] , <EOL> ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> with gr . Column ( ) : <EOL> upload_audio = gr . Audio ( <EOL> label = i18n ( "<STR_LIT>" ) , type = "<STR_LIT>" , editable = False <EOL> ) <EOL> with gr . Row ( ) : <EOL> audio = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = sorted ( audio_paths ) , <EOL> value = audio_paths [ <NUM_LIT> ] if audio_paths else "<STR_LIT>" , <EOL> interactive = True , <EOL> allow_custom_value = True , <EOL> ) <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) , open = False ) : <EOL> with gr . Column ( ) : <EOL> clear_outputs_infer = gr . Button ( <EOL> i18n ( "<STR_LIT>" ) <EOL> ) <EOL> output_path = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = ( <EOL> output_path_fn ( audio_paths [ <NUM_LIT> ] ) <EOL> if audio_paths <EOL> else os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> ) , <EOL> interactive = True , <EOL> ) <EOL> export_format = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> split_audio = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> autotune = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> clean_audio = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> clean_strength = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = False , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> pitch = gr . Slider ( <EOL> minimum = - <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> filter_radius = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> index_rate = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> rms_mix_rate = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> protect = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> hop_length = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = False , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> with gr . Column ( ) : <EOL> f0method = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> choices = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> convert_button1 = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> with gr . Row ( ) : <EOL> vc_output1 = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> ) <EOL> vc_output2 = gr . Audio ( label = i18n ( "<STR_LIT>" ) ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> input_folder_batch = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> value = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) , <EOL> interactive = True , <EOL> ) <EOL> output_folder_batch = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> value = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) , <EOL> interactive = True , <EOL> ) <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) , open = False ) : <EOL> with gr . Column ( ) : <EOL> clear_outputs_batch = gr . Button ( <EOL> i18n ( "<STR_LIT>" ) <EOL> ) <EOL> export_format_batch = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> split_audio_batch = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> autotune_batch = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> clean_audio_batch = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> clean_strength_batch = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = False , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> pitch_batch = gr . Slider ( <EOL> minimum = - <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> filter_radius_batch = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> index_rate_batch = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> rms_mix_rate_batch = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> protect_batch = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> hop_length_batch = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = False , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> with gr . Column ( ) : <EOL> f0method_batch = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> choices = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> convert_button2 = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> with gr . Row ( ) : <EOL> vc_output3 = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> ) <EOL> def toggle_visible ( checkbox ) : <EOL> return { "<STR_LIT>" : checkbox , "<STR_LIT>" : "<STR_LIT>" } <EOL> def toggle_visible_hop_length ( f0method ) : <EOL> if f0method == "<STR_LIT>" or f0method == "<STR_LIT>" : <EOL> return { "<STR_LIT>" : True , "<STR_LIT>" : "<STR_LIT>" } <EOL> return { "<STR_LIT>" : False , "<STR_LIT>" : "<STR_LIT>" } <EOL> clean_audio . change ( <EOL> fn = toggle_visible , <EOL> inputs = [ clean_audio ] , <EOL> outputs = [ clean_strength ] , <EOL> ) <EOL> clean_audio_batch . change ( <EOL> fn = toggle_visible , <EOL> inputs = [ clean_audio_batch ] , <EOL> outputs = [ clean_strength_batch ] , <EOL> ) <EOL> f0method . change ( <EOL> fn = toggle_visible_hop_length , <EOL> inputs = [ f0method ] , <EOL> outputs = [ hop_length ] , <EOL> ) <EOL> f0method_batch . change ( <EOL> fn = toggle_visible_hop_length , <EOL> inputs = [ f0method_batch ] , <EOL> outputs = [ hop_length_batch ] , <EOL> ) <EOL> refresh_button . click ( <EOL> fn = change_choices , <EOL> inputs = [ ] , <EOL> outputs = [ model_file , index_file , audio ] , <EOL> ) <EOL> audio . change ( <EOL> fn = output_path_fn , <EOL> inputs = [ audio ] , <EOL> outputs = [ output_path ] , <EOL> ) <EOL> upload_audio . upload ( <EOL> fn = save_to_wav2 , <EOL> inputs = [ upload_audio ] , <EOL> outputs = [ audio , output_path ] , <EOL> ) <EOL> upload_audio . stop_recording ( <EOL> fn = save_to_wav , <EOL> inputs = [ upload_audio ] , <EOL> outputs = [ audio , output_path ] , <EOL> ) <EOL> clear_outputs_infer . click ( <EOL> fn = delete_outputs , <EOL> inputs = [ ] , <EOL> outputs = [ ] , <EOL> ) <EOL> clear_outputs_batch . click ( <EOL> fn = delete_outputs , <EOL> inputs = [ ] , <EOL> outputs = [ ] , <EOL> ) <EOL> convert_button1 . click ( <EOL> fn = run_infer_script , <EOL> inputs = [ <EOL> pitch , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> audio , <EOL> output_path , <EOL> model_file , <EOL> index_file , <EOL> split_audio , <EOL> autotune , <EOL> clean_audio , <EOL> clean_strength , <EOL> export_format , <EOL> ] , <EOL> outputs = [ vc_output1 , vc_output2 ] , <EOL> ) <EOL> convert_button2 . click ( <EOL> fn = run_batch_infer_script , <EOL> inputs = [ <EOL> pitch_batch , <EOL> filter_radius_batch , <EOL> index_rate_batch , <EOL> rms_mix_rate_batch , <EOL> protect_batch , <EOL> hop_length_batch , <EOL> f0method_batch , <EOL> input_folder_batch , <EOL> output_folder_batch , <EOL> model_file , <EOL> index_file , <EOL> split_audio_batch , <EOL> autotune_batch , <EOL> clean_audio_batch , <EOL> clean_strength_batch , <EOL> export_format_batch , <EOL> ] , <EOL> outputs = [ vc_output3 ] , <EOL> ) <EOL> </s>
<s> import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from torch . nn import Conv1d <EOL> from torch . nn . utils import remove_weight_norm <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from . import commons <EOL> from . commons import init_weights , get_padding <EOL> from . transforms import piecewise_rational_quadratic_transform <EOL> LRELU_SLOPE = <NUM_LIT> <EOL> class LayerNorm ( nn . Module ) : <EOL> def __init__ ( self , channels , eps = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . eps = eps <EOL> self . gamma = nn . Parameter ( torch . ones ( channels ) ) <EOL> self . beta = nn . Parameter ( torch . zeros ( channels ) ) <EOL> def forward ( self , x ) : <EOL> x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) <EOL> return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) <EOL> class ConvReluNorm ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> hidden_channels , <EOL> out_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> p_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . hidden_channels = hidden_channels <EOL> self . out_channels = out_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> assert n_layers > <NUM_LIT> , "<STR_LIT>" <EOL> self . conv_layers = nn . ModuleList ( ) <EOL> self . norm_layers = nn . ModuleList ( ) <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) <EOL> for _ in range ( n_layers - <NUM_LIT> ) : <EOL> self . conv_layers . append ( <EOL> nn . Conv1d ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> padding = kernel_size // <NUM_LIT> , <EOL> ) <EOL> ) <EOL> self . norm_layers . append ( LayerNorm ( hidden_channels ) ) <EOL> self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask ) : <EOL> x_org = x <EOL> for i in range ( self . n_layers ) : <EOL> x = self . conv_layers [ i ] ( x * x_mask ) <EOL> x = self . norm_layers [ i ] ( x ) <EOL> x = self . relu_drop ( x ) <EOL> x = x_org + self . proj ( x ) <EOL> return x * x_mask <EOL> class DDSConv ( nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . p_dropout = p_dropout <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . convs_sep = nn . ModuleList ( ) <EOL> self . convs_1x1 = nn . ModuleList ( ) <EOL> self . norms_1 = nn . ModuleList ( ) <EOL> self . norms_2 = nn . ModuleList ( ) <EOL> for i in range ( n_layers ) : <EOL> dilation = kernel_size ** i <EOL> padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> <EOL> self . convs_sep . append ( <EOL> nn . Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> groups = channels , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> ) <EOL> self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) <EOL> self . norms_1 . append ( LayerNorm ( channels ) ) <EOL> self . norms_2 . append ( LayerNorm ( channels ) ) <EOL> def forward ( self , x , x_mask , g = None ) : <EOL> if g is not None : <EOL> x = x + g <EOL> for i in range ( self . n_layers ) : <EOL> y = self . convs_sep [ i ] ( x * x_mask ) <EOL> y = self . norms_1 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . convs_1x1 [ i ] ( y ) <EOL> y = self . norms_2 [ i ] ( y ) <EOL> y = F . gelu ( y ) <EOL> y = self . drop ( y ) <EOL> x = x + y <EOL> return x * x_mask <EOL> class WN ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> gin_channels = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> ) : <EOL> super ( WN , self ) . __init__ ( ) <EOL> assert kernel_size % <NUM_LIT> == <NUM_LIT> <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = ( kernel_size , ) <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . gin_channels = gin_channels <EOL> self . p_dropout = p_dropout <EOL> self . in_layers = torch . nn . ModuleList ( ) <EOL> self . res_skip_layers = torch . nn . ModuleList ( ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if gin_channels != <NUM_LIT> : <EOL> cond_layer = torch . nn . Conv1d ( <EOL> gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> <EOL> ) <EOL> self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> cond_layer , name = "<STR_LIT>" <EOL> ) <EOL> for i in range ( n_layers ) : <EOL> dilation = dilation_rate ** i <EOL> padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> in_layer = torch . nn . Conv1d ( <EOL> hidden_channels , <EOL> <NUM_LIT> * hidden_channels , <EOL> kernel_size , <EOL> dilation = dilation , <EOL> padding = padding , <EOL> ) <EOL> in_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> in_layer , name = "<STR_LIT>" <EOL> ) <EOL> self . in_layers . append ( in_layer ) <EOL> if i < n_layers - <NUM_LIT> : <EOL> res_skip_channels = <NUM_LIT> * hidden_channels <EOL> else : <EOL> res_skip_channels = hidden_channels <EOL> res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) <EOL> res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( <EOL> res_skip_layer , name = "<STR_LIT>" <EOL> ) <EOL> self . res_skip_layers . append ( res_skip_layer ) <EOL> def forward ( self , x , x_mask , g = None , ** kwargs ) : <EOL> output = torch . zeros_like ( x ) <EOL> n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) <EOL> if g is not None : <EOL> g = self . cond_layer ( g ) <EOL> for i in range ( self . n_layers ) : <EOL> x_in = self . in_layers [ i ] ( x ) <EOL> if g is not None : <EOL> cond_offset = i * <NUM_LIT> * self . hidden_channels <EOL> g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] <EOL> else : <EOL> g_l = torch . zeros_like ( x_in ) <EOL> acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) <EOL> acts = self . drop ( acts ) <EOL> res_skip_acts = self . res_skip_layers [ i ] ( acts ) <EOL> if i < self . n_layers - <NUM_LIT> : <EOL> res_acts = res_skip_acts [ : , : self . hidden_channels , : ] <EOL> x = ( x + res_acts ) * x_mask <EOL> output = output + res_skip_acts [ : , self . hidden_channels : , : ] <EOL> else : <EOL> output = output + res_skip_acts <EOL> return output * x_mask <EOL> def remove_weight_norm ( self ) : <EOL> if self . gin_channels != <NUM_LIT> : <EOL> torch . nn . utils . remove_weight_norm ( self . cond_layer ) <EOL> for l in self . in_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> for l in self . res_skip_layers : <EOL> torch . nn . utils . remove_weight_norm ( l ) <EOL> class ResBlock1 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock1 , self ) . __init__ ( ) <EOL> self . convs1 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs1 . apply ( init_weights ) <EOL> self . convs2 = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = <NUM_LIT> , <EOL> padding = get_padding ( kernel_size , <NUM_LIT> ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs2 . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c1 , c2 in zip ( self . convs1 , self . convs2 ) : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c1 ( xt ) <EOL> xt = F . leaky_relu ( xt , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c2 ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs1 : <EOL> remove_weight_norm ( l ) <EOL> for l in self . convs2 : <EOL> remove_weight_norm ( l ) <EOL> class ResBlock2 ( torch . nn . Module ) : <EOL> def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : <EOL> super ( ResBlock2 , self ) . __init__ ( ) <EOL> self . convs = nn . ModuleList ( <EOL> [ <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> weight_norm ( <EOL> Conv1d ( <EOL> channels , <EOL> channels , <EOL> kernel_size , <EOL> <NUM_LIT> , <EOL> dilation = dilation [ <NUM_LIT> ] , <EOL> padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , <EOL> ) <EOL> ) , <EOL> ] <EOL> ) <EOL> self . convs . apply ( init_weights ) <EOL> def forward ( self , x , x_mask = None ) : <EOL> for c in self . convs : <EOL> xt = F . leaky_relu ( x , LRELU_SLOPE ) <EOL> if x_mask is not None : <EOL> xt = xt * x_mask <EOL> xt = c ( xt ) <EOL> x = xt + x <EOL> if x_mask is not None : <EOL> x = x * x_mask <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> for l in self . convs : <EOL> remove_weight_norm ( l ) <EOL> class Log ( nn . Module ) : <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask <EOL> logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = torch . exp ( x ) * x_mask <EOL> return x <EOL> class Flip ( nn . Module ) : <EOL> def forward ( self , x , * args , reverse = False , ** kwargs ) : <EOL> x = torch . flip ( x , [ <NUM_LIT> ] ) <EOL> if not reverse : <EOL> logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> class ElementwiseAffine ( nn . Module ) : <EOL> def __init__ ( self , channels ) : <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) <EOL> def forward ( self , x , x_mask , reverse = False , ** kwargs ) : <EOL> if not reverse : <EOL> y = self . m + torch . exp ( self . logs ) * x <EOL> y = y * x_mask <EOL> logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return y , logdet <EOL> else : <EOL> x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask <EOL> return x <EOL> class ResidualCouplingLayer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = <NUM_LIT> , <EOL> gin_channels = <NUM_LIT> , <EOL> mean_only = False , <EOL> ) : <EOL> assert channels % <NUM_LIT> == <NUM_LIT> , "<STR_LIT>" <EOL> super ( ) . __init__ ( ) <EOL> self . channels = channels <EOL> self . hidden_channels = hidden_channels <EOL> self . kernel_size = kernel_size <EOL> self . dilation_rate = dilation_rate <EOL> self . n_layers = n_layers <EOL> self . half_channels = channels // <NUM_LIT> <EOL> self . mean_only = mean_only <EOL> self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) <EOL> self . enc = WN ( <EOL> hidden_channels , <EOL> kernel_size , <EOL> dilation_rate , <EOL> n_layers , <EOL> p_dropout = p_dropout , <EOL> gin_channels = gin_channels , <EOL> ) <EOL> self . post = nn . Conv1d ( hidden_channels , self . half_channels * ( <NUM_LIT> - mean_only ) , <NUM_LIT> ) <EOL> self . post . weight . data . zero_ ( ) <EOL> self . post . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask , g = None , reverse = False ) : <EOL> x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> h = self . pre ( x0 ) * x_mask <EOL> h = self . enc ( h , x_mask , g = g ) <EOL> stats = self . post ( h ) * x_mask <EOL> if not self . mean_only : <EOL> m , logs = torch . split ( stats , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> else : <EOL> m = stats <EOL> logs = torch . zeros_like ( m ) <EOL> if not reverse : <EOL> x1 = m + x1 * torch . exp ( logs ) * x_mask <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) <EOL> logdet = torch . sum ( logs , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> return x , logdet <EOL> else : <EOL> x1 = ( x1 - m ) * torch . exp ( - logs ) * x_mask <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) <EOL> return x <EOL> def remove_weight_norm ( self ) : <EOL> self . enc . remove_weight_norm ( ) <EOL> class ConvFlow ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> n_layers , <EOL> num_bins = <NUM_LIT> , <EOL> tail_bound = <NUM_LIT> , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . n_layers = n_layers <EOL> self . num_bins = num_bins <EOL> self . tail_bound = tail_bound <EOL> self . half_channels = in_channels // <NUM_LIT> <EOL> self . pre = nn . Conv1d ( self . half_channels , filter_channels , <NUM_LIT> ) <EOL> self . convs = DDSConv ( filter_channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) <EOL> self . proj = nn . Conv1d ( <EOL> filter_channels , self . half_channels * ( num_bins * <NUM_LIT> - <NUM_LIT> ) , <NUM_LIT> <EOL> ) <EOL> self . proj . weight . data . zero_ ( ) <EOL> self . proj . bias . data . zero_ ( ) <EOL> def forward ( self , x , x_mask , g = None , reverse = False ) : <EOL> x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) <EOL> h = self . pre ( x0 ) <EOL> h = self . convs ( h , x_mask , g = g ) <EOL> h = self . proj ( h ) * x_mask <EOL> b , c , t = x0 . shape <EOL> h = h . reshape ( b , c , - <NUM_LIT> , t ) . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> unnormalized_widths = h [ ... , : self . num_bins ] / math . sqrt ( self . filter_channels ) <EOL> unnormalized_heights = h [ ... , self . num_bins : <NUM_LIT> * self . num_bins ] / math . sqrt ( <EOL> self . filter_channels <EOL> ) <EOL> unnormalized_derivatives = h [ ... , <NUM_LIT> * self . num_bins : ] <EOL> x1 , logabsdet = piecewise_rational_quadratic_transform ( <EOL> x1 , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = reverse , <EOL> tails = "<STR_LIT>" , <EOL> tail_bound = self . tail_bound , <EOL> ) <EOL> x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) * x_mask <EOL> logdet = torch . sum ( logabsdet * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> if not reverse : <EOL> return x , logdet <EOL> else : <EOL> return x <EOL> </s>
<s> import os <EOL> import sys <EOL> import tqdm <EOL> import torch <EOL> import torch . nn . functional as F <EOL> import fairseq <EOL> import soundfile as sf <EOL> import numpy as np <EOL> import logging <EOL> logging . getLogger ( "<STR_LIT>" ) . setLevel ( logging . WARNING ) <EOL> device = sys . argv [ <NUM_LIT> ] <EOL> n_parts = int ( sys . argv [ <NUM_LIT> ] ) <EOL> i_part = int ( sys . argv [ <NUM_LIT> ] ) <EOL> if len ( sys . argv ) == <NUM_LIT> : <EOL> exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> else : <EOL> i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] <EOL> os . environ [ "<STR_LIT>" ] = str ( i_gpu ) <EOL> version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) <EOL> def forward_dml ( ctx , x , scale ) : <EOL> ctx . scale = scale <EOL> res = x . clone ( ) . detach ( ) <EOL> return res <EOL> fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml <EOL> model_path = "<STR_LIT>" <EOL> wav_path = f"<STR_LIT>" <EOL> out_path = f"<STR_LIT>" if version == "<STR_LIT>" else f"<STR_LIT>" <EOL> os . makedirs ( out_path , exist_ok = True ) <EOL> def read_wave ( wav_path , normalize = False ) : <EOL> wav , sr = sf . read ( wav_path ) <EOL> assert sr == <NUM_LIT> <EOL> feats = torch . from_numpy ( wav ) <EOL> feats = feats . half ( ) if is_half else feats . float ( ) <EOL> feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> if normalize : <EOL> with torch . no_grad ( ) : <EOL> feats = F . layer_norm ( feats , feats . shape ) <EOL> return feats <EOL> print ( "<STR_LIT>" ) <EOL> models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ model_path ] , <EOL> suffix = "<STR_LIT>" , <EOL> ) <EOL> model = models [ <NUM_LIT> ] <EOL> model = model . to ( device ) <EOL> if device not in [ "<STR_LIT>" , "<STR_LIT>" ] : <EOL> model = model . half ( ) <EOL> model . eval ( ) <EOL> todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] <EOL> n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) <EOL> if len ( todo ) == <NUM_LIT> : <EOL> print ( <EOL> "<STR_LIT>" <EOL> ) <EOL> else : <EOL> print ( f"<STR_LIT>" ) <EOL> with tqdm . tqdm ( total = len ( todo ) ) as pbar : <EOL> for idx , file in enumerate ( todo ) : <EOL> try : <EOL> if file . endswith ( "<STR_LIT>" ) : <EOL> wav_file_path = os . path . join ( wav_path , file ) <EOL> out_file_path = os . path . join ( out_path , file . replace ( "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> if os . path . exists ( out_file_path ) : <EOL> continue <EOL> feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) <EOL> inputs = { <EOL> "<STR_LIT>" : feats . to ( device ) , <EOL> "<STR_LIT>" : padding_mask . to ( device ) , <EOL> "<STR_LIT>" : <NUM_LIT> if version == "<STR_LIT>" else <NUM_LIT> , <EOL> } <EOL> with torch . no_grad ( ) : <EOL> logits = model . extract_features ( ** inputs ) <EOL> feats = ( <EOL> model . final_proj ( logits [ <NUM_LIT> ] ) <EOL> if version == "<STR_LIT>" <EOL> else logits [ <NUM_LIT> ] <EOL> ) <EOL> feats = feats . squeeze ( <NUM_LIT> ) . float ( ) . cpu ( ) . numpy ( ) <EOL> if np . isnan ( feats ) . sum ( ) == <NUM_LIT> : <EOL> np . save ( out_file_path , feats , allow_pickle = False ) <EOL> else : <EOL> print ( f"<STR_LIT>" ) <EOL> pbar . set_description ( f"<STR_LIT>" ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> pbar . update ( <NUM_LIT> ) <EOL> print ( "<STR_LIT>" ) <EOL> </s>
<s> import os <EOL> import torch <EOL> from collections import OrderedDict <EOL> def extract ( ckpt ) : <EOL> a = ckpt [ "<STR_LIT>" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ "<STR_LIT>" ] = { } <EOL> for key in a . keys ( ) : <EOL> if "<STR_LIT>" in key : <EOL> continue <EOL> opt [ "<STR_LIT>" ] [ key ] = a [ key ] <EOL> return opt <EOL> def model_blender ( name , path1 , path2 , ratio ) : <EOL> try : <EOL> message = f"<STR_LIT>" <EOL> ckpt1 = torch . load ( path1 , map_location = "<STR_LIT>" ) <EOL> ckpt2 = torch . load ( path2 , map_location = "<STR_LIT>" ) <EOL> cfg = ckpt1 [ "<STR_LIT>" ] <EOL> cfg_f0 = ckpt1 [ "<STR_LIT>" ] <EOL> cfg_version = ckpt1 [ "<STR_LIT>" ] <EOL> if "<STR_LIT>" in ckpt1 : <EOL> ckpt1 = extract ( ckpt1 ) <EOL> else : <EOL> ckpt1 = ckpt1 [ "<STR_LIT>" ] <EOL> if "<STR_LIT>" in ckpt2 : <EOL> ckpt2 = extract ( ckpt2 ) <EOL> else : <EOL> ckpt2 = ckpt2 [ "<STR_LIT>" ] <EOL> if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : <EOL> return "<STR_LIT>" <EOL> opt = OrderedDict ( ) <EOL> opt [ "<STR_LIT>" ] = { } <EOL> for key in ckpt1 . keys ( ) : <EOL> if key == "<STR_LIT>" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : <EOL> min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) <EOL> opt [ "<STR_LIT>" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) <EOL> ) . half ( ) <EOL> else : <EOL> opt [ "<STR_LIT>" ] [ key ] = ( <EOL> ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) <EOL> ) . half ( ) <EOL> opt [ "<STR_LIT>" ] = cfg <EOL> opt [ "<STR_LIT>" ] = message <EOL> opt [ "<STR_LIT>" ] = cfg_f0 <EOL> opt [ "<STR_LIT>" ] = cfg_version <EOL> opt [ "<STR_LIT>" ] = message <EOL> torch . save ( opt , os . path . join ( "<STR_LIT>" , "<STR_LIT>" % name ) ) <EOL> print ( message ) <EOL> return message , os . path . join ( "<STR_LIT>" , "<STR_LIT>" % name ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return error <EOL> </s>
<s> import math <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> from . import commons <EOL> from . modules import LayerNorm <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = <NUM_LIT> , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> window_size = window_size , <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask ) : <EOL> attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . attn_layers [ i ] ( x , x , attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> hidden_channels , <EOL> filter_channels , <EOL> n_heads , <EOL> n_layers , <EOL> kernel_size = <NUM_LIT> , <EOL> p_dropout = <NUM_LIT> , <EOL> proximal_bias = False , <EOL> proximal_init = True , <EOL> ** kwargs <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . hidden_channels = hidden_channels <EOL> self . filter_channels = filter_channels <EOL> self . n_heads = n_heads <EOL> self . n_layers = n_layers <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> self . self_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_0 = nn . ModuleList ( ) <EOL> self . encdec_attn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_1 = nn . ModuleList ( ) <EOL> self . ffn_layers = nn . ModuleList ( ) <EOL> self . norm_layers_2 = nn . ModuleList ( ) <EOL> for i in range ( self . n_layers ) : <EOL> self . self_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> n_heads , <EOL> p_dropout = p_dropout , <EOL> proximal_bias = proximal_bias , <EOL> proximal_init = proximal_init , <EOL> ) <EOL> ) <EOL> self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . encdec_attn_layers . append ( <EOL> MultiHeadAttention ( <EOL> hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout <EOL> ) <EOL> ) <EOL> self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) <EOL> self . ffn_layers . append ( <EOL> FFN ( <EOL> hidden_channels , <EOL> hidden_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = p_dropout , <EOL> causal = True , <EOL> ) <EOL> ) <EOL> self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) <EOL> def forward ( self , x , x_mask , h , h_mask ) : <EOL> self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( <EOL> device = x . device , dtype = x . dtype <EOL> ) <EOL> encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) <EOL> x = x * x_mask <EOL> for i in range ( self . n_layers ) : <EOL> y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_0 [ i ] ( x + y ) <EOL> y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_1 [ i ] ( x + y ) <EOL> y = self . ffn_layers [ i ] ( x , x_mask ) <EOL> y = self . drop ( y ) <EOL> x = self . norm_layers_2 [ i ] ( x + y ) <EOL> x = x * x_mask <EOL> return x <EOL> class MultiHeadAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> channels , <EOL> out_channels , <EOL> n_heads , <EOL> p_dropout = <NUM_LIT> , <EOL> window_size = None , <EOL> heads_share = True , <EOL> block_length = None , <EOL> proximal_bias = False , <EOL> proximal_init = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert channels % n_heads == <NUM_LIT> <EOL> self . channels = channels <EOL> self . out_channels = out_channels <EOL> self . n_heads = n_heads <EOL> self . p_dropout = p_dropout <EOL> self . window_size = window_size <EOL> self . heads_share = heads_share <EOL> self . block_length = block_length <EOL> self . proximal_bias = proximal_bias <EOL> self . proximal_init = proximal_init <EOL> self . attn = None <EOL> self . k_channels = channels // n_heads <EOL> self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) <EOL> self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> if window_size is not None : <EOL> n_heads_rel = <NUM_LIT> if heads_share else n_heads <EOL> rel_stddev = self . k_channels ** - <NUM_LIT> <EOL> self . emb_rel_k = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> self . emb_rel_v = nn . Parameter ( <EOL> torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) <EOL> * rel_stddev <EOL> ) <EOL> nn . init . xavier_uniform_ ( self . conv_q . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_k . weight ) <EOL> nn . init . xavier_uniform_ ( self . conv_v . weight ) <EOL> if proximal_init : <EOL> with torch . no_grad ( ) : <EOL> self . conv_k . weight . copy_ ( self . conv_q . weight ) <EOL> self . conv_k . bias . copy_ ( self . conv_q . bias ) <EOL> def forward ( self , x , c , attn_mask = None ) : <EOL> q = self . conv_q ( x ) <EOL> k = self . conv_k ( c ) <EOL> v = self . conv_v ( c ) <EOL> x , self . attn = self . attention ( q , k , v , mask = attn_mask ) <EOL> x = self . conv_o ( x ) <EOL> return x <EOL> def attention ( self , query , key , value , mask = None ) : <EOL> b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) <EOL> query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> if self . window_size is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , "<STR_LIT>" <EOL> key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) <EOL> rel_logits = self . _matmul_with_relative_keys ( <EOL> query / math . sqrt ( self . k_channels ) , key_relative_embeddings <EOL> ) <EOL> scores_local = self . _relative_position_to_absolute_position ( rel_logits ) <EOL> scores = scores + scores_local <EOL> if self . proximal_bias : <EOL> assert t_s == t_t , "<STR_LIT>" <EOL> scores = scores + self . _attention_bias_proximal ( t_s ) . to ( <EOL> device = scores . device , dtype = scores . dtype <EOL> ) <EOL> if mask is not None : <EOL> scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> if self . block_length is not None : <EOL> assert ( <EOL> t_s == t_t <EOL> ) , "<STR_LIT>" <EOL> block_mask = ( <EOL> torch . ones_like ( scores ) <EOL> . triu ( - self . block_length ) <EOL> . tril ( self . block_length ) <EOL> ) <EOL> scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) <EOL> p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) <EOL> p_attn = self . drop ( p_attn ) <EOL> output = torch . matmul ( p_attn , value ) <EOL> if self . window_size is not None : <EOL> relative_weights = self . _absolute_position_to_relative_position ( p_attn ) <EOL> value_relative_embeddings = self . _get_relative_embeddings ( <EOL> self . emb_rel_v , t_s <EOL> ) <EOL> output = output + self . _matmul_with_relative_values ( <EOL> relative_weights , value_relative_embeddings <EOL> ) <EOL> output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) <EOL> return output , p_attn <EOL> def _matmul_with_relative_values ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) <EOL> return ret <EOL> def _matmul_with_relative_keys ( self , x , y ) : <EOL> ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) <EOL> return ret <EOL> def _get_relative_embeddings ( self , relative_embeddings , length ) : <EOL> pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) <EOL> slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) <EOL> slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> <EOL> if pad_length > <NUM_LIT> : <EOL> padded_relative_embeddings = F . pad ( <EOL> relative_embeddings , <EOL> commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , <EOL> ) <EOL> else : <EOL> padded_relative_embeddings = relative_embeddings <EOL> used_relative_embeddings = padded_relative_embeddings [ <EOL> : , slice_start_position : slice_end_position <EOL> ] <EOL> return used_relative_embeddings <EOL> def _relative_position_to_absolute_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) <EOL> x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) <EOL> x_flat = F . pad ( <EOL> x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ <EOL> : , : , : length , length - <NUM_LIT> : <EOL> ] <EOL> return x_final <EOL> def _absolute_position_to_relative_position ( self , x ) : <EOL> batch , heads , length , _ = x . size ( ) <EOL> x = F . pad ( <EOL> x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) <EOL> ) <EOL> x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) <EOL> x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) <EOL> x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] <EOL> return x_final <EOL> def _attention_bias_proximal ( self , length ) : <EOL> r = torch . arange ( length , dtype = torch . float32 ) <EOL> diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) <EOL> return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) <EOL> class FFN ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> out_channels , <EOL> filter_channels , <EOL> kernel_size , <EOL> p_dropout = <NUM_LIT> , <EOL> activation = None , <EOL> causal = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . in_channels = in_channels <EOL> self . out_channels = out_channels <EOL> self . filter_channels = filter_channels <EOL> self . kernel_size = kernel_size <EOL> self . p_dropout = p_dropout <EOL> self . activation = activation <EOL> self . causal = causal <EOL> if causal : <EOL> self . padding = self . _causal_padding <EOL> else : <EOL> self . padding = self . _same_padding <EOL> self . conv_1 = nn . Conv1d ( in_channels , filter_channels , kernel_size ) <EOL> self . conv_2 = nn . Conv1d ( filter_channels , out_channels , kernel_size ) <EOL> self . drop = nn . Dropout ( p_dropout ) <EOL> def forward ( self , x , x_mask ) : <EOL> x = self . conv_1 ( self . padding ( x * x_mask ) ) <EOL> if self . activation == "<STR_LIT>" : <EOL> x = x * torch . sigmoid ( <NUM_LIT> * x ) <EOL> else : <EOL> x = torch . relu ( x ) <EOL> x = self . drop ( x ) <EOL> x = self . conv_2 ( self . padding ( x * x_mask ) ) <EOL> return x * x_mask <EOL> def _causal_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> pad_l = self . kernel_size - <NUM_LIT> <EOL> pad_r = <NUM_LIT> <EOL> padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] <EOL> x = F . pad ( x , commons . convert_pad_shape ( padding ) ) <EOL> return x <EOL> def _same_padding ( self , x ) : <EOL> if self . kernel_size == <NUM_LIT> : <EOL> return x <EOL> pad_l = ( self . kernel_size - <NUM_LIT> ) // <NUM_LIT> <EOL> pad_r = self . kernel_size // <NUM_LIT> <EOL> padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] <EOL> x = F . pad ( x , commons . convert_pad_shape ( padding ) ) <EOL> return x <EOL> </s>
<s> import os <EOL> import json <EOL> import pathlib <EOL> from random import shuffle <EOL> from rvc . configs . config import Config <EOL> config = Config ( ) <EOL> current_directory = os . getcwd ( ) <EOL> def generate_config ( rvc_version , sampling_rate , model_path ) : <EOL> if rvc_version == "<STR_LIT>" or sampling_rate == "<STR_LIT>" : <EOL> config_path = f"<STR_LIT>" <EOL> else : <EOL> config_path = f"<STR_LIT>" <EOL> config_save_path = os . path . join ( model_path , "<STR_LIT>" ) <EOL> if not pathlib . Path ( config_save_path ) . exists ( ) : <EOL> with open ( config_save_path , "<STR_LIT>" , encoding = "<STR_LIT>" ) as f : <EOL> json . dump ( <EOL> config . json_config [ config_path ] , <EOL> f , <EOL> ensure_ascii = False , <EOL> indent = <NUM_LIT> , <EOL> sort_keys = True , <EOL> ) <EOL> f . write ( "<STR_LIT>" ) <EOL> def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : <EOL> gt_wavs_dir = f"<STR_LIT>" <EOL> feature_dir = ( <EOL> f"<STR_LIT>" <EOL> if rvc_version == "<STR_LIT>" <EOL> else f"<STR_LIT>" <EOL> ) <EOL> if f0_method : <EOL> f0_dir = f"<STR_LIT>" <EOL> f0nsf_dir = f"<STR_LIT>" <EOL> names = ( <EOL> set ( [ name . split ( "<STR_LIT>" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) <EOL> & set ( [ name . split ( "<STR_LIT>" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) <EOL> & set ( [ name . split ( "<STR_LIT>" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) <EOL> & set ( [ name . split ( "<STR_LIT>" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) <EOL> ) <EOL> else : <EOL> names = set ( [ name . split ( "<STR_LIT>" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( <EOL> [ name . split ( "<STR_LIT>" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] <EOL> ) <EOL> options = [ ] <EOL> for name in names : <EOL> if f0_method : <EOL> options . append ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> else : <EOL> options . append ( f"<STR_LIT>" ) <EOL> fea_dim = <NUM_LIT> if rvc_version == "<STR_LIT>" else <NUM_LIT> <EOL> if f0_method : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> else : <EOL> for _ in range ( <NUM_LIT> ) : <EOL> options . append ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> shuffle ( options ) <EOL> with open ( f"<STR_LIT>" , "<STR_LIT>" ) as f : <EOL> f . write ( "<STR_LIT>" . join ( options ) ) <EOL> </s>
<s> from pypresence import Presence <EOL> import datetime as dt <EOL> import time <EOL> class RichPresenceManager : <EOL> def __init__ ( self ) : <EOL> self . client_id = "<STR_LIT>" <EOL> self . rpc = None <EOL> self . running = False <EOL> def start_presence ( self ) : <EOL> if not self . running : <EOL> self . running = True <EOL> self . rpc = Presence ( self . client_id ) <EOL> try : <EOL> self . rpc . connect ( ) <EOL> self . update_presence ( ) <EOL> except KeyboardInterrupt as error : <EOL> print ( error ) <EOL> self . rpc = None <EOL> self . running = False <EOL> except Exception as e : <EOL> print ( f"<STR_LIT>" ) <EOL> self . rpc = None <EOL> self . running = False <EOL> def update_presence ( self ) : <EOL> if self . rpc : <EOL> self . rpc . update ( <EOL> state = "<STR_LIT>" , <EOL> details = "<STR_LIT>" , <EOL> buttons = [ <EOL> { "<STR_LIT>" : "<STR_LIT>" , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : "<STR_LIT>" , "<STR_LIT>" : "<STR_LIT>" } , <EOL> ] , <EOL> large_image = "<STR_LIT>" , <EOL> large_text = "<STR_LIT>" , <EOL> start = dt . datetime . now ( ) . timestamp ( ) , <EOL> ) <EOL> def stop_presence ( self ) : <EOL> self . running = False <EOL> if self . rpc : <EOL> self . rpc . close ( ) <EOL> self . rpc = None <EOL> RPCManager = RichPresenceManager ( ) <EOL> </s>
<s> import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_small_model ( path , name , sr , if_f0 , version , epoch , step ) : <EOL> try : <EOL> ckpt = torch . load ( path , map_location = "<STR_LIT>" ) <EOL> pth_file = f"<STR_LIT>" <EOL> pth_file_old_version_path = os . path . join ( "<STR_LIT>" , f"<STR_LIT>" ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if "<STR_LIT>" not in key <EOL> } <EOL> ) <EOL> if "<STR_LIT>" in ckpt : <EOL> ckpt = ckpt [ "<STR_LIT>" ] <EOL> opt = OrderedDict ( ) <EOL> opt [ "<STR_LIT>" ] = { } <EOL> for key in ckpt . keys ( ) : <EOL> if "<STR_LIT>" in key : <EOL> continue <EOL> opt [ "<STR_LIT>" ] [ key ] = ckpt [ key ] . half ( ) <EOL> if sr == "<STR_LIT>" : <EOL> opt [ "<STR_LIT>" ] = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> "<STR_LIT>" , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> elif sr == "<STR_LIT>" : <EOL> if version == "<STR_LIT>" : <EOL> opt [ "<STR_LIT>" ] = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> "<STR_LIT>" , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> else : <EOL> opt [ "<STR_LIT>" ] = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> "<STR_LIT>" , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> elif sr == "<STR_LIT>" : <EOL> if version == "<STR_LIT>" : <EOL> opt [ "<STR_LIT>" ] = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> "<STR_LIT>" , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> else : <EOL> opt [ "<STR_LIT>" ] = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> "<STR_LIT>" , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> opt [ "<STR_LIT>" ] = epoch <EOL> opt [ "<STR_LIT>" ] = step <EOL> opt [ "<STR_LIT>" ] = sr <EOL> opt [ "<STR_LIT>" ] = int ( if_f0 ) <EOL> opt [ "<STR_LIT>" ] = version <EOL> opt [ "<STR_LIT>" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f"<STR_LIT>" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ "<STR_LIT>" ] = model_hash <EOL> model = torch . load ( pth_file_old_version_path , map_location = torch . device ( "<STR_LIT>" ) ) <EOL> torch . save ( <EOL> replace_keys_in_dict ( <EOL> replace_keys_in_dict ( <EOL> model , "<STR_LIT>" , "<STR_LIT>" <EOL> ) , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> pth_file_old_version_path , <EOL> ) <EOL> os . remove ( pth_file_old_version_path ) <EOL> os . rename ( pth_file_old_version_path , pth_file ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> </s>
<s> import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . themes . loadThemes as loadThemes <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> def theme_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> themes_select = gr . Dropdown ( <EOL> loadThemes . get_list ( ) , <EOL> value = loadThemes . read_json ( ) , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> ) <EOL> themes_select . change ( <EOL> fn = loadThemes . select_theme , <EOL> inputs = themes_select , <EOL> outputs = [ ] , <EOL> ) <EOL> </s>
<s> import os <EOL> import sys <EOL> import gradio as gr <EOL> import json <EOL> from assets . i18n . i18n import I18nAuto <EOL> from assets . discord_presence import RPCManager <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> def load_config_presence ( ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ "<STR_LIT>" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> config [ "<STR_LIT>" ] = value <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def presence_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_presence ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> if load_config_presence ( ) == True : <EOL> try : <EOL> RPCManager . start_presence ( ) <EOL> except KeyboardInterrupt : <EOL> RPCManager . stop_presence ( ) <EOL> else : <EOL> RPCManager . stop_presence ( ) <EOL> </s>
<s> import os <EOL> import sys <EOL> import numpy as np <EOL> import pyworld <EOL> import torchcrepe <EOL> import torch <EOL> import parselmouth <EOL> import tqdm <EOL> from multiprocessing import Process , cpu_count <EOL> current_directory = os . getcwd ( ) <EOL> sys . path . append ( current_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> exp_dir = sys . argv [ <NUM_LIT> ] <EOL> f0_method = sys . argv [ <NUM_LIT> ] <EOL> num_processes = cpu_count ( ) <EOL> try : <EOL> hop_length = int ( sys . argv [ <NUM_LIT> ] ) <EOL> except ValueError : <EOL> hop_length = <NUM_LIT> <EOL> DoFormant = False <EOL> Quefrency = <NUM_LIT> <EOL> Timbre = <NUM_LIT> <EOL> class FeatureInput : <EOL> def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : <EOL> self . fs = sample_rate <EOL> self . hop = hop_size <EOL> self . f0_method_dict = self . get_f0_method_dict ( ) <EOL> self . f0_bin = <NUM_LIT> <EOL> self . f0_max = <NUM_LIT> <EOL> self . f0_min = <NUM_LIT> <EOL> self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) <EOL> self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) <EOL> def mncrepe ( self , method , x , p_len , hop_length ) : <EOL> f0 = None <EOL> torch_device_index = <NUM_LIT> <EOL> torch_device = ( <EOL> torch . device ( f"<STR_LIT>" ) <EOL> if torch . cuda . is_available ( ) <EOL> else ( <EOL> torch . device ( "<STR_LIT>" ) <EOL> if torch . backends . mps . is_available ( ) <EOL> else torch . device ( "<STR_LIT>" ) <EOL> ) <EOL> ) <EOL> audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) <EOL> audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> if method == "<STR_LIT>" : <EOL> pitch = torchcrepe . predict ( <EOL> audio , <EOL> self . fs , <EOL> hop_length , <EOL> self . f0_min , <EOL> self . f0_max , <EOL> "<STR_LIT>" , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_pm ( self , x , p_len ) : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . fs ) <EOL> . to_pitch_ac ( <EOL> time_step = <NUM_LIT> / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = self . f0_min , <EOL> pitch_ceiling = self . f0_max , <EOL> ) <EOL> . selected_array [ "<STR_LIT>" ] <EOL> ) <EOL> return np . pad ( <EOL> f0 , <EOL> [ <EOL> [ <EOL> max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , <EOL> ] <EOL> ] , <EOL> mode = "<STR_LIT>" , <EOL> ) <EOL> def get_harvest ( self , x ) : <EOL> f0_spectral = pyworld . harvest ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_dio ( self , x ) : <EOL> f0_spectral = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . fs , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop / self . fs , <EOL> ) <EOL> return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) <EOL> def get_rmvpe ( self , x ) : <EOL> if not hasattr ( self , "<STR_LIT>" ) : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( "<STR_LIT>" , is_half = False , device = "<STR_LIT>" ) <EOL> return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> def get_f0_method_dict ( self ) : <EOL> return { <EOL> "<STR_LIT>" : self . get_pm , <EOL> "<STR_LIT>" : self . get_harvest , <EOL> "<STR_LIT>" : self . get_dio , <EOL> "<STR_LIT>" : self . get_rmvpe , <EOL> } <EOL> def compute_f0 ( self , path , f0_method , hop_length ) : <EOL> x = load_audio ( path , self . fs ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop <EOL> if f0_method in self . f0_method_dict : <EOL> f0 = ( <EOL> self . f0_method_dict [ f0_method ] ( x , p_len ) <EOL> if f0_method == "<STR_LIT>" <EOL> else self . f0_method_dict [ f0_method ] ( x ) <EOL> ) <EOL> elif f0_method == "<STR_LIT>" : <EOL> f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) <EOL> return f0 <EOL> def coarse_f0 ( self , f0 ) : <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( <EOL> self . f0_bin - <NUM_LIT> <EOL> ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( int ) <EOL> assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( <EOL> f0_coarse . max ( ) , <EOL> f0_coarse . min ( ) , <EOL> ) <EOL> return f0_coarse <EOL> def process_paths ( self , paths , f0_method , hop_length , thread_n ) : <EOL> if len ( paths ) == <NUM_LIT> : <EOL> print ( "<STR_LIT>" ) <EOL> return <EOL> with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : <EOL> description = f"<STR_LIT>" <EOL> pbar . set_description ( description ) <EOL> for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : <EOL> try : <EOL> if os . path . exists ( opt_path1 + "<STR_LIT>" ) and os . path . exists ( <EOL> opt_path2 + "<STR_LIT>" <EOL> ) : <EOL> pbar . update ( <NUM_LIT> ) <EOL> continue <EOL> feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) <EOL> np . save ( <EOL> opt_path2 , <EOL> feature_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> coarse_pit = self . coarse_f0 ( feature_pit ) <EOL> np . save ( <EOL> opt_path1 , <EOL> coarse_pit , <EOL> allow_pickle = False , <EOL> ) <EOL> pbar . update ( <NUM_LIT> ) <EOL> except Exception as error : <EOL> print ( f"<STR_LIT>" ) <EOL> if __name__ == "<STR_LIT>" : <EOL> feature_input = FeatureInput ( ) <EOL> paths = [ ] <EOL> input_root = f"<STR_LIT>" <EOL> output_root1 = f"<STR_LIT>" <EOL> output_root2 = f"<STR_LIT>" <EOL> os . makedirs ( output_root1 , exist_ok = True ) <EOL> os . makedirs ( output_root2 , exist_ok = True ) <EOL> for name in sorted ( list ( os . listdir ( input_root ) ) ) : <EOL> input_path = f"<STR_LIT>" <EOL> if "<STR_LIT>" in input_path : <EOL> continue <EOL> output_path1 = f"<STR_LIT>" <EOL> output_path2 = f"<STR_LIT>" <EOL> paths . append ( [ input_path , output_path1 , output_path2 ] ) <EOL> processes = [ ] <EOL> print ( "<STR_LIT>" + f0_method ) <EOL> for i in range ( num_processes ) : <EOL> p = Process ( <EOL> target = feature_input . process_paths , <EOL> args = ( paths [ i : : num_processes ] , f0_method , hop_length , i ) , <EOL> ) <EOL> processes . append ( p ) <EOL> p . start ( ) <EOL> for i in range ( num_processes ) : <EOL> processes [ i ] . join ( ) <EOL> </s>
<s> import math <EOL> import numpy as np <EOL> import torch <EOL> from torch import nn <EOL> from torch . nn import functional as F <EOL> def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : <EOL> classname = m . __class__ . __name__ <EOL> if classname . find ( "<STR_LIT>" ) != - <NUM_LIT> : <EOL> m . weight . data . normal_ ( mean , std ) <EOL> def get_padding ( kernel_size , dilation = <NUM_LIT> ) : <EOL> return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def kl_divergence ( m_p , logs_p , m_q , logs_q ) : <EOL> kl = ( logs_q - logs_p ) - <NUM_LIT> <EOL> kl += ( <EOL> <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) <EOL> ) <EOL> return kl <EOL> def rand_gumbel ( shape ) : <EOL> uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> <EOL> return - torch . log ( - torch . log ( uniform_samples ) ) <EOL> def rand_gumbel_like ( x ) : <EOL> g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) <EOL> return g <EOL> def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , : , idx_str : idx_end ] <EOL> return ret <EOL> def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : <EOL> ret = torch . zeros_like ( x [ : , : segment_size ] ) <EOL> for i in range ( x . size ( <NUM_LIT> ) ) : <EOL> idx_str = ids_str [ i ] <EOL> idx_end = idx_str + segment_size <EOL> ret [ i ] = x [ i , idx_str : idx_end ] <EOL> return ret <EOL> def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : <EOL> b , d , t = x . size ( ) <EOL> if x_lengths is None : <EOL> x_lengths = t <EOL> ids_str_max = x_lengths - segment_size + <NUM_LIT> <EOL> ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) <EOL> ret = slice_segments ( x , ids_str , segment_size ) <EOL> return ret , ids_str <EOL> def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> position = torch . arange ( length , dtype = torch . float ) <EOL> num_timescales = channels // <NUM_LIT> <EOL> log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( <EOL> num_timescales - <NUM_LIT> <EOL> ) <EOL> inv_timescales = min_timescale * torch . exp ( <EOL> torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment <EOL> ) <EOL> scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) <EOL> signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) <EOL> signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) <EOL> signal = signal . view ( <NUM_LIT> , channels , length ) <EOL> return signal <EOL> def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return x + signal . to ( dtype = x . dtype , device = x . device ) <EOL> def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : <EOL> b , channels , length = x . size ( ) <EOL> signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) <EOL> return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) <EOL> def subsequent_mask ( length ) : <EOL> mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> return mask <EOL> @ torch . jit . script <EOL> def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : <EOL> n_channels_int = n_channels [ <NUM_LIT> ] <EOL> in_act = input_a + input_b <EOL> t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) <EOL> s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) <EOL> acts = t_act * s_act <EOL> return acts <EOL> def convert_pad_shape ( pad_shape ) : <EOL> l = pad_shape [ : : - <NUM_LIT> ] <EOL> pad_shape = [ item for sublist in l for item in sublist ] <EOL> return pad_shape <EOL> def shift_1d ( x ) : <EOL> x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] <EOL> return x <EOL> def sequence_mask ( length , max_length = None ) : <EOL> if max_length is None : <EOL> max_length = length . max ( ) <EOL> x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) <EOL> return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) <EOL> def generate_path ( duration , mask ) : <EOL> device = duration . device <EOL> b , _ , t_y , t_x = mask . shape <EOL> cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) <EOL> cum_duration_flat = cum_duration . view ( b * t_x ) <EOL> path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) <EOL> path = path . view ( b , t_x , t_y ) <EOL> path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] <EOL> path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask <EOL> return path <EOL> def clip_grad_value_ ( parameters , clip_value , norm_type = <NUM_LIT> ) : <EOL> if isinstance ( parameters , torch . Tensor ) : <EOL> parameters = [ parameters ] <EOL> parameters = list ( filter ( lambda p : p . grad is not None , parameters ) ) <EOL> norm_type = float ( norm_type ) <EOL> if clip_value is not None : <EOL> clip_value = float ( clip_value ) <EOL> total_norm = <NUM_LIT> <EOL> for p in parameters : <EOL> param_norm = p . grad . data . norm ( norm_type ) <EOL> total_norm += param_norm . item ( ) ** norm_type <EOL> if clip_value is not None : <EOL> p . grad . data . clamp_ ( min = - clip_value , max = clip_value ) <EOL> total_norm = total_norm ** ( <NUM_LIT> / norm_type ) <EOL> return total_norm <EOL> </s>
<s> import os <EOL> import wget <EOL> url_base = "<STR_LIT>" <EOL> pretraineds_v1_list = [ <EOL> ( <EOL> "<STR_LIT>" , <EOL> [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> pretraineds_v2_list = [ <EOL> ( <EOL> "<STR_LIT>" , <EOL> [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> models_list = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] <EOL> executables_list = [ "<STR_LIT>" , "<STR_LIT>" ] <EOL> folder_mapping_list = { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : <EOL> def download_files ( file_list ) : <EOL> for file_name in file_list : <EOL> destination_path = os . path . join ( file_name ) <EOL> url = f"<STR_LIT>" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or "<STR_LIT>" , exist_ok = True ) <EOL> print ( f"<STR_LIT>" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if models == "<STR_LIT>" : <EOL> download_files ( models_list ) <EOL> if exe == "<STR_LIT>" and os . name == "<STR_LIT>" : <EOL> download_files ( executables_list ) <EOL> if pretraineds_v1 == "<STR_LIT>" : <EOL> for remote_folder , file_list in pretraineds_v1_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , "<STR_LIT>" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f"<STR_LIT>" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or "<STR_LIT>" , exist_ok = True ) <EOL> print ( f"<STR_LIT>" ) <EOL> wget . download ( url , out = destination_path ) <EOL> if pretraineds_v2 == "<STR_LIT>" : <EOL> for remote_folder , file_list in pretraineds_v2_list : <EOL> local_folder = folder_mapping_list . get ( remote_folder , "<STR_LIT>" ) <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> url = f"<STR_LIT>" <EOL> if not os . path . exists ( destination_path ) : <EOL> os . makedirs ( os . path . dirname ( destination_path ) or "<STR_LIT>" , exist_ok = True ) <EOL> print ( f"<STR_LIT>" ) <EOL> wget . download ( url , out = destination_path ) <EOL> </s>
<s> import os , sys <EOL> import json <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> def load_local_version ( ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ "<STR_LIT>" ] <EOL> def obtain_tag_name ( ) : <EOL> url = "<STR_LIT>" <EOL> try : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> data = response . json ( ) <EOL> tag_name = data [ "<STR_LIT>" ] <EOL> return tag_name <EOL> except requests . exceptions . RequestException as e : <EOL> print ( f"<STR_LIT>" ) <EOL> return None <EOL> def compare_version ( ) : <EOL> local_version = load_local_version ( ) <EOL> online_version = obtain_tag_name ( ) <EOL> elements_online_version = list ( map ( int , online_version . split ( "<STR_LIT>" ) ) ) <EOL> elements_local_version = list ( map ( int , local_version . split ( "<STR_LIT>" ) ) ) <EOL> for online , local in zip ( elements_online_version , elements_local_version ) : <EOL> if local < online : <EOL> return f"<STR_LIT>" <EOL> return f"<STR_LIT>" <EOL> </s>
<s> from __future__ import annotations <EOL> from typing import Iterable <EOL> import gradio as gr <EOL> from gradio . themes . base import Base <EOL> from gradio . themes . utils import colors , fonts , sizes <EOL> import time <EOL> class Applio ( Base ) : <EOL> def __init__ ( <EOL> self , <EOL> * , <EOL> primary_hue : colors . Color | str = colors . green , <EOL> secondary_hue : colors . Color | str = colors . emerald , <EOL> neutral_hue : colors . Color | str = colors . neutral , <EOL> spacing_size : sizes . Size | str = sizes . spacing_md , <EOL> radius_size : sizes . Size | str = sizes . radius_md , <EOL> text_size : sizes . Size | str = sizes . text_lg , <EOL> font : fonts . Font | str | Iterable [ fonts . Font | str ] = ( <EOL> "<STR_LIT>" , <EOL> fonts . GoogleFont ( "<STR_LIT>" ) , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> font_mono : fonts . Font | str | Iterable [ fonts . Font | str ] = ( <EOL> "<STR_LIT>" , <EOL> fonts . GoogleFont ( "<STR_LIT>" ) , <EOL> ) , <EOL> ) : <EOL> super ( ) . __init__ ( <EOL> primary_hue = primary_hue , <EOL> secondary_hue = secondary_hue , <EOL> neutral_hue = neutral_hue , <EOL> spacing_size = spacing_size , <EOL> radius_size = radius_size , <EOL> text_size = text_size , <EOL> font = font , <EOL> font_mono = font_mono , <EOL> ) <EOL> self . name = ( "<STR_LIT>" , ) <EOL> self . secondary_100 = ( "<STR_LIT>" , ) <EOL> self . secondary_200 = ( "<STR_LIT>" , ) <EOL> self . secondary_300 = ( "<STR_LIT>" , ) <EOL> self . secondary_400 = ( "<STR_LIT>" , ) <EOL> self . secondary_50 = ( "<STR_LIT>" , ) <EOL> self . secondary_500 = ( "<STR_LIT>" , ) <EOL> self . secondary_600 = ( "<STR_LIT>" , ) <EOL> self . secondary_700 = ( "<STR_LIT>" , ) <EOL> self . secondary_800 = ( "<STR_LIT>" , ) <EOL> self . secondary_900 = ( "<STR_LIT>" , ) <EOL> self . secondary_950 = ( "<STR_LIT>" , ) <EOL> super ( ) . set ( <EOL> background_fill_primary = "<STR_LIT>" , <EOL> background_fill_primary_dark = "<STR_LIT>" , <EOL> background_fill_secondary = "<STR_LIT>" , <EOL> background_fill_secondary_dark = "<STR_LIT>" , <EOL> block_background_fill = "<STR_LIT>" , <EOL> block_background_fill_dark = "<STR_LIT>" , <EOL> block_border_color = "<STR_LIT>" , <EOL> block_border_color_dark = "<STR_LIT>" , <EOL> block_border_width = "<STR_LIT>" , <EOL> block_border_width_dark = "<STR_LIT>" , <EOL> block_info_text_color = "<STR_LIT>" , <EOL> block_info_text_color_dark = "<STR_LIT>" , <EOL> block_info_text_size = "<STR_LIT>" , <EOL> block_info_text_weight = "<STR_LIT>" , <EOL> block_label_background_fill = "<STR_LIT>" , <EOL> block_label_background_fill_dark = "<STR_LIT>" , <EOL> block_label_border_color = "<STR_LIT>" , <EOL> block_label_border_color_dark = "<STR_LIT>" , <EOL> block_label_border_width = "<STR_LIT>" , <EOL> block_label_border_width_dark = "<STR_LIT>" , <EOL> block_label_margin = "<STR_LIT>" , <EOL> block_label_padding = "<STR_LIT>" , <EOL> block_label_radius = "<STR_LIT>" , <EOL> block_label_right_radius = "<STR_LIT>" , <EOL> block_label_shadow = "<STR_LIT>" , <EOL> block_label_text_color = "<STR_LIT>" , <EOL> block_label_text_color_dark = "<STR_LIT>" , <EOL> block_label_text_weight = "<STR_LIT>" , <EOL> block_padding = "<STR_LIT>" , <EOL> block_radius = "<STR_LIT>" , <EOL> block_shadow = "<STR_LIT>" , <EOL> block_shadow_dark = "<STR_LIT>" , <EOL> block_title_background_fill = "<STR_LIT>" , <EOL> block_title_background_fill_dark = "<STR_LIT>" , <EOL> block_title_border_color = "<STR_LIT>" , <EOL> block_title_border_color_dark = "<STR_LIT>" , <EOL> block_title_border_width = "<STR_LIT>" , <EOL> block_title_padding = "<STR_LIT>" , <EOL> block_title_radius = "<STR_LIT>" , <EOL> block_title_text_color = "<STR_LIT>" , <EOL> block_title_text_color_dark = "<STR_LIT>" , <EOL> block_title_text_size = "<STR_LIT>" , <EOL> block_title_text_weight = "<STR_LIT>" , <EOL> body_background_fill = "<STR_LIT>" , <EOL> body_background_fill_dark = "<STR_LIT>" , <EOL> body_text_color = "<STR_LIT>" , <EOL> body_text_color_dark = "<STR_LIT>" , <EOL> body_text_color_subdued = "<STR_LIT>" , <EOL> body_text_color_subdued_dark = "<STR_LIT>" , <EOL> body_text_size = "<STR_LIT>" , <EOL> body_text_weight = "<STR_LIT>" , <EOL> border_color_accent = "<STR_LIT>" , <EOL> border_color_accent_dark = "<STR_LIT>" , <EOL> border_color_primary = "<STR_LIT>" , <EOL> border_color_primary_dark = "<STR_LIT>" , <EOL> button_border_width = "<STR_LIT>" , <EOL> button_border_width_dark = "<STR_LIT>" , <EOL> button_cancel_background_fill = "<STR_LIT>" , <EOL> button_cancel_background_fill_dark = "<STR_LIT>" , <EOL> button_cancel_background_fill_hover = "<STR_LIT>" , <EOL> button_cancel_background_fill_hover_dark = "<STR_LIT>" , <EOL> button_cancel_border_color = "<STR_LIT>" , <EOL> button_cancel_border_color_dark = "<STR_LIT>" , <EOL> button_cancel_border_color_hover = "<STR_LIT>" , <EOL> button_cancel_border_color_hover_dark = "<STR_LIT>" , <EOL> button_cancel_text_color = "<STR_LIT>" , <EOL> button_cancel_text_color_dark = "<STR_LIT>" , <EOL> button_cancel_text_color_hover = "<STR_LIT>" , <EOL> button_cancel_text_color_hover_dark = "<STR_LIT>" , <EOL> button_large_padding = "<STR_LIT>" , <EOL> button_large_radius = "<STR_LIT>" , <EOL> button_large_text_size = "<STR_LIT>" , <EOL> button_large_text_weight = "<STR_LIT>" , <EOL> button_primary_background_fill = "<STR_LIT>" , <EOL> button_primary_background_fill_dark = "<STR_LIT>" , <EOL> button_primary_background_fill_hover = "<STR_LIT>" , <EOL> button_primary_background_fill_hover_dark = "<STR_LIT>" , <EOL> button_primary_border_color = "<STR_LIT>" , <EOL> button_primary_border_color_dark = "<STR_LIT>" , <EOL> button_primary_border_color_hover = "<STR_LIT>" , <EOL> button_primary_border_color_hover_dark = "<STR_LIT>" , <EOL> button_primary_text_color = "<STR_LIT>" , <EOL> button_primary_text_color_dark = "<STR_LIT>" , <EOL> button_primary_text_color_hover = "<STR_LIT>" , <EOL> button_primary_text_color_hover_dark = "<STR_LIT>" , <EOL> button_secondary_background_fill = "<STR_LIT>" , <EOL> button_secondary_background_fill_dark = "<STR_LIT>" , <EOL> button_secondary_background_fill_hover = "<STR_LIT>" , <EOL> button_secondary_background_fill_hover_dark = "<STR_LIT>" , <EOL> button_secondary_border_color = "<STR_LIT>" , <EOL> button_secondary_border_color_dark = "<STR_LIT>" , <EOL> button_secondary_border_color_hover = "<STR_LIT>" , <EOL> button_secondary_border_color_hover_dark = "<STR_LIT>" , <EOL> button_secondary_text_color = "<STR_LIT>" , <EOL> button_secondary_text_color_dark = "<STR_LIT>" , <EOL> button_secondary_text_color_hover = "<STR_LIT>" , <EOL> button_secondary_text_color_hover_dark = "<STR_LIT>" , <EOL> button_shadow = "<STR_LIT>" , <EOL> button_shadow_active = "<STR_LIT>" , <EOL> button_shadow_hover = "<STR_LIT>" , <EOL> button_small_padding = "<STR_LIT>" , <EOL> button_small_radius = "<STR_LIT>" , <EOL> button_small_text_size = "<STR_LIT>" , <EOL> button_small_text_weight = "<STR_LIT>" , <EOL> button_transition = "<STR_LIT>" , <EOL> checkbox_background_color = "<STR_LIT>" , <EOL> checkbox_background_color_dark = "<STR_LIT>" , <EOL> checkbox_background_color_focus = "<STR_LIT>" , <EOL> checkbox_background_color_focus_dark = "<STR_LIT>" , <EOL> checkbox_background_color_hover = "<STR_LIT>" , <EOL> checkbox_background_color_hover_dark = "<STR_LIT>" , <EOL> checkbox_background_color_selected = "<STR_LIT>" , <EOL> checkbox_background_color_selected_dark = "<STR_LIT>" , <EOL> checkbox_border_color = "<STR_LIT>" , <EOL> checkbox_border_color_dark = "<STR_LIT>" , <EOL> checkbox_border_color_focus = "<STR_LIT>" , <EOL> checkbox_border_color_focus_dark = "<STR_LIT>" , <EOL> checkbox_border_color_hover = "<STR_LIT>" , <EOL> checkbox_border_color_hover_dark = "<STR_LIT>" , <EOL> checkbox_border_color_selected = "<STR_LIT>" , <EOL> checkbox_border_color_selected_dark = "<STR_LIT>" , <EOL> checkbox_border_radius = "<STR_LIT>" , <EOL> checkbox_border_width = "<STR_LIT>" , <EOL> checkbox_border_width_dark = "<STR_LIT>" , <EOL> checkbox_check = "<STR_LIT>" , <EOL> checkbox_label_background_fill = "<STR_LIT>" , <EOL> checkbox_label_background_fill_dark = "<STR_LIT>" , <EOL> checkbox_label_background_fill_hover = "<STR_LIT>" , <EOL> checkbox_label_background_fill_hover_dark = "<STR_LIT>" , <EOL> checkbox_label_background_fill_selected = "<STR_LIT>" , <EOL> checkbox_label_background_fill_selected_dark = "<STR_LIT>" , <EOL> checkbox_label_border_color = "<STR_LIT>" , <EOL> checkbox_label_border_color_dark = "<STR_LIT>" , <EOL> checkbox_label_border_color_hover = "<STR_LIT>" , <EOL> checkbox_label_border_color_hover_dark = "<STR_LIT>" , <EOL> checkbox_label_border_width = "<STR_LIT>" , <EOL> checkbox_label_border_width_dark = "<STR_LIT>" , <EOL> checkbox_label_gap = "<STR_LIT>" , <EOL> checkbox_label_padding = "<STR_LIT>" , <EOL> checkbox_label_shadow = "<STR_LIT>" , <EOL> checkbox_label_text_color = "<STR_LIT>" , <EOL> checkbox_label_text_color_dark = "<STR_LIT>" , <EOL> checkbox_label_text_color_selected = "<STR_LIT>" , <EOL> checkbox_label_text_color_selected_dark = "<STR_LIT>" , <EOL> checkbox_label_text_size = "<STR_LIT>" , <EOL> checkbox_label_text_weight = "<STR_LIT>" , <EOL> checkbox_shadow = "<STR_LIT>" , <EOL> color_accent = "<STR_LIT>" , <EOL> color_accent_soft = "<STR_LIT>" , <EOL> color_accent_soft_dark = "<STR_LIT>" , <EOL> container_radius = "<STR_LIT>" , <EOL> embed_radius = "<STR_LIT>" , <EOL> error_background_fill = "<STR_LIT>" , <EOL> error_background_fill_dark = "<STR_LIT>" , <EOL> error_border_color = "<STR_LIT>" , <EOL> error_border_color_dark = "<STR_LIT>" , <EOL> error_border_width = "<STR_LIT>" , <EOL> error_border_width_dark = "<STR_LIT>" , <EOL> error_text_color = "<STR_LIT>" , <EOL> error_text_color_dark = "<STR_LIT>" , <EOL> form_gap_width = "<STR_LIT>" , <EOL> input_background_fill = "<STR_LIT>" , <EOL> input_background_fill_dark = "<STR_LIT>" , <EOL> input_background_fill_focus = "<STR_LIT>" , <EOL> input_background_fill_focus_dark = "<STR_LIT>" , <EOL> input_background_fill_hover = "<STR_LIT>" , <EOL> input_background_fill_hover_dark = "<STR_LIT>" , <EOL> input_border_color = "<STR_LIT>" , <EOL> input_border_color_dark = "<STR_LIT>" , <EOL> input_border_color_focus = "<STR_LIT>" , <EOL> input_border_color_focus_dark = "<STR_LIT>" , <EOL> input_border_color_hover = "<STR_LIT>" , <EOL> input_border_color_hover_dark = "<STR_LIT>" , <EOL> input_border_width = "<STR_LIT>" , <EOL> input_border_width_dark = "<STR_LIT>" , <EOL> input_padding = "<STR_LIT>" , <EOL> input_placeholder_color = "<STR_LIT>" , <EOL> input_placeholder_color_dark = "<STR_LIT>" , <EOL> input_radius = "<STR_LIT>" , <EOL> input_shadow = "<STR_LIT>" , <EOL> input_shadow_dark = "<STR_LIT>" , <EOL> input_shadow_focus = "<STR_LIT>" , <EOL> input_shadow_focus_dark = "<STR_LIT>" , <EOL> input_text_size = "<STR_LIT>" , <EOL> input_text_weight = "<STR_LIT>" , <EOL> layout_gap = "<STR_LIT>" , <EOL> link_text_color = "<STR_LIT>" , <EOL> link_text_color_active = "<STR_LIT>" , <EOL> link_text_color_active_dark = "<STR_LIT>" , <EOL> link_text_color_dark = "<STR_LIT>" , <EOL> link_text_color_hover = "<STR_LIT>" , <EOL> link_text_color_hover_dark = "<STR_LIT>" , <EOL> link_text_color_visited = "<STR_LIT>" , <EOL> link_text_color_visited_dark = "<STR_LIT>" , <EOL> loader_color = "<STR_LIT>" , <EOL> loader_color_dark = "<STR_LIT>" , <EOL> panel_background_fill = "<STR_LIT>" , <EOL> panel_background_fill_dark = "<STR_LIT>" , <EOL> panel_border_color = "<STR_LIT>" , <EOL> panel_border_color_dark = "<STR_LIT>" , <EOL> panel_border_width = "<STR_LIT>" , <EOL> panel_border_width_dark = "<STR_LIT>" , <EOL> prose_header_text_weight = "<STR_LIT>" , <EOL> prose_text_size = "<STR_LIT>" , <EOL> prose_text_weight = "<STR_LIT>" , <EOL> radio_circle = "<STR_LIT>" , <EOL> section_header_text_size = "<STR_LIT>" , <EOL> section_header_text_weight = "<STR_LIT>" , <EOL> shadow_drop = "<STR_LIT>" , <EOL> shadow_drop_lg = "<STR_LIT>" , <EOL> shadow_inset = "<STR_LIT>" , <EOL> shadow_spread = "<STR_LIT>" , <EOL> shadow_spread_dark = "<STR_LIT>" , <EOL> slider_color = "<STR_LIT>" , <EOL> slider_color_dark = "<STR_LIT>" , <EOL> stat_background_fill = "<STR_LIT>" , <EOL> stat_background_fill_dark = "<STR_LIT>" , <EOL> table_border_color = "<STR_LIT>" , <EOL> table_border_color_dark = "<STR_LIT>" , <EOL> table_even_background_fill = "<STR_LIT>" , <EOL> table_even_background_fill_dark = "<STR_LIT>" , <EOL> table_odd_background_fill = "<STR_LIT>" , <EOL> table_odd_background_fill_dark = "<STR_LIT>" , <EOL> table_radius = "<STR_LIT>" , <EOL> table_row_focus = "<STR_LIT>" , <EOL> table_row_focus_dark = "<STR_LIT>" , <EOL> ) <EOL> </s>
<s> def pretrained_selector ( pitch_guidance ) : <EOL> if pitch_guidance : <EOL> return { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> } , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> } , <EOL> } <EOL> else : <EOL> return { <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> } , <EOL> "<STR_LIT>" : { <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> "<STR_LIT>" : ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> } , <EOL> } <EOL> </s>
<s> import gradio as gr <EOL> import os <EOL> import sys <EOL> now_dir = os . getcwd ( ) <EOL> pid_file_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> def restart_applio ( ) : <EOL> if os . name != "<STR_LIT>" : <EOL> os . system ( "<STR_LIT>" ) <EOL> else : <EOL> os . system ( "<STR_LIT>" ) <EOL> try : <EOL> with open ( pid_file_path , "<STR_LIT>" ) as pid_file : <EOL> pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] <EOL> for pid in pids : <EOL> os . kill ( pid , <NUM_LIT> ) <EOL> os . remove ( pid_file_path ) <EOL> except : <EOL> pass <EOL> python = sys . executable <EOL> os . execl ( python , python , * sys . argv ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def restart_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> restart_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> restart_button . click ( <EOL> fn = restart_applio , <EOL> inputs = [ ] , <EOL> outputs = [ ] , <EOL> ) <EOL> </s>
<s> import os <EOL> import sys <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> import requests <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . flask . server import start_flask , load_config_flask , save_config <EOL> i18n = I18nAuto ( ) <EOL> def flask_server_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> flask_checkbox = gr . Checkbox ( <EOL> label = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> interactive = True , <EOL> value = load_config_flask ( ) , <EOL> ) <EOL> flask_checkbox . change ( <EOL> fn = toggle , <EOL> inputs = [ flask_checkbox ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> if load_config_flask ( ) == True : <EOL> start_flask ( ) <EOL> else : <EOL> try : <EOL> requests . post ( "<STR_LIT>" ) <EOL> except requests . exceptions . ConnectionError : <EOL> pass <EOL> </s>
<s> import gradio as gr <EOL> import sys <EOL> import os <EOL> import logging <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from tabs . inference . inference import inference_tab <EOL> from tabs . train . train import train_tab <EOL> from tabs . extra . extra import extra_tab <EOL> from tabs . report . report import report_tab <EOL> from tabs . download . download import download_tab <EOL> from tabs . tts . tts import tts_tab <EOL> from tabs . voice_blender . voice_blender import voice_blender_tab <EOL> from tabs . settings . presence import presence_tab , load_config_presence <EOL> from tabs . settings . flask_server import flask_server_tab <EOL> from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu <EOL> from tabs . settings . themes import theme_tab <EOL> from tabs . plugins . plugins import plugins_tab <EOL> from tabs . settings . version import version_tab <EOL> from tabs . settings . lang import lang_tab <EOL> from tabs . settings . restart import restart_tab <EOL> import assets . themes . loadThemes as loadThemes <EOL> from assets . i18n . i18n import I18nAuto <EOL> import assets . installation_checker as installation_checker <EOL> from assets . discord_presence import RPCManager <EOL> from assets . flask . server import start_flask , load_config_flask <EOL> from core import run_prerequisites_script <EOL> run_prerequisites_script ( "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> i18n = I18nAuto ( ) <EOL> if load_config_presence ( ) == True : <EOL> RPCManager . start_presence ( ) <EOL> installation_checker . check_installation ( ) <EOL> logging . getLogger ( "<STR_LIT>" ) . disabled = True <EOL> logging . getLogger ( "<STR_LIT>" ) . disabled = True <EOL> if load_config_flask ( ) == True : <EOL> print ( "<STR_LIT>" ) <EOL> start_flask ( ) <EOL> my_applio = loadThemes . load_json ( ) <EOL> if my_applio : <EOL> pass <EOL> else : <EOL> my_applio = "<STR_LIT>" <EOL> with gr . Blocks ( theme = my_applio , title = "<STR_LIT>" ) as Applio : <EOL> gr . Markdown ( "<STR_LIT>" ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> inference_tab ( ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> if gpu_available ( ) or load_fake_gpu ( ) : <EOL> train_tab ( ) <EOL> else : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> tts_tab ( ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> voice_blender_tab ( ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> plugins_tab ( ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> download_tab ( ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> report_tab ( ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> extra_tab ( ) <EOL> with gr . Tab ( i18n ( "<STR_LIT>" ) ) : <EOL> presence_tab ( ) <EOL> flask_server_tab ( ) <EOL> if not gpu_available ( ) : <EOL> fake_gpu_tab ( ) <EOL> theme_tab ( ) <EOL> version_tab ( ) <EOL> lang_tab ( ) <EOL> restart_tab ( ) <EOL> if __name__ == "<STR_LIT>" : <EOL> port = <NUM_LIT> <EOL> if "<STR_LIT>" in sys . argv : <EOL> port_index = sys . argv . index ( "<STR_LIT>" ) + <NUM_LIT> <EOL> if port_index < len ( sys . argv ) : <EOL> port = int ( sys . argv [ port_index ] ) <EOL> Applio . launch ( <EOL> favicon_path = "<STR_LIT>" , <EOL> share = "<STR_LIT>" in sys . argv , <EOL> inbrowser = "<STR_LIT>" in sys . argv , <EOL> server_port = port , <EOL> ) <EOL> </s>
<s> import os <EOL> import sys <EOL> import base64 <EOL> import pathlib <EOL> import tempfile <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> recorder_js_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> main_js_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> record_button_js_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) <EOL> main_js = pathlib . Path ( main_js_path ) . read_text ( ) <EOL> record_button_js = ( <EOL> pathlib . Path ( record_button_js_path ) <EOL> . read_text ( ) <EOL> . replace ( "<STR_LIT>" , recorder_js ) <EOL> . replace ( "<STR_LIT>" , main_js ) <EOL> ) <EOL> def save_base64_video ( base64_string ) : <EOL> base64_video = base64_string <EOL> video_data = base64 . b64decode ( base64_video ) <EOL> with tempfile . NamedTemporaryFile ( suffix = "<STR_LIT>" , delete = False ) as temp_file : <EOL> temp_filename = temp_file . name <EOL> temp_file . write ( video_data ) <EOL> print ( f"<STR_LIT>" ) <EOL> return temp_filename <EOL> def report_tab ( ) : <EOL> instructions = [ <EOL> i18n ( "<STR_LIT>" ) , <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> ] <EOL> components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] <EOL> start_button = gr . Button ( "<STR_LIT>" ) <EOL> video_component = gr . Video ( interactive = False ) <EOL> def toggle_button_label ( returned_string ) : <EOL> if returned_string . startswith ( "<STR_LIT>" ) : <EOL> return gr . Button ( value = "<STR_LIT>" ) , None <EOL> else : <EOL> try : <EOL> temp_filename = save_base64_video ( returned_string ) <EOL> except Exception as error : <EOL> return gr . Button ( value = "<STR_LIT>" ) , gr . Warning ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> return gr . Button ( value = "<STR_LIT>" ) , gr . Video ( <EOL> value = temp_filename , interactive = False <EOL> ) <EOL> start_button . click ( <EOL> toggle_button_label , <EOL> start_button , <EOL> [ start_button , video_component ] , <EOL> js = record_button_js , <EOL> ) <EOL> </s>
<s> import torch . nn as nn <EOL> import torch , numpy as np <EOL> import torch . nn . functional as F <EOL> from librosa . filters import mel <EOL> class BiGRU ( nn . Module ) : <EOL> def __init__ ( self , input_features , hidden_features , num_layers ) : <EOL> super ( BiGRU , self ) . __init__ ( ) <EOL> self . gru = nn . GRU ( <EOL> input_features , <EOL> hidden_features , <EOL> num_layers = num_layers , <EOL> batch_first = True , <EOL> bidirectional = True , <EOL> ) <EOL> def forward ( self , x ) : <EOL> return self . gru ( x ) [ <NUM_LIT> ] <EOL> class ConvBlockRes ( nn . Module ) : <EOL> def __init__ ( self , in_channels , out_channels , momentum = <NUM_LIT> ) : <EOL> super ( ConvBlockRes , self ) . __init__ ( ) <EOL> self . conv = nn . Sequential ( <EOL> nn . Conv2d ( <EOL> in_channels = in_channels , <EOL> out_channels = out_channels , <EOL> kernel_size = ( <NUM_LIT> , <NUM_LIT> ) , <EOL> stride = ( <NUM_LIT> , <NUM_LIT> ) , <EOL> padding = ( <NUM_LIT> , <NUM_LIT> ) , <EOL> bias = False , <EOL> ) , <EOL> nn . BatchNorm2d ( out_channels , momentum = momentum ) , <EOL> nn . ReLU ( ) , <EOL> nn . Conv2d ( <EOL> in_channels = out_channels , <EOL> out_channels = out_channels , <EOL> kernel_size = ( <NUM_LIT> , <NUM_LIT> ) , <EOL> stride = ( <NUM_LIT> , <NUM_LIT> ) , <EOL> padding = ( <NUM_LIT> , <NUM_LIT> ) , <EOL> bias = False , <EOL> ) , <EOL> nn . BatchNorm2d ( out_channels , momentum = momentum ) , <EOL> nn . ReLU ( ) , <EOL> ) <EOL> if in_channels != out_channels : <EOL> self . shortcut = nn . Conv2d ( in_channels , out_channels , ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> self . is_shortcut = True <EOL> else : <EOL> self . is_shortcut = False <EOL> def forward ( self , x ) : <EOL> if self . is_shortcut : <EOL> return self . conv ( x ) + self . shortcut ( x ) <EOL> else : <EOL> return self . conv ( x ) + x <EOL> class Encoder ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> in_channels , <EOL> in_size , <EOL> n_encoders , <EOL> kernel_size , <EOL> n_blocks , <EOL> out_channels = <NUM_LIT> , <EOL> momentum = <NUM_LIT> , <EOL> ) : <EOL> super ( Encoder , self ) . __init__ ( ) <EOL> self . n_encoders = n_encoders <EOL> self . bn = nn . BatchNorm2d ( in_channels , momentum = momentum ) <EOL> self . layers = nn . ModuleList ( ) <EOL> self . latent_channels = [ ] <EOL> for i in range ( self . n_encoders ) : <EOL> self . layers . append ( <EOL> ResEncoderBlock ( <EOL> in_channels , out_channels , kernel_size , n_blocks , momentum = momentum <EOL> ) <EOL> ) <EOL> self . latent_channels . append ( [ out_channels , in_size ] ) <EOL> in_channels = out_channels <EOL> out_channels *= <NUM_LIT> <EOL> in_size //= <NUM_LIT> <EOL> self . out_size = in_size <EOL> self . out_channel = out_channels <EOL> def forward ( self , x ) : <EOL> concat_tensors = [ ] <EOL> x = self . bn ( x ) <EOL> for i in range ( self . n_encoders ) : <EOL> _ , x = self . layers [ i ] ( x ) <EOL> concat_tensors . append ( _ ) <EOL> return x , concat_tensors <EOL> class ResEncoderBlock ( nn . Module ) : <EOL> def __init__ ( <EOL> self , in_channels , out_channels , kernel_size , n_blocks = <NUM_LIT> , momentum = <NUM_LIT> <EOL> ) : <EOL> super ( ResEncoderBlock , self ) . __init__ ( ) <EOL> self . n_blocks = n_blocks <EOL> self . conv = nn . ModuleList ( ) <EOL> self . conv . append ( ConvBlockRes ( in_channels , out_channels , momentum ) ) <EOL> for i in range ( n_blocks - <NUM_LIT> ) : <EOL> self . conv . append ( ConvBlockRes ( out_channels , out_channels , momentum ) ) <EOL> self . kernel_size = kernel_size <EOL> if self . kernel_size is not None : <EOL> self . pool = nn . AvgPool2d ( kernel_size = kernel_size ) <EOL> def forward ( self , x ) : <EOL> for i in range ( self . n_blocks ) : <EOL> x = self . conv [ i ] ( x ) <EOL> if self . kernel_size is not None : <EOL> return x , self . pool ( x ) <EOL> else : <EOL> return x <EOL> class Intermediate ( nn . Module ) : <EOL> def __init__ ( self , in_channels , out_channels , n_inters , n_blocks , momentum = <NUM_LIT> ) : <EOL> super ( Intermediate , self ) . __init__ ( ) <EOL> self . n_inters = n_inters <EOL> self . layers = nn . ModuleList ( ) <EOL> self . layers . append ( <EOL> ResEncoderBlock ( in_channels , out_channels , None , n_blocks , momentum ) <EOL> ) <EOL> for i in range ( self . n_inters - <NUM_LIT> ) : <EOL> self . layers . append ( <EOL> ResEncoderBlock ( out_channels , out_channels , None , n_blocks , momentum ) <EOL> ) <EOL> def forward ( self , x ) : <EOL> for i in range ( self . n_inters ) : <EOL> x = self . layers [ i ] ( x ) <EOL> return x <EOL> class ResDecoderBlock ( nn . Module ) : <EOL> def __init__ ( self , in_channels , out_channels , stride , n_blocks = <NUM_LIT> , momentum = <NUM_LIT> ) : <EOL> super ( ResDecoderBlock , self ) . __init__ ( ) <EOL> out_padding = ( <NUM_LIT> , <NUM_LIT> ) if stride == ( <NUM_LIT> , <NUM_LIT> ) else ( <NUM_LIT> , <NUM_LIT> ) <EOL> self . n_blocks = n_blocks <EOL> self . conv1 = nn . Sequential ( <EOL> nn . ConvTranspose2d ( <EOL> in_channels = in_channels , <EOL> out_channels = out_channels , <EOL> kernel_size = ( <NUM_LIT> , <NUM_LIT> ) , <EOL> stride = stride , <EOL> padding = ( <NUM_LIT> , <NUM_LIT> ) , <EOL> output_padding = out_padding , <EOL> bias = False , <EOL> ) , <EOL> nn . BatchNorm2d ( out_channels , momentum = momentum ) , <EOL> nn . ReLU ( ) , <EOL> ) <EOL> self . conv2 = nn . ModuleList ( ) <EOL> self . conv2 . append ( ConvBlockRes ( out_channels * <NUM_LIT> , out_channels , momentum ) ) <EOL> for i in range ( n_blocks - <NUM_LIT> ) : <EOL> self . conv2 . append ( ConvBlockRes ( out_channels , out_channels , momentum ) ) <EOL> def forward ( self , x , concat_tensor ) : <EOL> x = self . conv1 ( x ) <EOL> x = torch . cat ( ( x , concat_tensor ) , dim = <NUM_LIT> ) <EOL> for i in range ( self . n_blocks ) : <EOL> x = self . conv2 [ i ] ( x ) <EOL> return x <EOL> class Decoder ( nn . Module ) : <EOL> def __init__ ( self , in_channels , n_decoders , stride , n_blocks , momentum = <NUM_LIT> ) : <EOL> super ( Decoder , self ) . __init__ ( ) <EOL> self . layers = nn . ModuleList ( ) <EOL> self . n_decoders = n_decoders <EOL> for i in range ( self . n_decoders ) : <EOL> out_channels = in_channels // <NUM_LIT> <EOL> self . layers . append ( <EOL> ResDecoderBlock ( in_channels , out_channels , stride , n_blocks , momentum ) <EOL> ) <EOL> in_channels = out_channels <EOL> def forward ( self , x , concat_tensors ) : <EOL> for i in range ( self . n_decoders ) : <EOL> x = self . layers [ i ] ( x , concat_tensors [ - <NUM_LIT> - i ] ) <EOL> return x <EOL> class DeepUnet ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> kernel_size , <EOL> n_blocks , <EOL> en_de_layers = <NUM_LIT> , <EOL> inter_layers = <NUM_LIT> , <EOL> in_channels = <NUM_LIT> , <EOL> en_out_channels = <NUM_LIT> , <EOL> ) : <EOL> super ( DeepUnet , self ) . __init__ ( ) <EOL> self . encoder = Encoder ( <EOL> in_channels , <NUM_LIT> , en_de_layers , kernel_size , n_blocks , en_out_channels <EOL> ) <EOL> self . intermediate = Intermediate ( <EOL> self . encoder . out_channel // <NUM_LIT> , <EOL> self . encoder . out_channel , <EOL> inter_layers , <EOL> n_blocks , <EOL> ) <EOL> self . decoder = Decoder ( <EOL> self . encoder . out_channel , en_de_layers , kernel_size , n_blocks <EOL> ) <EOL> def forward ( self , x ) : <EOL> x , concat_tensors = self . encoder ( x ) <EOL> x = self . intermediate ( x ) <EOL> x = self . decoder ( x , concat_tensors ) <EOL> return x <EOL> class E2E ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> n_blocks , <EOL> n_gru , <EOL> kernel_size , <EOL> en_de_layers = <NUM_LIT> , <EOL> inter_layers = <NUM_LIT> , <EOL> in_channels = <NUM_LIT> , <EOL> en_out_channels = <NUM_LIT> , <EOL> ) : <EOL> super ( E2E , self ) . __init__ ( ) <EOL> self . unet = DeepUnet ( <EOL> kernel_size , <EOL> n_blocks , <EOL> en_de_layers , <EOL> inter_layers , <EOL> in_channels , <EOL> en_out_channels , <EOL> ) <EOL> self . cnn = nn . Conv2d ( en_out_channels , <NUM_LIT> , ( <NUM_LIT> , <NUM_LIT> ) , padding = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> if n_gru : <EOL> self . fc = nn . Sequential ( <EOL> BiGRU ( <NUM_LIT> * <NUM_LIT> , <NUM_LIT> , n_gru ) , <EOL> nn . Linear ( <NUM_LIT> , <NUM_LIT> ) , <EOL> nn . Dropout ( <NUM_LIT> ) , <EOL> nn . Sigmoid ( ) , <EOL> ) <EOL> def forward ( self , mel ) : <EOL> mel = mel . transpose ( - <NUM_LIT> , - <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) <EOL> x = self . cnn ( self . unet ( mel ) ) . transpose ( <NUM_LIT> , <NUM_LIT> ) . flatten ( - <NUM_LIT> ) <EOL> x = self . fc ( x ) <EOL> return x <EOL> class MelSpectrogram ( torch . nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> is_half , <EOL> n_mel_channels , <EOL> sampling_rate , <EOL> win_length , <EOL> hop_length , <EOL> n_fft = None , <EOL> mel_fmin = <NUM_LIT> , <EOL> mel_fmax = None , <EOL> clamp = <NUM_LIT> , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> n_fft = win_length if n_fft is None else n_fft <EOL> self . hann_window = { } <EOL> mel_basis = mel ( <EOL> sr = sampling_rate , <EOL> n_fft = n_fft , <EOL> n_mels = n_mel_channels , <EOL> fmin = mel_fmin , <EOL> fmax = mel_fmax , <EOL> htk = True , <EOL> ) <EOL> mel_basis = torch . from_numpy ( mel_basis ) . float ( ) <EOL> self . register_buffer ( "<STR_LIT>" , mel_basis ) <EOL> self . n_fft = win_length if n_fft is None else n_fft <EOL> self . hop_length = hop_length <EOL> self . win_length = win_length <EOL> self . sampling_rate = sampling_rate <EOL> self . n_mel_channels = n_mel_channels <EOL> self . clamp = clamp <EOL> self . is_half = is_half <EOL> def forward ( self , audio , keyshift = <NUM_LIT> , speed = <NUM_LIT> , center = True ) : <EOL> factor = <NUM_LIT> ** ( keyshift / <NUM_LIT> ) <EOL> n_fft_new = int ( np . round ( self . n_fft * factor ) ) <EOL> win_length_new = int ( np . round ( self . win_length * factor ) ) <EOL> hop_length_new = int ( np . round ( self . hop_length * speed ) ) <EOL> keyshift_key = str ( keyshift ) + "<STR_LIT>" + str ( audio . device ) <EOL> if keyshift_key not in self . hann_window : <EOL> self . hann_window [ keyshift_key ] = torch . hann_window ( win_length_new ) . to ( <EOL> audio . device <EOL> ) <EOL> fft = torch . stft ( <EOL> audio , <EOL> n_fft = n_fft_new , <EOL> hop_length = hop_length_new , <EOL> win_length = win_length_new , <EOL> window = self . hann_window [ keyshift_key ] , <EOL> center = center , <EOL> return_complex = True , <EOL> ) <EOL> magnitude = torch . sqrt ( fft . real . pow ( <NUM_LIT> ) + fft . imag . pow ( <NUM_LIT> ) ) <EOL> if keyshift != <NUM_LIT> : <EOL> size = self . n_fft // <NUM_LIT> + <NUM_LIT> <EOL> resize = magnitude . size ( <NUM_LIT> ) <EOL> if resize < size : <EOL> magnitude = F . pad ( magnitude , ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , size - resize ) ) <EOL> magnitude = magnitude [ : , : size , : ] * self . win_length / win_length_new <EOL> mel_output = torch . matmul ( self . mel_basis , magnitude ) <EOL> if self . is_half == True : <EOL> mel_output = mel_output . half ( ) <EOL> log_mel_spec = torch . log ( torch . clamp ( mel_output , min = self . clamp ) ) <EOL> return log_mel_spec <EOL> class RMVPE : <EOL> def __init__ ( self , model_path , is_half , device = None ) : <EOL> self . resample_kernel = { } <EOL> model = E2E ( <NUM_LIT> , <NUM_LIT> , ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> ckpt = torch . load ( model_path , map_location = "<STR_LIT>" ) <EOL> model . load_state_dict ( ckpt ) <EOL> model . eval ( ) <EOL> if is_half == True : <EOL> model = model . half ( ) <EOL> self . model = model <EOL> self . resample_kernel = { } <EOL> self . is_half = is_half <EOL> if device is None : <EOL> device = "<STR_LIT>" if torch . cuda . is_available ( ) else "<STR_LIT>" <EOL> self . device = device <EOL> self . mel_extractor = MelSpectrogram ( <EOL> is_half , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , None , <NUM_LIT> , <NUM_LIT> <EOL> ) . to ( device ) <EOL> self . model = self . model . to ( device ) <EOL> cents_mapping = <NUM_LIT> * np . arange ( <NUM_LIT> ) + <NUM_LIT> <EOL> self . cents_mapping = np . pad ( cents_mapping , ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> def mel2hidden ( self , mel ) : <EOL> with torch . no_grad ( ) : <EOL> n_frames = mel . shape [ - <NUM_LIT> ] <EOL> mel = F . pad ( <EOL> mel , ( <NUM_LIT> , <NUM_LIT> * ( ( n_frames - <NUM_LIT> ) // <NUM_LIT> + <NUM_LIT> ) - n_frames ) , mode = "<STR_LIT>" <EOL> ) <EOL> hidden = self . model ( mel ) <EOL> return hidden [ : , : n_frames ] <EOL> def decode ( self , hidden , thred = <NUM_LIT> ) : <EOL> cents_pred = self . to_local_average_cents ( hidden , thred = thred ) <EOL> f0 = <NUM_LIT> * ( <NUM_LIT> ** ( cents_pred / <NUM_LIT> ) ) <EOL> f0 [ f0 == <NUM_LIT> ] = <NUM_LIT> <EOL> return f0 <EOL> def infer_from_audio ( self , audio , thred = <NUM_LIT> ) : <EOL> audio = torch . from_numpy ( audio ) . float ( ) . to ( self . device ) . unsqueeze ( <NUM_LIT> ) <EOL> mel = self . mel_extractor ( audio , center = True ) <EOL> hidden = self . mel2hidden ( mel ) <EOL> hidden = hidden . squeeze ( <NUM_LIT> ) . cpu ( ) . numpy ( ) <EOL> if self . is_half == True : <EOL> hidden = hidden . astype ( "<STR_LIT>" ) <EOL> f0 = self . decode ( hidden , thred = thred ) <EOL> return f0 <EOL> def to_local_average_cents ( self , salience , thred = <NUM_LIT> ) : <EOL> center = np . argmax ( salience , axis = <NUM_LIT> ) <EOL> salience = np . pad ( salience , ( ( <NUM_LIT> , <NUM_LIT> ) , ( <NUM_LIT> , <NUM_LIT> ) ) ) <EOL> center += <NUM_LIT> <EOL> todo_salience = [ ] <EOL> todo_cents_mapping = [ ] <EOL> starts = center - <NUM_LIT> <EOL> ends = center + <NUM_LIT> <EOL> for idx in range ( salience . shape [ <NUM_LIT> ] ) : <EOL> todo_salience . append ( salience [ : , starts [ idx ] : ends [ idx ] ] [ idx ] ) <EOL> todo_cents_mapping . append ( self . cents_mapping [ starts [ idx ] : ends [ idx ] ] ) <EOL> todo_salience = np . array ( todo_salience ) <EOL> todo_cents_mapping = np . array ( todo_cents_mapping ) <EOL> product_sum = np . sum ( todo_salience * todo_cents_mapping , <NUM_LIT> ) <EOL> weight_sum = np . sum ( todo_salience , <NUM_LIT> ) <EOL> devided = product_sum / weight_sum <EOL> maxx = np . max ( salience , axis = <NUM_LIT> ) <EOL> devided [ maxx <= thred ] = <NUM_LIT> <EOL> return devided <EOL> </s>
<s> import gradio as gr <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def model_information_tab ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> interactive = True , <EOL> ) <EOL> model_information_output_info = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> model_information_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> model_information_button . click ( <EOL> run_model_information_script , <EOL> [ model_name ] , <EOL> model_information_output_info , <EOL> api_name = "<STR_LIT>" , <EOL> ) <EOL> </s>
<s> import numpy as np , parselmouth , torch , pdb , sys , os <EOL> from time import time as ttime <EOL> import torch . nn . functional as F <EOL> import torchcrepe <EOL> from torch import Tensor <EOL> import scipy . signal as signal <EOL> import pyworld , os , faiss , librosa , torchcrepe <EOL> from scipy import signal <EOL> from functools import lru_cache <EOL> import random <EOL> import gc <EOL> import re <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . lib . FCPEF0Predictor import FCPEF0Predictor <EOL> bh , ah = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = "<STR_LIT>" , fs = <NUM_LIT> ) <EOL> input_audio_path2wav = { } <EOL> @ lru_cache <EOL> def cache_harvest_f0 ( input_audio_path , fs , f0max , f0min , frame_period ) : <EOL> audio = input_audio_path2wav [ input_audio_path ] <EOL> f0 , t = pyworld . harvest ( <EOL> audio , <EOL> fs = fs , <EOL> f0_ceil = f0max , <EOL> f0_floor = f0min , <EOL> frame_period = frame_period , <EOL> ) <EOL> f0 = pyworld . stonemask ( audio , f0 , t , fs ) <EOL> return f0 <EOL> def change_rms ( data1 , sr1 , data2 , sr2 , rate ) : <EOL> rms1 = librosa . feature . rms ( y = data1 , frame_length = sr1 // <NUM_LIT> * <NUM_LIT> , hop_length = sr1 // <NUM_LIT> ) <EOL> rms2 = librosa . feature . rms ( y = data2 , frame_length = sr2 // <NUM_LIT> * <NUM_LIT> , hop_length = sr2 // <NUM_LIT> ) <EOL> rms1 = torch . from_numpy ( rms1 ) <EOL> rms1 = F . interpolate ( <EOL> rms1 . unsqueeze ( <NUM_LIT> ) , size = data2 . shape [ <NUM_LIT> ] , mode = "<STR_LIT>" <EOL> ) . squeeze ( ) <EOL> rms2 = torch . from_numpy ( rms2 ) <EOL> rms2 = F . interpolate ( <EOL> rms2 . unsqueeze ( <NUM_LIT> ) , size = data2 . shape [ <NUM_LIT> ] , mode = "<STR_LIT>" <EOL> ) . squeeze ( ) <EOL> rms2 = torch . max ( rms2 , torch . zeros_like ( rms2 ) + <NUM_LIT> ) <EOL> data2 *= ( <EOL> torch . pow ( rms1 , torch . tensor ( <NUM_LIT> - rate ) ) <EOL> * torch . pow ( rms2 , torch . tensor ( rate - <NUM_LIT> ) ) <EOL> ) . numpy ( ) <EOL> return data2 <EOL> class VC ( object ) : <EOL> def __init__ ( self , tgt_sr , config ) : <EOL> self . x_pad , self . x_query , self . x_center , self . x_max , self . is_half = ( <EOL> config . x_pad , <EOL> config . x_query , <EOL> config . x_center , <EOL> config . x_max , <EOL> config . is_half , <EOL> ) <EOL> self . sr = <NUM_LIT> <EOL> self . window = <NUM_LIT> <EOL> self . t_pad = self . sr * self . x_pad <EOL> self . t_pad_tgt = tgt_sr * self . x_pad <EOL> self . t_pad2 = self . t_pad * <NUM_LIT> <EOL> self . t_query = self . sr * self . x_query <EOL> self . t_center = self . sr * self . x_center <EOL> self . t_max = self . sr * self . x_max <EOL> self . device = config . device <EOL> self . ref_freqs = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> self . note_dict = self . generate_interpolated_frequencies ( ) <EOL> def generate_interpolated_frequencies ( self ) : <EOL> note_dict = [ ] <EOL> for i in range ( len ( self . ref_freqs ) - <NUM_LIT> ) : <EOL> freq_low = self . ref_freqs [ i ] <EOL> freq_high = self . ref_freqs [ i + <NUM_LIT> ] <EOL> interpolated_freqs = np . linspace ( <EOL> freq_low , freq_high , num = <NUM_LIT> , endpoint = False <EOL> ) <EOL> note_dict . extend ( interpolated_freqs ) <EOL> note_dict . append ( self . ref_freqs [ - <NUM_LIT> ] ) <EOL> return note_dict <EOL> def autotune_f0 ( self , f0 ) : <EOL> autotuned_f0 = np . zeros_like ( f0 ) <EOL> for i , freq in enumerate ( f0 ) : <EOL> closest_note = min ( self . note_dict , key = lambda x : abs ( x - freq ) ) <EOL> autotuned_f0 [ i ] = closest_note <EOL> return autotuned_f0 <EOL> def get_optimal_torch_device ( self , index : int = <NUM_LIT> ) -> torch . device : <EOL> if torch . cuda . is_available ( ) : <EOL> return torch . device ( f"<STR_LIT>" ) <EOL> elif torch . backends . mps . is_available ( ) : <EOL> return torch . device ( "<STR_LIT>" ) <EOL> return torch . device ( "<STR_LIT>" ) <EOL> def get_f0_crepe_computation ( <EOL> self , <EOL> x , <EOL> f0_min , <EOL> f0_max , <EOL> p_len , <EOL> hop_length , <EOL> model = "<STR_LIT>" , <EOL> ) : <EOL> x = x . astype ( np . float32 ) <EOL> x /= np . quantile ( np . abs ( x ) , <NUM_LIT> ) <EOL> torch_device = self . get_optimal_torch_device ( ) <EOL> audio = torch . from_numpy ( x ) . to ( torch_device , copy = True ) <EOL> audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) <EOL> if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : <EOL> audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) <EOL> audio = audio . detach ( ) <EOL> pitch : Tensor = torchcrepe . predict ( <EOL> audio , <EOL> self . sr , <EOL> hop_length , <EOL> f0_min , <EOL> f0_max , <EOL> model , <EOL> batch_size = hop_length * <NUM_LIT> , <EOL> device = torch_device , <EOL> pad = True , <EOL> ) <EOL> p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length <EOL> source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> f0 = np . nan_to_num ( target ) <EOL> return f0 <EOL> def get_f0_official_crepe_computation ( <EOL> self , <EOL> x , <EOL> f0_min , <EOL> f0_max , <EOL> model = "<STR_LIT>" , <EOL> ) : <EOL> batch_size = <NUM_LIT> <EOL> audio = torch . tensor ( np . copy ( x ) ) [ None ] . float ( ) <EOL> f0 , pd = torchcrepe . predict ( <EOL> audio , <EOL> self . sr , <EOL> self . window , <EOL> f0_min , <EOL> f0_max , <EOL> model , <EOL> batch_size = batch_size , <EOL> device = self . device , <EOL> return_periodicity = True , <EOL> ) <EOL> pd = torchcrepe . filter . median ( pd , <NUM_LIT> ) <EOL> f0 = torchcrepe . filter . mean ( f0 , <NUM_LIT> ) <EOL> f0 [ pd < <NUM_LIT> ] = <NUM_LIT> <EOL> f0 = f0 [ <NUM_LIT> ] . cpu ( ) . numpy ( ) <EOL> return f0 <EOL> def get_f0_hybrid_computation ( <EOL> self , <EOL> methods_str , <EOL> x , <EOL> f0_min , <EOL> f0_max , <EOL> p_len , <EOL> hop_length , <EOL> ) : <EOL> methods_str = re . search ( "<STR_LIT>" , methods_str ) <EOL> if methods_str : <EOL> methods = [ method . strip ( ) for method in methods_str . group ( <NUM_LIT> ) . split ( "<STR_LIT>" ) ] <EOL> f0_computation_stack = [ ] <EOL> print ( f"<STR_LIT>" ) <EOL> x = x . astype ( np . float32 ) <EOL> x /= np . quantile ( np . abs ( x ) , <NUM_LIT> ) <EOL> for method in methods : <EOL> f0 = None <EOL> if method == "<STR_LIT>" : <EOL> f0 = self . get_f0_crepe_computation ( <EOL> x , f0_min , f0_max , p_len , int ( hop_length ) <EOL> ) <EOL> elif method == "<STR_LIT>" : <EOL> if hasattr ( self , "<STR_LIT>" ) == False : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( <EOL> "<STR_LIT>" , is_half = self . is_half , device = self . device <EOL> ) <EOL> f0 = self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> f0 = f0 [ <NUM_LIT> : ] <EOL> elif method == "<STR_LIT>" : <EOL> self . model_fcpe = FCPEF0Predictor ( <EOL> "<STR_LIT>" , <EOL> f0_min = int ( f0_min ) , <EOL> f0_max = int ( f0_max ) , <EOL> dtype = torch . float32 , <EOL> device = self . device , <EOL> sampling_rate = self . sr , <EOL> threshold = <NUM_LIT> , <EOL> ) <EOL> f0 = self . model_fcpe . compute_f0 ( x , p_len = p_len ) <EOL> del self . model_fcpe <EOL> gc . collect ( ) <EOL> f0_computation_stack . append ( f0 ) <EOL> print ( f"<STR_LIT>" ) <EOL> f0_computation_stack = [ fc for fc in f0_computation_stack if fc is not None ] <EOL> f0_median_hybrid = None <EOL> if len ( f0_computation_stack ) == <NUM_LIT> : <EOL> f0_median_hybrid = f0_computation_stack [ <NUM_LIT> ] <EOL> else : <EOL> f0_median_hybrid = np . nanmedian ( f0_computation_stack , axis = <NUM_LIT> ) <EOL> return f0_median_hybrid <EOL> def get_f0 ( <EOL> self , <EOL> input_audio_path , <EOL> x , <EOL> p_len , <EOL> f0_up_key , <EOL> f0_method , <EOL> filter_radius , <EOL> hop_length , <EOL> f0autotune , <EOL> inp_f0 = None , <EOL> ) : <EOL> global input_audio_path2wav <EOL> time_step = self . window / self . sr * <NUM_LIT> <EOL> f0_min = <NUM_LIT> <EOL> f0_max = <NUM_LIT> <EOL> f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + f0_min / <NUM_LIT> ) <EOL> f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + f0_max / <NUM_LIT> ) <EOL> if f0_method == "<STR_LIT>" : <EOL> f0 = ( <EOL> parselmouth . Sound ( x , self . sr ) <EOL> . to_pitch_ac ( <EOL> time_step = time_step / <NUM_LIT> , <EOL> voicing_threshold = <NUM_LIT> , <EOL> pitch_floor = f0_min , <EOL> pitch_ceiling = f0_max , <EOL> ) <EOL> . selected_array [ "<STR_LIT>" ] <EOL> ) <EOL> pad_size = ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> <EOL> if pad_size > <NUM_LIT> or p_len - len ( f0 ) - pad_size > <NUM_LIT> : <EOL> f0 = np . pad ( <EOL> f0 , [ [ pad_size , p_len - len ( f0 ) - pad_size ] ] , mode = "<STR_LIT>" <EOL> ) <EOL> elif f0_method == "<STR_LIT>" : <EOL> input_audio_path2wav [ input_audio_path ] = x . astype ( np . double ) <EOL> f0 = cache_harvest_f0 ( input_audio_path , self . sr , f0_max , f0_min , <NUM_LIT> ) <EOL> if int ( filter_radius ) > <NUM_LIT> : <EOL> f0 = signal . medfilt ( f0 , <NUM_LIT> ) <EOL> elif f0_method == "<STR_LIT>" : <EOL> f0 , t = pyworld . dio ( <EOL> x . astype ( np . double ) , <EOL> fs = self . sr , <EOL> f0_ceil = f0_max , <EOL> f0_floor = f0_min , <EOL> frame_period = <NUM_LIT> , <EOL> ) <EOL> f0 = pyworld . stonemask ( x . astype ( np . double ) , f0 , t , self . sr ) <EOL> f0 = signal . medfilt ( f0 , <NUM_LIT> ) <EOL> elif f0_method == "<STR_LIT>" : <EOL> f0 = self . get_f0_crepe_computation ( <EOL> x , f0_min , f0_max , p_len , int ( hop_length ) <EOL> ) <EOL> elif f0_method == "<STR_LIT>" : <EOL> f0 = self . get_f0_crepe_computation ( <EOL> x , f0_min , f0_max , p_len , int ( hop_length ) , "<STR_LIT>" <EOL> ) <EOL> elif f0_method == "<STR_LIT>" : <EOL> if hasattr ( self , "<STR_LIT>" ) == False : <EOL> from rvc . lib . rmvpe import RMVPE <EOL> self . model_rmvpe = RMVPE ( <EOL> "<STR_LIT>" , is_half = self . is_half , device = self . device <EOL> ) <EOL> f0 = self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) <EOL> elif f0_method == "<STR_LIT>" : <EOL> self . model_fcpe = FCPEF0Predictor ( <EOL> "<STR_LIT>" , <EOL> f0_min = int ( f0_min ) , <EOL> f0_max = int ( f0_max ) , <EOL> dtype = torch . float32 , <EOL> device = self . device , <EOL> sampling_rate = self . sr , <EOL> threshold = <NUM_LIT> , <EOL> ) <EOL> f0 = self . model_fcpe . compute_f0 ( x , p_len = p_len ) <EOL> del self . model_fcpe <EOL> gc . collect ( ) <EOL> elif "<STR_LIT>" in f0_method : <EOL> input_audio_path2wav [ input_audio_path ] = x . astype ( np . double ) <EOL> f0 = self . get_f0_hybrid_computation ( <EOL> f0_method , <EOL> x , <EOL> f0_min , <EOL> f0_max , <EOL> p_len , <EOL> hop_length , <EOL> ) <EOL> if f0autotune == "<STR_LIT>" : <EOL> f0 = self . autotune_f0 ( f0 ) <EOL> f0 *= pow ( <NUM_LIT> , f0_up_key / <NUM_LIT> ) <EOL> tf0 = self . sr // self . window <EOL> if inp_f0 is not None : <EOL> delta_t = np . round ( <EOL> ( inp_f0 [ : , <NUM_LIT> ] . max ( ) - inp_f0 [ : , <NUM_LIT> ] . min ( ) ) * tf0 + <NUM_LIT> <EOL> ) . astype ( "<STR_LIT>" ) <EOL> replace_f0 = np . interp ( <EOL> list ( range ( delta_t ) ) , inp_f0 [ : , <NUM_LIT> ] * <NUM_LIT> , inp_f0 [ : , <NUM_LIT> ] <EOL> ) <EOL> shape = f0 [ self . x_pad * tf0 : self . x_pad * tf0 + len ( replace_f0 ) ] . shape [ <NUM_LIT> ] <EOL> f0 [ self . x_pad * tf0 : self . x_pad * tf0 + len ( replace_f0 ) ] = replace_f0 [ <EOL> : shape <EOL> ] <EOL> f0bak = f0 . copy ( ) <EOL> f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - f0_mel_min ) * <NUM_LIT> / ( <EOL> f0_mel_max - f0_mel_min <EOL> ) + <NUM_LIT> <EOL> f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> <EOL> f0_mel [ f0_mel > <NUM_LIT> ] = <NUM_LIT> <EOL> f0_coarse = np . rint ( f0_mel ) . astype ( np . int ) <EOL> return f0_coarse , f0bak <EOL> def vc ( <EOL> self , <EOL> model , <EOL> net_g , <EOL> sid , <EOL> audio0 , <EOL> pitch , <EOL> pitchf , <EOL> index , <EOL> big_npy , <EOL> index_rate , <EOL> version , <EOL> protect , <EOL> ) : <EOL> feats = torch . from_numpy ( audio0 ) <EOL> if self . is_half : <EOL> feats = feats . half ( ) <EOL> else : <EOL> feats = feats . float ( ) <EOL> if feats . dim ( ) == <NUM_LIT> : <EOL> feats = feats . mean ( - <NUM_LIT> ) <EOL> assert feats . dim ( ) == <NUM_LIT> , feats . dim ( ) <EOL> feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) <EOL> padding_mask = torch . BoolTensor ( feats . shape ) . to ( self . device ) . fill_ ( False ) <EOL> inputs = { <EOL> "<STR_LIT>" : feats . to ( self . device ) , <EOL> "<STR_LIT>" : padding_mask , <EOL> "<STR_LIT>" : <NUM_LIT> if version == "<STR_LIT>" else <NUM_LIT> , <EOL> } <EOL> t0 = ttime ( ) <EOL> with torch . no_grad ( ) : <EOL> logits = model . extract_features ( ** inputs ) <EOL> feats = model . final_proj ( logits [ <NUM_LIT> ] ) if version == "<STR_LIT>" else logits [ <NUM_LIT> ] <EOL> if protect < <NUM_LIT> and pitch != None and pitchf != None : <EOL> feats0 = feats . clone ( ) <EOL> if ( <EOL> isinstance ( index , type ( None ) ) == False <EOL> and isinstance ( big_npy , type ( None ) ) == False <EOL> and index_rate != <NUM_LIT> <EOL> ) : <EOL> npy = feats [ <NUM_LIT> ] . cpu ( ) . numpy ( ) <EOL> if self . is_half : <EOL> npy = npy . astype ( "<STR_LIT>" ) <EOL> score , ix = index . search ( npy , k = <NUM_LIT> ) <EOL> weight = np . square ( <NUM_LIT> / score ) <EOL> weight /= weight . sum ( axis = <NUM_LIT> , keepdims = True ) <EOL> npy = np . sum ( big_npy [ ix ] * np . expand_dims ( weight , axis = <NUM_LIT> ) , axis = <NUM_LIT> ) <EOL> if self . is_half : <EOL> npy = npy . astype ( "<STR_LIT>" ) <EOL> feats = ( <EOL> torch . from_numpy ( npy ) . unsqueeze ( <NUM_LIT> ) . to ( self . device ) * index_rate <EOL> + ( <NUM_LIT> - index_rate ) * feats <EOL> ) <EOL> feats = F . interpolate ( feats . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) , scale_factor = <NUM_LIT> ) . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> if protect < <NUM_LIT> and pitch != None and pitchf != None : <EOL> feats0 = F . interpolate ( feats0 . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) , scale_factor = <NUM_LIT> ) . permute ( <EOL> <NUM_LIT> , <NUM_LIT> , <NUM_LIT> <EOL> ) <EOL> t1 = ttime ( ) <EOL> p_len = audio0 . shape [ <NUM_LIT> ] // self . window <EOL> if feats . shape [ <NUM_LIT> ] < p_len : <EOL> p_len = feats . shape [ <NUM_LIT> ] <EOL> if pitch != None and pitchf != None : <EOL> pitch = pitch [ : , : p_len ] <EOL> pitchf = pitchf [ : , : p_len ] <EOL> if protect < <NUM_LIT> and pitch != None and pitchf != None : <EOL> pitchff = pitchf . clone ( ) <EOL> pitchff [ pitchf > <NUM_LIT> ] = <NUM_LIT> <EOL> pitchff [ pitchf < <NUM_LIT> ] = protect <EOL> pitchff = pitchff . unsqueeze ( - <NUM_LIT> ) <EOL> feats = feats * pitchff + feats0 * ( <NUM_LIT> - pitchff ) <EOL> feats = feats . to ( feats0 . dtype ) <EOL> p_len = torch . tensor ( [ p_len ] , device = self . device ) . long ( ) <EOL> with torch . no_grad ( ) : <EOL> if pitch != None and pitchf != None : <EOL> audio1 = ( <EOL> ( net_g . infer ( feats , p_len , pitch , pitchf , sid ) [ <NUM_LIT> ] [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> . data . cpu ( ) <EOL> . float ( ) <EOL> . numpy ( ) <EOL> ) <EOL> else : <EOL> audio1 = ( <EOL> ( net_g . infer ( feats , p_len , sid ) [ <NUM_LIT> ] [ <NUM_LIT> , <NUM_LIT> ] ) . data . cpu ( ) . float ( ) . numpy ( ) <EOL> ) <EOL> del feats , p_len , padding_mask <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> t2 = ttime ( ) <EOL> return audio1 <EOL> def pipeline ( <EOL> self , <EOL> model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = None , <EOL> ) : <EOL> if file_index != "<STR_LIT>" and os . path . exists ( file_index ) == True and index_rate != <NUM_LIT> : <EOL> try : <EOL> index = faiss . read_index ( file_index ) <EOL> big_npy = index . reconstruct_n ( <NUM_LIT> , index . ntotal ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> index = big_npy = None <EOL> else : <EOL> index = big_npy = None <EOL> audio = signal . filtfilt ( bh , ah , audio ) <EOL> audio_pad = np . pad ( audio , ( self . window // <NUM_LIT> , self . window // <NUM_LIT> ) , mode = "<STR_LIT>" ) <EOL> opt_ts = [ ] <EOL> if audio_pad . shape [ <NUM_LIT> ] > self . t_max : <EOL> audio_sum = np . zeros_like ( audio ) <EOL> for i in range ( self . window ) : <EOL> audio_sum += audio_pad [ i : i - self . window ] <EOL> for t in range ( self . t_center , audio . shape [ <NUM_LIT> ] , self . t_center ) : <EOL> opt_ts . append ( <EOL> t <EOL> - self . t_query <EOL> + np . where ( <EOL> np . abs ( audio_sum [ t - self . t_query : t + self . t_query ] ) <EOL> == np . abs ( audio_sum [ t - self . t_query : t + self . t_query ] ) . min ( ) <EOL> ) [ <NUM_LIT> ] [ <NUM_LIT> ] <EOL> ) <EOL> s = <NUM_LIT> <EOL> audio_opt = [ ] <EOL> t = None <EOL> t1 = ttime ( ) <EOL> audio_pad = np . pad ( audio , ( self . t_pad , self . t_pad ) , mode = "<STR_LIT>" ) <EOL> p_len = audio_pad . shape [ <NUM_LIT> ] // self . window <EOL> inp_f0 = None <EOL> if hasattr ( f0_file , "<STR_LIT>" ) == True : <EOL> try : <EOL> with open ( f0_file . name , "<STR_LIT>" ) as f : <EOL> lines = f . read ( ) . strip ( "<STR_LIT>" ) . split ( "<STR_LIT>" ) <EOL> inp_f0 = [ ] <EOL> for line in lines : <EOL> inp_f0 . append ( [ float ( i ) for i in line . split ( "<STR_LIT>" ) ] ) <EOL> inp_f0 = np . array ( inp_f0 , dtype = "<STR_LIT>" ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> sid = torch . tensor ( sid , device = self . device ) . unsqueeze ( <NUM_LIT> ) . long ( ) <EOL> pitch , pitchf = None , None <EOL> if if_f0 == <NUM_LIT> : <EOL> pitch , pitchf = self . get_f0 ( <EOL> input_audio_path , <EOL> audio_pad , <EOL> p_len , <EOL> f0_up_key , <EOL> f0_method , <EOL> filter_radius , <EOL> hop_length , <EOL> f0autotune , <EOL> inp_f0 , <EOL> ) <EOL> pitch = pitch [ : p_len ] <EOL> pitchf = pitchf [ : p_len ] <EOL> if self . device == "<STR_LIT>" : <EOL> pitchf = pitchf . astype ( np . float32 ) <EOL> pitch = torch . tensor ( pitch , device = self . device ) . unsqueeze ( <NUM_LIT> ) . long ( ) <EOL> pitchf = torch . tensor ( pitchf , device = self . device ) . unsqueeze ( <NUM_LIT> ) . float ( ) <EOL> t2 = ttime ( ) <EOL> for t in opt_ts : <EOL> t = t // self . window * self . window <EOL> if if_f0 == <NUM_LIT> : <EOL> audio_opt . append ( <EOL> self . vc ( <EOL> model , <EOL> net_g , <EOL> sid , <EOL> audio_pad [ s : t + self . t_pad2 + self . window ] , <EOL> pitch [ : , s // self . window : ( t + self . t_pad2 ) // self . window ] , <EOL> pitchf [ : , s // self . window : ( t + self . t_pad2 ) // self . window ] , <EOL> index , <EOL> big_npy , <EOL> index_rate , <EOL> version , <EOL> protect , <EOL> ) [ self . t_pad_tgt : - self . t_pad_tgt ] <EOL> ) <EOL> else : <EOL> audio_opt . append ( <EOL> self . vc ( <EOL> model , <EOL> net_g , <EOL> sid , <EOL> audio_pad [ s : t + self . t_pad2 + self . window ] , <EOL> None , <EOL> None , <EOL> index , <EOL> big_npy , <EOL> index_rate , <EOL> version , <EOL> protect , <EOL> ) [ self . t_pad_tgt : - self . t_pad_tgt ] <EOL> ) <EOL> s = t <EOL> if if_f0 == <NUM_LIT> : <EOL> audio_opt . append ( <EOL> self . vc ( <EOL> model , <EOL> net_g , <EOL> sid , <EOL> audio_pad [ t : ] , <EOL> pitch [ : , t // self . window : ] if t is not None else pitch , <EOL> pitchf [ : , t // self . window : ] if t is not None else pitchf , <EOL> index , <EOL> big_npy , <EOL> index_rate , <EOL> version , <EOL> protect , <EOL> ) [ self . t_pad_tgt : - self . t_pad_tgt ] <EOL> ) <EOL> else : <EOL> audio_opt . append ( <EOL> self . vc ( <EOL> model , <EOL> net_g , <EOL> sid , <EOL> audio_pad [ t : ] , <EOL> None , <EOL> None , <EOL> index , <EOL> big_npy , <EOL> index_rate , <EOL> version , <EOL> protect , <EOL> ) [ self . t_pad_tgt : - self . t_pad_tgt ] <EOL> ) <EOL> audio_opt = np . concatenate ( audio_opt ) <EOL> if rms_mix_rate != <NUM_LIT> : <EOL> audio_opt = change_rms ( audio , <NUM_LIT> , audio_opt , tgt_sr , rms_mix_rate ) <EOL> if resample_sr >= <NUM_LIT> and tgt_sr != resample_sr : <EOL> audio_opt = librosa . resample ( <EOL> audio_opt , orig_sr = tgt_sr , target_sr = resample_sr <EOL> ) <EOL> audio_max = np . abs ( audio_opt ) . max ( ) / <NUM_LIT> <EOL> max_int16 = <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> max_int16 /= audio_max <EOL> audio_opt = ( audio_opt * max_int16 ) . astype ( np . int16 ) <EOL> del pitch , pitchf , sid <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> return audio_opt <EOL> </s>
<s> import gradio as gr <EOL> from assets . version_checker import compare_version <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def version_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> version_check = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> interactive = False , <EOL> ) <EOL> version_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> version_button . click ( <EOL> fn = compare_version , <EOL> inputs = [ ] , <EOL> outputs = [ version_check ] , <EOL> ) <EOL> </s>
<s> import ffmpeg <EOL> import numpy as np <EOL> import re <EOL> import unicodedata <EOL> def load_audio ( file , sampling_rate ) : <EOL> try : <EOL> file = file . strip ( "<STR_LIT>" ) . strip ( '<STR_LIT>' ) . strip ( "<STR_LIT>" ) . strip ( '<STR_LIT>' ) . strip ( "<STR_LIT>" ) <EOL> out , _ = ( <EOL> ffmpeg . input ( file , threads = <NUM_LIT> ) <EOL> . output ( "<STR_LIT>" , format = "<STR_LIT>" , acodec = "<STR_LIT>" , ac = <NUM_LIT> , ar = sampling_rate ) <EOL> . run ( cmd = [ "<STR_LIT>" , "<STR_LIT>" ] , capture_stdout = True , capture_stderr = True ) <EOL> ) <EOL> except Exception as error : <EOL> raise RuntimeError ( f"<STR_LIT>" ) <EOL> return np . frombuffer ( out , np . float32 ) . flatten ( ) <EOL> def format_title ( title ) : <EOL> formatted_title = ( <EOL> unicodedata . normalize ( "<STR_LIT>" , title ) . encode ( "<STR_LIT>" , "<STR_LIT>" ) . decode ( "<STR_LIT>" ) <EOL> ) <EOL> formatted_title = re . sub ( r"<STR_LIT>" , "<STR_LIT>" , formatted_title ) <EOL> formatted_title = re . sub ( r"<STR_LIT>" , "<STR_LIT>" , formatted_title ) <EOL> formatted_title = re . sub ( r"<STR_LIT>" , "<STR_LIT>" , formatted_title ) <EOL> return formatted_title <EOL> </s>
<s> import os <EOL> import socket <EOL> import subprocess <EOL> import time <EOL> import requests <EOL> import sys <EOL> import json <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> config_file = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> env_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> host = "<STR_LIT>" <EOL> port = <NUM_LIT> <EOL> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> sock . settimeout ( <NUM_LIT> ) <EOL> def start_flask ( ) : <EOL> try : <EOL> sock . connect ( ( host , port ) ) <EOL> print ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> print ( "<STR_LIT>" ) <EOL> sock . close ( ) <EOL> requests . post ( "<STR_LIT>" ) <EOL> time . sleep ( <NUM_LIT> ) <EOL> script_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( f"<STR_LIT>" ) <EOL> print ( e ) <EOL> except Exception as e : <EOL> sock . close ( ) <EOL> script_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> try : <EOL> subprocess . Popen ( <EOL> [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE <EOL> ) <EOL> except Exception as e : <EOL> print ( "<STR_LIT>" ) <EOL> print ( e ) <EOL> def load_config_flask ( ) : <EOL> with open ( config_file , "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ "<STR_LIT>" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> config [ "<STR_LIT>" ] = value <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> </s>
<s> from typing import Union <EOL> import torch . nn . functional as F <EOL> import numpy as np <EOL> import torch <EOL> import torch . nn as nn <EOL> from torch . nn . utils . parametrizations import weight_norm <EOL> from torchaudio . transforms import Resample <EOL> import os <EOL> import librosa <EOL> import soundfile as sf <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> import math <EOL> from functools import partial <EOL> from einops import rearrange , repeat <EOL> from local_attention import LocalAttention <EOL> from torch import nn <EOL> os . environ [ "<STR_LIT>" ] = "<STR_LIT>" <EOL> def load_wav_to_torch ( full_path , target_sr = None , return_empty_on_exception = False ) : <EOL> sampling_rate = None <EOL> try : <EOL> data , sampling_rate = sf . read ( full_path , always_2d = True ) <EOL> except Exception as error : <EOL> print ( f"<STR_LIT>" ) <EOL> if return_empty_on_exception : <EOL> return [ ] , sampling_rate or target_sr or <NUM_LIT> <EOL> else : <EOL> raise Exception ( error ) <EOL> if len ( data . shape ) > <NUM_LIT> : <EOL> data = data [ : , <NUM_LIT> ] <EOL> assert ( <EOL> len ( data ) > <NUM_LIT> <EOL> ) <EOL> if np . issubdtype ( data . dtype , np . integer ) : <EOL> max_mag = - np . iinfo ( <EOL> data . dtype <EOL> ) . min <EOL> else : <EOL> max_mag = max ( np . amax ( data ) , - np . amin ( data ) ) <EOL> max_mag = ( <EOL> ( <NUM_LIT> ** <NUM_LIT> ) + <NUM_LIT> <EOL> if max_mag > ( <NUM_LIT> ** <NUM_LIT> ) <EOL> else ( ( <NUM_LIT> ** <NUM_LIT> ) + <NUM_LIT> if max_mag > <NUM_LIT> else <NUM_LIT> ) <EOL> ) <EOL> data = torch . FloatTensor ( data . astype ( np . float32 ) ) / max_mag <EOL> if ( <EOL> torch . isinf ( data ) | torch . isnan ( data ) <EOL> ) . any ( ) and return_empty_on_exception : <EOL> return [ ] , sampling_rate or target_sr or <NUM_LIT> <EOL> if target_sr is not None and sampling_rate != target_sr : <EOL> data = torch . from_numpy ( <EOL> librosa . core . resample ( <EOL> data . numpy ( ) , orig_sr = sampling_rate , target_sr = target_sr <EOL> ) <EOL> ) <EOL> sampling_rate = target_sr <EOL> return data , sampling_rate <EOL> def dynamic_range_compression ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return np . log ( np . clip ( x , a_min = clip_val , a_max = None ) * C ) <EOL> def dynamic_range_decompression ( x , C = <NUM_LIT> ) : <EOL> return np . exp ( x ) / C <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> class STFT : <EOL> def __init__ ( <EOL> self , <EOL> sr = <NUM_LIT> , <EOL> n_mels = <NUM_LIT> , <EOL> n_fft = <NUM_LIT> , <EOL> win_size = <NUM_LIT> , <EOL> hop_length = <NUM_LIT> , <EOL> fmin = <NUM_LIT> , <EOL> fmax = <NUM_LIT> , <EOL> clip_val = <NUM_LIT> , <EOL> ) : <EOL> self . target_sr = sr <EOL> self . n_mels = n_mels <EOL> self . n_fft = n_fft <EOL> self . win_size = win_size <EOL> self . hop_length = hop_length <EOL> self . fmin = fmin <EOL> self . fmax = fmax <EOL> self . clip_val = clip_val <EOL> self . mel_basis = { } <EOL> self . hann_window = { } <EOL> def get_mel ( self , y , keyshift = <NUM_LIT> , speed = <NUM_LIT> , center = False , train = False ) : <EOL> sampling_rate = self . target_sr <EOL> n_mels = self . n_mels <EOL> n_fft = self . n_fft <EOL> win_size = self . win_size <EOL> hop_length = self . hop_length <EOL> fmin = self . fmin <EOL> fmax = self . fmax <EOL> clip_val = self . clip_val <EOL> factor = <NUM_LIT> ** ( keyshift / <NUM_LIT> ) <EOL> n_fft_new = int ( np . round ( n_fft * factor ) ) <EOL> win_size_new = int ( np . round ( win_size * factor ) ) <EOL> hop_length_new = int ( np . round ( hop_length * speed ) ) <EOL> if not train : <EOL> mel_basis = self . mel_basis <EOL> hann_window = self . hann_window <EOL> else : <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> mel_basis_key = str ( fmax ) + "<STR_LIT>" + str ( y . device ) <EOL> if mel_basis_key not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = n_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ mel_basis_key ] = torch . from_numpy ( mel ) . float ( ) . to ( y . device ) <EOL> keyshift_key = str ( keyshift ) + "<STR_LIT>" + str ( y . device ) <EOL> if keyshift_key not in hann_window : <EOL> hann_window [ keyshift_key ] = torch . hann_window ( win_size_new ) . to ( y . device ) <EOL> pad_left = ( win_size_new - hop_length_new ) // <NUM_LIT> <EOL> pad_right = max ( <EOL> ( win_size_new - hop_length_new + <NUM_LIT> ) // <NUM_LIT> , <EOL> win_size_new - y . size ( - <NUM_LIT> ) - pad_left , <EOL> ) <EOL> if pad_right < y . size ( - <NUM_LIT> ) : <EOL> mode = "<STR_LIT>" <EOL> else : <EOL> mode = "<STR_LIT>" <EOL> y = torch . nn . functional . pad ( y . unsqueeze ( <NUM_LIT> ) , ( pad_left , pad_right ) , mode = mode ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft_new , <EOL> hop_length = hop_length_new , <EOL> win_length = win_size_new , <EOL> window = hann_window [ keyshift_key ] , <EOL> center = center , <EOL> pad_mode = "<STR_LIT>" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + ( <NUM_LIT> ) ) <EOL> if keyshift != <NUM_LIT> : <EOL> size = n_fft // <NUM_LIT> + <NUM_LIT> <EOL> resize = spec . size ( <NUM_LIT> ) <EOL> if resize < size : <EOL> spec = F . pad ( spec , ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , size - resize ) ) <EOL> spec = spec [ : , : size , : ] * win_size / win_size_new <EOL> spec = torch . matmul ( mel_basis [ mel_basis_key ] , spec ) <EOL> spec = dynamic_range_compression_torch ( spec , clip_val = clip_val ) <EOL> return spec <EOL> def __call__ ( self , audiopath ) : <EOL> audio , sr = load_wav_to_torch ( audiopath , target_sr = self . target_sr ) <EOL> spect = self . get_mel ( audio . unsqueeze ( <NUM_LIT> ) ) . squeeze ( <NUM_LIT> ) <EOL> return spect <EOL> stft = STFT ( ) <EOL> def softmax_kernel ( <EOL> data , * , projection_matrix , is_query , normalize_data = True , eps = <NUM_LIT> , device = None <EOL> ) : <EOL> b , h , * _ = data . shape <EOL> data_normalizer = ( data . shape [ - <NUM_LIT> ] ** - <NUM_LIT> ) if normalize_data else <NUM_LIT> <EOL> ratio = projection_matrix . shape [ <NUM_LIT> ] ** - <NUM_LIT> <EOL> projection = repeat ( projection_matrix , "<STR_LIT>" , b = b , h = h ) <EOL> projection = projection . type_as ( data ) <EOL> data_dash = torch . einsum ( "<STR_LIT>" , ( data_normalizer * data ) , projection ) <EOL> diag_data = data ** <NUM_LIT> <EOL> diag_data = torch . sum ( diag_data , dim = - <NUM_LIT> ) <EOL> diag_data = ( diag_data / <NUM_LIT> ) * ( data_normalizer ** <NUM_LIT> ) <EOL> diag_data = diag_data . unsqueeze ( dim = - <NUM_LIT> ) <EOL> if is_query : <EOL> data_dash = ratio * ( <EOL> torch . exp ( <EOL> data_dash <EOL> - diag_data <EOL> - torch . max ( data_dash , dim = - <NUM_LIT> , keepdim = True ) . values <EOL> ) <EOL> + eps <EOL> ) <EOL> else : <EOL> data_dash = ratio * ( <EOL> torch . exp ( data_dash - diag_data + eps ) <EOL> ) <EOL> return data_dash . type_as ( data ) <EOL> def orthogonal_matrix_chunk ( cols , qr_uniform_q = False , device = None ) : <EOL> unstructured_block = torch . randn ( ( cols , cols ) , device = device ) <EOL> q , r = torch . linalg . qr ( unstructured_block . cpu ( ) , mode = "<STR_LIT>" ) <EOL> q , r = map ( lambda t : t . to ( device ) , ( q , r ) ) <EOL> if qr_uniform_q : <EOL> d = torch . diag ( r , <NUM_LIT> ) <EOL> q *= d . sign ( ) <EOL> return q . t ( ) <EOL> def exists ( val ) : <EOL> return val is not None <EOL> def empty ( tensor ) : <EOL> return tensor . numel ( ) == <NUM_LIT> <EOL> def default ( val , d ) : <EOL> return val if exists ( val ) else d <EOL> def cast_tuple ( val ) : <EOL> return ( val , ) if not isinstance ( val , tuple ) else val <EOL> class PCmer ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> num_layers , <EOL> num_heads , <EOL> dim_model , <EOL> dim_keys , <EOL> dim_values , <EOL> residual_dropout , <EOL> attention_dropout , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> self . num_layers = num_layers <EOL> self . num_heads = num_heads <EOL> self . dim_model = dim_model <EOL> self . dim_values = dim_values <EOL> self . dim_keys = dim_keys <EOL> self . residual_dropout = residual_dropout <EOL> self . attention_dropout = attention_dropout <EOL> self . _layers = nn . ModuleList ( [ _EncoderLayer ( self ) for _ in range ( num_layers ) ] ) <EOL> def forward ( self , phone , mask = None ) : <EOL> for i , layer in enumerate ( self . _layers ) : <EOL> phone = layer ( phone , mask ) <EOL> return phone <EOL> class _EncoderLayer ( nn . Module ) : <EOL> def __init__ ( self , parent : PCmer ) : <EOL> super ( ) . __init__ ( ) <EOL> self . conformer = ConformerConvModule ( parent . dim_model ) <EOL> self . norm = nn . LayerNorm ( parent . dim_model ) <EOL> self . dropout = nn . Dropout ( parent . residual_dropout ) <EOL> self . attn = SelfAttention ( <EOL> dim = parent . dim_model , heads = parent . num_heads , causal = False <EOL> ) <EOL> def forward ( self , phone , mask = None ) : <EOL> phone = phone + ( self . attn ( self . norm ( phone ) , mask = mask ) ) <EOL> phone = phone + ( self . conformer ( phone ) ) <EOL> return phone <EOL> def calc_same_padding ( kernel_size ) : <EOL> pad = kernel_size // <NUM_LIT> <EOL> return ( pad , pad - ( kernel_size + <NUM_LIT> ) % <NUM_LIT> ) <EOL> class Swish ( nn . Module ) : <EOL> def forward ( self , x ) : <EOL> return x * x . sigmoid ( ) <EOL> class Transpose ( nn . Module ) : <EOL> def __init__ ( self , dims ) : <EOL> super ( ) . __init__ ( ) <EOL> assert len ( dims ) == <NUM_LIT> , "<STR_LIT>" <EOL> self . dims = dims <EOL> def forward ( self , x ) : <EOL> return x . transpose ( * self . dims ) <EOL> class GLU ( nn . Module ) : <EOL> def __init__ ( self , dim ) : <EOL> super ( ) . __init__ ( ) <EOL> self . dim = dim <EOL> def forward ( self , x ) : <EOL> out , gate = x . chunk ( <NUM_LIT> , dim = self . dim ) <EOL> return out * gate . sigmoid ( ) <EOL> class DepthWiseConv1d ( nn . Module ) : <EOL> def __init__ ( self , chan_in , chan_out , kernel_size , padding ) : <EOL> super ( ) . __init__ ( ) <EOL> self . padding = padding <EOL> self . conv = nn . Conv1d ( chan_in , chan_out , kernel_size , groups = chan_in ) <EOL> def forward ( self , x ) : <EOL> x = F . pad ( x , self . padding ) <EOL> return self . conv ( x ) <EOL> class ConformerConvModule ( nn . Module ) : <EOL> def __init__ ( <EOL> self , dim , causal = False , expansion_factor = <NUM_LIT> , kernel_size = <NUM_LIT> , dropout = <NUM_LIT> <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> inner_dim = dim * expansion_factor <EOL> padding = calc_same_padding ( kernel_size ) if not causal else ( kernel_size - <NUM_LIT> , <NUM_LIT> ) <EOL> self . net = nn . Sequential ( <EOL> nn . LayerNorm ( dim ) , <EOL> Transpose ( ( <NUM_LIT> , <NUM_LIT> ) ) , <EOL> nn . Conv1d ( dim , inner_dim * <NUM_LIT> , <NUM_LIT> ) , <EOL> GLU ( dim = <NUM_LIT> ) , <EOL> DepthWiseConv1d ( <EOL> inner_dim , inner_dim , kernel_size = kernel_size , padding = padding <EOL> ) , <EOL> Swish ( ) , <EOL> nn . Conv1d ( inner_dim , dim , <NUM_LIT> ) , <EOL> Transpose ( ( <NUM_LIT> , <NUM_LIT> ) ) , <EOL> nn . Dropout ( dropout ) , <EOL> ) <EOL> def forward ( self , x ) : <EOL> return self . net ( x ) <EOL> def linear_attention ( q , k , v ) : <EOL> if v is None : <EOL> out = torch . einsum ( "<STR_LIT>" , k , q ) <EOL> return out <EOL> else : <EOL> k_cumsum = k . sum ( dim = - <NUM_LIT> ) <EOL> D_inv = <NUM_LIT> / ( torch . einsum ( "<STR_LIT>" , q , k_cumsum . type_as ( q ) ) + <NUM_LIT> ) <EOL> context = torch . einsum ( "<STR_LIT>" , k , v ) <EOL> out = torch . einsum ( "<STR_LIT>" , context , q , D_inv ) <EOL> return out <EOL> def gaussian_orthogonal_random_matrix ( <EOL> nb_rows , nb_columns , scaling = <NUM_LIT> , qr_uniform_q = False , device = None <EOL> ) : <EOL> nb_full_blocks = int ( nb_rows / nb_columns ) <EOL> block_list = [ ] <EOL> for _ in range ( nb_full_blocks ) : <EOL> q = orthogonal_matrix_chunk ( <EOL> nb_columns , qr_uniform_q = qr_uniform_q , device = device <EOL> ) <EOL> block_list . append ( q ) <EOL> remaining_rows = nb_rows - nb_full_blocks * nb_columns <EOL> if remaining_rows > <NUM_LIT> : <EOL> q = orthogonal_matrix_chunk ( <EOL> nb_columns , qr_uniform_q = qr_uniform_q , device = device <EOL> ) <EOL> block_list . append ( q [ : remaining_rows ] ) <EOL> final_matrix = torch . cat ( block_list ) <EOL> if scaling == <NUM_LIT> : <EOL> multiplier = torch . randn ( ( nb_rows , nb_columns ) , device = device ) . norm ( dim = <NUM_LIT> ) <EOL> elif scaling == <NUM_LIT> : <EOL> multiplier = math . sqrt ( ( float ( nb_columns ) ) ) * torch . ones ( <EOL> ( nb_rows , ) , device = device <EOL> ) <EOL> else : <EOL> raise ValueError ( f"<STR_LIT>" ) <EOL> return torch . diag ( multiplier ) @ final_matrix <EOL> class FastAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> dim_heads , <EOL> nb_features = None , <EOL> ortho_scaling = <NUM_LIT> , <EOL> causal = False , <EOL> generalized_attention = False , <EOL> kernel_fn = nn . ReLU ( ) , <EOL> qr_uniform_q = False , <EOL> no_projection = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> nb_features = default ( nb_features , int ( dim_heads * math . log ( dim_heads ) ) ) <EOL> self . dim_heads = dim_heads <EOL> self . nb_features = nb_features <EOL> self . ortho_scaling = ortho_scaling <EOL> self . create_projection = partial ( <EOL> gaussian_orthogonal_random_matrix , <EOL> nb_rows = self . nb_features , <EOL> nb_columns = dim_heads , <EOL> scaling = ortho_scaling , <EOL> qr_uniform_q = qr_uniform_q , <EOL> ) <EOL> projection_matrix = self . create_projection ( ) <EOL> self . register_buffer ( "<STR_LIT>" , projection_matrix ) <EOL> self . generalized_attention = generalized_attention <EOL> self . kernel_fn = kernel_fn <EOL> self . no_projection = no_projection <EOL> self . causal = causal <EOL> @ torch . no_grad ( ) <EOL> def redraw_projection_matrix ( self ) : <EOL> projections = self . create_projection ( ) <EOL> self . projection_matrix . copy_ ( projections ) <EOL> del projections <EOL> def forward ( self , q , k , v ) : <EOL> device = q . device <EOL> if self . no_projection : <EOL> q = q . softmax ( dim = - <NUM_LIT> ) <EOL> k = torch . exp ( k ) if self . causal else k . softmax ( dim = - <NUM_LIT> ) <EOL> else : <EOL> create_kernel = partial ( <EOL> softmax_kernel , projection_matrix = self . projection_matrix , device = device <EOL> ) <EOL> q = create_kernel ( q , is_query = True ) <EOL> k = create_kernel ( k , is_query = False ) <EOL> attn_fn = linear_attention if not self . causal else self . causal_linear_fn <EOL> if v is None : <EOL> out = attn_fn ( q , k , None ) <EOL> return out <EOL> else : <EOL> out = attn_fn ( q , k , v ) <EOL> return out <EOL> class SelfAttention ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> dim , <EOL> causal = False , <EOL> heads = <NUM_LIT> , <EOL> dim_head = <NUM_LIT> , <EOL> local_heads = <NUM_LIT> , <EOL> local_window_size = <NUM_LIT> , <EOL> nb_features = None , <EOL> feature_redraw_interval = <NUM_LIT> , <EOL> generalized_attention = False , <EOL> kernel_fn = nn . ReLU ( ) , <EOL> qr_uniform_q = False , <EOL> dropout = <NUM_LIT> , <EOL> no_projection = False , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> assert dim % heads == <NUM_LIT> , "<STR_LIT>" <EOL> dim_head = default ( dim_head , dim // heads ) <EOL> inner_dim = dim_head * heads <EOL> self . fast_attention = FastAttention ( <EOL> dim_head , <EOL> nb_features , <EOL> causal = causal , <EOL> generalized_attention = generalized_attention , <EOL> kernel_fn = kernel_fn , <EOL> qr_uniform_q = qr_uniform_q , <EOL> no_projection = no_projection , <EOL> ) <EOL> self . heads = heads <EOL> self . global_heads = heads - local_heads <EOL> self . local_attn = ( <EOL> LocalAttention ( <EOL> window_size = local_window_size , <EOL> causal = causal , <EOL> autopad = True , <EOL> dropout = dropout , <EOL> look_forward = int ( not causal ) , <EOL> rel_pos_emb_config = ( dim_head , local_heads ) , <EOL> ) <EOL> if local_heads > <NUM_LIT> <EOL> else None <EOL> ) <EOL> self . to_q = nn . Linear ( dim , inner_dim ) <EOL> self . to_k = nn . Linear ( dim , inner_dim ) <EOL> self . to_v = nn . Linear ( dim , inner_dim ) <EOL> self . to_out = nn . Linear ( inner_dim , dim ) <EOL> self . dropout = nn . Dropout ( dropout ) <EOL> @ torch . no_grad ( ) <EOL> def redraw_projection_matrix ( self ) : <EOL> self . fast_attention . redraw_projection_matrix ( ) <EOL> def forward ( <EOL> self , <EOL> x , <EOL> context = None , <EOL> mask = None , <EOL> context_mask = None , <EOL> name = None , <EOL> inference = False , <EOL> ** kwargs , <EOL> ) : <EOL> _ , _ , _ , h , gh = * x . shape , self . heads , self . global_heads <EOL> cross_attend = exists ( context ) <EOL> context = default ( context , x ) <EOL> context_mask = default ( context_mask , mask ) if not cross_attend else context_mask <EOL> q , k , v = self . to_q ( x ) , self . to_k ( context ) , self . to_v ( context ) <EOL> q , k , v = map ( lambda t : rearrange ( t , "<STR_LIT>" , h = h ) , ( q , k , v ) ) <EOL> ( q , lq ) , ( k , lk ) , ( v , lv ) = map ( lambda t : ( t [ : , : gh ] , t [ : , gh : ] ) , ( q , k , v ) ) <EOL> attn_outs = [ ] <EOL> if not empty ( q ) : <EOL> if exists ( context_mask ) : <EOL> global_mask = context_mask [ : , None , : , None ] <EOL> v . masked_fill_ ( ~ global_mask , <NUM_LIT> ) <EOL> if cross_attend : <EOL> pass <EOL> else : <EOL> out = self . fast_attention ( q , k , v ) <EOL> attn_outs . append ( out ) <EOL> if not empty ( lq ) : <EOL> assert ( <EOL> not cross_attend <EOL> ) , "<STR_LIT>" <EOL> out = self . local_attn ( lq , lk , lv , input_mask = mask ) <EOL> attn_outs . append ( out ) <EOL> out = torch . cat ( attn_outs , dim = <NUM_LIT> ) <EOL> out = rearrange ( out , "<STR_LIT>" ) <EOL> out = self . to_out ( out ) <EOL> return self . dropout ( out ) <EOL> def l2_regularization ( model , l2_alpha ) : <EOL> l2_loss = [ ] <EOL> for module in model . modules ( ) : <EOL> if type ( module ) is nn . Conv2d : <EOL> l2_loss . append ( ( module . weight ** <NUM_LIT> ) . sum ( ) / <NUM_LIT> ) <EOL> return l2_alpha * sum ( l2_loss ) <EOL> class FCPE ( nn . Module ) : <EOL> def __init__ ( <EOL> self , <EOL> input_channel = <NUM_LIT> , <EOL> out_dims = <NUM_LIT> , <EOL> n_layers = <NUM_LIT> , <EOL> n_chans = <NUM_LIT> , <EOL> use_siren = False , <EOL> use_full = False , <EOL> loss_mse_scale = <NUM_LIT> , <EOL> loss_l2_regularization = False , <EOL> loss_l2_regularization_scale = <NUM_LIT> , <EOL> loss_grad1_mse = False , <EOL> loss_grad1_mse_scale = <NUM_LIT> , <EOL> f0_max = <NUM_LIT> , <EOL> f0_min = <NUM_LIT> , <EOL> confidence = False , <EOL> threshold = <NUM_LIT> , <EOL> use_input_conv = True , <EOL> ) : <EOL> super ( ) . __init__ ( ) <EOL> if use_siren is True : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> if use_full is True : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> self . loss_mse_scale = loss_mse_scale if ( loss_mse_scale is not None ) else <NUM_LIT> <EOL> self . loss_l2_regularization = ( <EOL> loss_l2_regularization if ( loss_l2_regularization is not None ) else False <EOL> ) <EOL> self . loss_l2_regularization_scale = ( <EOL> loss_l2_regularization_scale <EOL> if ( loss_l2_regularization_scale is not None ) <EOL> else <NUM_LIT> <EOL> ) <EOL> self . loss_grad1_mse = loss_grad1_mse if ( loss_grad1_mse is not None ) else False <EOL> self . loss_grad1_mse_scale = ( <EOL> loss_grad1_mse_scale if ( loss_grad1_mse_scale is not None ) else <NUM_LIT> <EOL> ) <EOL> self . f0_max = f0_max if ( f0_max is not None ) else <NUM_LIT> <EOL> self . f0_min = f0_min if ( f0_min is not None ) else <NUM_LIT> <EOL> self . confidence = confidence if ( confidence is not None ) else False <EOL> self . threshold = threshold if ( threshold is not None ) else <NUM_LIT> <EOL> self . use_input_conv = use_input_conv if ( use_input_conv is not None ) else True <EOL> self . cent_table_b = torch . Tensor ( <EOL> np . linspace ( <EOL> self . f0_to_cent ( torch . Tensor ( [ f0_min ] ) ) [ <NUM_LIT> ] , <EOL> self . f0_to_cent ( torch . Tensor ( [ f0_max ] ) ) [ <NUM_LIT> ] , <EOL> out_dims , <EOL> ) <EOL> ) <EOL> self . register_buffer ( "<STR_LIT>" , self . cent_table_b ) <EOL> _leaky = nn . LeakyReLU ( ) <EOL> self . stack = nn . Sequential ( <EOL> nn . Conv1d ( input_channel , n_chans , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) , <EOL> nn . GroupNorm ( <NUM_LIT> , n_chans ) , <EOL> _leaky , <EOL> nn . Conv1d ( n_chans , n_chans , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) , <EOL> ) <EOL> self . decoder = PCmer ( <EOL> num_layers = n_layers , <EOL> num_heads = <NUM_LIT> , <EOL> dim_model = n_chans , <EOL> dim_keys = n_chans , <EOL> dim_values = n_chans , <EOL> residual_dropout = <NUM_LIT> , <EOL> attention_dropout = <NUM_LIT> , <EOL> ) <EOL> self . norm = nn . LayerNorm ( n_chans ) <EOL> self . n_out = out_dims <EOL> self . dense_out = weight_norm ( nn . Linear ( n_chans , self . n_out ) ) <EOL> def forward ( <EOL> self , mel , infer = True , gt_f0 = None , return_hz_f0 = False , cdecoder = "<STR_LIT>" <EOL> ) : <EOL> if cdecoder == "<STR_LIT>" : <EOL> self . cdecoder = self . cents_decoder <EOL> elif cdecoder == "<STR_LIT>" : <EOL> self . cdecoder = self . cents_local_decoder <EOL> if self . use_input_conv : <EOL> x = self . stack ( mel . transpose ( <NUM_LIT> , <NUM_LIT> ) ) . transpose ( <NUM_LIT> , <NUM_LIT> ) <EOL> else : <EOL> x = mel <EOL> x = self . decoder ( x ) <EOL> x = self . norm ( x ) <EOL> x = self . dense_out ( x ) <EOL> x = torch . sigmoid ( x ) <EOL> if not infer : <EOL> gt_cent_f0 = self . f0_to_cent ( gt_f0 ) <EOL> gt_cent_f0 = self . gaussian_blurred_cent ( gt_cent_f0 ) <EOL> loss_all = self . loss_mse_scale * F . binary_cross_entropy ( <EOL> x , gt_cent_f0 <EOL> ) <EOL> if self . loss_l2_regularization : <EOL> loss_all = loss_all + l2_regularization ( <EOL> model = self , l2_alpha = self . loss_l2_regularization_scale <EOL> ) <EOL> x = loss_all <EOL> if infer : <EOL> x = self . cdecoder ( x ) <EOL> x = self . cent_to_f0 ( x ) <EOL> if not return_hz_f0 : <EOL> x = ( <NUM_LIT> + x / <NUM_LIT> ) . log ( ) <EOL> return x <EOL> def cents_decoder ( self , y , mask = True ) : <EOL> B , N , _ = y . size ( ) <EOL> ci = self . cent_table [ None , None , : ] . expand ( B , N , - <NUM_LIT> ) <EOL> rtn = torch . sum ( ci * y , dim = - <NUM_LIT> , keepdim = True ) / torch . sum ( <EOL> y , dim = - <NUM_LIT> , keepdim = True <EOL> ) <EOL> if mask : <EOL> confident = torch . max ( y , dim = - <NUM_LIT> , keepdim = True ) [ <NUM_LIT> ] <EOL> confident_mask = torch . ones_like ( confident ) <EOL> confident_mask [ confident <= self . threshold ] = float ( "<STR_LIT>" ) <EOL> rtn = rtn * confident_mask <EOL> if self . confidence : <EOL> return rtn , confident <EOL> else : <EOL> return rtn <EOL> def cents_local_decoder ( self , y , mask = True ) : <EOL> B , N , _ = y . size ( ) <EOL> ci = self . cent_table [ None , None , : ] . expand ( B , N , - <NUM_LIT> ) <EOL> confident , max_index = torch . max ( y , dim = - <NUM_LIT> , keepdim = True ) <EOL> local_argmax_index = torch . arange ( <NUM_LIT> , <NUM_LIT> ) . to ( max_index . device ) + ( max_index - <NUM_LIT> ) <EOL> local_argmax_index [ local_argmax_index < <NUM_LIT> ] = <NUM_LIT> <EOL> local_argmax_index [ local_argmax_index >= self . n_out ] = self . n_out - <NUM_LIT> <EOL> ci_l = torch . gather ( ci , - <NUM_LIT> , local_argmax_index ) <EOL> y_l = torch . gather ( y , - <NUM_LIT> , local_argmax_index ) <EOL> rtn = torch . sum ( ci_l * y_l , dim = - <NUM_LIT> , keepdim = True ) / torch . sum ( <EOL> y_l , dim = - <NUM_LIT> , keepdim = True <EOL> ) <EOL> if mask : <EOL> confident_mask = torch . ones_like ( confident ) <EOL> confident_mask [ confident <= self . threshold ] = float ( "<STR_LIT>" ) <EOL> rtn = rtn * confident_mask <EOL> if self . confidence : <EOL> return rtn , confident <EOL> else : <EOL> return rtn <EOL> def cent_to_f0 ( self , cent ) : <EOL> return <NUM_LIT> * <NUM_LIT> ** ( cent / <NUM_LIT> ) <EOL> def f0_to_cent ( self , f0 ) : <EOL> return <NUM_LIT> * torch . log2 ( f0 / <NUM_LIT> ) <EOL> def gaussian_blurred_cent ( self , cents ) : <EOL> mask = ( cents > <NUM_LIT> ) & ( cents < ( <NUM_LIT> * np . log2 ( self . f0_max / <NUM_LIT> ) ) ) <EOL> B , N , _ = cents . size ( ) <EOL> ci = self . cent_table [ None , None , : ] . expand ( B , N , - <NUM_LIT> ) <EOL> return torch . exp ( - torch . square ( ci - cents ) / <NUM_LIT> ) * mask . float ( ) <EOL> class FCPEInfer : <EOL> def __init__ ( self , model_path , device = None , dtype = torch . float32 ) : <EOL> if device is None : <EOL> device = "<STR_LIT>" if torch . cuda . is_available ( ) else "<STR_LIT>" <EOL> self . device = device <EOL> ckpt = torch . load ( model_path , map_location = torch . device ( self . device ) ) <EOL> self . args = DotDict ( ckpt [ "<STR_LIT>" ] ) <EOL> self . dtype = dtype <EOL> model = FCPE ( <EOL> input_channel = self . args . model . input_channel , <EOL> out_dims = self . args . model . out_dims , <EOL> n_layers = self . args . model . n_layers , <EOL> n_chans = self . args . model . n_chans , <EOL> use_siren = self . args . model . use_siren , <EOL> use_full = self . args . model . use_full , <EOL> loss_mse_scale = self . args . loss . loss_mse_scale , <EOL> loss_l2_regularization = self . args . loss . loss_l2_regularization , <EOL> loss_l2_regularization_scale = self . args . loss . loss_l2_regularization_scale , <EOL> loss_grad1_mse = self . args . loss . loss_grad1_mse , <EOL> loss_grad1_mse_scale = self . args . loss . loss_grad1_mse_scale , <EOL> f0_max = self . args . model . f0_max , <EOL> f0_min = self . args . model . f0_min , <EOL> confidence = self . args . model . confidence , <EOL> ) <EOL> model . to ( self . device ) . to ( self . dtype ) <EOL> model . load_state_dict ( ckpt [ "<STR_LIT>" ] ) <EOL> model . eval ( ) <EOL> self . model = model <EOL> self . wav2mel = Wav2Mel ( self . args , dtype = self . dtype , device = self . device ) <EOL> @ torch . no_grad ( ) <EOL> def __call__ ( self , audio , sr , threshold = <NUM_LIT> ) : <EOL> self . model . threshold = threshold <EOL> audio = audio [ None , : ] <EOL> mel = self . wav2mel ( audio = audio , sample_rate = sr ) . to ( self . dtype ) <EOL> f0 = self . model ( mel = mel , infer = True , return_hz_f0 = True ) <EOL> return f0 <EOL> class Wav2Mel : <EOL> def __init__ ( self , args , device = None , dtype = torch . float32 ) : <EOL> self . sampling_rate = args . mel . sampling_rate <EOL> self . hop_size = args . mel . hop_size <EOL> if device is None : <EOL> device = "<STR_LIT>" if torch . cuda . is_available ( ) else "<STR_LIT>" <EOL> self . device = device <EOL> self . dtype = dtype <EOL> self . stft = STFT ( <EOL> args . mel . sampling_rate , <EOL> args . mel . num_mels , <EOL> args . mel . n_fft , <EOL> args . mel . win_size , <EOL> args . mel . hop_size , <EOL> args . mel . fmin , <EOL> args . mel . fmax , <EOL> ) <EOL> self . resample_kernel = { } <EOL> def extract_nvstft ( self , audio , keyshift = <NUM_LIT> , train = False ) : <EOL> mel = self . stft . get_mel ( audio , keyshift = keyshift , train = train ) . transpose ( <EOL> <NUM_LIT> , <NUM_LIT> <EOL> ) <EOL> return mel <EOL> def extract_mel ( self , audio , sample_rate , keyshift = <NUM_LIT> , train = False ) : <EOL> audio = audio . to ( self . dtype ) . to ( self . device ) <EOL> if sample_rate == self . sampling_rate : <EOL> audio_res = audio <EOL> else : <EOL> key_str = str ( sample_rate ) <EOL> if key_str not in self . resample_kernel : <EOL> self . resample_kernel [ key_str ] = Resample ( <EOL> sample_rate , self . sampling_rate , lowpass_filter_width = <NUM_LIT> <EOL> ) <EOL> self . resample_kernel [ key_str ] = ( <EOL> self . resample_kernel [ key_str ] . to ( self . dtype ) . to ( self . device ) <EOL> ) <EOL> audio_res = self . resample_kernel [ key_str ] ( audio ) <EOL> mel = self . extract_nvstft ( <EOL> audio_res , keyshift = keyshift , train = train <EOL> ) <EOL> n_frames = int ( audio . shape [ <NUM_LIT> ] // self . hop_size ) + <NUM_LIT> <EOL> if n_frames > int ( mel . shape [ <NUM_LIT> ] ) : <EOL> mel = torch . cat ( ( mel , mel [ : , - <NUM_LIT> : , : ] ) , <NUM_LIT> ) <EOL> if n_frames < int ( mel . shape [ <NUM_LIT> ] ) : <EOL> mel = mel [ : , : n_frames , : ] <EOL> return mel <EOL> def __call__ ( self , audio , sample_rate , keyshift = <NUM_LIT> , train = False ) : <EOL> return self . extract_mel ( audio , sample_rate , keyshift = keyshift , train = train ) <EOL> class DotDict ( dict ) : <EOL> def __getattr__ ( * args ) : <EOL> val = dict . get ( * args ) <EOL> return DotDict ( val ) if type ( val ) is dict else val <EOL> __setattr__ = dict . __setitem__ <EOL> __delattr__ = dict . __delitem__ <EOL> class F0Predictor ( object ) : <EOL> def compute_f0 ( self , wav , p_len ) : <EOL> pass <EOL> def compute_f0_uv ( self , wav , p_len ) : <EOL> pass <EOL> class FCPEF0Predictor ( F0Predictor ) : <EOL> def __init__ ( <EOL> self , <EOL> model_path , <EOL> hop_length = <NUM_LIT> , <EOL> f0_min = <NUM_LIT> , <EOL> f0_max = <NUM_LIT> , <EOL> dtype = torch . float32 , <EOL> device = None , <EOL> sampling_rate = <NUM_LIT> , <EOL> threshold = <NUM_LIT> , <EOL> ) : <EOL> self . fcpe = FCPEInfer ( model_path , device = device , dtype = dtype ) <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> if device is None : <EOL> self . device = "<STR_LIT>" if torch . cuda . is_available ( ) else "<STR_LIT>" <EOL> else : <EOL> self . device = device <EOL> self . threshold = threshold <EOL> self . sampling_rate = sampling_rate <EOL> self . dtype = dtype <EOL> self . name = "<STR_LIT>" <EOL> def repeat_expand ( <EOL> self , <EOL> content : Union [ torch . Tensor , np . ndarray ] , <EOL> target_len : int , <EOL> mode : str = "<STR_LIT>" , <EOL> ) : <EOL> ndim = content . ndim <EOL> if content . ndim == <NUM_LIT> : <EOL> content = content [ None , None ] <EOL> elif content . ndim == <NUM_LIT> : <EOL> content = content [ None ] <EOL> assert content . ndim == <NUM_LIT> <EOL> is_np = isinstance ( content , np . ndarray ) <EOL> if is_np : <EOL> content = torch . from_numpy ( content ) <EOL> results = torch . nn . functional . interpolate ( content , size = target_len , mode = mode ) <EOL> if is_np : <EOL> results = results . numpy ( ) <EOL> if ndim == <NUM_LIT> : <EOL> return results [ <NUM_LIT> , <NUM_LIT> ] <EOL> elif ndim == <NUM_LIT> : <EOL> return results [ <NUM_LIT> ] <EOL> def post_process ( self , x , sampling_rate , f0 , pad_to ) : <EOL> if isinstance ( f0 , np . ndarray ) : <EOL> f0 = torch . from_numpy ( f0 ) . float ( ) . to ( x . device ) <EOL> if pad_to is None : <EOL> return f0 <EOL> f0 = self . repeat_expand ( f0 , pad_to ) <EOL> vuv_vector = torch . zeros_like ( f0 ) <EOL> vuv_vector [ f0 > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ f0 <= <NUM_LIT> ] = <NUM_LIT> <EOL> nzindex = torch . nonzero ( f0 ) . squeeze ( ) <EOL> f0 = torch . index_select ( f0 , dim = <NUM_LIT> , index = nzindex ) . cpu ( ) . numpy ( ) <EOL> time_org = self . hop_length / sampling_rate * nzindex . cpu ( ) . numpy ( ) <EOL> time_frame = np . arange ( pad_to ) * self . hop_length / sampling_rate <EOL> vuv_vector = F . interpolate ( vuv_vector [ None , None , : ] , size = pad_to ) [ <NUM_LIT> ] [ <NUM_LIT> ] <EOL> if f0 . shape [ <NUM_LIT> ] <= <NUM_LIT> : <EOL> return ( <EOL> torch . zeros ( pad_to , dtype = torch . float , device = x . device ) . cpu ( ) . numpy ( ) , <EOL> vuv_vector . cpu ( ) . numpy ( ) , <EOL> ) <EOL> if f0 . shape [ <NUM_LIT> ] == <NUM_LIT> : <EOL> return ( <EOL> torch . ones ( pad_to , dtype = torch . float , device = x . device ) * f0 [ <NUM_LIT> ] <EOL> ) . cpu ( ) . numpy ( ) , vuv_vector . cpu ( ) . numpy ( ) <EOL> f0 = np . interp ( time_frame , time_org , f0 , left = f0 [ <NUM_LIT> ] , right = f0 [ - <NUM_LIT> ] ) <EOL> return f0 , vuv_vector . cpu ( ) . numpy ( ) <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> x = torch . FloatTensor ( wav ) . to ( self . dtype ) . to ( self . device ) <EOL> if p_len is None : <EOL> print ( "<STR_LIT>" ) <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 = self . fcpe ( x , sr = self . sampling_rate , threshold = self . threshold ) [ <NUM_LIT> , : , <NUM_LIT> ] <EOL> if torch . all ( f0 == <NUM_LIT> ) : <EOL> rtn = f0 . cpu ( ) . numpy ( ) if p_len is None else np . zeros ( p_len ) <EOL> return rtn , rtn <EOL> return self . post_process ( x , self . sampling_rate , f0 , p_len ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> x = torch . FloatTensor ( wav ) . to ( self . dtype ) . to ( self . device ) <EOL> if p_len is None : <EOL> p_len = x . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 = self . fcpe ( x , sr = self . sampling_rate , threshold = self . threshold ) [ <NUM_LIT> , : , <NUM_LIT> ] <EOL> if torch . all ( f0 == <NUM_LIT> ) : <EOL> rtn = f0 . cpu ( ) . numpy ( ) if p_len is None else np . zeros ( p_len ) <EOL> return rtn , rtn <EOL> return self . post_process ( x , self . sampling_rate , f0 , p_len ) <EOL> </s>
<s> import torch <EOL> import sys <EOL> import os <EOL> import datetime <EOL> from utils import ( <EOL> get_hparams , <EOL> plot_spectrogram_to_numpy , <EOL> summarize , <EOL> load_checkpoint , <EOL> save_checkpoint , <EOL> latest_checkpoint_path , <EOL> ) <EOL> from random import randint , shuffle <EOL> from time import sleep <EOL> from time import time as ttime <EOL> from torch . cuda . amp import GradScaler , autocast <EOL> from torch . nn import functional as F <EOL> from torch . nn . parallel import DistributedDataParallel as DDP <EOL> from torch . utils . data import DataLoader <EOL> from torch . utils . tensorboard import SummaryWriter <EOL> import torch . distributed as dist <EOL> import torch . multiprocessing as mp <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( os . path . join ( now_dir ) ) <EOL> from data_utils import ( <EOL> DistributedBucketSampler , <EOL> TextAudioCollate , <EOL> TextAudioCollateMultiNSFsid , <EOL> TextAudioLoader , <EOL> TextAudioLoaderMultiNSFsid , <EOL> ) <EOL> from losses import ( <EOL> discriminator_loss , <EOL> feature_loss , <EOL> generator_loss , <EOL> kl_loss , <EOL> ) <EOL> from mel_processing import mel_spectrogram_torch , spec_to_mel_torch <EOL> from rvc . train . process . extract_model import extract_model <EOL> from rvc . lib . infer_pack import commons <EOL> hps = get_hparams ( ) <EOL> if hps . version == "<STR_LIT>" : <EOL> from rvc . lib . infer_pack . models import MultiPeriodDiscriminator <EOL> from rvc . lib . infer_pack . models import SynthesizerTrnMs256NSFsid as RVC_Model_f0 <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid_nono as RVC_Model_nof0 , <EOL> ) <EOL> elif hps . version == "<STR_LIT>" : <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs768NSFsid as RVC_Model_f0 , <EOL> SynthesizerTrnMs768NSFsid_nono as RVC_Model_nof0 , <EOL> MultiPeriodDiscriminatorV2 as MultiPeriodDiscriminator , <EOL> ) <EOL> os . environ [ "<STR_LIT>" ] = hps . gpus . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> n_gpus = len ( hps . gpus . split ( "<STR_LIT>" ) ) <EOL> torch . backends . cudnn . deterministic = False <EOL> torch . backends . cudnn . benchmark = False <EOL> global_step = <NUM_LIT> <EOL> lowest_value = { "<STR_LIT>" : <NUM_LIT> , "<STR_LIT>" : float ( "<STR_LIT>" ) , "<STR_LIT>" : <NUM_LIT> } <EOL> last_loss_gen_all = <NUM_LIT> <EOL> epochs_since_last_lowest = <NUM_LIT> <EOL> class EpochRecorder : <EOL> def __init__ ( self ) : <EOL> self . last_time = ttime ( ) <EOL> def record ( self ) : <EOL> now_time = ttime ( ) <EOL> elapsed_time = now_time - self . last_time <EOL> self . last_time = now_time <EOL> elapsed_time = round ( elapsed_time , <NUM_LIT> ) <EOL> elapsed_time_str = str ( datetime . timedelta ( seconds = int ( elapsed_time ) ) ) <EOL> current_time = datetime . datetime . now ( ) . strftime ( "<STR_LIT>" ) <EOL> return f"<STR_LIT>" <EOL> def main ( ) : <EOL> n_gpus = torch . cuda . device_count ( ) <EOL> if torch . cuda . is_available ( ) == False and torch . backends . mps . is_available ( ) == True : <EOL> n_gpus = <NUM_LIT> <EOL> if n_gpus < <NUM_LIT> : <EOL> print ( "<STR_LIT>" ) <EOL> n_gpus = <NUM_LIT> <EOL> children = [ ] <EOL> pid_file_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> with open ( pid_file_path , "<STR_LIT>" ) as pid_file : <EOL> for i in range ( n_gpus ) : <EOL> subproc = mp . Process ( <EOL> target = run , <EOL> args = ( i , n_gpus , hps ) , <EOL> ) <EOL> children . append ( subproc ) <EOL> subproc . start ( ) <EOL> pid_file . write ( str ( subproc . pid ) + "<STR_LIT>" ) <EOL> for i in range ( n_gpus ) : <EOL> children [ i ] . join ( ) <EOL> def run ( <EOL> rank , <EOL> n_gpus , <EOL> hps , <EOL> ) : <EOL> global global_step <EOL> if rank == <NUM_LIT> : <EOL> writer = SummaryWriter ( log_dir = hps . model_dir ) <EOL> writer_eval = SummaryWriter ( log_dir = os . path . join ( hps . model_dir , "<STR_LIT>" ) ) <EOL> os . environ [ "<STR_LIT>" ] = "<STR_LIT>" <EOL> os . environ [ "<STR_LIT>" ] = str ( randint ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> dist . init_process_group ( <EOL> backend = "<STR_LIT>" , init_method = "<STR_LIT>" , world_size = n_gpus , rank = rank <EOL> ) <EOL> torch . manual_seed ( hps . train . seed ) <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . set_device ( rank ) <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> train_dataset = TextAudioLoaderMultiNSFsid ( hps . data ) <EOL> else : <EOL> train_dataset = TextAudioLoader ( hps . data ) <EOL> train_sampler = DistributedBucketSampler ( <EOL> train_dataset , <EOL> hps . train . batch_size * n_gpus , <EOL> [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , <EOL> num_replicas = n_gpus , <EOL> rank = rank , <EOL> shuffle = True , <EOL> ) <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> collate_fn = TextAudioCollateMultiNSFsid ( ) <EOL> else : <EOL> collate_fn = TextAudioCollate ( ) <EOL> train_loader = DataLoader ( <EOL> train_dataset , <EOL> num_workers = <NUM_LIT> , <EOL> shuffle = False , <EOL> pin_memory = True , <EOL> collate_fn = collate_fn , <EOL> batch_sampler = train_sampler , <EOL> persistent_workers = True , <EOL> prefetch_factor = <NUM_LIT> , <EOL> ) <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> net_g = RVC_Model_f0 ( <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> hps . train . segment_size // hps . data . hop_length , <EOL> ** hps . model , <EOL> is_half = hps . train . fp16_run , <EOL> sr = hps . sample_rate , <EOL> ) <EOL> else : <EOL> net_g = RVC_Model_nof0 ( <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> hps . train . segment_size // hps . data . hop_length , <EOL> ** hps . model , <EOL> is_half = hps . train . fp16_run , <EOL> ) <EOL> if torch . cuda . is_available ( ) : <EOL> net_g = net_g . cuda ( rank ) <EOL> net_d = MultiPeriodDiscriminator ( hps . model . use_spectral_norm ) <EOL> if torch . cuda . is_available ( ) : <EOL> net_d = net_d . cuda ( rank ) <EOL> optim_g = torch . optim . AdamW ( <EOL> net_g . parameters ( ) , <EOL> hps . train . learning_rate , <EOL> betas = hps . train . betas , <EOL> eps = hps . train . eps , <EOL> ) <EOL> optim_d = torch . optim . AdamW ( <EOL> net_d . parameters ( ) , <EOL> hps . train . learning_rate , <EOL> betas = hps . train . betas , <EOL> eps = hps . train . eps , <EOL> ) <EOL> if torch . cuda . is_available ( ) : <EOL> net_g = DDP ( net_g , device_ids = [ rank ] ) <EOL> net_d = DDP ( net_d , device_ids = [ rank ] ) <EOL> else : <EOL> net_g = DDP ( net_g ) <EOL> net_d = DDP ( net_d ) <EOL> try : <EOL> print ( "<STR_LIT>" ) <EOL> _ , _ , _ , epoch_str = load_checkpoint ( <EOL> latest_checkpoint_path ( hps . model_dir , "<STR_LIT>" ) , net_d , optim_d <EOL> ) <EOL> _ , _ , _ , epoch_str = load_checkpoint ( <EOL> latest_checkpoint_path ( hps . model_dir , "<STR_LIT>" ) , net_g , optim_g <EOL> ) <EOL> global_step = ( epoch_str - <NUM_LIT> ) * len ( train_loader ) <EOL> except : <EOL> epoch_str = <NUM_LIT> <EOL> global_step = <NUM_LIT> <EOL> if hps . pretrainG != "<STR_LIT>" : <EOL> if rank == <NUM_LIT> : <EOL> print ( f"<STR_LIT>" ) <EOL> if hasattr ( net_g , "<STR_LIT>" ) : <EOL> print ( <EOL> net_g . module . load_state_dict ( <EOL> torch . load ( hps . pretrainG , map_location = "<STR_LIT>" ) [ "<STR_LIT>" ] <EOL> ) <EOL> ) <EOL> else : <EOL> print ( <EOL> net_g . load_state_dict ( <EOL> torch . load ( hps . pretrainG , map_location = "<STR_LIT>" ) [ "<STR_LIT>" ] <EOL> ) <EOL> ) <EOL> if hps . pretrainD != "<STR_LIT>" : <EOL> if rank == <NUM_LIT> : <EOL> print ( f"<STR_LIT>" ) <EOL> if hasattr ( net_d , "<STR_LIT>" ) : <EOL> print ( <EOL> net_d . module . load_state_dict ( <EOL> torch . load ( hps . pretrainD , map_location = "<STR_LIT>" ) [ "<STR_LIT>" ] <EOL> ) <EOL> ) <EOL> else : <EOL> print ( <EOL> net_d . load_state_dict ( <EOL> torch . load ( hps . pretrainD , map_location = "<STR_LIT>" ) [ "<STR_LIT>" ] <EOL> ) <EOL> ) <EOL> scheduler_g = torch . optim . lr_scheduler . ExponentialLR ( <EOL> optim_g , gamma = hps . train . lr_decay , last_epoch = epoch_str - <NUM_LIT> <EOL> ) <EOL> scheduler_d = torch . optim . lr_scheduler . ExponentialLR ( <EOL> optim_d , gamma = hps . train . lr_decay , last_epoch = epoch_str - <NUM_LIT> <EOL> ) <EOL> scaler = GradScaler ( enabled = hps . train . fp16_run ) <EOL> cache = [ ] <EOL> for epoch in range ( epoch_str , hps . train . epochs + <NUM_LIT> ) : <EOL> if rank == <NUM_LIT> : <EOL> train_and_evaluate ( <EOL> rank , <EOL> epoch , <EOL> hps , <EOL> [ net_g , net_d ] , <EOL> [ optim_g , optim_d ] , <EOL> scaler , <EOL> [ train_loader , None ] , <EOL> [ writer , writer_eval ] , <EOL> cache , <EOL> ) <EOL> else : <EOL> train_and_evaluate ( <EOL> rank , <EOL> epoch , <EOL> hps , <EOL> [ net_g , net_d ] , <EOL> [ optim_g , optim_d ] , <EOL> scaler , <EOL> [ train_loader , None ] , <EOL> None , <EOL> cache , <EOL> ) <EOL> scheduler_g . step ( ) <EOL> scheduler_d . step ( ) <EOL> def train_and_evaluate ( rank , epoch , hps , nets , optims , scaler , loaders , writers , cache ) : <EOL> global global_step , last_loss_gen_all , lowest_value , epochs_since_last_lowest <EOL> if epoch == <NUM_LIT> : <EOL> lowest_value = { "<STR_LIT>" : <NUM_LIT> , "<STR_LIT>" : float ( "<STR_LIT>" ) , "<STR_LIT>" : <NUM_LIT> } <EOL> last_loss_gen_all = <NUM_LIT> <EOL> epochs_since_last_lowest = <NUM_LIT> <EOL> net_g , net_d = nets <EOL> optim_g , optim_d = optims <EOL> train_loader = loaders [ <NUM_LIT> ] if loaders is not None else None <EOL> if writers is not None : <EOL> writer = writers [ <NUM_LIT> ] <EOL> train_loader . batch_sampler . set_epoch ( epoch ) <EOL> net_g . train ( ) <EOL> net_d . train ( ) <EOL> if hps . if_cache_data_in_gpu == True : <EOL> data_iterator = cache <EOL> if cache == [ ] : <EOL> for batch_idx , info in enumerate ( train_loader ) : <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> ( <EOL> phone , <EOL> phone_lengths , <EOL> pitch , <EOL> pitchf , <EOL> spec , <EOL> spec_lengths , <EOL> wave , <EOL> wave_lengths , <EOL> sid , <EOL> ) = info <EOL> else : <EOL> ( <EOL> phone , <EOL> phone_lengths , <EOL> spec , <EOL> spec_lengths , <EOL> wave , <EOL> wave_lengths , <EOL> sid , <EOL> ) = info <EOL> if torch . cuda . is_available ( ) : <EOL> phone = phone . cuda ( rank , non_blocking = True ) <EOL> phone_lengths = phone_lengths . cuda ( rank , non_blocking = True ) <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> pitch = pitch . cuda ( rank , non_blocking = True ) <EOL> pitchf = pitchf . cuda ( rank , non_blocking = True ) <EOL> sid = sid . cuda ( rank , non_blocking = True ) <EOL> spec = spec . cuda ( rank , non_blocking = True ) <EOL> spec_lengths = spec_lengths . cuda ( rank , non_blocking = True ) <EOL> wave = wave . cuda ( rank , non_blocking = True ) <EOL> wave_lengths = wave_lengths . cuda ( rank , non_blocking = True ) <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> cache . append ( <EOL> ( <EOL> batch_idx , <EOL> ( <EOL> phone , <EOL> phone_lengths , <EOL> pitch , <EOL> pitchf , <EOL> spec , <EOL> spec_lengths , <EOL> wave , <EOL> wave_lengths , <EOL> sid , <EOL> ) , <EOL> ) <EOL> ) <EOL> else : <EOL> cache . append ( <EOL> ( <EOL> batch_idx , <EOL> ( <EOL> phone , <EOL> phone_lengths , <EOL> spec , <EOL> spec_lengths , <EOL> wave , <EOL> wave_lengths , <EOL> sid , <EOL> ) , <EOL> ) <EOL> ) <EOL> else : <EOL> shuffle ( cache ) <EOL> else : <EOL> data_iterator = enumerate ( train_loader ) <EOL> epoch_recorder = EpochRecorder ( ) <EOL> for batch_idx , info in data_iterator : <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> ( <EOL> phone , <EOL> phone_lengths , <EOL> pitch , <EOL> pitchf , <EOL> spec , <EOL> spec_lengths , <EOL> wave , <EOL> wave_lengths , <EOL> sid , <EOL> ) = info <EOL> else : <EOL> phone , phone_lengths , spec , spec_lengths , wave , wave_lengths , sid = info <EOL> if ( hps . if_cache_data_in_gpu == False ) and torch . cuda . is_available ( ) : <EOL> phone = phone . cuda ( rank , non_blocking = True ) <EOL> phone_lengths = phone_lengths . cuda ( rank , non_blocking = True ) <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> pitch = pitch . cuda ( rank , non_blocking = True ) <EOL> pitchf = pitchf . cuda ( rank , non_blocking = True ) <EOL> sid = sid . cuda ( rank , non_blocking = True ) <EOL> spec = spec . cuda ( rank , non_blocking = True ) <EOL> spec_lengths = spec_lengths . cuda ( rank , non_blocking = True ) <EOL> wave = wave . cuda ( rank , non_blocking = True ) <EOL> with autocast ( enabled = hps . train . fp16_run ) : <EOL> if hps . if_f0 == <NUM_LIT> : <EOL> ( <EOL> y_hat , <EOL> ids_slice , <EOL> x_mask , <EOL> z_mask , <EOL> ( z , z_p , m_p , logs_p , m_q , logs_q ) , <EOL> ) = net_g ( phone , phone_lengths , pitch , pitchf , spec , spec_lengths , sid ) <EOL> else : <EOL> ( <EOL> y_hat , <EOL> ids_slice , <EOL> x_mask , <EOL> z_mask , <EOL> ( z , z_p , m_p , logs_p , m_q , logs_q ) , <EOL> ) = net_g ( phone , phone_lengths , spec , spec_lengths , sid ) <EOL> mel = spec_to_mel_torch ( <EOL> spec , <EOL> hps . data . filter_length , <EOL> hps . data . n_mel_channels , <EOL> hps . data . sampling_rate , <EOL> hps . data . mel_fmin , <EOL> hps . data . mel_fmax , <EOL> ) <EOL> y_mel = commons . slice_segments ( <EOL> mel , ids_slice , hps . train . segment_size // hps . data . hop_length <EOL> ) <EOL> with autocast ( enabled = False ) : <EOL> y_hat_mel = mel_spectrogram_torch ( <EOL> y_hat . float ( ) . squeeze ( <NUM_LIT> ) , <EOL> hps . data . filter_length , <EOL> hps . data . n_mel_channels , <EOL> hps . data . sampling_rate , <EOL> hps . data . hop_length , <EOL> hps . data . win_length , <EOL> hps . data . mel_fmin , <EOL> hps . data . mel_fmax , <EOL> ) <EOL> if hps . train . fp16_run == True : <EOL> y_hat_mel = y_hat_mel . half ( ) <EOL> wave = commons . slice_segments ( <EOL> wave , ids_slice * hps . data . hop_length , hps . train . segment_size <EOL> ) <EOL> y_d_hat_r , y_d_hat_g , _ , _ = net_d ( wave , y_hat . detach ( ) ) <EOL> with autocast ( enabled = False ) : <EOL> loss_disc , losses_disc_r , losses_disc_g = discriminator_loss ( <EOL> y_d_hat_r , y_d_hat_g <EOL> ) <EOL> optim_d . zero_grad ( ) <EOL> scaler . scale ( loss_disc ) . backward ( ) <EOL> scaler . unscale_ ( optim_d ) <EOL> grad_norm_d = commons . clip_grad_value_ ( net_d . parameters ( ) , None ) <EOL> scaler . step ( optim_d ) <EOL> with autocast ( enabled = hps . train . fp16_run ) : <EOL> y_d_hat_r , y_d_hat_g , fmap_r , fmap_g = net_d ( wave , y_hat ) <EOL> with autocast ( enabled = False ) : <EOL> loss_mel = F . l1_loss ( y_mel , y_hat_mel ) * hps . train . c_mel <EOL> loss_kl = kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) * hps . train . c_kl <EOL> loss_fm = feature_loss ( fmap_r , fmap_g ) <EOL> loss_gen , losses_gen = generator_loss ( y_d_hat_g ) <EOL> loss_gen_all = loss_gen + loss_fm + loss_mel + loss_kl <EOL> if loss_gen_all < lowest_value [ "<STR_LIT>" ] : <EOL> lowest_value [ "<STR_LIT>" ] = loss_gen_all <EOL> lowest_value [ "<STR_LIT>" ] = global_step <EOL> lowest_value [ "<STR_LIT>" ] = epoch <EOL> if epoch > lowest_value [ "<STR_LIT>" ] : <EOL> print ( <EOL> "<STR_LIT>" <EOL> ) <EOL> optim_g . zero_grad ( ) <EOL> scaler . scale ( loss_gen_all ) . backward ( ) <EOL> scaler . unscale_ ( optim_g ) <EOL> grad_norm_g = commons . clip_grad_value_ ( net_g . parameters ( ) , None ) <EOL> scaler . step ( optim_g ) <EOL> scaler . update ( ) <EOL> if rank == <NUM_LIT> : <EOL> if global_step % hps . train . log_interval == <NUM_LIT> : <EOL> lr = optim_g . param_groups [ <NUM_LIT> ] [ "<STR_LIT>" ] <EOL> if loss_mel > <NUM_LIT> : <EOL> loss_mel = <NUM_LIT> <EOL> if loss_kl > <NUM_LIT> : <EOL> loss_kl = <NUM_LIT> <EOL> scalar_dict = { <EOL> "<STR_LIT>" : loss_gen_all , <EOL> "<STR_LIT>" : loss_disc , <EOL> "<STR_LIT>" : lr , <EOL> "<STR_LIT>" : grad_norm_d , <EOL> "<STR_LIT>" : grad_norm_g , <EOL> } <EOL> scalar_dict . update ( <EOL> { <EOL> "<STR_LIT>" : loss_fm , <EOL> "<STR_LIT>" : loss_mel , <EOL> "<STR_LIT>" : loss_kl , <EOL> } <EOL> ) <EOL> scalar_dict . update ( <EOL> { "<STR_LIT>" . format ( i ) : v for i , v in enumerate ( losses_gen ) } <EOL> ) <EOL> scalar_dict . update ( <EOL> { "<STR_LIT>" . format ( i ) : v for i , v in enumerate ( losses_disc_r ) } <EOL> ) <EOL> scalar_dict . update ( <EOL> { "<STR_LIT>" . format ( i ) : v for i , v in enumerate ( losses_disc_g ) } <EOL> ) <EOL> image_dict = { <EOL> "<STR_LIT>" : plot_spectrogram_to_numpy ( <EOL> y_mel [ <NUM_LIT> ] . data . cpu ( ) . numpy ( ) <EOL> ) , <EOL> "<STR_LIT>" : plot_spectrogram_to_numpy ( <EOL> y_hat_mel [ <NUM_LIT> ] . data . cpu ( ) . numpy ( ) <EOL> ) , <EOL> "<STR_LIT>" : plot_spectrogram_to_numpy ( mel [ <NUM_LIT> ] . data . cpu ( ) . numpy ( ) ) , <EOL> } <EOL> summarize ( <EOL> writer = writer , <EOL> global_step = global_step , <EOL> images = image_dict , <EOL> scalars = scalar_dict , <EOL> ) <EOL> global_step += <NUM_LIT> <EOL> if epoch % hps . save_every_epoch == <NUM_LIT> and rank == <NUM_LIT> : <EOL> checkpoint_suffix = "<STR_LIT>" . format ( <EOL> global_step if hps . if_latest == <NUM_LIT> else <NUM_LIT> <EOL> ) <EOL> save_checkpoint ( <EOL> net_g , <EOL> optim_g , <EOL> hps . train . learning_rate , <EOL> epoch , <EOL> os . path . join ( hps . model_dir , "<STR_LIT>" + checkpoint_suffix ) , <EOL> ) <EOL> save_checkpoint ( <EOL> net_d , <EOL> optim_d , <EOL> hps . train . learning_rate , <EOL> epoch , <EOL> os . path . join ( hps . model_dir , "<STR_LIT>" + checkpoint_suffix ) , <EOL> ) <EOL> if rank == <NUM_LIT> and hps . save_every_weights == "<STR_LIT>" : <EOL> if hasattr ( net_g , "<STR_LIT>" ) : <EOL> ckpt = net_g . module . state_dict ( ) <EOL> else : <EOL> ckpt = net_g . state_dict ( ) <EOL> extract_model ( <EOL> ckpt , <EOL> hps . sample_rate , <EOL> hps . if_f0 , <EOL> hps . name , <EOL> os . path . join ( <EOL> hps . model_dir , "<STR_LIT>" . format ( hps . name , epoch , global_step ) <EOL> ) , <EOL> epoch , <EOL> global_step , <EOL> hps . version , <EOL> hps , <EOL> ) <EOL> if hps . overtraining_detector == <NUM_LIT> : <EOL> if lowest_value [ "<STR_LIT>" ] < last_loss_gen_all : <EOL> epochs_since_last_lowest += <NUM_LIT> <EOL> else : <EOL> epochs_since_last_lowest = <NUM_LIT> <EOL> if epochs_since_last_lowest >= hps . overtraining_threshold : <EOL> print ( <EOL> "<STR_LIT>" . format ( <EOL> lowest_value [ "<STR_LIT>" ] , lowest_value [ "<STR_LIT>" ] , lowest_value [ "<STR_LIT>" ] <EOL> ) <EOL> ) <EOL> os . _exit ( <NUM_LIT> ) <EOL> if rank == <NUM_LIT> : <EOL> if epoch > <NUM_LIT> : <EOL> print ( hps . overtraining_threshold ) <EOL> print ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> else : <EOL> print ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> last_loss_gen_all = loss_gen_all <EOL> if epoch >= hps . total_epoch and rank == <NUM_LIT> : <EOL> print ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> print ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> pid_file_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> os . remove ( pid_file_path ) <EOL> if hasattr ( net_g , "<STR_LIT>" ) : <EOL> ckpt = net_g . module . state_dict ( ) <EOL> else : <EOL> ckpt = net_g . state_dict ( ) <EOL> extract_model ( <EOL> ckpt , <EOL> hps . sample_rate , <EOL> hps . if_f0 , <EOL> hps . name , <EOL> os . path . join ( <EOL> hps . model_dir , "<STR_LIT>" . format ( hps . name , epoch , global_step ) <EOL> ) , <EOL> epoch , <EOL> global_step , <EOL> hps . version , <EOL> hps , <EOL> ) <EOL> sleep ( <NUM_LIT> ) <EOL> os . _exit ( <NUM_LIT> ) <EOL> if __name__ == "<STR_LIT>" : <EOL> torch . multiprocessing . set_start_method ( "<STR_LIT>" ) <EOL> main ( ) <EOL> </s>
<s> import os , sys <EOL> import gradio as gr <EOL> import regex as re <EOL> import json <EOL> import random <EOL> from core import ( <EOL> run_tts_script , <EOL> ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> model_root = os . path . join ( now_dir , "<STR_LIT>" ) <EOL> model_root_relative = os . path . relpath ( model_root , now_dir ) <EOL> names = [ <EOL> os . path . join ( root , file ) <EOL> for root , _ , files in os . walk ( model_root_relative , topdown = False ) <EOL> for file in files <EOL> if ( <EOL> file . endswith ( ( "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> and not ( file . startswith ( "<STR_LIT>" ) or file . startswith ( "<STR_LIT>" ) ) <EOL> ) <EOL> ] <EOL> indexes_list = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( model_root_relative , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( "<STR_LIT>" ) and "<STR_LIT>" not in name <EOL> ] <EOL> def change_choices ( ) : <EOL> names = [ <EOL> os . path . join ( root , file ) <EOL> for root , _ , files in os . walk ( model_root_relative , topdown = False ) <EOL> for file in files <EOL> if ( <EOL> file . endswith ( ( "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> and not ( file . startswith ( "<STR_LIT>" ) or file . startswith ( "<STR_LIT>" ) ) <EOL> ) <EOL> ] <EOL> indexes_list = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( model_root_relative , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( "<STR_LIT>" ) and "<STR_LIT>" not in name <EOL> ] <EOL> return ( <EOL> { "<STR_LIT>" : sorted ( names ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : sorted ( indexes_list ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> ) <EOL> def get_indexes ( ) : <EOL> indexes_list = [ <EOL> os . path . join ( dirpath , filename ) <EOL> for dirpath , _ , filenames in os . walk ( model_root_relative ) <EOL> for filename in filenames <EOL> if filename . endswith ( "<STR_LIT>" ) and "<STR_LIT>" not in filename <EOL> ] <EOL> return indexes_list if indexes_list else "<STR_LIT>" <EOL> def process_input ( file_path ) : <EOL> with open ( file_path , "<STR_LIT>" ) as file : <EOL> file_contents = file . read ( ) <EOL> gr . Info ( f"<STR_LIT>" ) <EOL> return file_contents , None <EOL> def match_index ( model_file_value ) : <EOL> if model_file_value : <EOL> model_folder = os . path . dirname ( model_file_value ) <EOL> index_files = get_indexes ( ) <EOL> for index_file in index_files : <EOL> if os . path . dirname ( index_file ) == model_folder : <EOL> return index_file <EOL> return "<STR_LIT>" <EOL> def tts_tab ( ) : <EOL> default_weight = random . choice ( names ) if names else "<STR_LIT>" <EOL> with gr . Row ( ) : <EOL> with gr . Row ( ) : <EOL> model_file = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = sorted ( names , key = lambda path : os . path . getsize ( path ) ) , <EOL> interactive = True , <EOL> value = default_weight , <EOL> allow_custom_value = True , <EOL> ) <EOL> best_default_index_path = match_index ( model_file . value ) <EOL> index_file = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = get_indexes ( ) , <EOL> value = best_default_index_path , <EOL> interactive = True , <EOL> allow_custom_value = True , <EOL> ) <EOL> with gr . Column ( ) : <EOL> refresh_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> unload_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> unload_button . click ( <EOL> fn = lambda : ( <EOL> { "<STR_LIT>" : "<STR_LIT>" , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : "<STR_LIT>" , "<STR_LIT>" : "<STR_LIT>" } , <EOL> ) , <EOL> inputs = [ ] , <EOL> outputs = [ model_file , index_file ] , <EOL> ) <EOL> model_file . select ( <EOL> fn = lambda model_file_value : match_index ( model_file_value ) , <EOL> inputs = [ model_file ] , <EOL> outputs = [ index_file ] , <EOL> ) <EOL> json_path = os . path . join ( "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> with open ( json_path , "<STR_LIT>" ) as file : <EOL> tts_voices_data = json . load ( file ) <EOL> short_names = [ voice . get ( "<STR_LIT>" , "<STR_LIT>" ) for voice in tts_voices_data ] <EOL> tts_voice = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = short_names , <EOL> interactive = True , <EOL> value = None , <EOL> ) <EOL> tts_text = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> lines = <NUM_LIT> , <EOL> ) <EOL> txt_file = gr . File ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> type = "<STR_LIT>" , <EOL> ) <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) , open = False ) : <EOL> with gr . Column ( ) : <EOL> output_tts_path = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> value = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) , <EOL> interactive = True , <EOL> ) <EOL> output_rvc_path = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> value = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) , <EOL> interactive = True , <EOL> ) <EOL> export_format = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> split_audio = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> autotune = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> clean_audio = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = True , <EOL> interactive = True , <EOL> ) <EOL> clean_strength = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> visible = True , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> pitch = gr . Slider ( <EOL> minimum = - <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> filter_radius = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> index_rate = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> rms_mix_rate = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> protect = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> hop_length = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> ) <EOL> with gr . Column ( ) : <EOL> f0method = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> choices = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> convert_button1 = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> with gr . Row ( ) : <EOL> vc_output1 = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> ) <EOL> vc_output2 = gr . Audio ( label = i18n ( "<STR_LIT>" ) ) <EOL> def toggle_visible ( checkbox ) : <EOL> return { "<STR_LIT>" : checkbox , "<STR_LIT>" : "<STR_LIT>" } <EOL> clean_audio . change ( <EOL> fn = toggle_visible , <EOL> inputs = [ clean_audio ] , <EOL> outputs = [ clean_strength ] , <EOL> ) <EOL> refresh_button . click ( <EOL> fn = change_choices , <EOL> inputs = [ ] , <EOL> outputs = [ model_file , index_file ] , <EOL> ) <EOL> txt_file . upload ( <EOL> fn = process_input , <EOL> inputs = [ txt_file ] , <EOL> outputs = [ tts_text , txt_file ] , <EOL> ) <EOL> convert_button1 . click ( <EOL> fn = run_tts_script , <EOL> inputs = [ <EOL> tts_text , <EOL> tts_voice , <EOL> pitch , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> output_tts_path , <EOL> output_rvc_path , <EOL> model_file , <EOL> index_file , <EOL> split_audio , <EOL> autotune , <EOL> clean_audio , <EOL> clean_strength , <EOL> export_format , <EOL> ] , <EOL> outputs = [ vc_output1 , vc_output2 ] , <EOL> ) <EOL> </s>
<s> import os , sys <EOL> import torch <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from tabs . settings . restart import restart_applio <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> ngpu = torch . cuda . device_count ( ) <EOL> config_file = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> def gpu_available ( ) : <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> return True <EOL> def load_fake_gpu ( ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> return config [ "<STR_LIT>" ] <EOL> def save_config ( value ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> config [ "<STR_LIT>" ] = value <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def fake_gpu_tab ( ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> presence = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> interactive = True , <EOL> value = load_fake_gpu ( ) , <EOL> ) <EOL> presence . change ( <EOL> fn = toggle , <EOL> inputs = [ presence ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle ( checkbox ) : <EOL> save_config ( bool ( checkbox ) ) <EOL> restart_applio ( ) <EOL> </s>
<s> import torch <EOL> import json <EOL> import os <EOL> version_config_list = [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] <EOL> def singleton_variable ( func ) : <EOL> def wrapper ( * args , ** kwargs ) : <EOL> if not wrapper . instance : <EOL> wrapper . instance = func ( * args , ** kwargs ) <EOL> return wrapper . instance <EOL> wrapper . instance = None <EOL> return wrapper <EOL> @ singleton_variable <EOL> class Config : <EOL> def __init__ ( self ) : <EOL> self . device = "<STR_LIT>" <EOL> self . is_half = True <EOL> self . use_jit = False <EOL> self . n_cpu = <NUM_LIT> <EOL> self . gpu_name = None <EOL> self . json_config = self . load_config_json ( ) <EOL> self . gpu_mem = None <EOL> self . instead = "<STR_LIT>" <EOL> self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) <EOL> @ staticmethod <EOL> def load_config_json ( ) -> dict : <EOL> d = { } <EOL> for config_file in version_config_list : <EOL> with open ( f"<STR_LIT>" , "<STR_LIT>" ) as f : <EOL> d [ config_file ] = json . load ( f ) <EOL> return d <EOL> @ staticmethod <EOL> def has_mps ( ) -> bool : <EOL> if not torch . backends . mps . is_available ( ) : <EOL> return False <EOL> try : <EOL> torch . zeros ( <NUM_LIT> ) . to ( torch . device ( "<STR_LIT>" ) ) <EOL> return True <EOL> except Exception : <EOL> return False <EOL> @ staticmethod <EOL> def has_xpu ( ) -> bool : <EOL> if hasattr ( torch , "<STR_LIT>" ) and torch . xpu . is_available ( ) : <EOL> return True <EOL> else : <EOL> return False <EOL> def use_fp32_config ( self ) : <EOL> print ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> for config_file in version_config_list : <EOL> self . json_config [ config_file ] [ "<STR_LIT>" ] [ "<STR_LIT>" ] = False <EOL> with open ( f"<STR_LIT>" , "<STR_LIT>" ) as f : <EOL> strr = f . read ( ) . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> with open ( f"<STR_LIT>" , "<STR_LIT>" ) as f : <EOL> f . write ( strr ) <EOL> with open ( "<STR_LIT>" , "<STR_LIT>" ) as f : <EOL> strr = f . read ( ) . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> with open ( "<STR_LIT>" , "<STR_LIT>" ) as f : <EOL> f . write ( strr ) <EOL> def device_config ( self ) -> tuple : <EOL> if torch . cuda . is_available ( ) : <EOL> if self . has_xpu ( ) : <EOL> self . device = self . instead = "<STR_LIT>" <EOL> self . is_half = True <EOL> i_device = int ( self . device . split ( "<STR_LIT>" ) [ - <NUM_LIT> ] ) <EOL> self . gpu_name = torch . cuda . get_device_name ( i_device ) <EOL> if ( <EOL> ( "<STR_LIT>" in self . gpu_name and "<STR_LIT>" not in self . gpu_name . upper ( ) ) <EOL> or "<STR_LIT>" in self . gpu_name . upper ( ) <EOL> or "<STR_LIT>" in self . gpu_name . upper ( ) <EOL> or "<STR_LIT>" in self . gpu_name <EOL> or "<STR_LIT>" in self . gpu_name <EOL> or "<STR_LIT>" in self . gpu_name <EOL> ) : <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> self . gpu_mem = int ( <EOL> torch . cuda . get_device_properties ( i_device ) . total_memory <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> if self . gpu_mem <= <NUM_LIT> : <EOL> with open ( "<STR_LIT>" , "<STR_LIT>" ) as f : <EOL> strr = f . read ( ) . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> with open ( "<STR_LIT>" , "<STR_LIT>" ) as f : <EOL> f . write ( strr ) <EOL> elif self . has_mps ( ) : <EOL> print ( "<STR_LIT>" ) <EOL> self . device = self . instead = "<STR_LIT>" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> else : <EOL> print ( "<STR_LIT>" ) <EOL> self . device = self . instead = "<STR_LIT>" <EOL> self . is_half = False <EOL> self . use_fp32_config ( ) <EOL> if self . n_cpu == <NUM_LIT> : <EOL> self . n_cpu = os . cpu_count ( ) <EOL> if self . is_half : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> else : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : <EOL> x_pad = <NUM_LIT> <EOL> x_query = <NUM_LIT> <EOL> x_center = <NUM_LIT> <EOL> x_max = <NUM_LIT> <EOL> return x_pad , x_query , x_center , x_max <EOL> def max_vram_gpu ( gpu ) : <EOL> if torch . cuda . is_available ( ) : <EOL> gpu_properties = torch . cuda . get_device_properties ( gpu ) <EOL> total_memory_gb = round ( gpu_properties . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> ) <EOL> return total_memory_gb <EOL> else : <EOL> return "<STR_LIT>" <EOL> def get_gpu_info ( ) : <EOL> ngpu = torch . cuda . device_count ( ) <EOL> gpu_infos = [ ] <EOL> if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : <EOL> for i in range ( ngpu ) : <EOL> gpu_name = torch . cuda . get_device_name ( i ) <EOL> mem = int ( <EOL> torch . cuda . get_device_properties ( i ) . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> <EOL> + <NUM_LIT> <EOL> ) <EOL> gpu_infos . append ( "<STR_LIT>" % ( i , gpu_name , mem ) ) <EOL> if len ( gpu_infos ) > <NUM_LIT> : <EOL> gpu_info = "<STR_LIT>" . join ( gpu_infos ) <EOL> else : <EOL> gpu_info = "<STR_LIT>" <EOL> return gpu_info <EOL> </s>
<s> import os <EOL> import subprocess <EOL> import sys <EOL> import shutil <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import ( <EOL> run_preprocess_script , <EOL> run_extract_script , <EOL> run_train_script , <EOL> run_index_script , <EOL> run_prerequisites_script , <EOL> ) <EOL> from rvc . configs . config import max_vram_gpu , get_gpu_info <EOL> from rvc . lib . utils import format_title <EOL> from tabs . settings . restart import restart_applio <EOL> i18n = I18nAuto ( ) <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> pretraineds_v1 = [ <EOL> ( <EOL> "<STR_LIT>" , <EOL> [ <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ] , <EOL> ) , <EOL> ] <EOL> folder_mapping = { <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> sup_audioext = { <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> } <EOL> pretraineds_custom_path = os . path . join ( <EOL> now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" <EOL> ) <EOL> pretraineds_custom_path_relative = os . path . relpath ( pretraineds_custom_path , now_dir ) <EOL> if not os . path . exists ( pretraineds_custom_path_relative ) : <EOL> os . makedirs ( pretraineds_custom_path_relative ) <EOL> def get_pretrained_list ( suffix ) : <EOL> return [ <EOL> os . path . join ( dirpath , filename ) <EOL> for dirpath , _ , filenames in os . walk ( pretraineds_custom_path_relative ) <EOL> for filename in filenames <EOL> if filename . endswith ( "<STR_LIT>" ) and suffix in filename <EOL> ] <EOL> pretraineds_list_d = get_pretrained_list ( "<STR_LIT>" ) <EOL> pretraineds_list_g = get_pretrained_list ( "<STR_LIT>" ) <EOL> def refresh_custom_pretraineds ( ) : <EOL> return ( <EOL> { "<STR_LIT>" : sorted ( get_pretrained_list ( "<STR_LIT>" ) ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : sorted ( get_pretrained_list ( "<STR_LIT>" ) ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> ) <EOL> datasets_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> if not os . path . exists ( datasets_path ) : <EOL> os . makedirs ( datasets_path ) <EOL> datasets_path_relative = os . path . relpath ( datasets_path , now_dir ) <EOL> def get_datasets_list ( ) : <EOL> return [ <EOL> dirpath <EOL> for dirpath , _ , filenames in os . walk ( datasets_path_relative ) <EOL> if any ( filename . endswith ( tuple ( sup_audioext ) ) for filename in filenames ) <EOL> ] <EOL> def refresh_datasets ( ) : <EOL> return { "<STR_LIT>" : sorted ( get_datasets_list ( ) ) , "<STR_LIT>" : "<STR_LIT>" } <EOL> models_path = os . path . join ( now_dir , "<STR_LIT>" ) <EOL> def get_models_list ( ) : <EOL> return [ <EOL> os . path . basename ( dirpath ) <EOL> for dirpath in os . listdir ( models_path ) <EOL> if os . path . isdir ( os . path . join ( models_path , dirpath ) ) <EOL> and all ( excluded not in dirpath for excluded in [ "<STR_LIT>" , "<STR_LIT>" ] ) <EOL> ] <EOL> def refresh_models ( ) : <EOL> return { "<STR_LIT>" : sorted ( get_models_list ( ) ) , "<STR_LIT>" : "<STR_LIT>" } <EOL> def refresh_models_and_datasets ( ) : <EOL> return ( <EOL> { "<STR_LIT>" : sorted ( get_models_list ( ) ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : sorted ( get_datasets_list ( ) ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> ) <EOL> def save_drop_model ( dropbox ) : <EOL> if "<STR_LIT>" not in dropbox : <EOL> gr . Info ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> else : <EOL> file_name = os . path . basename ( dropbox ) <EOL> pretrained_path = os . path . join ( pretraineds_custom_path_relative , file_name ) <EOL> if os . path . exists ( pretrained_path ) : <EOL> os . remove ( pretrained_path ) <EOL> os . rename ( dropbox , pretrained_path ) <EOL> gr . Info ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> return None <EOL> def save_drop_dataset_audio ( dropbox , dataset_name ) : <EOL> if not dataset_name : <EOL> gr . Info ( "<STR_LIT>" ) <EOL> return None , None <EOL> else : <EOL> file_extension = os . path . splitext ( dropbox ) [ <NUM_LIT> ] [ <NUM_LIT> : ] . lower ( ) <EOL> if file_extension not in sup_audioext : <EOL> gr . Info ( "<STR_LIT>" ) <EOL> else : <EOL> dataset_name = format_title ( dataset_name ) <EOL> audio_file = format_title ( os . path . basename ( dropbox ) ) <EOL> dataset_path = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , dataset_name ) <EOL> if not os . path . exists ( dataset_path ) : <EOL> os . makedirs ( dataset_path ) <EOL> destination_path = os . path . join ( dataset_path , audio_file ) <EOL> if os . path . exists ( destination_path ) : <EOL> os . remove ( destination_path ) <EOL> os . rename ( dropbox , destination_path ) <EOL> gr . Info ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> dataset_path = os . path . dirname ( destination_path ) <EOL> relative_dataset_path = os . path . relpath ( dataset_path , now_dir ) <EOL> return None , relative_dataset_path <EOL> def get_pth_list ( ) : <EOL> return [ <EOL> os . path . relpath ( os . path . join ( dirpath , filename ) , now_dir ) <EOL> for dirpath , _ , filenames in os . walk ( models_path ) <EOL> for filename in filenames <EOL> if filename . endswith ( "<STR_LIT>" ) <EOL> ] <EOL> def get_index_list ( ) : <EOL> return [ <EOL> os . path . relpath ( os . path . join ( dirpath , filename ) , now_dir ) <EOL> for dirpath , _ , filenames in os . walk ( models_path ) <EOL> for filename in filenames <EOL> if filename . endswith ( "<STR_LIT>" ) and "<STR_LIT>" not in filename <EOL> ] <EOL> def refresh_pth_and_index_list ( ) : <EOL> return ( <EOL> { "<STR_LIT>" : sorted ( get_pth_list ( ) ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> { "<STR_LIT>" : sorted ( get_index_list ( ) ) , "<STR_LIT>" : "<STR_LIT>" } , <EOL> ) <EOL> def export_pth ( pth_path ) : <EOL> if pth_path and os . path . exists ( pth_path ) : <EOL> return pth_path <EOL> return None <EOL> def export_index ( index_path ) : <EOL> if index_path and os . path . exists ( index_path ) : <EOL> return index_path <EOL> return None <EOL> def upload_to_google_drive ( pth_path , index_path ) : <EOL> def upload_file ( file_path ) : <EOL> if file_path : <EOL> try : <EOL> gr . Info ( f"<STR_LIT>" ) <EOL> google_drive_folder = "<STR_LIT>" <EOL> if not os . path . exists ( google_drive_folder ) : <EOL> os . makedirs ( google_drive_folder ) <EOL> google_drive_file_path = os . path . join ( <EOL> google_drive_folder , os . path . basename ( file_path ) <EOL> ) <EOL> if os . path . exists ( google_drive_file_path ) : <EOL> os . remove ( google_drive_file_path ) <EOL> shutil . copy2 ( file_path , google_drive_file_path ) <EOL> gr . Info ( "<STR_LIT>" ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> gr . Info ( "<STR_LIT>" ) <EOL> upload_file ( pth_path ) <EOL> upload_file ( index_path ) <EOL> def train_tab ( ) : <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_name = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = get_models_list ( ) , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> allow_custom_value = True , <EOL> ) <EOL> dataset_path = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = get_datasets_list ( ) , <EOL> allow_custom_value = True , <EOL> interactive = True , <EOL> ) <EOL> refresh = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> dataset_creator = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> value = False , <EOL> interactive = True , <EOL> visible = True , <EOL> ) <EOL> with gr . Column ( visible = False ) as dataset_creator_settings : <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) ) : <EOL> dataset_name = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> interactive = True , <EOL> ) <EOL> upload_audio_dataset = gr . File ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> type = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> with gr . Column ( ) : <EOL> sampling_rate = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> rvc_version = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = [ "<STR_LIT>" , "<STR_LIT>" ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> preprocess_output_info = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> with gr . Row ( ) : <EOL> preprocess_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> preprocess_button . click ( <EOL> run_preprocess_script , <EOL> [ model_name , dataset_path , sampling_rate ] , <EOL> preprocess_output_info , <EOL> api_name = "<STR_LIT>" , <EOL> ) <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) ) : <EOL> with gr . Row ( ) : <EOL> hop_length = gr . Slider ( <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> interactive = True , <EOL> visible = False , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> f0method = gr . Radio ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> choices = [ "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ] , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> extract_output_info = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> extract_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> extract_button . click ( <EOL> run_extract_script , <EOL> [ model_name , rvc_version , f0method , hop_length , sampling_rate ] , <EOL> extract_output_info , <EOL> api_name = "<STR_LIT>" , <EOL> ) <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) ) : <EOL> with gr . Row ( ) : <EOL> batch_size = gr . Slider ( <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> max_vram_gpu ( <NUM_LIT> ) , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> interactive = True , <EOL> ) <EOL> save_every_epoch = gr . Slider ( <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> interactive = True , <EOL> ) <EOL> total_epoch = gr . Slider ( <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> interactive = True , <EOL> ) <EOL> with gr . Row ( ) : <EOL> pitch_guidance = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = True , <EOL> interactive = True , <EOL> ) <EOL> pretrained = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = True , <EOL> interactive = True , <EOL> ) <EOL> save_only_latest = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> save_every_weights = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = True , <EOL> interactive = True , <EOL> ) <EOL> custom_pretrained = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> multiple_gpu = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> overtraining_detector = gr . Checkbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = False , <EOL> interactive = True , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( visible = False ) as pretrained_custom_settings : <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) ) : <EOL> upload_pretrained = gr . File ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> type = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> refresh_custom_pretaineds_button = gr . Button ( <EOL> i18n ( "<STR_LIT>" ) <EOL> ) <EOL> g_pretrained_path = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> choices = sorted ( pretraineds_list_g ) , <EOL> interactive = True , <EOL> allow_custom_value = True , <EOL> ) <EOL> d_pretrained_path = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> choices = sorted ( pretraineds_list_d ) , <EOL> interactive = True , <EOL> allow_custom_value = True , <EOL> ) <EOL> with gr . Column ( visible = False ) as gpu_custom_settings : <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) ) : <EOL> gpu = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> ) <EOL> gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = get_gpu_info ( ) , <EOL> interactive = False , <EOL> ) <EOL> with gr . Column ( visible = False ) as overtraining_settings : <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) ) : <EOL> overtraining_threshold = gr . Slider ( <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> step = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> interactive = True , <EOL> ) <EOL> with gr . Row ( ) : <EOL> train_output_info = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = False , <EOL> ) <EOL> with gr . Row ( ) : <EOL> train_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> train_button . click ( <EOL> run_train_script , <EOL> [ <EOL> model_name , <EOL> rvc_version , <EOL> save_every_epoch , <EOL> save_only_latest , <EOL> save_every_weights , <EOL> total_epoch , <EOL> sampling_rate , <EOL> batch_size , <EOL> gpu , <EOL> pitch_guidance , <EOL> overtraining_detector , <EOL> overtraining_threshold , <EOL> pretrained , <EOL> custom_pretrained , <EOL> g_pretrained_path , <EOL> d_pretrained_path , <EOL> ] , <EOL> train_output_info , <EOL> api_name = "<STR_LIT>" , <EOL> ) <EOL> stop_train_button = gr . Button ( <EOL> i18n ( "<STR_LIT>" ) , visible = False <EOL> ) <EOL> stop_train_button . click ( <EOL> fn = restart_applio , <EOL> inputs = [ ] , <EOL> outputs = [ ] , <EOL> ) <EOL> index_button = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> index_button . click ( <EOL> run_index_script , <EOL> [ model_name , rvc_version ] , <EOL> train_output_info , <EOL> api_name = "<STR_LIT>" , <EOL> ) <EOL> with gr . Accordion ( i18n ( "<STR_LIT>" ) , open = False ) : <EOL> if not os . name == "<STR_LIT>" : <EOL> gr . Markdown ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> pth_file_export = gr . File ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> type = "<STR_LIT>" , <EOL> value = None , <EOL> interactive = False , <EOL> ) <EOL> pth_dropdown_export = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = get_pth_list ( ) , <EOL> value = None , <EOL> interactive = True , <EOL> allow_custom_value = True , <EOL> ) <EOL> with gr . Column ( ) : <EOL> index_file_export = gr . File ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> type = "<STR_LIT>" , <EOL> value = None , <EOL> interactive = False , <EOL> ) <EOL> index_dropdown_export = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> choices = get_index_list ( ) , <EOL> value = None , <EOL> interactive = True , <EOL> allow_custom_value = True , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> refresh_export = gr . Button ( i18n ( "<STR_LIT>" ) ) <EOL> if not os . name == "<STR_LIT>" : <EOL> upload_exported = gr . Button ( i18n ( "<STR_LIT>" ) , variant = "<STR_LIT>" ) <EOL> upload_exported . click ( <EOL> fn = upload_to_google_drive , <EOL> inputs = [ pth_dropdown_export , index_dropdown_export ] , <EOL> outputs = [ ] , <EOL> ) <EOL> def toggle_visible ( checkbox ) : <EOL> return { "<STR_LIT>" : checkbox , "<STR_LIT>" : "<STR_LIT>" } <EOL> def toggle_visible_hop_length ( f0method ) : <EOL> if f0method == "<STR_LIT>" or f0method == "<STR_LIT>" : <EOL> return { "<STR_LIT>" : True , "<STR_LIT>" : "<STR_LIT>" } <EOL> return { "<STR_LIT>" : False , "<STR_LIT>" : "<STR_LIT>" } <EOL> def toggle_pretrained ( pretrained , custom_pretrained ) : <EOL> if custom_pretrained == False : <EOL> return { "<STR_LIT>" : pretrained , "<STR_LIT>" : "<STR_LIT>" } , { <EOL> "<STR_LIT>" : False , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> else : <EOL> return { "<STR_LIT>" : pretrained , "<STR_LIT>" : "<STR_LIT>" } , { <EOL> "<STR_LIT>" : pretrained , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> def enable_stop_train_button ( ) : <EOL> return { "<STR_LIT>" : False , "<STR_LIT>" : "<STR_LIT>" } , { <EOL> "<STR_LIT>" : True , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> def disable_stop_train_button ( ) : <EOL> return { "<STR_LIT>" : True , "<STR_LIT>" : "<STR_LIT>" } , { <EOL> "<STR_LIT>" : False , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> } <EOL> def download_prerequisites ( version ) : <EOL> for remote_folder , file_list in pretraineds_v1 : <EOL> local_folder = folder_mapping . get ( remote_folder , "<STR_LIT>" ) <EOL> missing = False <EOL> for file in file_list : <EOL> destination_path = os . path . join ( local_folder , file ) <EOL> if not os . path . exists ( destination_path ) : <EOL> missing = True <EOL> if version == "<STR_LIT>" and missing == True : <EOL> gr . Info ( <EOL> "<STR_LIT>" <EOL> ) <EOL> run_prerequisites_script ( "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> gr . Info ( <EOL> "<STR_LIT>" <EOL> ) <EOL> rvc_version . change ( <EOL> fn = download_prerequisites , <EOL> inputs = [ rvc_version ] , <EOL> outputs = [ ] , <EOL> ) <EOL> refresh . click ( <EOL> fn = refresh_models_and_datasets , <EOL> inputs = [ ] , <EOL> outputs = [ model_name , dataset_path ] , <EOL> ) <EOL> dataset_creator . change ( <EOL> fn = toggle_visible , <EOL> inputs = [ dataset_creator ] , <EOL> outputs = [ dataset_creator_settings ] , <EOL> ) <EOL> upload_audio_dataset . upload ( <EOL> fn = save_drop_dataset_audio , <EOL> inputs = [ upload_audio_dataset , dataset_name ] , <EOL> outputs = [ upload_audio_dataset , dataset_path ] , <EOL> ) <EOL> f0method . change ( <EOL> fn = toggle_visible_hop_length , <EOL> inputs = [ f0method ] , <EOL> outputs = [ hop_length ] , <EOL> ) <EOL> pretrained . change ( <EOL> fn = toggle_pretrained , <EOL> inputs = [ pretrained , custom_pretrained ] , <EOL> outputs = [ custom_pretrained , pretrained_custom_settings ] , <EOL> ) <EOL> custom_pretrained . change ( <EOL> fn = toggle_visible , <EOL> inputs = [ custom_pretrained ] , <EOL> outputs = [ pretrained_custom_settings ] , <EOL> ) <EOL> refresh_custom_pretaineds_button . click ( <EOL> fn = refresh_custom_pretraineds , <EOL> inputs = [ ] , <EOL> outputs = [ g_pretrained_path , d_pretrained_path ] , <EOL> ) <EOL> upload_pretrained . upload ( <EOL> fn = save_drop_model , <EOL> inputs = [ upload_pretrained ] , <EOL> outputs = [ upload_pretrained ] , <EOL> ) <EOL> overtraining_detector . change ( <EOL> fn = toggle_visible , <EOL> inputs = [ overtraining_detector ] , <EOL> outputs = [ overtraining_settings ] , <EOL> ) <EOL> multiple_gpu . change ( <EOL> fn = toggle_visible , <EOL> inputs = [ multiple_gpu ] , <EOL> outputs = [ gpu_custom_settings ] , <EOL> ) <EOL> train_button . click ( <EOL> fn = enable_stop_train_button , <EOL> inputs = [ ] , <EOL> outputs = [ train_button , stop_train_button ] , <EOL> ) <EOL> train_output_info . change ( <EOL> fn = disable_stop_train_button , <EOL> inputs = [ ] , <EOL> outputs = [ train_button , stop_train_button ] , <EOL> ) <EOL> pth_dropdown_export . change ( <EOL> fn = export_pth , <EOL> inputs = [ pth_dropdown_export ] , <EOL> outputs = [ pth_file_export ] , <EOL> ) <EOL> index_dropdown_export . change ( <EOL> fn = export_index , <EOL> inputs = [ index_dropdown_export ] , <EOL> outputs = [ index_file_export ] , <EOL> ) <EOL> refresh_export . click ( <EOL> fn = refresh_pth_and_index_list , <EOL> inputs = [ ] , <EOL> outputs = [ pth_dropdown_export , index_dropdown_export ] , <EOL> ) <EOL> </s>
<s> import os , sys <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_model_information_script <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> import gradio as gr <EOL> def processing ( ) : <EOL> with gr . Accordion ( label = i18n ( "<STR_LIT>" ) ) : <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_view_model_path = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> ) <EOL> model_view_output_info = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> max_lines = <NUM_LIT> , <EOL> ) <EOL> model_view_button = gr . Button ( i18n ( "<STR_LIT>" ) , variant = "<STR_LIT>" ) <EOL> model_view_button . click ( <EOL> run_model_information_script , <EOL> [ model_view_model_path ] , <EOL> model_view_output_info , <EOL> api_name = "<STR_LIT>" , <EOL> ) <EOL> </s>
<s> from pydub . silence import detect_nonsilent <EOL> from pydub import AudioSegment <EOL> import numpy as np <EOL> import re <EOL> import os <EOL> from rvc . lib . utils import format_title <EOL> def process_audio ( file_path ) : <EOL> try : <EOL> song = AudioSegment . from_file ( file_path ) <EOL> silence_thresh = - <NUM_LIT> <EOL> min_silence_len = <NUM_LIT> <EOL> nonsilent_parts = detect_nonsilent ( <EOL> song , min_silence_len = min_silence_len , silence_thresh = silence_thresh <EOL> ) <EOL> file_dir = os . path . dirname ( file_path ) <EOL> file_name = os . path . basename ( file_path ) . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> file_name = format_title ( file_name ) <EOL> new_dir_path = os . path . join ( file_dir , file_name ) <EOL> os . makedirs ( new_dir_path , exist_ok = True ) <EOL> timestamps_file = os . path . join ( file_dir , f"<STR_LIT>" ) <EOL> if os . path . isfile ( timestamps_file ) : <EOL> os . remove ( timestamps_file ) <EOL> segment_count = <NUM_LIT> <EOL> for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : <EOL> chunk = song [ start_i : end_i ] <EOL> chunk_file_path = os . path . join ( new_dir_path , f"<STR_LIT>" ) <EOL> chunk . export ( chunk_file_path , format = "<STR_LIT>" ) <EOL> print ( f"<STR_LIT>" ) <EOL> segment_count += <NUM_LIT> <EOL> with open ( timestamps_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as f : <EOL> f . write ( f"<STR_LIT>" ) <EOL> print ( f"<STR_LIT>" ) <EOL> print ( f"<STR_LIT>" ) <EOL> return "<STR_LIT>" , new_dir_path <EOL> except Exception as e : <EOL> print ( f"<STR_LIT>" ) <EOL> return "<STR_LIT>" , None <EOL> def merge_audio ( timestamps_file ) : <EOL> try : <EOL> prefix = os . path . basename ( timestamps_file ) . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> timestamps_dir = os . path . dirname ( timestamps_file ) <EOL> with open ( timestamps_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as f : <EOL> lines = f . readlines ( ) <EOL> audio_segments = [ ] <EOL> last_end_time = <NUM_LIT> <EOL> print ( f"<STR_LIT>" ) <EOL> for line in lines : <EOL> match = re . search ( r"<STR_LIT>" , line ) <EOL> if match : <EOL> filename , start_time = match . groups ( ) <EOL> start_time = int ( start_time ) <EOL> chunk_file = os . path . join ( timestamps_dir , prefix , filename ) <EOL> silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) <EOL> silence = AudioSegment . silent ( duration = silence_duration ) <EOL> audio_segments . append ( silence ) <EOL> audio = AudioSegment . from_wav ( chunk_file ) <EOL> audio_segments . append ( audio ) <EOL> last_end_time = start_time + len ( audio ) <EOL> print ( f"<STR_LIT>" ) <EOL> merged_audio = sum ( audio_segments ) <EOL> merged_audio_np = np . array ( merged_audio . get_array_of_samples ( ) ) <EOL> return merged_audio . frame_rate , merged_audio_np <EOL> except Exception as e : <EOL> print ( f"<STR_LIT>" ) <EOL> </s>
<s> import gradio as gr <EOL> import tabs . extra . processing . processing as processing <EOL> import tabs . extra . analyzer . analyzer as analyzer <EOL> from assets . i18n . i18n import I18nAuto <EOL> i18n = I18nAuto ( ) <EOL> def extra_tab ( ) : <EOL> gr . Markdown ( <EOL> value = i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> with gr . TabItem ( i18n ( "<STR_LIT>" ) ) : <EOL> processing . processing ( ) <EOL> with gr . TabItem ( i18n ( "<STR_LIT>" ) ) : <EOL> analyzer . analyzer ( ) <EOL> </s>
<s> import torch <EOL> from datetime import datetime <EOL> def prettify_date ( date_str ) : <EOL> date_time_obj = datetime . strptime ( date_str , "<STR_LIT>" ) <EOL> return date_time_obj . strftime ( "<STR_LIT>" ) <EOL> def model_information ( path ) : <EOL> model_data = torch . load ( path , map_location = "<STR_LIT>" ) <EOL> print ( f"<STR_LIT>" ) <EOL> epochs = model_data . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> steps = model_data . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> sr = model_data . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> f0 = model_data . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> version = model_data . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> creation_date = model_data . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> model_hash = model_data . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> pitch_guidance = "<STR_LIT>" if f0 == <NUM_LIT> else "<STR_LIT>" <EOL> return ( <EOL> f"<STR_LIT>" <EOL> f"<STR_LIT>" <EOL> f"<STR_LIT>" <EOL> f"<STR_LIT>" <EOL> f"<STR_LIT>" <EOL> f"<STR_LIT>" <EOL> f"<STR_LIT>" <EOL> ) <EOL> </s>
<s> import os <EOL> import sys <EOL> import wget <EOL> import zipfile <EOL> from bs4 import BeautifulSoup <EOL> import requests <EOL> from urllib . parse import unquote , urlencode , parse_qs , urlparse <EOL> import re <EOL> import shutil <EOL> import six <EOL> def find_folder_parent ( search_dir , folder_name ) : <EOL> for dirpath , dirnames , _ in os . walk ( search_dir ) : <EOL> if folder_name in dirnames : <EOL> return os . path . abspath ( dirpath ) <EOL> return None <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . lib . utils import format_title <EOL> from rvc . lib . tools import gdown <EOL> file_path = find_folder_parent ( now_dir , "<STR_LIT>" ) <EOL> zips_path = os . getcwd ( ) + "<STR_LIT>" <EOL> def search_pth_index ( folder ) : <EOL> pth_paths = [ <EOL> os . path . join ( folder , file ) <EOL> for file in os . listdir ( folder ) <EOL> if os . path . isfile ( os . path . join ( folder , file ) ) and file . endswith ( "<STR_LIT>" ) <EOL> ] <EOL> index_paths = [ <EOL> os . path . join ( folder , file ) <EOL> for file in os . listdir ( folder ) <EOL> if os . path . isfile ( os . path . join ( folder , file ) ) and file . endswith ( "<STR_LIT>" ) <EOL> ] <EOL> return pth_paths , index_paths <EOL> def get_mediafire_download_link ( url ) : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> soup = BeautifulSoup ( response . text , "<STR_LIT>" ) <EOL> download_button = soup . find ( <EOL> "<STR_LIT>" , { "<STR_LIT>" : "<STR_LIT>" , "<STR_LIT>" : "<STR_LIT>" } <EOL> ) <EOL> if download_button : <EOL> download_link = download_button . get ( "<STR_LIT>" ) <EOL> return download_link <EOL> else : <EOL> return None <EOL> def download_from_url ( url ) : <EOL> os . makedirs ( zips_path , exist_ok = True ) <EOL> if url != "<STR_LIT>" : <EOL> if "<STR_LIT>" in url : <EOL> if "<STR_LIT>" in url : <EOL> file_id = url . split ( "<STR_LIT>" ) [ <NUM_LIT> ] . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> elif "<STR_LIT>" in url : <EOL> file_id = url . split ( "<STR_LIT>" ) [ <NUM_LIT> ] . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> else : <EOL> return None <EOL> if file_id : <EOL> os . chdir ( zips_path ) <EOL> try : <EOL> gdown . download ( <EOL> f"<STR_LIT>" , <EOL> quiet = True , <EOL> fuzzy = True , <EOL> ) <EOL> except Exception as error : <EOL> error_message = str ( error ) <EOL> if ( <EOL> "<STR_LIT>" <EOL> in error_message <EOL> ) : <EOL> os . chdir ( now_dir ) <EOL> return "<STR_LIT>" <EOL> elif ( <EOL> "<STR_LIT>" in error_message <EOL> ) : <EOL> os . chdir ( now_dir ) <EOL> return "<STR_LIT>" <EOL> else : <EOL> print ( error_message ) <EOL> os . chdir ( now_dir ) <EOL> return None <EOL> elif "<STR_LIT>" in url : <EOL> base_url = "<STR_LIT>" <EOL> public_key = url <EOL> final_url = base_url + urlencode ( dict ( public_key = public_key ) ) <EOL> response = requests . get ( final_url ) <EOL> download_url = response . json ( ) [ "<STR_LIT>" ] <EOL> download_response = requests . get ( download_url ) <EOL> if download_response . status_code == <NUM_LIT> : <EOL> filename = parse_qs ( urlparse ( unquote ( download_url ) ) . query ) . get ( <EOL> "<STR_LIT>" , [ "<STR_LIT>" ] <EOL> ) [ <NUM_LIT> ] <EOL> if filename : <EOL> os . chdir ( zips_path ) <EOL> with open ( filename , "<STR_LIT>" ) as f : <EOL> f . write ( download_response . content ) <EOL> else : <EOL> print ( "<STR_LIT>" ) <EOL> return None <EOL> elif "<STR_LIT>" in url : <EOL> try : <EOL> file_id = url . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> os . chdir ( zips_path ) <EOL> print ( file_id ) <EOL> response = requests . get ( f"<STR_LIT>" ) <EOL> if response . status_code == <NUM_LIT> : <EOL> file_name = ( <EOL> response . headers . get ( "<STR_LIT>" ) <EOL> . split ( "<STR_LIT>" ) [ - <NUM_LIT> ] <EOL> . strip ( '<STR_LIT>' ) <EOL> ) <EOL> os . makedirs ( zips_path , exist_ok = True ) <EOL> with open ( os . path . join ( zips_path , file_name ) , "<STR_LIT>" ) as newfile : <EOL> newfile . write ( response . content ) <EOL> os . chdir ( file_path ) <EOL> return "<STR_LIT>" <EOL> else : <EOL> os . chdir ( file_path ) <EOL> return None <EOL> except Exception as e : <EOL> print ( e ) <EOL> os . chdir ( file_path ) <EOL> return None <EOL> elif "<STR_LIT>" in url : <EOL> file = requests . get ( url ) <EOL> os . chdir ( zips_path ) <EOL> if file . status_code == <NUM_LIT> : <EOL> name = url . split ( "<STR_LIT>" ) <EOL> with open ( os . path . join ( name [ - <NUM_LIT> ] ) , "<STR_LIT>" ) as newfile : <EOL> newfile . write ( file . content ) <EOL> else : <EOL> return None <EOL> elif "<STR_LIT>" in url or "<STR_LIT>" in url : <EOL> os . chdir ( zips_path ) <EOL> if "<STR_LIT>" in url : <EOL> url = url . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> response = requests . get ( url , stream = True ) <EOL> if response . status_code == <NUM_LIT> : <EOL> content_disposition = six . moves . urllib_parse . unquote ( <EOL> response . headers [ "<STR_LIT>" ] <EOL> ) <EOL> m = re . search ( r'<STR_LIT>' , content_disposition ) <EOL> file_name = m . groups ( ) [ <NUM_LIT> ] <EOL> file_name = file_name . replace ( os . path . sep , "<STR_LIT>" ) <EOL> total_size_in_bytes = int ( response . headers . get ( "<STR_LIT>" , <NUM_LIT> ) ) <EOL> block_size = <NUM_LIT> <EOL> progress_bar_length = <NUM_LIT> <EOL> progress = <NUM_LIT> <EOL> with open ( os . path . join ( zips_path , file_name ) , "<STR_LIT>" ) as file : <EOL> for data in response . iter_content ( block_size ) : <EOL> file . write ( data ) <EOL> progress += len ( data ) <EOL> progress_percent = int ( ( progress / total_size_in_bytes ) * <NUM_LIT> ) <EOL> num_dots = int ( <EOL> ( progress / total_size_in_bytes ) * progress_bar_length <EOL> ) <EOL> progress_bar = ( <EOL> "<STR_LIT>" <EOL> + "<STR_LIT>" * num_dots <EOL> + "<STR_LIT>" * ( progress_bar_length - num_dots ) <EOL> + "<STR_LIT>" <EOL> ) <EOL> print ( <EOL> f"<STR_LIT>" , <EOL> end = "<STR_LIT>" , <EOL> ) <EOL> if progress_percent == <NUM_LIT> : <EOL> print ( "<STR_LIT>" ) <EOL> else : <EOL> os . chdir ( now_dir ) <EOL> return None <EOL> elif "<STR_LIT>" in url : <EOL> os . chdir ( zips_path ) <EOL> response = requests . get ( url ) <EOL> soup = BeautifulSoup ( response . content , "<STR_LIT>" ) <EOL> temp_url = "<STR_LIT>" <EOL> for link in soup . find_all ( "<STR_LIT>" , href = True ) : <EOL> if link [ "<STR_LIT>" ] . endswith ( "<STR_LIT>" ) : <EOL> temp_url = link [ "<STR_LIT>" ] <EOL> break <EOL> if temp_url : <EOL> url = temp_url <EOL> url = url . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> if "<STR_LIT>" not in url : <EOL> url = "<STR_LIT>" + url <EOL> wget . download ( url ) <EOL> else : <EOL> os . chdir ( now_dir ) <EOL> return None <EOL> elif "<STR_LIT>" in url : <EOL> parts = url . split ( "<STR_LIT>" ) <EOL> id_with_query = parts [ - <NUM_LIT> ] <EOL> id_parts = id_with_query . split ( "<STR_LIT>" ) <EOL> id_number = id_parts [ <NUM_LIT> ] <EOL> url = "<STR_LIT>" <EOL> headers = { <EOL> "<STR_LIT>" : "<STR_LIT>" <EOL> } <EOL> params = { "<STR_LIT>" : f"<STR_LIT>" } <EOL> response = requests . get ( url , headers = headers , params = params ) <EOL> if response . status_code == <NUM_LIT> : <EOL> json_response = response . json ( ) <EOL> print ( json_response ) <EOL> if json_response : <EOL> link = json_response [ <NUM_LIT> ] [ "<STR_LIT>" ] <EOL> verify = download_from_url ( link ) <EOL> if verify == "<STR_LIT>" : <EOL> return "<STR_LIT>" <EOL> else : <EOL> return None <EOL> else : <EOL> return None <EOL> else : <EOL> try : <EOL> os . chdir ( zips_path ) <EOL> wget . download ( url ) <EOL> except Exception as error : <EOL> os . chdir ( now_dir ) <EOL> print ( error ) <EOL> return None <EOL> for currentPath , _ , zipFiles in os . walk ( zips_path ) : <EOL> for Files in zipFiles : <EOL> filePart = Files . split ( "<STR_LIT>" ) <EOL> extensionFile = filePart [ len ( filePart ) - <NUM_LIT> ] <EOL> filePart . pop ( ) <EOL> nameFile = "<STR_LIT>" . join ( filePart ) <EOL> realPath = os . path . join ( currentPath , Files ) <EOL> os . rename ( realPath , nameFile + "<STR_LIT>" + extensionFile ) <EOL> os . chdir ( now_dir ) <EOL> return "<STR_LIT>" <EOL> os . chdir ( now_dir ) <EOL> return None <EOL> def extract_and_show_progress ( zipfile_path , unzips_path ) : <EOL> try : <EOL> with zipfile . ZipFile ( zipfile_path , "<STR_LIT>" ) as zip_ref : <EOL> for file_info in zip_ref . infolist ( ) : <EOL> zip_ref . extract ( file_info , unzips_path ) <EOL> os . remove ( zipfile_path ) <EOL> return True <EOL> except Exception as error : <EOL> print ( error ) <EOL> return False <EOL> def unzip_file ( zip_path , zip_file_name ) : <EOL> zip_file_path = os . path . join ( zip_path , zip_file_name + "<STR_LIT>" ) <EOL> extract_path = os . path . join ( file_path , zip_file_name ) <EOL> with zipfile . ZipFile ( zip_file_path , "<STR_LIT>" ) as zip_ref : <EOL> zip_ref . extractall ( extract_path ) <EOL> os . remove ( zip_file_path ) <EOL> def model_download_pipeline ( url ) : <EOL> verify = download_from_url ( url ) <EOL> if verify == "<STR_LIT>" : <EOL> extract_folder_path = "<STR_LIT>" <EOL> for filename in os . listdir ( zips_path ) : <EOL> if filename . endswith ( "<STR_LIT>" ) : <EOL> zipfile_path = os . path . join ( zips_path , filename ) <EOL> print ( "<STR_LIT>" ) <EOL> model_zip = os . path . basename ( zipfile_path ) <EOL> model_name = format_title ( model_zip . split ( "<STR_LIT>" ) [ <NUM_LIT> ] ) <EOL> extract_folder_path = os . path . join ( <EOL> "<STR_LIT>" , <EOL> os . path . normpath ( model_name ) , <EOL> ) <EOL> success = extract_and_show_progress ( zipfile_path , extract_folder_path ) <EOL> subfolders = [ <EOL> f <EOL> for f in os . listdir ( extract_folder_path ) <EOL> if os . path . isdir ( os . path . join ( extract_folder_path , f ) ) <EOL> ] <EOL> if len ( subfolders ) == <NUM_LIT> : <EOL> subfolder_path = os . path . join ( extract_folder_path , subfolders [ <NUM_LIT> ] ) <EOL> for item in os . listdir ( subfolder_path ) : <EOL> s = os . path . join ( subfolder_path , item ) <EOL> d = os . path . join ( extract_folder_path , item ) <EOL> shutil . move ( s , d ) <EOL> os . rmdir ( subfolder_path ) <EOL> for item in os . listdir ( extract_folder_path ) : <EOL> if "<STR_LIT>" in item : <EOL> file_name = item . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> if file_name != model_name : <EOL> os . rename ( <EOL> os . path . join ( extract_folder_path , item ) , <EOL> os . path . join ( extract_folder_path , model_name + "<STR_LIT>" ) , <EOL> ) <EOL> else : <EOL> if "<STR_LIT>" not in item : <EOL> file_name = item . split ( "<STR_LIT>" ) [ <NUM_LIT> ] . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> if file_name != model_name : <EOL> new_file_name = ( <EOL> item . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> + "<STR_LIT>" <EOL> + model_name <EOL> + "<STR_LIT>" <EOL> ) <EOL> os . rename ( <EOL> os . path . join ( extract_folder_path , item ) , <EOL> os . path . join ( <EOL> extract_folder_path , new_file_name + "<STR_LIT>" <EOL> ) , <EOL> ) <EOL> else : <EOL> file_name = item . split ( "<STR_LIT>" ) [ <NUM_LIT> ] . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> if file_name != model_name : <EOL> new_file_name = ( <EOL> item . split ( "<STR_LIT>" ) [ <NUM_LIT> ] <EOL> + "<STR_LIT>" <EOL> + model_name <EOL> + "<STR_LIT>" <EOL> ) <EOL> os . rename ( <EOL> os . path . join ( extract_folder_path , item ) , <EOL> os . path . join ( <EOL> extract_folder_path , new_file_name + "<STR_LIT>" <EOL> ) , <EOL> ) <EOL> if success : <EOL> print ( f"<STR_LIT>" ) <EOL> else : <EOL> print ( f"<STR_LIT>" ) <EOL> sys . exit ( ) <EOL> if extract_folder_path == "<STR_LIT>" : <EOL> print ( "<STR_LIT>" ) <EOL> sys . exit ( ) <EOL> result = search_pth_index ( extract_folder_path ) <EOL> else : <EOL> message = "<STR_LIT>" <EOL> </s>
<s> import os <EOL> import torch <EOL> import hashlib <EOL> import datetime <EOL> from collections import OrderedDict <EOL> def replace_keys_in_dict ( d , old_key_part , new_key_part ) : <EOL> if isinstance ( d , OrderedDict ) : <EOL> updated_dict = OrderedDict ( ) <EOL> else : <EOL> updated_dict = { } <EOL> for key , value in d . items ( ) : <EOL> new_key = key . replace ( old_key_part , new_key_part ) <EOL> if isinstance ( value , dict ) : <EOL> value = replace_keys_in_dict ( value , old_key_part , new_key_part ) <EOL> updated_dict [ new_key ] = value <EOL> return updated_dict <EOL> def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : <EOL> try : <EOL> print ( f"<STR_LIT>" ) <EOL> pth_file = f"<STR_LIT>" <EOL> pth_file_old_version_path = os . path . join ( <EOL> model_dir , f"<STR_LIT>" <EOL> ) <EOL> opt = OrderedDict ( <EOL> weight = { <EOL> key : value . half ( ) for key , value in ckpt . items ( ) if "<STR_LIT>" not in key <EOL> } <EOL> ) <EOL> opt [ "<STR_LIT>" ] = [ <EOL> hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> hps . model . inter_channels , <EOL> hps . model . hidden_channels , <EOL> hps . model . filter_channels , <EOL> hps . model . n_heads , <EOL> hps . model . n_layers , <EOL> hps . model . kernel_size , <EOL> hps . model . p_dropout , <EOL> hps . model . resblock , <EOL> hps . model . resblock_kernel_sizes , <EOL> hps . model . resblock_dilation_sizes , <EOL> hps . model . upsample_rates , <EOL> hps . model . upsample_initial_channel , <EOL> hps . model . upsample_kernel_sizes , <EOL> hps . model . spk_embed_dim , <EOL> hps . model . gin_channels , <EOL> hps . data . sampling_rate , <EOL> ] <EOL> opt [ "<STR_LIT>" ] = epoch <EOL> opt [ "<STR_LIT>" ] = step <EOL> opt [ "<STR_LIT>" ] = sr <EOL> opt [ "<STR_LIT>" ] = if_f0 <EOL> opt [ "<STR_LIT>" ] = version <EOL> opt [ "<STR_LIT>" ] = datetime . datetime . now ( ) . isoformat ( ) <EOL> hash_input = f"<STR_LIT>" <EOL> model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) <EOL> opt [ "<STR_LIT>" ] = model_hash <EOL> torch . save ( opt , model_dir ) <EOL> model = torch . load ( model_dir , map_location = torch . device ( "<STR_LIT>" ) ) <EOL> torch . save ( <EOL> replace_keys_in_dict ( <EOL> replace_keys_in_dict ( <EOL> model , "<STR_LIT>" , "<STR_LIT>" <EOL> ) , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> ) , <EOL> pth_file_old_version_path , <EOL> ) <EOL> os . remove ( model_dir ) <EOL> os . rename ( pth_file_old_version_path , model_dir ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> </s>
<s> import numpy as np <EOL> import matplotlib . pyplot as plt <EOL> import librosa . display <EOL> import librosa <EOL> def calculate_features ( y , sr ) : <EOL> stft = np . abs ( librosa . stft ( y ) ) <EOL> duration = librosa . get_duration ( y = y , sr = sr ) <EOL> cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] <EOL> return stft , duration , cent , bw , rolloff <EOL> def plot_title ( title ) : <EOL> plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = "<STR_LIT>" ) <EOL> def plot_spectrogram ( y , sr , stft , duration , cmap = "<STR_LIT>" ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . imshow ( <EOL> librosa . amplitude_to_db ( stft , ref = np . max ) , <EOL> origin = "<STR_LIT>" , <EOL> extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , <EOL> aspect = "<STR_LIT>" , <EOL> cmap = cmap , <EOL> ) <EOL> plt . colorbar ( format = "<STR_LIT>" ) <EOL> plt . xlabel ( "<STR_LIT>" ) <EOL> plt . ylabel ( "<STR_LIT>" ) <EOL> plt . title ( "<STR_LIT>" ) <EOL> def plot_waveform ( y , sr , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> librosa . display . waveshow ( y , sr = sr ) <EOL> plt . xlabel ( "<STR_LIT>" ) <EOL> plt . ylabel ( "<STR_LIT>" ) <EOL> plt . title ( "<STR_LIT>" ) <EOL> def plot_features ( times , cent , bw , rolloff , duration ) : <EOL> plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) <EOL> plt . plot ( times , cent , label = "<STR_LIT>" , color = "<STR_LIT>" ) <EOL> plt . plot ( times , bw , label = "<STR_LIT>" , color = "<STR_LIT>" ) <EOL> plt . plot ( times , rolloff , label = "<STR_LIT>" , color = "<STR_LIT>" ) <EOL> plt . xlabel ( "<STR_LIT>" ) <EOL> plt . title ( "<STR_LIT>" ) <EOL> plt . legend ( ) <EOL> def analyze_audio ( audio_file , save_plot_path = "<STR_LIT>" ) : <EOL> y , sr = librosa . load ( audio_file ) <EOL> stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) <EOL> plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> plot_title ( "<STR_LIT>" + "<STR_LIT>" + audio_file . split ( "<STR_LIT>" ) [ - <NUM_LIT> ] ) <EOL> plot_spectrogram ( y , sr , stft , duration ) <EOL> plot_waveform ( y , sr , duration ) <EOL> plot_features ( librosa . times_like ( cent ) , cent , bw , rolloff , duration ) <EOL> plt . tight_layout ( ) <EOL> if save_plot_path : <EOL> plt . savefig ( save_plot_path , bbox_inches = "<STR_LIT>" , dpi = <NUM_LIT> ) <EOL> plt . close ( ) <EOL> audio_info = <EOL> return audio_info , save_plot_path <EOL> </s>
<s> import os <EOL> import sys <EOL> import time <EOL> import torch <EOL> import logging <EOL> import numpy as np <EOL> import soundfile as sf <EOL> import librosa <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from rvc . infer . pipeline import VC <EOL> from scipy . io import wavfile <EOL> import noisereduce as nr <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . lib . tools . split_audio import process_audio , merge_audio <EOL> from fairseq import checkpoint_utils <EOL> from rvc . lib . infer_pack . models import ( <EOL> SynthesizerTrnMs256NSFsid , <EOL> SynthesizerTrnMs256NSFsid_nono , <EOL> SynthesizerTrnMs768NSFsid , <EOL> SynthesizerTrnMs768NSFsid_nono , <EOL> ) <EOL> from rvc . configs . config import Config <EOL> logging . getLogger ( "<STR_LIT>" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( "<STR_LIT>" ) . setLevel ( logging . WARNING ) <EOL> logging . getLogger ( "<STR_LIT>" ) . setLevel ( logging . WARNING ) <EOL> config = Config ( ) <EOL> hubert_model = None <EOL> tgt_sr = None <EOL> net_g = None <EOL> vc = None <EOL> cpt = None <EOL> version = None <EOL> n_spk = None <EOL> def load_hubert ( ) : <EOL> global hubert_model <EOL> models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( <EOL> [ "<STR_LIT>" ] , <EOL> suffix = "<STR_LIT>" , <EOL> ) <EOL> hubert_model = models [ <NUM_LIT> ] <EOL> hubert_model = hubert_model . to ( config . device ) <EOL> if config . is_half : <EOL> hubert_model = hubert_model . half ( ) <EOL> else : <EOL> hubert_model = hubert_model . float ( ) <EOL> hubert_model . eval ( ) <EOL> def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : <EOL> try : <EOL> rate , data = wavfile . read ( input_audio_path ) <EOL> reduced_noise = nr . reduce_noise ( <EOL> y = data , <EOL> sr = rate , <EOL> prop_decrease = reduction_strength , <EOL> ) <EOL> return reduced_noise <EOL> except Exception as error : <EOL> print ( f"<STR_LIT>" ) <EOL> return None <EOL> def convert_audio_format ( input_path , output_path , output_format ) : <EOL> try : <EOL> if output_format != "<STR_LIT>" : <EOL> print ( f"<STR_LIT>" ) <EOL> audio , sample_rate = librosa . load ( input_path , sr = None ) <EOL> common_sample_rates = [ <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> <NUM_LIT> , <EOL> ] <EOL> target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) <EOL> audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) <EOL> sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) <EOL> return output_path <EOL> except Exception as error : <EOL> print ( f"<STR_LIT>" ) <EOL> def vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = None , <EOL> f0_up_key = None , <EOL> f0_file = None , <EOL> f0_method = None , <EOL> file_index = None , <EOL> index_rate = None , <EOL> resample_sr = <NUM_LIT> , <EOL> rms_mix_rate = None , <EOL> protect = None , <EOL> hop_length = None , <EOL> output_path = None , <EOL> split_audio = False , <EOL> f0autotune = False , <EOL> filter_radius = None , <EOL> ) : <EOL> global tgt_sr , net_g , vc , hubert_model , version <EOL> f0_up_key = int ( f0_up_key ) <EOL> try : <EOL> audio = load_audio ( input_audio_path , <NUM_LIT> ) <EOL> audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> <EOL> if audio_max > <NUM_LIT> : <EOL> audio /= audio_max <EOL> if not hubert_model : <EOL> load_hubert ( ) <EOL> if_f0 = cpt . get ( "<STR_LIT>" , <NUM_LIT> ) <EOL> file_index = ( <EOL> file_index . strip ( "<STR_LIT>" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( "<STR_LIT>" ) <EOL> . strip ( '<STR_LIT>' ) <EOL> . strip ( "<STR_LIT>" ) <EOL> . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> ) <EOL> if tgt_sr != resample_sr >= <NUM_LIT> : <EOL> tgt_sr = resample_sr <EOL> if split_audio == "<STR_LIT>" : <EOL> result , new_dir_path = process_audio ( input_audio_path ) <EOL> if result == "<STR_LIT>" : <EOL> return "<STR_LIT>" , None <EOL> dir_path = ( <EOL> new_dir_path . strip ( "<STR_LIT>" ) . strip ( '<STR_LIT>' ) . strip ( "<STR_LIT>" ) . strip ( '<STR_LIT>' ) . strip ( "<STR_LIT>" ) <EOL> ) <EOL> if dir_path != "<STR_LIT>" : <EOL> paths = [ <EOL> os . path . join ( root , name ) <EOL> for root , _ , files in os . walk ( dir_path , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( "<STR_LIT>" ) and root == dir_path <EOL> ] <EOL> try : <EOL> for path in paths : <EOL> vc_single ( <EOL> sid , <EOL> path , <EOL> f0_up_key , <EOL> None , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> path , <EOL> False , <EOL> f0autotune , <EOL> ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> return f"<STR_LIT>" <EOL> print ( "<STR_LIT>" ) <EOL> merge_timestamps_file = os . path . join ( <EOL> os . path . dirname ( new_dir_path ) , <EOL> f"<STR_LIT>" , <EOL> ) <EOL> tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) <EOL> os . remove ( merge_timestamps_file ) <EOL> else : <EOL> audio_opt = vc . pipeline ( <EOL> hubert_model , <EOL> net_g , <EOL> sid , <EOL> audio , <EOL> input_audio_path , <EOL> f0_up_key , <EOL> f0_method , <EOL> file_index , <EOL> index_rate , <EOL> if_f0 , <EOL> filter_radius , <EOL> tgt_sr , <EOL> resample_sr , <EOL> rms_mix_rate , <EOL> version , <EOL> protect , <EOL> hop_length , <EOL> f0autotune , <EOL> f0_file = f0_file , <EOL> ) <EOL> if output_path is not None : <EOL> sf . write ( output_path , audio_opt , tgt_sr , format = "<STR_LIT>" ) <EOL> return ( tgt_sr , audio_opt ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def get_vc ( weight_root , sid ) : <EOL> global n_spk , tgt_sr , net_g , vc , cpt , version <EOL> if sid == "<STR_LIT>" or sid == [ ] : <EOL> global hubert_model <EOL> if hubert_model is not None : <EOL> print ( "<STR_LIT>" ) <EOL> del net_g , n_spk , vc , hubert_model , tgt_sr <EOL> hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> if_f0 = cpt . get ( "<STR_LIT>" , <NUM_LIT> ) <EOL> version = cpt . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> if version == "<STR_LIT>" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( <EOL> * cpt [ "<STR_LIT>" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ "<STR_LIT>" ] ) <EOL> elif version == "<STR_LIT>" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( <EOL> * cpt [ "<STR_LIT>" ] , is_half = config . is_half <EOL> ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ "<STR_LIT>" ] ) <EOL> del net_g , cpt <EOL> if torch . cuda . is_available ( ) : <EOL> torch . cuda . empty_cache ( ) <EOL> cpt = None <EOL> person = weight_root <EOL> cpt = torch . load ( person , map_location = "<STR_LIT>" ) <EOL> tgt_sr = cpt [ "<STR_LIT>" ] [ - <NUM_LIT> ] <EOL> cpt [ "<STR_LIT>" ] [ - <NUM_LIT> ] = cpt [ "<STR_LIT>" ] [ "<STR_LIT>" ] . shape [ <NUM_LIT> ] <EOL> if_f0 = cpt . get ( "<STR_LIT>" , <NUM_LIT> ) <EOL> version = cpt . get ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> if version == "<STR_LIT>" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs256NSFsid ( * cpt [ "<STR_LIT>" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ "<STR_LIT>" ] ) <EOL> elif version == "<STR_LIT>" : <EOL> if if_f0 == <NUM_LIT> : <EOL> net_g = SynthesizerTrnMs768NSFsid ( * cpt [ "<STR_LIT>" ] , is_half = config . is_half ) <EOL> else : <EOL> net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ "<STR_LIT>" ] ) <EOL> del net_g . enc_q <EOL> print ( net_g . load_state_dict ( cpt [ "<STR_LIT>" ] , strict = False ) ) <EOL> net_g . eval ( ) . to ( config . device ) <EOL> if config . is_half : <EOL> net_g = net_g . half ( ) <EOL> else : <EOL> net_g = net_g . float ( ) <EOL> vc = VC ( tgt_sr , config ) <EOL> n_spk = cpt [ "<STR_LIT>" ] [ - <NUM_LIT> ] <EOL> def infer_pipeline ( <EOL> f0up_key , <EOL> filter_radius , <EOL> index_rate , <EOL> rms_mix_rate , <EOL> protect , <EOL> hop_length , <EOL> f0method , <EOL> audio_input_path , <EOL> audio_output_path , <EOL> model_path , <EOL> index_path , <EOL> split_audio , <EOL> f0autotune , <EOL> clean_audio , <EOL> clean_strength , <EOL> export_format , <EOL> ) : <EOL> global tgt_sr , net_g , vc , cpt <EOL> get_vc ( model_path , <NUM_LIT> ) <EOL> try : <EOL> start_time = time . time ( ) <EOL> vc_single ( <EOL> sid = <NUM_LIT> , <EOL> input_audio_path = audio_input_path , <EOL> f0_up_key = f0up_key , <EOL> f0_file = None , <EOL> f0_method = f0method , <EOL> file_index = index_path , <EOL> index_rate = index_rate , <EOL> rms_mix_rate = rms_mix_rate , <EOL> protect = protect , <EOL> hop_length = hop_length , <EOL> output_path = audio_output_path , <EOL> split_audio = split_audio , <EOL> f0autotune = f0autotune , <EOL> filter_radius = filter_radius , <EOL> ) <EOL> if clean_audio == "<STR_LIT>" : <EOL> cleaned_audio = remove_audio_noise ( audio_output_path , clean_strength ) <EOL> if cleaned_audio is not None : <EOL> sf . write ( audio_output_path , cleaned_audio , tgt_sr , format = "<STR_LIT>" ) <EOL> output_path_format = audio_output_path . replace ( <EOL> "<STR_LIT>" , f"<STR_LIT>" <EOL> ) <EOL> audio_output_path = convert_audio_format ( <EOL> audio_output_path , output_path_format , export_format <EOL> ) <EOL> end_time = time . time ( ) <EOL> elapsed_time = end_time - start_time <EOL> print ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> except Exception as error : <EOL> print ( f"<STR_LIT>" ) <EOL> </s>
<s> import os <EOL> import numpy as np <EOL> import torch <EOL> import torch . utils . data <EOL> from mel_processing import spectrogram_torch <EOL> from utils import load_filepaths_and_text , load_wav_to_torch <EOL> class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , "<STR_LIT>" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , "<STR_LIT>" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = torch . LongTensor ( [ int ( sid ) ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> pitch = audiopath_and_text [ <NUM_LIT> ] <EOL> pitchf = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> pitch = pitch [ : len_min ] <EOL> pitchf = pitchf [ : len_min ] <EOL> return ( spec , wav , phone , pitch , pitchf , dv ) <EOL> def get_labels ( self , phone , pitch , pitchf ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> pitch = np . load ( pitch ) <EOL> pitchf = np . load ( pitchf ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> pitch = pitch [ : n_num ] <EOL> pitchf = pitchf [ : n_num ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> pitch = torch . LongTensor ( pitch ) <EOL> pitchf = torch . FloatTensor ( pitchf ) <EOL> return phone , pitch , pitchf <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> "<STR_LIT>" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f"<STR_LIT>" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollateMultiNSFsid : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) <EOL> pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) <EOL> phone_padded . zero_ ( ) <EOL> pitch_padded . zero_ ( ) <EOL> pitchf_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> pitch = row [ <NUM_LIT> ] <EOL> pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch <EOL> pitchf = row [ <NUM_LIT> ] <EOL> pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> pitch_padded , <EOL> pitchf_padded , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class TextAudioLoader ( torch . utils . data . Dataset ) : <EOL> def __init__ ( self , hparams ) : <EOL> self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) <EOL> self . max_wav_value = hparams . max_wav_value <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . filter_length = hparams . filter_length <EOL> self . hop_length = hparams . hop_length <EOL> self . win_length = hparams . win_length <EOL> self . sampling_rate = hparams . sampling_rate <EOL> self . min_text_len = getattr ( hparams , "<STR_LIT>" , <NUM_LIT> ) <EOL> self . max_text_len = getattr ( hparams , "<STR_LIT>" , <NUM_LIT> ) <EOL> self . _filter ( ) <EOL> def _filter ( self ) : <EOL> audiopaths_and_text_new = [ ] <EOL> lengths = [ ] <EOL> for entry in self . audiopaths_and_text : <EOL> if len ( entry ) >= <NUM_LIT> : <EOL> audiopath , text , dv = entry [ : <NUM_LIT> ] <EOL> if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : <EOL> audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) <EOL> lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) <EOL> self . audiopaths_and_text = audiopaths_and_text_new <EOL> self . lengths = lengths <EOL> def get_sid ( self , sid ) : <EOL> sid = os . path . basename ( os . path . dirname ( sid ) ) <EOL> try : <EOL> sid = torch . LongTensor ( [ int ( "<STR_LIT>" . join ( filter ( str . isdigit , sid ) ) ) ] ) <EOL> except ValueError as error : <EOL> print ( f"<STR_LIT>" ) <EOL> sid = torch . LongTensor ( [ <NUM_LIT> ] ) <EOL> return sid <EOL> def get_audio_text_pair ( self , audiopath_and_text ) : <EOL> file = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = audiopath_and_text [ <NUM_LIT> ] <EOL> dv = audiopath_and_text [ <NUM_LIT> ] <EOL> phone = self . get_labels ( phone ) <EOL> spec , wav = self . get_audio ( file ) <EOL> dv = self . get_sid ( dv ) <EOL> len_phone = phone . size ( ) [ <NUM_LIT> ] <EOL> len_spec = spec . size ( ) [ - <NUM_LIT> ] <EOL> if len_phone != len_spec : <EOL> len_min = min ( len_phone , len_spec ) <EOL> len_wav = len_min * self . hop_length <EOL> spec = spec [ : , : len_min ] <EOL> wav = wav [ : , : len_wav ] <EOL> phone = phone [ : len_min , : ] <EOL> return ( spec , wav , phone , dv ) <EOL> def get_labels ( self , phone ) : <EOL> phone = np . load ( phone ) <EOL> phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) <EOL> n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) <EOL> phone = phone [ : n_num , : ] <EOL> phone = torch . FloatTensor ( phone ) <EOL> return phone <EOL> def get_audio ( self , filename ) : <EOL> audio , sampling_rate = load_wav_to_torch ( filename ) <EOL> if sampling_rate != self . sampling_rate : <EOL> raise ValueError ( <EOL> "<STR_LIT>" . format ( <EOL> sampling_rate , self . sampling_rate <EOL> ) <EOL> ) <EOL> audio_norm = audio <EOL> audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) <EOL> spec_filename = filename . replace ( "<STR_LIT>" , "<STR_LIT>" ) <EOL> if os . path . exists ( spec_filename ) : <EOL> try : <EOL> spec = torch . load ( spec_filename ) <EOL> except Exception as error : <EOL> print ( f"<STR_LIT>" ) <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> else : <EOL> spec = spectrogram_torch ( <EOL> audio_norm , <EOL> self . filter_length , <EOL> self . hop_length , <EOL> self . win_length , <EOL> center = False , <EOL> ) <EOL> spec = torch . squeeze ( spec , <NUM_LIT> ) <EOL> torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) <EOL> return spec , audio_norm <EOL> def __getitem__ ( self , index ) : <EOL> return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) <EOL> def __len__ ( self ) : <EOL> return len ( self . audiopaths_and_text ) <EOL> class TextAudioCollate : <EOL> def __init__ ( self , return_ids = False ) : <EOL> self . return_ids = return_ids <EOL> def __call__ ( self , batch ) : <EOL> _ , ids_sorted_decreasing = torch . sort ( <EOL> torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True <EOL> ) <EOL> max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> spec_lengths = torch . LongTensor ( len ( batch ) ) <EOL> wave_lengths = torch . LongTensor ( len ( batch ) ) <EOL> spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) <EOL> wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) <EOL> spec_padded . zero_ ( ) <EOL> wave_padded . zero_ ( ) <EOL> max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) <EOL> phone_lengths = torch . LongTensor ( len ( batch ) ) <EOL> phone_padded = torch . FloatTensor ( <EOL> len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] <EOL> ) <EOL> phone_padded . zero_ ( ) <EOL> sid = torch . LongTensor ( len ( batch ) ) <EOL> for i in range ( len ( ids_sorted_decreasing ) ) : <EOL> row = batch [ ids_sorted_decreasing [ i ] ] <EOL> spec = row [ <NUM_LIT> ] <EOL> spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec <EOL> spec_lengths [ i ] = spec . size ( <NUM_LIT> ) <EOL> wave = row [ <NUM_LIT> ] <EOL> wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave <EOL> wave_lengths [ i ] = wave . size ( <NUM_LIT> ) <EOL> phone = row [ <NUM_LIT> ] <EOL> phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone <EOL> phone_lengths [ i ] = phone . size ( <NUM_LIT> ) <EOL> sid [ i ] = row [ <NUM_LIT> ] <EOL> return ( <EOL> phone_padded , <EOL> phone_lengths , <EOL> spec_padded , <EOL> spec_lengths , <EOL> wave_padded , <EOL> wave_lengths , <EOL> sid , <EOL> ) <EOL> class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : <EOL> def __init__ ( <EOL> self , <EOL> dataset , <EOL> batch_size , <EOL> boundaries , <EOL> num_replicas = None , <EOL> rank = None , <EOL> shuffle = True , <EOL> ) : <EOL> super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) <EOL> self . lengths = dataset . lengths <EOL> self . batch_size = batch_size <EOL> self . boundaries = boundaries <EOL> self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) <EOL> self . total_size = sum ( self . num_samples_per_bucket ) <EOL> self . num_samples = self . total_size // self . num_replicas <EOL> def _create_buckets ( self ) : <EOL> buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] <EOL> for i in range ( len ( self . lengths ) ) : <EOL> length = self . lengths [ i ] <EOL> idx_bucket = self . _bisect ( length ) <EOL> if idx_bucket != - <NUM_LIT> : <EOL> buckets [ idx_bucket ] . append ( i ) <EOL> for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : <EOL> if len ( buckets [ i ] ) == <NUM_LIT> : <EOL> buckets . pop ( i ) <EOL> self . boundaries . pop ( i + <NUM_LIT> ) <EOL> num_samples_per_bucket = [ ] <EOL> for i in range ( len ( buckets ) ) : <EOL> len_bucket = len ( buckets [ i ] ) <EOL> total_batch_size = self . num_replicas * self . batch_size <EOL> rem = ( <EOL> total_batch_size - ( len_bucket % total_batch_size ) <EOL> ) % total_batch_size <EOL> num_samples_per_bucket . append ( len_bucket + rem ) <EOL> return buckets , num_samples_per_bucket <EOL> def __iter__ ( self ) : <EOL> g = torch . Generator ( ) <EOL> g . manual_seed ( self . epoch ) <EOL> indices = [ ] <EOL> if self . shuffle : <EOL> for bucket in self . buckets : <EOL> indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) <EOL> else : <EOL> for bucket in self . buckets : <EOL> indices . append ( list ( range ( len ( bucket ) ) ) ) <EOL> batches = [ ] <EOL> for i in range ( len ( self . buckets ) ) : <EOL> bucket = self . buckets [ i ] <EOL> len_bucket = len ( bucket ) <EOL> ids_bucket = indices [ i ] <EOL> num_samples_bucket = self . num_samples_per_bucket [ i ] <EOL> rem = num_samples_bucket - len_bucket <EOL> ids_bucket = ( <EOL> ids_bucket <EOL> + ids_bucket * ( rem // len_bucket ) <EOL> + ids_bucket [ : ( rem % len_bucket ) ] <EOL> ) <EOL> ids_bucket = ids_bucket [ self . rank : : self . num_replicas ] <EOL> for j in range ( len ( ids_bucket ) // self . batch_size ) : <EOL> batch = [ <EOL> bucket [ idx ] <EOL> for idx in ids_bucket [ <EOL> j * self . batch_size : ( j + <NUM_LIT> ) * self . batch_size <EOL> ] <EOL> ] <EOL> batches . append ( batch ) <EOL> if self . shuffle : <EOL> batch_ids = torch . randperm ( len ( batches ) , generator = g ) . tolist ( ) <EOL> batches = [ batches [ i ] for i in batch_ids ] <EOL> self . batches = batches <EOL> assert len ( self . batches ) * self . batch_size == self . num_samples <EOL> return iter ( self . batches ) <EOL> def _bisect ( self , x , lo = <NUM_LIT> , hi = None ) : <EOL> if hi is None : <EOL> hi = len ( self . boundaries ) - <NUM_LIT> <EOL> if hi > lo : <EOL> mid = ( hi + lo ) // <NUM_LIT> <EOL> if self . boundaries [ mid ] < x and x <= self . boundaries [ mid + <NUM_LIT> ] : <EOL> return mid <EOL> elif x <= self . boundaries [ mid ] : <EOL> return self . _bisect ( x , lo , mid ) <EOL> else : <EOL> return self . _bisect ( x , mid + <NUM_LIT> , hi ) <EOL> else : <EOL> return - <NUM_LIT> <EOL> def __len__ ( self ) : <EOL> return self . num_samples // self . batch_size <EOL> </s>
<s> import sys <EOL> import asyncio <EOL> import edge_tts <EOL> async def main ( ) : <EOL> text = sys . argv [ <NUM_LIT> ] <EOL> voice = sys . argv [ <NUM_LIT> ] <EOL> output_file = sys . argv [ <NUM_LIT> ] <EOL> await edge_tts . Communicate ( text , voice ) . save ( output_file ) <EOL> print ( f"<STR_LIT>" ) <EOL> if __name__ == "<STR_LIT>" : <EOL> asyncio . run ( main ( ) ) <EOL> </s>
<s> import sys <EOL> import os <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class InstallationError ( Exception ) : <EOL> def __init__ ( self , message = "<STR_LIT>" ) : <EOL> self . message = message <EOL> super ( ) . __init__ ( self . message ) <EOL> def check_installation ( ) : <EOL> try : <EOL> system_drive = os . getenv ( "<STR_LIT>" ) <EOL> current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] <EOL> if current_drive . upper ( ) != system_drive . upper ( ) : <EOL> raise InstallationError ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> except : <EOL> pass <EOL> else : <EOL> if "<STR_LIT>" in now_dir : <EOL> raise InstallationError ( <EOL> "<STR_LIT>" <EOL> ) <EOL> elif "<STR_LIT>" in now_dir : <EOL> raise InstallationError ( <EOL> "<STR_LIT>" <EOL> ) <EOL> try : <EOL> now_dir . encode ( "<STR_LIT>" ) <EOL> except UnicodeEncodeError : <EOL> raise InstallationError ( <EOL> "<STR_LIT>" <EOL> ) <EOL> </s>
<s> import os , sys <EOL> import json <EOL> from pathlib import Path <EOL> from locale import getdefaultlocale <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> class I18nAuto : <EOL> LANGUAGE_PATH = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) <EOL> def __init__ ( self , language = None ) : <EOL> with open ( <EOL> os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) , "<STR_LIT>" , encoding = "<STR_LIT>" <EOL> ) as file : <EOL> config = json . load ( file ) <EOL> override = config [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> lang_prefix = config [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> self . language = lang_prefix <EOL> if override == False : <EOL> language = language or getdefaultlocale ( ) [ <NUM_LIT> ] <EOL> lang_prefix = language [ : <NUM_LIT> ] if language is not None else "<STR_LIT>" <EOL> available_languages = self . _get_available_languages ( ) <EOL> matching_languages = [ <EOL> lang for lang in available_languages if lang . startswith ( lang_prefix ) <EOL> ] <EOL> self . language = matching_languages [ <NUM_LIT> ] if matching_languages else "<STR_LIT>" <EOL> self . language_map = self . _load_language_list ( ) <EOL> def _load_language_list ( self ) : <EOL> try : <EOL> file_path = Path ( self . LANGUAGE_PATH ) / f"<STR_LIT>" <EOL> with open ( file_path , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> return json . load ( file ) <EOL> except FileNotFoundError : <EOL> raise FileNotFoundError ( <EOL> f"<STR_LIT>" <EOL> ) <EOL> def _get_available_languages ( self ) : <EOL> language_files = [ path . stem for path in Path ( self . LANGUAGE_PATH ) . glob ( "<STR_LIT>" ) ] <EOL> return language_files <EOL> def _language_exists ( self , language ) : <EOL> return ( Path ( self . LANGUAGE_PATH ) / f"<STR_LIT>" ) . exists ( ) <EOL> def __call__ ( self , key ) : <EOL> return self . language_map . get ( key , key ) <EOL> </s>
<s> import torch <EOL> import torch . utils . data <EOL> from librosa . filters import mel as librosa_mel_fn <EOL> def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : <EOL> return torch . log ( torch . clamp ( x , min = clip_val ) * C ) <EOL> def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : <EOL> return torch . exp ( x ) / C <EOL> def spectral_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_compression_torch ( magnitudes ) <EOL> def spectral_de_normalize_torch ( magnitudes ) : <EOL> return dynamic_range_decompression_torch ( magnitudes ) <EOL> mel_basis = { } <EOL> hann_window = { } <EOL> def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : <EOL> global hann_window <EOL> dtype_device = str ( y . dtype ) + "<STR_LIT>" + str ( y . device ) <EOL> wnsize_dtype_device = str ( win_size ) + "<STR_LIT>" + dtype_device <EOL> if wnsize_dtype_device not in hann_window : <EOL> hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( <EOL> dtype = y . dtype , device = y . device <EOL> ) <EOL> y = torch . nn . functional . pad ( <EOL> y . unsqueeze ( <NUM_LIT> ) , <EOL> ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , <EOL> mode = "<STR_LIT>" , <EOL> ) <EOL> y = y . squeeze ( <NUM_LIT> ) <EOL> spec = torch . stft ( <EOL> y , <EOL> n_fft , <EOL> hop_length = hop_size , <EOL> win_length = win_size , <EOL> window = hann_window [ wnsize_dtype_device ] , <EOL> center = center , <EOL> pad_mode = "<STR_LIT>" , <EOL> normalized = False , <EOL> onesided = True , <EOL> return_complex = True , <EOL> ) <EOL> spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) <EOL> return spec <EOL> def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : <EOL> global mel_basis <EOL> dtype_device = str ( spec . dtype ) + "<STR_LIT>" + str ( spec . device ) <EOL> fmax_dtype_device = str ( fmax ) + "<STR_LIT>" + dtype_device <EOL> if fmax_dtype_device not in mel_basis : <EOL> mel = librosa_mel_fn ( <EOL> sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax <EOL> ) <EOL> mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( <EOL> dtype = spec . dtype , device = spec . device <EOL> ) <EOL> melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) <EOL> melspec = spectral_normalize_torch ( melspec ) <EOL> return melspec <EOL> def mel_spectrogram_torch ( <EOL> y , n_fft , num_mels , sampling_rate , hop_size , win_size , fmin , fmax , center = False <EOL> ) : <EOL> spec = spectrogram_torch ( y , n_fft , hop_size , win_size , center ) <EOL> melspec = spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) <EOL> return melspec <EOL> </s>
<s> import json <EOL> import os <EOL> import importlib <EOL> import gradio as gr <EOL> now_dir = os . getcwd ( ) <EOL> folder = os . path . dirname ( os . path . abspath ( __file__ ) ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . dirname ( folder ) <EOL> folder = os . path . join ( folder , "<STR_LIT>" , "<STR_LIT>" ) <EOL> config_file = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> import sys <EOL> sys . path . append ( folder ) <EOL> def get_class ( filename ) : <EOL> with open ( filename , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> for line_number , line in enumerate ( file , start = <NUM_LIT> ) : <EOL> if "<STR_LIT>" in line : <EOL> found = line . split ( "<STR_LIT>" ) [ <NUM_LIT> ] . split ( "<STR_LIT>" ) [ <NUM_LIT> ] . split ( "<STR_LIT>" ) [ <NUM_LIT> ] . strip ( ) <EOL> return found <EOL> break <EOL> return None <EOL> def get_list ( ) : <EOL> themes_from_files = [ <EOL> os . path . splitext ( name ) [ <NUM_LIT> ] <EOL> for root , _ , files in os . walk ( folder , topdown = False ) <EOL> for name in files <EOL> if name . endswith ( "<STR_LIT>" ) and root == folder <EOL> ] <EOL> json_file_path = os . path . join ( folder , "<STR_LIT>" ) <EOL> try : <EOL> with open ( json_file_path , "<STR_LIT>" , encoding = "<STR_LIT>" ) as json_file : <EOL> themes_from_url = [ item [ "<STR_LIT>" ] for item in json . load ( json_file ) ] <EOL> except FileNotFoundError : <EOL> themes_from_url = [ ] <EOL> combined_themes = set ( themes_from_files + themes_from_url ) <EOL> return list ( combined_themes ) <EOL> def select_theme ( name ) : <EOL> selected_file = name + "<STR_LIT>" <EOL> full_path = os . path . join ( folder , selected_file ) <EOL> if not os . path . exists ( full_path ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ "<STR_LIT>" ] [ "<STR_LIT>" ] = None <EOL> config_data [ "<STR_LIT>" ] [ "<STR_LIT>" ] = name <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f"<STR_LIT>" ) <EOL> gr . Info ( f"<STR_LIT>" ) <EOL> return <EOL> class_found = get_class ( full_path ) <EOL> if class_found : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as json_file : <EOL> config_data = json . load ( json_file ) <EOL> config_data [ "<STR_LIT>" ] [ "<STR_LIT>" ] = selected_file <EOL> config_data [ "<STR_LIT>" ] [ "<STR_LIT>" ] = class_found <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as json_file : <EOL> json . dump ( config_data , json_file , indent = <NUM_LIT> ) <EOL> print ( f"<STR_LIT>" ) <EOL> gr . Info ( f"<STR_LIT>" ) <EOL> else : <EOL> print ( f"<STR_LIT>" ) <EOL> def read_json ( ) : <EOL> try : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> class_name = data [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> if selected_file is not None and class_name : <EOL> return class_name <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> return "<STR_LIT>" <EOL> except Exception as e : <EOL> print ( f"<STR_LIT>" ) <EOL> return "<STR_LIT>" <EOL> def load_json ( ) : <EOL> try : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as json_file : <EOL> data = json . load ( json_file ) <EOL> selected_file = data [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> class_name = data [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> if selected_file is not None and class_name : <EOL> module = importlib . import_module ( selected_file [ : - <NUM_LIT> ] ) <EOL> obtained_class = getattr ( module , class_name ) <EOL> instance = obtained_class ( ) <EOL> print ( f"<STR_LIT>" ) <EOL> return instance <EOL> elif selected_file == None and class_name : <EOL> return class_name <EOL> else : <EOL> print ( "<STR_LIT>" ) <EOL> return None <EOL> except Exception as e : <EOL> print ( f"<STR_LIT>" ) <EOL> return None <EOL> </s>
<s> import os , sys <EOL> import gradio as gr <EOL> import shutil <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from assets . i18n . i18n import I18nAuto <EOL> from core import run_model_blender_script <EOL> i18n = I18nAuto ( ) <EOL> def update_model_fusion ( dropbox ) : <EOL> return dropbox , None <EOL> def voice_blender_tab ( ) : <EOL> gr . Markdown ( i18n ( "<STR_LIT>" ) ) <EOL> gr . Markdown ( <EOL> i18n ( <EOL> "<STR_LIT>" <EOL> ) <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_name = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> max_lines = <NUM_LIT> , <EOL> interactive = True , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> ) <EOL> with gr . Row ( ) : <EOL> with gr . Column ( ) : <EOL> model_fusion_a_dropbox = gr . File ( <EOL> label = i18n ( "<STR_LIT>" ) , type = "<STR_LIT>" <EOL> ) <EOL> model_fusion_a = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> ) <EOL> with gr . Column ( ) : <EOL> model_fusion_b_dropbox = gr . File ( <EOL> label = i18n ( "<STR_LIT>" ) , type = "<STR_LIT>" <EOL> ) <EOL> model_fusion_b = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> interactive = True , <EOL> placeholder = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> ) <EOL> alpha_a = gr . Slider ( <EOL> minimum = <NUM_LIT> , <EOL> maximum = <NUM_LIT> , <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> value = <NUM_LIT> , <EOL> interactive = True , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> ) <EOL> model_fusion_button = gr . Button ( i18n ( "<STR_LIT>" ) , variant = "<STR_LIT>" ) <EOL> with gr . Row ( ) : <EOL> model_fusion_output_info = gr . Textbox ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( "<STR_LIT>" ) , <EOL> value = "<STR_LIT>" , <EOL> ) <EOL> model_fusion_pth_output = gr . File ( <EOL> label = i18n ( "<STR_LIT>" ) , type = "<STR_LIT>" , interactive = False <EOL> ) <EOL> model_fusion_button . click ( <EOL> fn = run_model_blender_script , <EOL> inputs = [ <EOL> model_fusion_name , <EOL> model_fusion_a , <EOL> model_fusion_b , <EOL> alpha_a , <EOL> ] , <EOL> outputs = [ model_fusion_output_info , model_fusion_pth_output ] , <EOL> ) <EOL> model_fusion_a_dropbox . upload ( <EOL> fn = update_model_fusion , <EOL> inputs = model_fusion_a_dropbox , <EOL> outputs = [ model_fusion_a , model_fusion_a_dropbox ] , <EOL> ) <EOL> model_fusion_b_dropbox . upload ( <EOL> fn = update_model_fusion , <EOL> inputs = model_fusion_b_dropbox , <EOL> outputs = [ model_fusion_b , model_fusion_b_dropbox ] , <EOL> ) <EOL> </s>
<s> import torch <EOL> from torch . nn import functional as F <EOL> import numpy as np <EOL> DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> <EOL> DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> <EOL> DEFAULT_MIN_DERIVATIVE = <NUM_LIT> <EOL> def piecewise_rational_quadratic_transform ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = None , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if tails is None : <EOL> spline_fn = rational_quadratic_spline <EOL> spline_kwargs = { } <EOL> else : <EOL> spline_fn = unconstrained_rational_quadratic_spline <EOL> spline_kwargs = { "<STR_LIT>" : tails , "<STR_LIT>" : tail_bound } <EOL> outputs , logabsdet = spline_fn ( <EOL> inputs = inputs , <EOL> unnormalized_widths = unnormalized_widths , <EOL> unnormalized_heights = unnormalized_heights , <EOL> unnormalized_derivatives = unnormalized_derivatives , <EOL> inverse = inverse , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ** spline_kwargs <EOL> ) <EOL> return outputs , logabsdet <EOL> def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : <EOL> bin_locations [ ... , - <NUM_LIT> ] += eps <EOL> return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> <EOL> def unconstrained_rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> tails = "<STR_LIT>" , <EOL> tail_bound = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) <EOL> outside_interval_mask = ~ inside_interval_mask <EOL> outputs = torch . zeros_like ( inputs ) <EOL> logabsdet = torch . zeros_like ( inputs ) <EOL> if tails == "<STR_LIT>" : <EOL> unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) <EOL> unnormalized_derivatives [ ... , <NUM_LIT> ] = constant <EOL> unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant <EOL> outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] <EOL> logabsdet [ outside_interval_mask ] = <NUM_LIT> <EOL> else : <EOL> raise RuntimeError ( "<STR_LIT>" . format ( tails ) ) <EOL> ( <EOL> outputs [ inside_interval_mask ] , <EOL> logabsdet [ inside_interval_mask ] , <EOL> ) = rational_quadratic_spline ( <EOL> inputs = inputs [ inside_interval_mask ] , <EOL> unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , <EOL> unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , <EOL> unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , <EOL> inverse = inverse , <EOL> left = - tail_bound , <EOL> right = tail_bound , <EOL> bottom = - tail_bound , <EOL> top = tail_bound , <EOL> min_bin_width = min_bin_width , <EOL> min_bin_height = min_bin_height , <EOL> min_derivative = min_derivative , <EOL> ) <EOL> return outputs , logabsdet <EOL> def rational_quadratic_spline ( <EOL> inputs , <EOL> unnormalized_widths , <EOL> unnormalized_heights , <EOL> unnormalized_derivatives , <EOL> inverse = False , <EOL> left = <NUM_LIT> , <EOL> right = <NUM_LIT> , <EOL> bottom = <NUM_LIT> , <EOL> top = <NUM_LIT> , <EOL> min_bin_width = DEFAULT_MIN_BIN_WIDTH , <EOL> min_bin_height = DEFAULT_MIN_BIN_HEIGHT , <EOL> min_derivative = DEFAULT_MIN_DERIVATIVE , <EOL> ) : <EOL> if torch . min ( inputs ) < left or torch . max ( inputs ) > right : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] <EOL> if min_bin_width * num_bins > <NUM_LIT> : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> if min_bin_height * num_bins > <NUM_LIT> : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) <EOL> widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths <EOL> cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) <EOL> cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = "<STR_LIT>" , value = <NUM_LIT> ) <EOL> cumwidths = ( right - left ) * cumwidths + left <EOL> cumwidths [ ... , <NUM_LIT> ] = left <EOL> cumwidths [ ... , - <NUM_LIT> ] = right <EOL> widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] <EOL> derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) <EOL> heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) <EOL> heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights <EOL> cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) <EOL> cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = "<STR_LIT>" , value = <NUM_LIT> ) <EOL> cumheights = ( top - bottom ) * cumheights + bottom <EOL> cumheights [ ... , <NUM_LIT> ] = bottom <EOL> cumheights [ ... , - <NUM_LIT> ] = top <EOL> heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] <EOL> if inverse : <EOL> bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] <EOL> else : <EOL> bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] <EOL> input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> delta = heights / widths <EOL> input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] <EOL> if inverse : <EOL> a = ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) + input_heights * ( input_delta - input_derivatives ) <EOL> b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( <EOL> input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta <EOL> ) <EOL> c = - input_delta * ( inputs - input_cumheights ) <EOL> discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c <EOL> assert ( discriminant >= <NUM_LIT> ) . all ( ) <EOL> root = ( <NUM_LIT> * c ) / ( - b - torch . sqrt ( discriminant ) ) <EOL> outputs = root * input_bin_widths + input_cumwidths <EOL> theta_one_minus_theta = root * ( <NUM_LIT> - root ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> * theta_one_minus_theta <EOL> ) <EOL> derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( <EOL> input_derivatives_plus_one * root . pow ( <NUM_LIT> ) <EOL> + <NUM_LIT> * input_delta * theta_one_minus_theta <EOL> + input_derivatives * ( <NUM_LIT> - root ) . pow ( <NUM_LIT> ) <EOL> ) <EOL> logabsdet = torch . log ( derivative_numerator ) - <NUM_LIT> * torch . log ( denominator ) <EOL> return outputs , - logabsdet <EOL> else : <EOL> theta = ( inputs - input_cumwidths ) / input_bin_widths <EOL> theta_one_minus_theta = theta * ( <NUM_LIT> - theta ) <EOL> numerator = input_heights * ( <EOL> input_delta * theta . pow ( <NUM_LIT> ) + input_derivatives * theta_one_minus_theta <EOL> ) <EOL> denominator = input_delta + ( <EOL> ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) <EOL> * theta_one_minus_theta <EOL> ) <EOL> outputs = input_cumheights + numerator / denominator <EOL> derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( <EOL> input_derivatives_plus_one * theta . pow ( <NUM_LIT> ) <EOL> + <NUM_LIT> * input_delta * theta_one_minus_theta <EOL> + input_derivatives * ( <NUM_LIT> - theta ) . pow ( <NUM_LIT> ) <EOL> ) <EOL> logabsdet = torch . log ( derivative_numerator ) - <NUM_LIT> * torch . log ( denominator ) <EOL> return outputs , logabsdet <EOL> </s>
<s> from multiprocessing import cpu_count <EOL> import os <EOL> import sys <EOL> from scipy import signal <EOL> from scipy . io import wavfile <EOL> import librosa <EOL> import numpy as np <EOL> now_directory = os . getcwd ( ) <EOL> sys . path . append ( now_directory ) <EOL> from rvc . lib . utils import load_audio <EOL> from rvc . train . slicer import Slicer <EOL> experiment_directory = sys . argv [ <NUM_LIT> ] <EOL> input_root = sys . argv [ <NUM_LIT> ] <EOL> sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) <EOL> percentage = float ( sys . argv [ <NUM_LIT> ] ) <EOL> num_processes = cpu_count ( ) <EOL> import multiprocessing <EOL> class PreProcess : <EOL> def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : <EOL> self . slicer = Slicer ( <EOL> sr = sr , <EOL> threshold = - <NUM_LIT> , <EOL> min_length = <NUM_LIT> , <EOL> min_interval = <NUM_LIT> , <EOL> hop_size = <NUM_LIT> , <EOL> max_sil_kept = <NUM_LIT> , <EOL> ) <EOL> self . sr = sr <EOL> self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = "<STR_LIT>" , fs = self . sr ) <EOL> self . per = per <EOL> self . overlap = <NUM_LIT> <EOL> self . tail = self . per + self . overlap <EOL> self . max_amplitude = <NUM_LIT> <EOL> self . alpha = <NUM_LIT> <EOL> self . exp_dir = exp_dir <EOL> self . gt_wavs_dir = f"<STR_LIT>" <EOL> self . wavs16k_dir = f"<STR_LIT>" <EOL> os . makedirs ( self . exp_dir , exist_ok = True ) <EOL> os . makedirs ( self . gt_wavs_dir , exist_ok = True ) <EOL> os . makedirs ( self . wavs16k_dir , exist_ok = True ) <EOL> def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : <EOL> tmp_max = np . abs ( tmp_audio ) . max ( ) <EOL> if tmp_max > <NUM_LIT> : <EOL> print ( f"<STR_LIT>" ) <EOL> return <EOL> tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( <EOL> <NUM_LIT> - self . alpha <EOL> ) * tmp_audio <EOL> wavfile . write ( <EOL> f"<STR_LIT>" , <EOL> self . sr , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> tmp_audio = librosa . resample ( <EOL> tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> <EOL> ) <EOL> wavfile . write ( <EOL> f"<STR_LIT>" , <EOL> <NUM_LIT> , <EOL> tmp_audio . astype ( np . float32 ) , <EOL> ) <EOL> def process_audio ( self , path , idx0 ) : <EOL> try : <EOL> audio = load_audio ( path , self . sr ) <EOL> audio = signal . lfilter ( self . b_high , self . a_high , audio ) <EOL> idx1 = <NUM_LIT> <EOL> for audio_segment in self . slicer . slice ( audio ) : <EOL> i = <NUM_LIT> <EOL> while <NUM_LIT> : <EOL> start = int ( self . sr * ( self . per - self . overlap ) * i ) <EOL> i += <NUM_LIT> <EOL> if len ( audio_segment [ start : ] ) > self . tail * self . sr : <EOL> tmp_audio = audio_segment [ <EOL> start : start + int ( self . per * self . sr ) <EOL> ] <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> idx1 += <NUM_LIT> <EOL> else : <EOL> tmp_audio = audio_segment [ start : ] <EOL> idx1 += <NUM_LIT> <EOL> break <EOL> self . normalize_and_write ( tmp_audio , idx0 , idx1 ) <EOL> except Exception as error : <EOL> print ( f"<STR_LIT>" ) <EOL> def process_audio_multiprocessing ( self , infos ) : <EOL> for path , idx0 in infos : <EOL> self . process_audio ( path , idx0 ) <EOL> def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : <EOL> try : <EOL> infos = [ <EOL> ( f"<STR_LIT>" , idx ) <EOL> for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) <EOL> ] <EOL> processes = [ ] <EOL> for i in range ( num_processes ) : <EOL> p = multiprocessing . Process ( <EOL> target = self . process_audio_multiprocessing , <EOL> args = ( infos [ i : : num_processes ] , ) , <EOL> ) <EOL> processes . append ( p ) <EOL> p . start ( ) <EOL> for i in range ( num_processes ) : <EOL> processes [ i ] . join ( ) <EOL> except Exception as error : <EOL> print ( error ) <EOL> def preprocess_training_set ( input_root , sr , num_processes , exp_dir , per ) : <EOL> pp = PreProcess ( sr , exp_dir , per ) <EOL> print ( "<STR_LIT>" ) <EOL> pp . process_audio_multiprocessing_input_directory ( input_root , num_processes ) <EOL> print ( "<STR_LIT>" ) <EOL> if __name__ == "<STR_LIT>" : <EOL> preprocess_training_set ( <EOL> input_root , sampling_rate , num_processes , experiment_directory , percentage <EOL> ) <EOL> </s>
<s> import os , sys <EOL> import signal <EOL> from flask import Flask , request , redirect <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> from core import run_download_script <EOL> app = Flask ( __name__ ) <EOL> @ app . route ( "<STR_LIT>" , methods = [ "<STR_LIT>" ] ) <EOL> def download ( url ) : <EOL> file_path = run_download_script ( url ) <EOL> if file_path == "<STR_LIT>" : <EOL> if "<STR_LIT>" in request . headers . get ( "<STR_LIT>" , "<STR_LIT>" ) : <EOL> return redirect ( "<STR_LIT>" , code = <NUM_LIT> ) <EOL> else : <EOL> return "<STR_LIT>" <EOL> else : <EOL> return "<STR_LIT>" , <NUM_LIT> <EOL> @ app . route ( "<STR_LIT>" , methods = [ "<STR_LIT>" ] ) <EOL> def shutdown ( ) : <EOL> print ( "<STR_LIT>" ) <EOL> os . kill ( os . getpid ( ) , signal . SIGTERM ) <EOL> if __name__ == "<STR_LIT>" : <EOL> app . run ( host = "<STR_LIT>" , port = <NUM_LIT> ) <EOL> </s>
<s> import os <EOL> import glob <EOL> import json <EOL> import torch <EOL> import argparse <EOL> import numpy as np <EOL> from scipy . io . wavfile import read <EOL> def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : <EOL> assert os . path . isfile ( checkpoint_path ) <EOL> checkpoint_dict = torch . load ( checkpoint_path , map_location = "<STR_LIT>" ) <EOL> saved_state_dict = checkpoint_dict [ "<STR_LIT>" ] <EOL> if hasattr ( model , "<STR_LIT>" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> new_state_dict = { } <EOL> for k , v in state_dict . items ( ) : <EOL> try : <EOL> new_state_dict [ k ] = saved_state_dict [ k ] <EOL> if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : <EOL> print ( <EOL> "<STR_LIT>" , <EOL> k , <EOL> state_dict [ k ] . shape , <EOL> saved_state_dict [ k ] . shape , <EOL> ) <EOL> raise KeyError <EOL> except : <EOL> print ( "<STR_LIT>" , k ) <EOL> new_state_dict [ k ] = v <EOL> if hasattr ( model , "<STR_LIT>" ) : <EOL> model . module . load_state_dict ( new_state_dict , strict = False ) <EOL> else : <EOL> model . load_state_dict ( new_state_dict , strict = False ) <EOL> iteration = checkpoint_dict [ "<STR_LIT>" ] <EOL> learning_rate = checkpoint_dict [ "<STR_LIT>" ] <EOL> if optimizer is not None and load_opt == <NUM_LIT> : <EOL> optimizer . load_state_dict ( checkpoint_dict [ "<STR_LIT>" ] ) <EOL> print ( f"<STR_LIT>" ) <EOL> return model , optimizer , learning_rate , iteration <EOL> def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : <EOL> print ( f"<STR_LIT>" ) <EOL> if hasattr ( model , "<STR_LIT>" ) : <EOL> state_dict = model . module . state_dict ( ) <EOL> else : <EOL> state_dict = model . state_dict ( ) <EOL> torch . save ( <EOL> { <EOL> "<STR_LIT>" : state_dict , <EOL> "<STR_LIT>" : iteration , <EOL> "<STR_LIT>" : optimizer . state_dict ( ) , <EOL> "<STR_LIT>" : learning_rate , <EOL> } , <EOL> checkpoint_path , <EOL> ) <EOL> def summarize ( <EOL> writer , <EOL> global_step , <EOL> scalars = { } , <EOL> histograms = { } , <EOL> images = { } , <EOL> audios = { } , <EOL> audio_sampling_rate = <NUM_LIT> , <EOL> ) : <EOL> for k , v in scalars . items ( ) : <EOL> writer . add_scalar ( k , v , global_step ) <EOL> for k , v in histograms . items ( ) : <EOL> writer . add_histogram ( k , v , global_step ) <EOL> for k , v in images . items ( ) : <EOL> writer . add_image ( k , v , global_step , dataformats = "<STR_LIT>" ) <EOL> for k , v in audios . items ( ) : <EOL> writer . add_audio ( k , v , global_step , audio_sampling_rate ) <EOL> def latest_checkpoint_path ( dir_path , regex = "<STR_LIT>" ) : <EOL> f_list = glob . glob ( os . path . join ( dir_path , regex ) ) <EOL> f_list . sort ( key = lambda f : int ( "<STR_LIT>" . join ( filter ( str . isdigit , f ) ) ) ) <EOL> x = f_list [ - <NUM_LIT> ] <EOL> return x <EOL> def plot_spectrogram_to_numpy ( spectrogram ) : <EOL> import matplotlib . pylab as plt <EOL> import numpy as np <EOL> fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) <EOL> im = ax . imshow ( spectrogram , aspect = "<STR_LIT>" , origin = "<STR_LIT>" , interpolation = "<STR_LIT>" ) <EOL> plt . colorbar ( im , ax = ax ) <EOL> plt . xlabel ( "<STR_LIT>" ) <EOL> plt . ylabel ( "<STR_LIT>" ) <EOL> plt . tight_layout ( ) <EOL> fig . canvas . draw ( ) <EOL> data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = "<STR_LIT>" ) <EOL> data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) <EOL> plt . close ( ) <EOL> return data <EOL> def load_wav_to_torch ( full_path ) : <EOL> sampling_rate , data = read ( full_path ) <EOL> return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate <EOL> def load_filepaths_and_text ( filename , split = "<STR_LIT>" ) : <EOL> with open ( filename , encoding = "<STR_LIT>" ) as f : <EOL> filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] <EOL> return filepaths_and_text <EOL> def get_hparams ( ) : <EOL> parser = argparse . ArgumentParser ( ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> type = int , <EOL> required = True , <EOL> help = "<STR_LIT>" , <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , "<STR_LIT>" , type = int , required = True , help = "<STR_LIT>" <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , "<STR_LIT>" , type = str , default = "<STR_LIT>" , help = "<STR_LIT>" <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , "<STR_LIT>" , type = str , default = "<STR_LIT>" , help = "<STR_LIT>" <EOL> ) <EOL> parser . add_argument ( "<STR_LIT>" , "<STR_LIT>" , type = str , default = "<STR_LIT>" , help = "<STR_LIT>" ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , "<STR_LIT>" , type = int , required = True , help = "<STR_LIT>" <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , "<STR_LIT>" , type = str , required = True , help = "<STR_LIT>" <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , "<STR_LIT>" , type = str , required = True , help = "<STR_LIT>" <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> type = str , <EOL> default = "<STR_LIT>" , <EOL> help = "<STR_LIT>" , <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , "<STR_LIT>" , type = str , required = True , help = "<STR_LIT>" <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> type = int , <EOL> required = True , <EOL> help = "<STR_LIT>" , <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> type = int , <EOL> required = True , <EOL> help = "<STR_LIT>" , <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> type = int , <EOL> required = True , <EOL> help = "<STR_LIT>" , <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> type = int , <EOL> required = True , <EOL> help = "<STR_LIT>" , <EOL> ) <EOL> parser . add_argument ( <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> type = int , <EOL> default = <NUM_LIT> , <EOL> help = "<STR_LIT>" , <EOL> ) <EOL> args = parser . parse_args ( ) <EOL> name = args . experiment_dir <EOL> experiment_dir = os . path . join ( "<STR_LIT>" , args . experiment_dir ) <EOL> config_save_path = os . path . join ( experiment_dir , "<STR_LIT>" ) <EOL> with open ( config_save_path , "<STR_LIT>" ) as f : <EOL> config = json . load ( f ) <EOL> hparams = HParams ( ** config ) <EOL> hparams . model_dir = hparams . experiment_dir = experiment_dir <EOL> hparams . save_every_epoch = args . save_every_epoch <EOL> hparams . name = name <EOL> hparams . total_epoch = args . total_epoch <EOL> hparams . pretrainG = args . pretrainG <EOL> hparams . pretrainD = args . pretrainD <EOL> hparams . version = args . version <EOL> hparams . gpus = args . gpus <EOL> hparams . train . batch_size = args . batch_size <EOL> hparams . sample_rate = args . sample_rate <EOL> hparams . if_f0 = args . if_f0 <EOL> hparams . if_latest = args . if_latest <EOL> hparams . save_every_weights = args . save_every_weights <EOL> hparams . if_cache_data_in_gpu = args . if_cache_data_in_gpu <EOL> hparams . data . training_files = f"<STR_LIT>" <EOL> hparams . overtraining_detector = args . overtraining_detector <EOL> hparams . overtraining_threshold = args . overtraining_threshold <EOL> return hparams <EOL> class HParams : <EOL> def __init__ ( self , ** kwargs ) : <EOL> for k , v in kwargs . items ( ) : <EOL> if type ( v ) == dict : <EOL> v = HParams ( ** v ) <EOL> self [ k ] = v <EOL> def keys ( self ) : <EOL> return self . __dict__ . keys ( ) <EOL> def items ( self ) : <EOL> return self . __dict__ . items ( ) <EOL> def values ( self ) : <EOL> return self . __dict__ . values ( ) <EOL> def __len__ ( self ) : <EOL> return len ( self . __dict__ ) <EOL> def __getitem__ ( self , key ) : <EOL> return getattr ( self , key ) <EOL> def __setitem__ ( self , key , value ) : <EOL> return setattr ( self , key , value ) <EOL> def __contains__ ( self , key ) : <EOL> return key in self . __dict__ <EOL> def __repr__ ( self ) : <EOL> return self . __dict__ . __repr__ ( ) <EOL> </s>
<s> import os <EOL> import torch <EOL> def change_info ( path , info , name ) : <EOL> try : <EOL> ckpt = torch . load ( path , map_location = "<STR_LIT>" ) <EOL> ckpt [ "<STR_LIT>" ] = info <EOL> if name == "<STR_LIT>" : <EOL> name = os . path . basename ( path ) <EOL> torch . save ( ckpt , f"<STR_LIT>" ) <EOL> return "<STR_LIT>" <EOL> except Exception as error : <EOL> print ( error ) <EOL> </s>
<s> import os , sys <EOL> import json <EOL> import gradio as gr <EOL> from assets . i18n . i18n import I18nAuto <EOL> now_dir = os . getcwd ( ) <EOL> sys . path . append ( now_dir ) <EOL> i18n = I18nAuto ( ) <EOL> config_file = os . path . join ( now_dir , "<STR_LIT>" , "<STR_LIT>" ) <EOL> def get_language_settings ( ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> if config [ "<STR_LIT>" ] [ "<STR_LIT>" ] == False : <EOL> return "<STR_LIT>" <EOL> else : <EOL> return config [ "<STR_LIT>" ] [ "<STR_LIT>" ] <EOL> def save_lang_settings ( selected_language ) : <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> config = json . load ( file ) <EOL> if selected_language == "<STR_LIT>" : <EOL> config [ "<STR_LIT>" ] [ "<STR_LIT>" ] = False <EOL> else : <EOL> config [ "<STR_LIT>" ] [ "<STR_LIT>" ] = True <EOL> config [ "<STR_LIT>" ] [ "<STR_LIT>" ] = selected_language <EOL> gr . Info ( "<STR_LIT>" ) <EOL> with open ( config_file , "<STR_LIT>" , encoding = "<STR_LIT>" ) as file : <EOL> json . dump ( config , file , indent = <NUM_LIT> ) <EOL> def lang_tab ( ) : <EOL> with gr . Column ( ) : <EOL> selected_language = gr . Dropdown ( <EOL> label = i18n ( "<STR_LIT>" ) , <EOL> info = i18n ( <EOL> "<STR_LIT>" <EOL> ) , <EOL> value = get_language_settings ( ) , <EOL> choices = [ "<STR_LIT>" ] <EOL> + i18n . _get_available_languages ( ) , <EOL> interactive = True , <EOL> ) <EOL> selected_language . change ( <EOL> fn = save_lang_settings , <EOL> inputs = [ selected_language ] , <EOL> outputs = [ ] , <EOL> ) <EOL> </s>
<s> from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class DioF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . dio ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> for index , pitch in enumerate ( f0 ) : <EOL> f0 [ index ] = round ( pitch , <NUM_LIT> ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) <EOL> </s>
<s> import torch <EOL> def feature_loss ( fmap_r , fmap_g ) : <EOL> loss = <NUM_LIT> <EOL> for dr , dg in zip ( fmap_r , fmap_g ) : <EOL> for rl , gl in zip ( dr , dg ) : <EOL> rl = rl . float ( ) . detach ( ) <EOL> gl = gl . float ( ) <EOL> loss += torch . mean ( torch . abs ( rl - gl ) ) <EOL> return loss * <NUM_LIT> <EOL> def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : <EOL> loss = <NUM_LIT> <EOL> r_losses = [ ] <EOL> g_losses = [ ] <EOL> for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : <EOL> dr = dr . float ( ) <EOL> dg = dg . float ( ) <EOL> r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) <EOL> g_loss = torch . mean ( dg ** <NUM_LIT> ) <EOL> loss += r_loss + g_loss <EOL> r_losses . append ( r_loss . item ( ) ) <EOL> g_losses . append ( g_loss . item ( ) ) <EOL> return loss , r_losses , g_losses <EOL> def generator_loss ( disc_outputs ) : <EOL> loss = <NUM_LIT> <EOL> gen_losses = [ ] <EOL> for dg in disc_outputs : <EOL> dg = dg . float ( ) <EOL> l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) <EOL> gen_losses . append ( l ) <EOL> loss += l <EOL> return loss , gen_losses <EOL> def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : <EOL> z_p = z_p . float ( ) <EOL> logs_q = logs_q . float ( ) <EOL> m_p = m_p . float ( ) <EOL> logs_p = logs_p . float ( ) <EOL> z_mask = z_mask . float ( ) <EOL> kl = logs_p - logs_q - <NUM_LIT> <EOL> kl += <NUM_LIT> * ( ( z_p - m_p ) ** <NUM_LIT> ) * torch . exp ( - <NUM_LIT> * logs_p ) <EOL> kl = torch . sum ( kl * z_mask ) <EOL> l = kl / torch . sum ( z_mask ) <EOL> return l <EOL> </s>
<s> from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor <EOL> import pyworld <EOL> import numpy as np <EOL> class HarvestF0Predictor ( F0Predictor ) : <EOL> def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : <EOL> self . hop_length = hop_length <EOL> self . f0_min = f0_min <EOL> self . f0_max = f0_max <EOL> self . sampling_rate = sampling_rate <EOL> def interpolate_f0 ( self , f0 ) : <EOL> data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) <EOL> vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) <EOL> vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> <EOL> vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> <EOL> ip_data = data <EOL> frame_number = data . size <EOL> last_value = <NUM_LIT> <EOL> for i in range ( frame_number ) : <EOL> if data [ i ] <= <NUM_LIT> : <EOL> j = i + <NUM_LIT> <EOL> for j in range ( i + <NUM_LIT> , frame_number ) : <EOL> if data [ j ] > <NUM_LIT> : <EOL> break <EOL> if j < frame_number - <NUM_LIT> : <EOL> if last_value > <NUM_LIT> : <EOL> step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) <EOL> else : <EOL> for k in range ( i , j ) : <EOL> ip_data [ k ] = data [ j ] <EOL> else : <EOL> for k in range ( i , frame_number ) : <EOL> ip_data [ k ] = last_value <EOL> else : <EOL> ip_data [ i ] = data [ i ] <EOL> last_value = data [ i ] <EOL> return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] <EOL> def resize_f0 ( self , x , target_len ) : <EOL> source = np . array ( x ) <EOL> source [ source < <NUM_LIT> ] = np . nan <EOL> target = np . interp ( <EOL> np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , <EOL> np . arange ( <NUM_LIT> , len ( source ) ) , <EOL> source , <EOL> ) <EOL> res = np . nan_to_num ( target ) <EOL> return res <EOL> def compute_f0 ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_ceil = self . f0_max , <EOL> f0_floor = self . f0_min , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] <EOL> def compute_f0_uv ( self , wav , p_len = None ) : <EOL> if p_len is None : <EOL> p_len = wav . shape [ <NUM_LIT> ] // self . hop_length <EOL> f0 , t = pyworld . harvest ( <EOL> wav . astype ( np . double ) , <EOL> fs = self . sampling_rate , <EOL> f0_floor = self . f0_min , <EOL> f0_ceil = self . f0_max , <EOL> frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , <EOL> ) <EOL> f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) <EOL> return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) <EOL> </s>
<s> class F0Predictor ( object ) : <EOL> def compute_f0 ( self , wav , p_len ) : <EOL> pass <EOL> def compute_f0_uv ( self , wav , p_len ) : <EOL> pass <EOL> </s>
