<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . alter_column ( '<STR_LIT>' , <EOL> server_default = None , <EOL> nullable = True ) <EOL> def downgrade ( ) -> None : <EOL> pass <EOL> </s>
<s> ENV = '<STR_LIT>' <EOL> SECRET_KEY = b'<STR_LIT>' <EOL> TEMPLATES_AUTO_RELOAD = True <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . create_table ( '<STR_LIT>' , <EOL> sa . Column ( '<STR_LIT>' , sa . INTEGER ( ) , nullable = False ) , <EOL> sa . Column ( '<STR_LIT>' , sa . INTEGER ( ) , nullable = False ) , <EOL> sa . Column ( '<STR_LIT>' , sa . VARCHAR ( ) , nullable = False ) , <EOL> sa . ForeignKeyConstraint ( [ '<STR_LIT>' ] , [ '<STR_LIT>' ] , ) , <EOL> sa . PrimaryKeyConstraint ( '<STR_LIT>' ) , <EOL> sa . UniqueConstraint ( '<STR_LIT>' ) <EOL> ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_table ( '<STR_LIT>' ) <EOL> </s>
<s> import json <EOL> import logging <EOL> import shutil <EOL> import subprocess <EOL> import urllib <EOL> import zipfile <EOL> import favicon . favicon as favicon <EOL> from bs4 import BeautifulSoup <EOL> from feedi . requests import USER_AGENT , requests <EOL> logger = logging . getLogger ( __name__ ) <EOL> def get_favicon ( url , html = None ) : <EOL> "<STR_LIT>" <EOL> url_parts = urllib . parse . urlparse ( url ) <EOL> url = f'<STR_LIT>' <EOL> try : <EOL> if not html : <EOL> favicons = favicon . get ( url , headers = { '<STR_LIT>' : USER_AGENT } , timeout = <NUM_LIT> ) <EOL> else : <EOL> favicons = sorted ( favicon . tags ( url , html ) , <EOL> key = lambda i : i . width + i . height , reverse = True ) <EOL> except Exception : <EOL> logger . exception ( "<STR_LIT>" , url ) <EOL> return <EOL> ico_format = [ f for f in favicons if f . format == '<STR_LIT>' ] <EOL> if ico_format : <EOL> return ico_format [ <NUM_LIT> ] . url <EOL> return favicons [ <NUM_LIT> ] . url if favicons else None <EOL> class CachingRequestsMixin : <EOL> def __init__ ( self ) : <EOL> self . response_cache = { } <EOL> def request ( self , url ) : <EOL> if url in self . response_cache : <EOL> logger . debug ( "<STR_LIT>" , url ) <EOL> return self . response_cache [ url ] <EOL> logger . debug ( "<STR_LIT>" , url ) <EOL> content = requests . get ( url ) . content <EOL> self . response_cache [ url ] = content <EOL> return content <EOL> def fetch_meta ( self , url , * tags ) : <EOL> soup = BeautifulSoup ( self . request ( url ) , '<STR_LIT>' ) <EOL> return extract_meta ( soup , * tags ) <EOL> def extract_meta ( soup , * tags ) : <EOL> for tag in tags : <EOL> for attr in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : <EOL> meta_tag = soup . find ( "<STR_LIT>" , { attr : tag } , content = True ) <EOL> if meta_tag : <EOL> return meta_tag [ '<STR_LIT>' ] <EOL> def all_meta ( soup ) : <EOL> result = { } <EOL> for attr in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : <EOL> for meta_tag in soup . find_all ( "<STR_LIT>" , { attr : True } , content = True ) : <EOL> result [ meta_tag [ attr ] ] = meta_tag [ '<STR_LIT>' ] <EOL> return result <EOL> def extract_links ( url , html ) : <EOL> soup = BeautifulSoup ( html , '<STR_LIT>' ) <EOL> links = soup . find_all ( lambda tag : tag . name == '<STR_LIT>' and tag . text and '<STR_LIT>' in tag ) <EOL> return [ ( make_absolute ( url , a [ '<STR_LIT>' ] ) , a . text ) for a in links ] <EOL> def make_absolute ( url , path ) : <EOL> "<STR_LIT>" <EOL> if not urllib . parse . urlparse ( path ) . netloc : <EOL> path = urllib . parse . urljoin ( url , path ) <EOL> return path <EOL> def extract ( url = None , html = None ) : <EOL> if url : <EOL> html = requests . get ( url ) . content <EOL> elif not html : <EOL> raise ValueError ( '<STR_LIT>' ) <EOL> r = subprocess . run ( [ "<STR_LIT>" , "<STR_LIT>" , url ] , input = html , <EOL> capture_output = True , check = True ) <EOL> article = json . loads ( r . stdout ) <EOL> soup = BeautifulSoup ( article [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> LAZY_DATA_ATTRS = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> for data_attr in LAZY_DATA_ATTRS : <EOL> for img in soup . findAll ( '<STR_LIT>' , attrs = { data_attr : True } ) : <EOL> img . attrs = { '<STR_LIT>' : img [ data_attr ] } <EOL> for iframe in soup . findAll ( '<STR_LIT>' , height = True ) : <EOL> del iframe [ '<STR_LIT>' ] <EOL> article [ '<STR_LIT>' ] = str ( soup ) <EOL> return article <EOL> def compress ( outfilename , article ) : <EOL> soup = BeautifulSoup ( article [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> with zipfile . ZipFile ( outfilename , '<STR_LIT>' , compression = zipfile . ZIP_DEFLATED ) as zip : <EOL> for img in soup . findAll ( '<STR_LIT>' ) : <EOL> img_url = img [ '<STR_LIT>' ] <EOL> img_filename = '<STR_LIT>' + img [ '<STR_LIT>' ] . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] . split ( '<STR_LIT>' ) [ <NUM_LIT> ] <EOL> img [ '<STR_LIT>' ] = img_filename <EOL> with requests . get ( img_url , stream = True ) as img_src , zip . open ( img_filename , mode = '<STR_LIT>' ) as img_dest : <EOL> shutil . copyfileobj ( img_src . raw , img_dest ) <EOL> zip . writestr ( '<STR_LIT>' , str ( soup ) ) <EOL> </s>
<s> import urllib <EOL> import flask <EOL> import flask_login <EOL> from flask import current_app as app <EOL> from flask_login import current_user , login_required <EOL> import feedi . models as models <EOL> from feedi . models import db <EOL> def init ( ) : <EOL> login_manager = flask_login . LoginManager ( ) <EOL> login_manager . login_view = '<STR_LIT>' <EOL> login_manager . init_app ( app ) <EOL> @ login_manager . user_loader <EOL> def load_user ( user_id ) : <EOL> return db . session . get ( models . User , int ( user_id ) ) <EOL> @ app . get ( "<STR_LIT>" ) <EOL> def login ( ) : <EOL> default_email = app . config . get ( '<STR_LIT>' ) <EOL> if default_email : <EOL> app . logger . debug ( "<STR_LIT>" , default_email ) <EOL> user = db . session . scalar ( db . select ( models . User ) . filter_by ( email = default_email ) ) <EOL> flask_login . login_user ( user , remember = True ) <EOL> return flask . redirect ( flask . url_for ( '<STR_LIT>' ) ) <EOL> return flask . render_template ( '<STR_LIT>' ) <EOL> @ app . post ( '<STR_LIT>' ) <EOL> def login_post ( ) : <EOL> email = flask . request . form . get ( '<STR_LIT>' ) <EOL> password = flask . request . form . get ( '<STR_LIT>' ) <EOL> if not email or not password : <EOL> return flask . render_template ( '<STR_LIT>' , error_msg = "<STR_LIT>" ) <EOL> user = db . session . scalar ( db . select ( models . User ) . filter_by ( email = email ) ) <EOL> if not user or not user . check_password ( password ) : <EOL> return flask . render_template ( '<STR_LIT>' , error_msg = "<STR_LIT>" ) <EOL> flask_login . login_user ( user , remember = True ) <EOL> return flask . redirect ( flask . url_for ( '<STR_LIT>' ) ) <EOL> @ app . get ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def kindle_add ( ) : <EOL> verifier , url = models . KindleDevice . signin_url ( ) <EOL> return flask . render_template ( '<STR_LIT>' , signin_url = url , verifier = verifier ) <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def kindle_add_submit ( ) : <EOL> verifier = flask . request . form . get ( '<STR_LIT>' ) <EOL> redirect_url = flask . request . form . get ( '<STR_LIT>' ) <EOL> models . KindleDevice . add_from_url ( current_user . id , verifier , redirect_url ) <EOL> db . session . commit ( ) <EOL> return flask . redirect ( flask . url_for ( '<STR_LIT>' ) ) <EOL> @ app . get ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def mastodon_oauth ( ) : <EOL> "<STR_LIT>" <EOL> return flask . render_template ( '<STR_LIT>' ) <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def mastodon_oauth_submit ( ) : <EOL> base_url = flask . request . form . get ( '<STR_LIT>' ) <EOL> if not base_url : <EOL> return flask . render_template ( '<STR_LIT>' , error_msg = "<STR_LIT>" ) <EOL> url_parts = urllib . parse . urlparse ( base_url ) <EOL> base_url = f'<STR_LIT>' <EOL> app . logger . info ( '<STR_LIT>' , base_url ) <EOL> masto_app = models . MastodonApp . get_or_create ( base_url ) <EOL> return flask . redirect ( masto_app . auth_redirect_url ( ) ) <EOL> @ app . get ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def mastodon_oauth_callback ( ) : <EOL> code = flask . request . args . get ( '<STR_LIT>' ) <EOL> base_url = flask . request . args . get ( '<STR_LIT>' ) <EOL> if not code or not base_url : <EOL> app . logger . error ( "<STR_LIT>" ) <EOL> flask . abort ( <NUM_LIT> ) <EOL> masto_app = db . session . scalar ( db . select ( models . MastodonApp ) . filter_by ( api_base_url = base_url ) ) <EOL> if not masto_app : <EOL> app . logger . error ( "<STR_LIT>" , base_url ) <EOL> flask . abort ( <NUM_LIT> ) <EOL> app . logger . info ( "<STR_LIT>" , current_user . id , base_url ) <EOL> account = masto_app . create_account ( current_user . id , code ) <EOL> app . logger . info ( "<STR_LIT>" ) <EOL> return flask . redirect ( flask . url_for ( '<STR_LIT>' , masto_acct = account . id ) ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . INTEGER ( ) , server_default = sa . text ( "<STR_LIT>" ) , nullable = False ) ) <EOL> </s>
<s> import os <EOL> import re <EOL> import uuid <EOL> import feedgen . feed as feedgen <EOL> import feedi . app as feedi_app <EOL> import httpretty <EOL> import pytest <EOL> from feedi . models import db <EOL> @ pytest . fixture ( scope = '<STR_LIT>' ) <EOL> def app ( ) : <EOL> assert os . getenv ( '<STR_LIT>' ) == '<STR_LIT>' , "<STR_LIT>" <EOL> app = feedi_app . create_app ( ) <EOL> httpretty . enable ( allow_net_connect = False , verbose = True ) <EOL> yield app <EOL> httpretty . disable ( ) <EOL> with app . app_context ( ) : <EOL> db . drop_all ( ) <EOL> @ pytest . fixture <EOL> def client ( app ) : <EOL> "<STR_LIT>" <EOL> email = f'<STR_LIT>' <EOL> with app . app_context ( ) : <EOL> from feedi import models <EOL> user = models . User ( email = email ) <EOL> user . set_password ( '<STR_LIT>' ) <EOL> db . session . add ( user ) <EOL> db . session . commit ( ) <EOL> client = app . test_client ( ) <EOL> response = client . post ( <EOL> '<STR_LIT>' , data = { '<STR_LIT>' : email , '<STR_LIT>' : '<STR_LIT>' } , follow_redirects = True ) <EOL> assert response . status_code == <NUM_LIT> <EOL> httpretty . reset ( ) <EOL> return client <EOL> def create_feed ( client , domain , items , folder = None ) : <EOL> feed_url = mock_feed ( domain , items ) <EOL> return client . post ( '<STR_LIT>' , data = { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : domain , <EOL> '<STR_LIT>' : feed_url , <EOL> '<STR_LIT>' : folder <EOL> } , follow_redirects = True ) <EOL> def mock_feed ( domain , items ) : <EOL> base_url = f'<STR_LIT>' <EOL> feed_url = f'<STR_LIT>' <EOL> fg = feedgen . FeedGenerator ( ) <EOL> fg . id ( base_url ) <EOL> fg . link ( href = feed_url ) <EOL> fg . title ( f'<STR_LIT>' ) <EOL> fg . description ( f'<STR_LIT>' ) <EOL> for item in items : <EOL> entry_url = f'<STR_LIT>' <EOL> entry = fg . add_entry ( ) <EOL> entry . id ( ) <EOL> entry . link ( href = entry_url ) <EOL> entry . title ( item [ '<STR_LIT>' ] ) <EOL> entry . author ( { "<STR_LIT>" : item . get ( '<STR_LIT>' , '<STR_LIT>' ) } ) <EOL> entry . published ( item [ '<STR_LIT>' ] ) <EOL> entry . updated ( item [ '<STR_LIT>' ] ) <EOL> entry . description ( item . get ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> mock_request ( entry_url , body = item . get ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> rssfeed = fg . rss_str ( ) <EOL> mock_request ( base_url ) <EOL> mock_request ( f'<STR_LIT>' , ctype = '<STR_LIT>' ) <EOL> mock_request ( feed_url , body = rssfeed , ctype = '<STR_LIT>' ) <EOL> return feed_url <EOL> def mock_request ( url , body = '<STR_LIT>' , ctype = '<STR_LIT>' ) : <EOL> httpretty . register_uri ( httpretty . HEAD , url , adding_headers = { <EOL> '<STR_LIT>' : ctype } , priority = <NUM_LIT> ) <EOL> httpretty . register_uri ( httpretty . GET , url , body = body , adding_headers = { <EOL> '<STR_LIT>' : ctype } , priority = <NUM_LIT> ) <EOL> def extract_entry_ids ( response ) : <EOL> entry_ids_with_duplicates = re . findall ( r'<STR_LIT>' , response . text ) <EOL> entry_ids = [ ] <EOL> for e in entry_ids_with_duplicates : <EOL> if e not in entry_ids : <EOL> entry_ids . append ( e ) <EOL> return entry_ids <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . Boolean ( ) , nullable = True ) ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . VARCHAR ( ) , nullable = True ) ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> from werkzeug . security import generate_password_hash <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> table = op . create_table ( '<STR_LIT>' , <EOL> sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = False ) , <EOL> sa . Column ( '<STR_LIT>' , sa . String ( length = <NUM_LIT> ) , nullable = False ) , <EOL> sa . Column ( '<STR_LIT>' , sa . String ( length = <NUM_LIT> ) , nullable = False ) , <EOL> sa . PrimaryKeyConstraint ( '<STR_LIT>' ) , <EOL> sa . UniqueConstraint ( '<STR_LIT>' ) <EOL> ) <EOL> op . bulk_insert ( <EOL> table , <EOL> [ { "<STR_LIT>" : <NUM_LIT> , <EOL> "<STR_LIT>" : "<STR_LIT>" , <EOL> "<STR_LIT>" : generate_password_hash ( "<STR_LIT>" ) } ] ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_table ( '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . BOOLEAN ( ) , nullable = True ) ) <EOL> </s>
<s> from logging . config import fileConfig <EOL> from alembic import context <EOL> from feedi . models import db <EOL> from sqlalchemy import engine_from_config , pool <EOL> config = context . config <EOL> if config . config_file_name is not None : <EOL> fileConfig ( config . config_file_name ) <EOL> target_metadata = db . Model . metadata <EOL> def run_migrations_offline ( ) -> None : <EOL> url = config . get_main_option ( "<STR_LIT>" ) <EOL> context . configure ( <EOL> url = url , <EOL> target_metadata = target_metadata , <EOL> literal_binds = True , <EOL> render_as_batch = True , <EOL> dialect_opts = { "<STR_LIT>" : "<STR_LIT>" } , <EOL> ) <EOL> with context . begin_transaction ( ) : <EOL> context . run_migrations ( ) <EOL> def run_migrations_online ( ) -> None : <EOL> connectable = engine_from_config ( <EOL> config . get_section ( config . config_ini_section , { } ) , <EOL> prefix = "<STR_LIT>" , <EOL> poolclass = pool . NullPool , <EOL> ) <EOL> with connectable . connect ( ) as connection : <EOL> context . configure ( <EOL> connection = connection , <EOL> target_metadata = target_metadata , <EOL> render_as_batch = True <EOL> ) <EOL> with context . begin_transaction ( ) : <EOL> context . run_migrations ( ) <EOL> if context . is_offline_mode ( ) : <EOL> run_migrations_offline ( ) <EOL> else : <EOL> run_migrations_online ( ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_index ( '<STR_LIT>' ) <EOL> batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) <EOL> batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) <EOL> batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) <EOL> </s>
<s> import datetime <EOL> import html <EOL> import json <EOL> import logging <EOL> import pprint <EOL> import time <EOL> import traceback <EOL> import urllib <EOL> import feedparser <EOL> from bs4 import BeautifulSoup <EOL> from feedi import scraping <EOL> from feedi . requests import USER_AGENT , requests <EOL> from feedi . scraping import CachingRequestsMixin <EOL> logger = logging . getLogger ( __name__ ) <EOL> feedparser . USER_AGENT = USER_AGENT <EOL> def fetch ( feed_name , url , skip_older_than , min_amount , <EOL> previous_fetch , etag , modified , filters ) : <EOL> parser_cls = RSSParser <EOL> for cls in RSSParser . __subclasses__ ( ) : <EOL> if cls . is_compatible ( url ) : <EOL> parser_cls = cls <EOL> parser = parser_cls ( feed_name , url , skip_older_than , min_amount ) <EOL> return parser . fetch ( previous_fetch , etag , modified , filters ) <EOL> def fetch_icon ( url ) : <EOL> feed = feedparser . parse ( url ) <EOL> feed_link = feed [ '<STR_LIT>' ] . get ( '<STR_LIT>' , url ) <EOL> icon_url = scraping . get_favicon ( feed_link ) <EOL> if icon_url : <EOL> logger . debug ( "<STR_LIT>" , icon_url ) <EOL> return icon_url <EOL> icon_url = feed [ '<STR_LIT>' ] . get ( '<STR_LIT>' , feed [ '<STR_LIT>' ] . get ( '<STR_LIT>' ) ) <EOL> if icon_url and requests . get ( icon_url ) . ok : <EOL> logger . debug ( "<STR_LIT>" , icon_url ) <EOL> return icon_url <EOL> logger . debug ( "<STR_LIT>" , url ) <EOL> class RSSParser ( CachingRequestsMixin ) : <EOL> FIELDS = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , ] <EOL> @ staticmethod <EOL> def is_compatible ( _feed_url ) : <EOL> raise NotImplementedError <EOL> def __init__ ( self , feed_name , url , skip_older_than , min_amount ) : <EOL> super ( ) . __init__ ( ) <EOL> self . feed_name = feed_name <EOL> self . url = url <EOL> self . skip_older_than = skip_older_than <EOL> self . min_amount = min_amount <EOL> def fetch ( self , previous_fetch , etag , modified , filters = None ) : <EOL> feed = feedparser . parse ( self . url , etag = etag , modified = modified ) <EOL> if feed . bozo : <EOL> logger . warning ( "<STR_LIT>" , self . feed_name , feed . bozo_exception ) <EOL> if not feed [ '<STR_LIT>' ] : <EOL> logger . info ( '<STR_LIT>' , self . url , feed . get ( '<STR_LIT>' ) ) <EOL> return None , [ ] , None , None <EOL> etag = getattr ( feed , '<STR_LIT>' , None ) <EOL> modified = getattr ( feed , '<STR_LIT>' , None ) <EOL> entries = [ ] <EOL> for item in feed [ '<STR_LIT>' ] : <EOL> try : <EOL> entry = self . parse ( item , len ( entries ) , previous_fetch , filters ) <EOL> if entry : <EOL> entry [ '<STR_LIT>' ] = json . dumps ( item ) <EOL> entries . append ( entry ) <EOL> except Exception as error : <EOL> exc_desc_lines = traceback . format_exception_only ( type ( error ) , error ) <EOL> exc_desc = '<STR_LIT>' . join ( exc_desc_lines ) . rstrip ( ) <EOL> logger . error ( "<STR_LIT>" , <EOL> self . feed_name , <EOL> item . get ( '<STR_LIT>' ) , <EOL> exc_desc ) <EOL> logger . debug ( traceback . format_exc ( ) ) <EOL> return feed [ '<STR_LIT>' ] , entries , etag , modified <EOL> def parse ( self , item , parsed_count , previous_fetch , filters ) : <EOL> if self . should_skip ( item ) : <EOL> return <EOL> is_first_load = previous_fetch is None <EOL> published = item . get ( '<STR_LIT>' , item . get ( '<STR_LIT>' ) ) <EOL> if ( self . skip_older_than and published and to_datetime ( published ) < self . skip_older_than ) : <EOL> if not is_first_load or not self . min_amount or parsed_count >= self . min_amount : <EOL> logger . debug ( '<STR_LIT>' , item . get ( '<STR_LIT>' ) ) <EOL> return <EOL> if filters and not self . _matches ( item , filters ) : <EOL> logger . debug ( '<STR_LIT>' , item . get ( '<STR_LIT>' ) , filters ) <EOL> return <EOL> result = { } <EOL> for field in self . FIELDS : <EOL> method = '<STR_LIT>' + field <EOL> result [ field ] = getattr ( self , method ) ( item ) <EOL> return result <EOL> @ staticmethod <EOL> def should_skip ( _entry ) : <EOL> return False <EOL> @ staticmethod <EOL> def _matches ( entry , filters ) : <EOL> filters = filters . split ( '<STR_LIT>' ) <EOL> for filter in filters : <EOL> field , value = filter . strip ( ) . split ( '<STR_LIT>' ) <EOL> field = field . lower ( ) . strip ( ) <EOL> value = value . lower ( ) . strip ( ) <EOL> if value not in entry . get ( field , '<STR_LIT>' ) . lower ( ) : <EOL> return False <EOL> return True <EOL> def parse_title ( self , entry ) : <EOL> return entry . get ( '<STR_LIT>' ) or self . fetch_meta ( self . parse_content_url ( entry ) , '<STR_LIT>' ) <EOL> def parse_content_url ( self , entry ) : <EOL> return entry [ '<STR_LIT>' ] <EOL> def parse_target_url ( self , entry ) : <EOL> return self . parse_content_url ( entry ) <EOL> def parse_comments_url ( self , entry ) : <EOL> return entry . get ( '<STR_LIT>' ) <EOL> def parse_username ( self , entry ) : <EOL> author = entry . get ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> if author : <EOL> author = BeautifulSoup ( author , '<STR_LIT>' ) . text <EOL> author = author . split ( '<STR_LIT>' ) [ <NUM_LIT> ] <EOL> if '<STR_LIT>' in author : <EOL> author = author . split ( '<STR_LIT>' ) [ <NUM_LIT> ] . split ( '<STR_LIT>' ) [ <NUM_LIT> ] <EOL> return author <EOL> def parse_avatar_url ( self , entry ) : <EOL> url = entry . get ( '<STR_LIT>' , { } ) . get ( '<STR_LIT>' ) <EOL> if url and requests . get ( url ) . ok : <EOL> logger . debug ( '<STR_LIT>' , url ) <EOL> return url <EOL> def parse_content_short ( self , entry ) : <EOL> content_url = self . parse_content_url ( entry ) <EOL> summary = entry . get ( '<STR_LIT>' ) <EOL> if summary : <EOL> footer = summary . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] <EOL> if content_url . split ( '<STR_LIT>' ) [ <NUM_LIT> ] in footer : <EOL> summary = summary . replace ( footer , '<STR_LIT>' ) . strip ( ) <EOL> summary = html . unescape ( summary ) <EOL> else : <EOL> if not content_url : <EOL> return <EOL> summary = self . fetch_meta ( content_url , '<STR_LIT>' , '<STR_LIT>' ) <EOL> if not summary : <EOL> return <EOL> soup = BeautifulSoup ( summary , '<STR_LIT>' ) <EOL> for tag in soup ( '<STR_LIT>' ) : <EOL> tag . decompose ( ) <EOL> return str ( soup ) <EOL> def parse_content_full ( self , _entry ) : <EOL> return None <EOL> def parse_media_url ( self , entry ) : <EOL> if '<STR_LIT>' in entry : <EOL> return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] <EOL> if '<STR_LIT>' in entry and entry [ '<STR_LIT>' ] [ <NUM_LIT> ] . get ( '<STR_LIT>' ) == '<STR_LIT>' : <EOL> return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] <EOL> if '<STR_LIT>' in entry : <EOL> soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> if soup . img : <EOL> return soup . img [ '<STR_LIT>' ] <EOL> parsed_dest_url = self . parse_content_url ( entry ) <EOL> return self . fetch_meta ( parsed_dest_url , "<STR_LIT>" , "<STR_LIT>" ) <EOL> def parse_remote_id ( self , entry ) : <EOL> return entry . get ( '<STR_LIT>' , entry [ '<STR_LIT>' ] ) <EOL> def parse_display_date ( self , entry ) : <EOL> dt = to_datetime ( entry . get ( '<STR_LIT>' , entry . get ( '<STR_LIT>' ) ) ) <EOL> if dt > datetime . datetime . utcnow ( ) : <EOL> raise ValueError ( f"<STR_LIT>" ) <EOL> return dt <EOL> def parse_sort_date ( self , entry ) : <EOL> dt = to_datetime ( entry [ '<STR_LIT>' ] ) <EOL> if dt > datetime . datetime . utcnow ( ) : <EOL> raise ValueError ( "<STR_LIT>" ) <EOL> return dt <EOL> def parse_header ( self , entry ) : <EOL> return None <EOL> def discover_feed ( url ) : <EOL> res = requests . get ( url ) <EOL> if not res . ok : <EOL> logger . warn ( "<STR_LIT>" , url , res ) <EOL> return <EOL> parsed = feedparser . parse ( res . content ) <EOL> if not parsed . bozo : <EOL> title = parsed . feed . get ( '<STR_LIT>' ) <EOL> return url , title <EOL> soup = BeautifulSoup ( res . content , '<STR_LIT>' ) <EOL> title = scraping . extract_meta ( soup , '<STR_LIT>' , '<STR_LIT>' ) <EOL> if not title : <EOL> title = soup . find ( '<STR_LIT>' ) <EOL> if title : <EOL> title = title . text <EOL> link_types = [ "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" , <EOL> "<STR_LIT>" ] <EOL> feed_url = None <EOL> for type in link_types : <EOL> link = soup . find ( '<STR_LIT>' , type = type , href = True ) <EOL> if link : <EOL> feed_url = scraping . make_absolute ( url , link [ '<STR_LIT>' ] ) <EOL> return feed_url , title <EOL> common_paths = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> for path in common_paths : <EOL> rss_url = scraping . make_absolute ( url , path ) <EOL> res = requests . get ( rss_url ) <EOL> mime = res . headers . get ( '<STR_LIT>' , '<STR_LIT>' ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] <EOL> if res . ok and mime . endswith ( '<STR_LIT>' ) : <EOL> return rss_url , title <EOL> return None , title <EOL> def pretty_print ( url ) : <EOL> feed = feedparser . parse ( url ) <EOL> pp = pprint . PrettyPrinter ( depth = <NUM_LIT> ) <EOL> pp . pprint ( feed ) <EOL> def to_datetime ( struct_time ) : <EOL> try : <EOL> return datetime . datetime . fromtimestamp ( time . mktime ( struct_time ) ) <EOL> except Exception : <EOL> logger . error ( "<STR_LIT>" , struct_time ) <EOL> raise <EOL> def short_date_handler ( date_str ) : <EOL> return datetime . datetime . strptime ( date_str , '<STR_LIT>' ) . timetuple ( ) <EOL> feedparser . registerDateHandler ( short_date_handler ) <EOL> class RedditInboxParser ( RSSParser ) : <EOL> "<STR_LIT>" <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] <EOL> def parse_title ( self , entry ) : <EOL> return entry [ '<STR_LIT>' ] . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] . capitalize ( ) <EOL> class RedditParser ( RSSParser ) : <EOL> "<STR_LIT>" <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url and '<STR_LIT>' not in feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> link_anchor = soup . find ( "<STR_LIT>" , string = "<STR_LIT>" ) <EOL> comments_anchor = soup . find ( "<STR_LIT>" , string = "<STR_LIT>" ) <EOL> if link_anchor [ '<STR_LIT>' ] == comments_anchor [ '<STR_LIT>' ] : <EOL> link_anchor . decompose ( ) <EOL> comments_anchor . decompose ( ) <EOL> return str ( soup ) <EOL> return self . fetch_meta ( link_anchor [ '<STR_LIT>' ] , '<STR_LIT>' , '<STR_LIT>' ) <EOL> def parse_content_url ( self , entry ) : <EOL> soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> return soup . find ( "<STR_LIT>" , string = "<STR_LIT>" ) [ '<STR_LIT>' ] <EOL> def parse_comments_url ( self , entry ) : <EOL> return entry [ '<STR_LIT>' ] <EOL> def parse_username ( self , entry ) : <EOL> if entry . get ( '<STR_LIT>' , [ ] ) : <EOL> return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] <EOL> return super ( ) . parse_username ( entry ) <EOL> class LobstersParser ( RSSParser ) : <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> if '<STR_LIT>' in entry [ '<STR_LIT>' ] : <EOL> url = self . parse_content_url ( entry ) <EOL> return self . fetch_meta ( url , '<STR_LIT>' , '<STR_LIT>' ) <EOL> return entry [ '<STR_LIT>' ] <EOL> def parse_username ( self , entry ) : <EOL> username = super ( ) . parse_username ( entry ) <EOL> return username . split ( '<STR_LIT>' ) [ <NUM_LIT> ] <EOL> class HackerNewsParser ( RSSParser ) : <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url or '<STR_LIT>' in feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> if '<STR_LIT>' in entry [ '<STR_LIT>' ] : <EOL> url = self . parse_content_url ( entry ) <EOL> return self . fetch_meta ( url , '<STR_LIT>' , '<STR_LIT>' ) <EOL> return entry [ '<STR_LIT>' ] <EOL> class GithubFeedParser ( RSSParser ) : <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url and '<STR_LIT>' in feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> return entry [ '<STR_LIT>' ] <EOL> def parse_username ( self , entry ) : <EOL> return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] <EOL> def parse_title ( self , _entry ) : <EOL> return None <EOL> def parse_avatar_url ( self , entry ) : <EOL> return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] <EOL> def parse_media_url ( self , _entry ) : <EOL> return None <EOL> def parse_content_url ( self , _entry ) : <EOL> return None <EOL> def parse_target_url ( self , _entry ) : <EOL> return None <EOL> class GoodreadsFeedParser ( RSSParser ) : <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url and '<STR_LIT>' in feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> summary = html . unescape ( entry [ '<STR_LIT>' ] ) <EOL> soup = BeautifulSoup ( summary , '<STR_LIT>' ) <EOL> for img in soup ( '<STR_LIT>' ) : <EOL> img . decompose ( ) <EOL> for a in soup ( '<STR_LIT>' ) : <EOL> a [ '<STR_LIT>' ] = urllib . parse . urljoin ( '<STR_LIT>' , a [ '<STR_LIT>' ] ) <EOL> return str ( soup ) <EOL> def parse_title ( self , _entry ) : <EOL> return None <EOL> def parse_media_url ( self , _entry ) : <EOL> return None <EOL> def parse_target_url ( self , entry ) : <EOL> return entry [ '<STR_LIT>' ] <EOL> def parse_content_url ( self , _entry ) : <EOL> return None <EOL> class RevistaCrisisParser ( RSSParser ) : <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url <EOL> @ staticmethod <EOL> def should_skip ( entry ) : <EOL> return '<STR_LIT>' in entry [ '<STR_LIT>' ] or entry [ '<STR_LIT>' ] . lower ( ) . startswith ( '<STR_LIT>' ) <EOL> def parse_content_short ( self , entry ) : <EOL> return self . fetch_meta ( entry [ '<STR_LIT>' ] , '<STR_LIT>' , '<STR_LIT>' ) <EOL> class ACMQueueParser ( RSSParser ) : <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> content = self . request ( entry [ '<STR_LIT>' ] ) <EOL> soup = BeautifulSoup ( content , '<STR_LIT>' ) <EOL> title = soup . find ( '<STR_LIT>' ) <EOL> return str ( title . find_next ( '<STR_LIT>' ) ) <EOL> def parse_username ( self , entry ) : <EOL> content = self . request ( entry [ '<STR_LIT>' ] ) <EOL> soup = BeautifulSoup ( content , '<STR_LIT>' ) <EOL> title = soup . find ( '<STR_LIT>' ) <EOL> author = title . find_next ( '<STR_LIT>' ) <EOL> if author : <EOL> return author . text . split ( '<STR_LIT>' ) [ <NUM_LIT> ] <EOL> class WikiFeaturedParser ( RSSParser ) : <EOL> @ staticmethod <EOL> def is_compatible ( feed_url ) : <EOL> return '<STR_LIT>' in feed_url and '<STR_LIT>' in feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> return str ( soup . find ( '<STR_LIT>' ) ) <EOL> def parse_title ( self , entry ) : <EOL> soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> return soup . find ( '<STR_LIT>' ) . find ( '<STR_LIT>' ) . text <EOL> class IndieBlogParser ( RSSParser ) : <EOL> @ staticmethod <EOL> def is_compatible ( _feed_url ) : <EOL> return '<STR_LIT>' in _feed_url <EOL> def parse_content_short ( self , entry ) : <EOL> soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> body = soup . blockquote <EOL> body . name = '<STR_LIT>' <EOL> return str ( body ) <EOL> </s>
<s> import functools <EOL> import requests <EOL> USER_AGENT = '<STR_LIT>' <EOL> TIMEOUT_SECONDS = <NUM_LIT> <EOL> requests = requests . Session ( ) <EOL> requests . headers . update ( { '<STR_LIT>' : USER_AGENT } ) <EOL> requests . get = functools . partial ( requests . get , timeout = TIMEOUT_SECONDS ) <EOL> </s>
<s> import datetime <EOL> import pathlib <EOL> import tempfile <EOL> import flask <EOL> import sqlalchemy as sa <EOL> from flask import current_app as app <EOL> from flask_login import current_user , login_required <EOL> import feedi . models as models <EOL> import feedi . tasks as tasks <EOL> from feedi import scraping <EOL> from feedi . models import db <EOL> from feedi . parsers import mastodon , rss <EOL> @ app . route ( "<STR_LIT>" ) <EOL> @ app . route ( "<STR_LIT>" , defaults = { '<STR_LIT>' : True } , endpoint = '<STR_LIT>' ) <EOL> @ app . route ( "<STR_LIT>" , defaults = { '<STR_LIT>' : True } , endpoint = '<STR_LIT>' ) <EOL> @ app . route ( "<STR_LIT>" ) <EOL> @ app . route ( "<STR_LIT>" ) <EOL> @ app . route ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def entry_list ( ** filters ) : <EOL> page = flask . request . args . get ( '<STR_LIT>' ) <EOL> hide_seen = flask . session . get ( '<STR_LIT>' , True ) <EOL> ordering = flask . session . get ( '<STR_LIT>' , models . Entry . ORDER_FREQUENCY ) <EOL> filters = dict ( ** filters ) <EOL> text = flask . request . args . get ( '<STR_LIT>' , '<STR_LIT>' ) . strip ( ) <EOL> if text : <EOL> filters [ '<STR_LIT>' ] = text <EOL> is_mixed_feed_list = filters . get ( '<STR_LIT>' ) or ( <EOL> flask . request . path == '<STR_LIT>' and not filters . get ( '<STR_LIT>' ) ) <EOL> ( entries , next_page ) = fetch_entries_page ( page , current_user . id , ordering , hide_seen , is_mixed_feed_list , <EOL> ** filters ) <EOL> if page : <EOL> return flask . render_template ( '<STR_LIT>' , <EOL> entries = entries , <EOL> filters = filters , <EOL> next_page = next_page ) <EOL> return flask . render_template ( '<STR_LIT>' , <EOL> pinned = models . Entry . select_pinned ( current_user . id , ** filters ) , <EOL> entries = entries , <EOL> next_page = next_page , <EOL> is_mixed_feed_view = is_mixed_feed_list , <EOL> filters = filters ) <EOL> def fetch_entries_page ( page_arg , <EOL> user_id , <EOL> ordering_setting , <EOL> hide_seen_setting , <EOL> is_mixed_feed_list , ** filters ) : <EOL> filters [ '<STR_LIT>' ] = is_mixed_feed_list and hide_seen_setting <EOL> ordering = ordering_setting if is_mixed_feed_list else models . Entry . ORDER_RECENCY <EOL> if page_arg : <EOL> start_at , page_num = page_arg . split ( '<STR_LIT>' ) <EOL> page_num = int ( page_num ) <EOL> start_at = datetime . datetime . fromtimestamp ( float ( start_at ) ) <EOL> else : <EOL> start_at = datetime . datetime . utcnow ( ) <EOL> page_num = <NUM_LIT> <EOL> query = models . Entry . sorted_by ( user_id , ordering , start_at , ** filters ) <EOL> entry_page = db . paginate ( query , per_page = app . config [ '<STR_LIT>' ] , page = page_num ) <EOL> next_page = f'<STR_LIT>' if entry_page . has_next else None <EOL> if entry_page . has_prev : <EOL> previous_ids = [ e . id for e in entry_page . prev ( ) . items ] <EOL> update = db . update ( models . Entry ) . where ( models . Entry . id . in_ ( previous_ids ) ) . values ( viewed = datetime . datetime . utcnow ( ) ) <EOL> db . session . execute ( update ) <EOL> db . session . commit ( ) <EOL> return entry_page , next_page <EOL> @ app . get ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def autocomplete ( ) : <EOL> term = flask . request . args [ '<STR_LIT>' ] . strip ( ) <EOL> options = [ ] <EOL> if term . startswith ( '<STR_LIT>' ) or term . startswith ( '<STR_LIT>' ) : <EOL> options += [ <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , url = term ) , '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , url = term , redirect = <NUM_LIT> ) , '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , url = term ) , '<STR_LIT>' ) , <EOL> ] <EOL> if current_user . has_kindle : <EOL> options += [ ( '<STR_LIT>' , <EOL> flask . url_for ( '<STR_LIT>' , url = term ) , '<STR_LIT>' , <EOL> '<STR_LIT>' ) ] <EOL> else : <EOL> folders = db . session . scalars ( <EOL> db . select ( models . Feed . folder ) <EOL> . filter ( models . Feed . folder . icontains ( term ) , <EOL> models . Feed . user_id == current_user . id ) . distinct ( ) <EOL> ) . all ( ) <EOL> options += [ ( f , flask . url_for ( '<STR_LIT>' , folder = f ) , '<STR_LIT>' ) <EOL> for f in folders ] <EOL> feed_names = db . session . scalars ( <EOL> db . select ( models . Feed . name ) <EOL> . filter ( models . Feed . name . icontains ( term ) , <EOL> models . Feed . user_id == current_user . id <EOL> ) . distinct ( ) <EOL> ) . all ( ) <EOL> options += [ ( f , flask . url_for ( '<STR_LIT>' , feed_name = f ) , '<STR_LIT>' ) <EOL> for f in feed_names ] <EOL> options . append ( ( '<STR_LIT>' + term , flask . url_for ( '<STR_LIT>' , q = term ) , '<STR_LIT>' ) ) <EOL> options += [ ( '<STR_LIT>' + f , flask . url_for ( '<STR_LIT>' , feed_name = f ) , '<STR_LIT>' ) <EOL> for f in feed_names ] <EOL> static_options = [ <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , favorited = True ) , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , favorited = True ) , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) , <EOL> ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) <EOL> ] <EOL> for so in static_options : <EOL> if term . lower ( ) in so [ <NUM_LIT> ] . lower ( ) : <EOL> options . append ( so ) <EOL> return flask . render_template ( "<STR_LIT>" , options = options ) <EOL> @ app . put ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def entry_pin ( id ) : <EOL> entry = db . get_or_404 ( models . Entry , id ) <EOL> if entry . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> if entry . pinned : <EOL> entry . pinned = None <EOL> else : <EOL> entry . fetch_content ( ) <EOL> entry . pinned = datetime . datetime . utcnow ( ) <EOL> entry . backlogged = None <EOL> db . session . commit ( ) <EOL> filters = dict ( ** flask . request . args ) <EOL> pinned = models . Entry . select_pinned ( current_user . id , ** filters ) <EOL> return flask . render_template ( "<STR_LIT>" , <EOL> is_pinned_list = True , <EOL> filters = filters , <EOL> entries = pinned ) <EOL> @ app . put ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def entry_favorite ( id ) : <EOL> "<STR_LIT>" <EOL> entry = db . get_or_404 ( models . Entry , id ) <EOL> if entry . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> if entry . favorited : <EOL> entry . favorited = None <EOL> else : <EOL> entry . favorited = datetime . datetime . utcnow ( ) <EOL> db . session . commit ( ) <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . put ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def entry_backlog_push ( id ) : <EOL> "<STR_LIT>" <EOL> entry = db . get_or_404 ( models . Entry , id ) <EOL> if entry . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> entry . backlog ( ) <EOL> db . session . commit ( ) <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . delete ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def entry_backlog_pop ( id ) : <EOL> "<STR_LIT>" <EOL> entry = db . get_or_404 ( models . Entry , id ) <EOL> if entry . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> if entry . backlogged : <EOL> entry . unbacklog ( ) <EOL> db . session . commit ( ) <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . put ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def mastodon_favorite ( id ) : <EOL> entry = db . get_or_404 ( models . Entry , id ) <EOL> if entry . feed . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> if not entry . feed . is_mastodon : <EOL> flask . abort ( <NUM_LIT> ) <EOL> masto_acct = entry . feed . account <EOL> mastodon . favorite ( masto_acct . app . api_base_url , <EOL> masto_acct . access_token , <EOL> entry . remote_id ) <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . put ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def mastodon_boost ( id ) : <EOL> entry = db . get_or_404 ( models . Entry , id ) <EOL> if entry . feed . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> if not entry . feed . is_mastodon : <EOL> flask . abort ( <NUM_LIT> ) <EOL> masto_acct = entry . feed . account <EOL> mastodon . boost ( masto_acct . app . api_base_url , <EOL> masto_acct . access_token , <EOL> entry . remote_id ) <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . route ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def feed_list ( ) : <EOL> subquery = models . Feed . frequency_rank_query ( ) <EOL> feeds = db . session . execute ( db . select ( models . Feed , subquery . c . rank , sa . func . count ( <NUM_LIT> ) , <EOL> sa . func . max ( models . Entry . sort_date ) . label ( '<STR_LIT>' ) ) <EOL> . filter ( models . Feed . user_id == current_user . id ) <EOL> . join ( subquery , models . Feed . id == subquery . c . id , isouter = True ) <EOL> . join ( models . Entry , models . Feed . id == models . Entry . feed_id , isouter = True ) <EOL> . group_by ( models . Feed ) <EOL> . order_by ( sa . text ( '<STR_LIT>' ) , sa . text ( '<STR_LIT>' ) ) ) <EOL> return flask . render_template ( '<STR_LIT>' , feeds = feeds ) <EOL> @ app . get ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def feed_add ( ) : <EOL> url = flask . request . args . get ( '<STR_LIT>' ) <EOL> name = None <EOL> error_msg = None <EOL> if url : <EOL> result = rss . discover_feed ( url ) <EOL> if result : <EOL> ( url , name ) = result <EOL> if not result or not url : <EOL> error_msg = "<STR_LIT>" <EOL> folders = db . session . scalars ( <EOL> db . select ( models . Feed . folder ) <EOL> . filter ( models . Feed . folder . isnot ( None ) , <EOL> models . Feed . folder . isnot ( '<STR_LIT>' ) ) <EOL> . filter_by ( user_id = current_user . id ) . distinct ( ) ) <EOL> return flask . render_template ( '<STR_LIT>' , <EOL> url = url , <EOL> name = name , <EOL> folders = folders , <EOL> error_msg = error_msg ) <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def feed_add_submit ( ) : <EOL> values = { k : v . strip ( ) for k , v in flask . request . form . items ( ) if v } <EOL> if not values . get ( '<STR_LIT>' ) : <EOL> return flask . render_template ( '<STR_LIT>' , error_msg = '<STR_LIT>' , ** values ) <EOL> if not values . get ( '<STR_LIT>' ) and not values . get ( '<STR_LIT>' , '<STR_LIT>' ) . startswith ( '<STR_LIT>' ) : <EOL> return flask . render_template ( '<STR_LIT>' , error_msg = '<STR_LIT>' , ** values ) <EOL> name = values . get ( '<STR_LIT>' ) <EOL> feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( <EOL> name = name , user_id = current_user . id ) ) <EOL> if feed : <EOL> return flask . render_template ( '<STR_LIT>' , error_msg = f"<STR_LIT>" , ** values ) <EOL> feed_cls = models . Feed . resolve ( values [ '<STR_LIT>' ] ) <EOL> if not values [ '<STR_LIT>' ] . startswith ( '<STR_LIT>' ) and values . get ( '<STR_LIT>' ) : <EOL> del values [ '<STR_LIT>' ] <EOL> feed = feed_cls ( ** values ) <EOL> feed . user_id = current_user . id <EOL> db . session . add ( feed ) <EOL> db . session . flush ( ) <EOL> feed . load_icon ( ) <EOL> db . session . commit ( ) <EOL> tasks . sync_feed ( feed . id , feed . name ) . get ( ) <EOL> return flask . redirect ( flask . url_for ( '<STR_LIT>' , feed_name = feed . name ) ) <EOL> @ app . get ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def feed_edit ( feed_name ) : <EOL> feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( <EOL> name = feed_name , user_id = current_user . id ) ) <EOL> if not feed : <EOL> flask . abort ( <NUM_LIT> , "<STR_LIT>" ) <EOL> folders = db . session . scalars ( <EOL> db . select ( models . Feed . folder ) <EOL> . filter ( models . Feed . folder . isnot ( None ) , <EOL> models . Feed . folder . isnot ( '<STR_LIT>' ) ) <EOL> . filter_by ( user_id = current_user . id ) . distinct ( ) ) . all ( ) <EOL> return flask . render_template ( '<STR_LIT>' , feed = feed , folders = folders ) <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def feed_edit_submit ( feed_name ) : <EOL> feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( <EOL> name = feed_name , user_id = current_user . id ) ) <EOL> if not feed : <EOL> flask . abort ( <NUM_LIT> , "<STR_LIT>" ) <EOL> values = flask . request . form <EOL> if not values . get ( '<STR_LIT>' ) or not values . get ( '<STR_LIT>' ) : <EOL> return flask . render_template ( '<STR_LIT>' , error_msg = '<STR_LIT>' , ** values ) <EOL> for ( attr , value ) in values . items ( ) : <EOL> setattr ( feed , attr , value . strip ( ) ) <EOL> db . session . commit ( ) <EOL> return flask . redirect ( flask . url_for ( '<STR_LIT>' ) ) <EOL> @ app . delete ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def feed_delete ( feed_name ) : <EOL> "<STR_LIT>" <EOL> feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( <EOL> name = feed_name , user_id = current_user . id ) ) <EOL> if not feed : <EOL> flask . abort ( <NUM_LIT> , "<STR_LIT>" ) <EOL> update = db . update ( models . Entry ) . where ( ( models . Entry . feed_id == feed . id ) & ( <EOL> models . Entry . favorited . isnot ( None ) | <EOL> models . Entry . backlogged . isnot ( None ) | <EOL> models . Entry . pinned . isnot ( None ) ) ) . values ( feed_id = None ) <EOL> db . session . execute ( update ) <EOL> db . session . delete ( feed ) <EOL> db . session . commit ( ) <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def feed_sync ( feed_name ) : <EOL> "<STR_LIT>" <EOL> feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( <EOL> name = feed_name , user_id = current_user . id ) ) <EOL> if not feed : <EOL> flask . abort ( <NUM_LIT> , "<STR_LIT>" ) <EOL> task = tasks . sync_feed ( feed . id , feed . name , force = True ) <EOL> task . get ( ) <EOL> response = flask . make_response ( ) <EOL> response . headers [ '<STR_LIT>' ] = flask . url_for ( '<STR_LIT>' , feed_name = feed . name ) <EOL> return response <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def entry_add ( ) : <EOL> url = flask . request . args [ '<STR_LIT>' ] <EOL> redirect = flask . request . args . get ( '<STR_LIT>' ) <EOL> try : <EOL> entry = models . Entry . from_url ( current_user . id , url ) <EOL> except Exception : <EOL> if redirect : <EOL> return redirect_response ( url ) <EOL> else : <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> db . session . add ( entry ) <EOL> db . session . commit ( ) <EOL> if redirect : <EOL> return redirect_response ( flask . url_for ( '<STR_LIT>' , id = entry . id ) ) <EOL> else : <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def entry_unwrap ( id ) : <EOL> "<STR_LIT>" <EOL> entry = db . get_or_404 ( models . Entry , id ) <EOL> if entry . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> if entry . content_short : <EOL> for link in entry . embedded_links ( ) : <EOL> try : <EOL> subentry = models . Entry . from_url ( current_user . id , link ) <EOL> entry . viewed = datetime . datetime . now ( ) <EOL> db . session . add ( subentry ) <EOL> db . session . commit ( ) <EOL> return flask . render_template ( '<STR_LIT>' , <EOL> entries = [ subentry ] ) <EOL> except Exception : <EOL> continue <EOL> return "<STR_LIT>" , <NUM_LIT> <EOL> @ app . get ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def entry_view ( id ) : <EOL> entry = db . get_or_404 ( models . Entry , id ) <EOL> if entry . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> if '<STR_LIT>' in flask . request . headers and '<STR_LIT>' not in flask . request . args and not entry . content_full : <EOL> return flask . render_template ( "<STR_LIT>" , entry = entry , content = None ) <EOL> else : <EOL> if not entry . content_url and not entry . target_url : <EOL> return "<STR_LIT>" , <NUM_LIT> <EOL> if '<STR_LIT>' in entry . content_url or '<STR_LIT>' in entry . content_url : <EOL> return redirect_response ( entry . target_url ) <EOL> entry . fetch_content ( ) <EOL> if entry . content_full : <EOL> entry . viewed = entry . viewed or datetime . datetime . utcnow ( ) <EOL> db . session . commit ( ) <EOL> return flask . render_template ( "<STR_LIT>" , entry = entry , content = entry . content_full ) <EOL> return redirect_response ( entry . target_url ) <EOL> def redirect_response ( url ) : <EOL> if '<STR_LIT>' in flask . request . headers : <EOL> response = flask . make_response ( ) <EOL> response . headers [ '<STR_LIT>' ] = url <EOL> return response <EOL> else : <EOL> return flask . redirect ( url ) <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def send_to_kindle ( ) : <EOL> if not current_user . has_kindle : <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> kindle = db . session . scalar ( db . select ( models . KindleDevice ) . filter_by ( <EOL> user_id = current_user . id ) ) <EOL> url = flask . request . args [ '<STR_LIT>' ] <EOL> article = scraping . extract ( url ) <EOL> with tempfile . NamedTemporaryFile ( mode = '<STR_LIT>' , delete = False ) as fp : <EOL> scraping . compress ( fp . name , article ) <EOL> kindle . send ( pathlib . Path ( fp . name ) , <EOL> author = article [ '<STR_LIT>' ] , <EOL> title = article [ '<STR_LIT>' ] ) <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . route ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def raw_feed ( feed_name ) : <EOL> feed = db . session . scalar ( <EOL> db . select ( models . Feed ) <EOL> . filter_by ( name = feed_name , user_id = current_user . id ) <EOL> . options ( sa . orm . undefer ( models . Feed . raw_data ) ) <EOL> ) <EOL> if not feed : <EOL> flask . abort ( <NUM_LIT> , "<STR_LIT>" ) <EOL> return app . response_class ( <EOL> response = feed . raw_data , <EOL> status = <NUM_LIT> , <EOL> mimetype = '<STR_LIT>' <EOL> ) <EOL> @ app . route ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def raw_entry ( id ) : <EOL> entry = db . get_or_404 ( models . Entry , id , <EOL> options = [ sa . orm . undefer ( models . Entry . raw_data ) ] ) <EOL> if entry . user_id != current_user . id : <EOL> flask . abort ( <NUM_LIT> ) <EOL> return app . response_class ( <EOL> response = entry . raw_data , <EOL> status = <NUM_LIT> , <EOL> mimetype = '<STR_LIT>' <EOL> ) <EOL> @ app . put ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def update_setting ( setting , value ) : <EOL> flask . session [ setting ] = value <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . post ( "<STR_LIT>" ) <EOL> @ login_required <EOL> def toggle_setting ( setting ) : <EOL> flask . session [ setting ] = not flask . session . get ( setting , True ) <EOL> return '<STR_LIT>' , <NUM_LIT> <EOL> @ app . context_processor <EOL> def sidebar_feeds ( ) : <EOL> if current_user . is_authenticated : <EOL> folders = db . session . scalars ( db . select ( models . Feed . folder ) <EOL> . filter_by ( user_id = current_user . id ) <EOL> . filter ( models . Feed . folder . isnot ( None ) , <EOL> models . Feed . folder . isnot ( '<STR_LIT>' ) ) <EOL> . group_by ( models . Feed . folder ) <EOL> . order_by ( sa . func . count ( models . Feed . folder ) . desc ( ) ) ) . all ( ) <EOL> return dict ( shortcut_folders = folders , filters = { } ) <EOL> return { } <EOL> </s>
<s> import datetime as dt <EOL> import re <EOL> from tests . conftest import ( create_feed , extract_entry_ids , mock_feed , <EOL> mock_request ) <EOL> def test_feed_add ( client ) : <EOL> feed_domain = '<STR_LIT>' <EOL> response = create_feed ( client , feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) <EOL> assert response . status_code == <NUM_LIT> <EOL> assert response . request . path == f'<STR_LIT>' , '<STR_LIT>' <EOL> assert '<STR_LIT>' in response . text , '<STR_LIT>' <EOL> assert '<STR_LIT>' in response . text , '<STR_LIT>' <EOL> assert response . text . find ( <EOL> '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) , '<STR_LIT>' <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> assert '<STR_LIT>' in response . text , '<STR_LIT>' <EOL> assert '<STR_LIT>' in response . text , '<STR_LIT>' <EOL> assert response . text . find ( <EOL> '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) , '<STR_LIT>' <EOL> def test_folders ( client ) : <EOL> create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] , <EOL> folder = '<STR_LIT>' ) <EOL> create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] , <EOL> folder = '<STR_LIT>' ) <EOL> create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] , <EOL> folder = '<STR_LIT>' ) <EOL> create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert all ( [ feed in response . text for feed in [ '<STR_LIT>' , '<STR_LIT>' , <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert all ( [ feed in response . text for feed in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] ) <EOL> assert all ( [ feed not in response . text for feed in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert all ( [ feed in response . text for feed in [ '<STR_LIT>' , '<STR_LIT>' ] ] ) <EOL> assert all ( [ feed not in response . text for feed in [ <EOL> '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] ) <EOL> def test_home_sorting ( client ) : <EOL> date12h = dt . datetime . now ( dt . timezone . utc ) - dt . timedelta ( hours = <NUM_LIT> ) <EOL> create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : date12h } ] ) <EOL> items = [ ] <EOL> for i in range ( <NUM_LIT> , <NUM_LIT> ) : <EOL> items . append ( { '<STR_LIT>' : f'<STR_LIT>' , '<STR_LIT>' : date12h + dt . timedelta ( hours = <NUM_LIT> , minutes = i ) } ) <EOL> create_feed ( client , '<STR_LIT>' , items ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) <EOL> assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) <EOL> date13h = date12h - dt . timedelta ( hours = <NUM_LIT> ) <EOL> create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : date13h } ] ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) <EOL> assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) <EOL> client . put ( '<STR_LIT>' ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> def test_home_pagination ( app , client ) : <EOL> now = dt . datetime . now ( dt . timezone . utc ) <EOL> items = [ ] <EOL> per_page = app . config [ '<STR_LIT>' ] <EOL> for i in range ( <NUM_LIT> , per_page * <NUM_LIT> ) : <EOL> items . append ( { '<STR_LIT>' : f'<STR_LIT>' , '<STR_LIT>' : now - dt . timedelta ( hours = <NUM_LIT> , minutes = i ) } ) <EOL> create_feed ( client , '<STR_LIT>' , items ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert f'<STR_LIT>' in response . text <EOL> assert f'<STR_LIT>' not in response . text <EOL> assert response . text . find ( '<STR_LIT>' ) < response . text . find ( f'<STR_LIT>' ) <EOL> next_page = re . search ( r'<STR_LIT>' , response . text ) . group ( <NUM_LIT> ) <EOL> response = client . get ( f'<STR_LIT>' ) <EOL> assert f'<STR_LIT>' not in response . text <EOL> assert f'<STR_LIT>' in response . text <EOL> assert f'<STR_LIT>' in response . text <EOL> assert f'<STR_LIT>' not in response . text <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert f'<STR_LIT>' not in response . text <EOL> assert f'<STR_LIT>' in response . text <EOL> assert f'<STR_LIT>' in response . text <EOL> assert f'<STR_LIT>' not in response . text <EOL> response = client . post ( '<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert f'<STR_LIT>' in response . text <EOL> assert f'<STR_LIT>' not in response . text <EOL> def test_sync_old_entries ( client ) : <EOL> pass <EOL> def test_sync_updates ( client ) : <EOL> feed_domain = '<STR_LIT>' <EOL> response = create_feed ( client , feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> mock_feed ( feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) <EOL> response = client . post ( f'<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> def test_sync_between_pages ( client ) : <EOL> pass <EOL> def test_favorites ( client ) : <EOL> feed_domain = '<STR_LIT>' <EOL> response = create_feed ( client , feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) <EOL> entry_ids = extract_entry_ids ( response ) <EOL> response = client . put ( f'<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . put ( f'<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) <EOL> def test_backlog ( client ) : <EOL> feed_domain = '<STR_LIT>' <EOL> response = create_feed ( client , feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) <EOL> entry_ids = extract_entry_ids ( response ) <EOL> response = client . put ( f'<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . put ( f'<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> response = client . delete ( f'<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> def test_pinned ( client ) : <EOL> response = create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] , <EOL> folder = '<STR_LIT>' ) <EOL> f1a2_pin_url = re . search ( r'<STR_LIT>' , response . text ) . group ( <NUM_LIT> ) <EOL> response = create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) <EOL> f2_a2_pin_url = re . search ( r'<STR_LIT>' , response . text ) . group ( <NUM_LIT> ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> now = dt . datetime . now ( dt . timezone . utc ) <EOL> for i in range ( <NUM_LIT> , <NUM_LIT> ) : <EOL> date = now - dt . timedelta ( hours = <NUM_LIT> , minutes = <NUM_LIT> ) <EOL> create_feed ( client , f'<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : date } ] , <EOL> folder = '<STR_LIT>' ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' not in response . text <EOL> response = client . put ( f1a2_pin_url ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . put ( f2_a2_pin_url ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> def test_entries_not_mixed_between_users ( client ) : <EOL> pass <EOL> def test_view_entry_content ( client ) : <EOL> with open ( '<STR_LIT>' ) as sample : <EOL> body = sample . read ( ) <EOL> response = create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : body } ] ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> entry_url = re . search ( r'<STR_LIT>' , response . text ) . group ( <NUM_LIT> ) <EOL> response = client . get ( entry_url ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> def test_add_external_entry ( client ) : <EOL> with open ( '<STR_LIT>' ) as sample : <EOL> body = sample . read ( ) <EOL> content_url = '<STR_LIT>' <EOL> mock_request ( content_url , body = body ) <EOL> response = client . post ( <EOL> '<STR_LIT>' , query_string = { '<STR_LIT>' : content_url , '<STR_LIT>' : <NUM_LIT> } , follow_redirects = True ) <EOL> assert response . status_code == <NUM_LIT> <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> previous_entry_url = response . request . path <EOL> response = client . post ( <EOL> '<STR_LIT>' , query_string = { '<STR_LIT>' : content_url , '<STR_LIT>' : <NUM_LIT> } , follow_redirects = True ) <EOL> assert response . status_code == <NUM_LIT> <EOL> assert response . request . path == previous_entry_url <EOL> client . post ( '<STR_LIT>' ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> def test_discover_feed ( client ) : <EOL> pass <EOL> def test_feed_list ( client ) : <EOL> pass <EOL> def test_feed_edit ( client ) : <EOL> pass <EOL> def test_feed_delete ( client ) : <EOL> response = create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , <EOL> { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> entry_ids = extract_entry_ids ( response ) <EOL> response = client . put ( '<STR_LIT>' + entry_ids [ <NUM_LIT> ] ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . put ( '<STR_LIT>' + entry_ids [ <NUM_LIT> ] ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . delete ( '<STR_LIT>' ) <EOL> assert response . status_code == <NUM_LIT> <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> response = client . get ( '<STR_LIT>' ) <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> assert '<STR_LIT>' not in response . text <EOL> def test_mastodon_feed ( client ) : <EOL> pass <EOL> </s>
<s> import datetime <EOL> import json <EOL> import logging <EOL> import urllib <EOL> import sqlalchemy as sa <EOL> import sqlalchemy . dialects . sqlite as sqlite <EOL> import stkclient <EOL> import werkzeug . security as security <EOL> from flask_login import UserMixin <EOL> from flask_sqlalchemy import SQLAlchemy <EOL> from sqlalchemy . ext . hybrid import hybrid_property <EOL> import feedi . parsers as parsers <EOL> from feedi import scraping <EOL> db = SQLAlchemy ( ) <EOL> logger = logging . getLogger ( __name__ ) <EOL> def init_db ( app ) : <EOL> db . init_app ( app ) <EOL> @ sa . event . listens_for ( db . engine , '<STR_LIT>' ) <EOL> def on_connect ( dbapi_connection , _connection_record ) : <EOL> dbapi_connection . execute ( '<STR_LIT>' ) <EOL> dbapi_connection . execute ( '<STR_LIT>' ) <EOL> app . logger . debug ( "<STR_LIT>" ) <EOL> @ sa . event . listens_for ( User . __table__ , '<STR_LIT>' ) <EOL> def after_create ( user_table , connection , ** kw ) : <EOL> email = app . config . get ( '<STR_LIT>' ) <EOL> if email : <EOL> app . logger . info ( "<STR_LIT>" , email ) <EOL> stmt = sa . insert ( user_table ) . values ( <EOL> email = email , password = security . generate_password_hash ( '<STR_LIT>' ) ) <EOL> connection . execute ( stmt ) <EOL> db . create_all ( ) <EOL> class User ( UserMixin , db . Model ) : <EOL> __tablename__ = '<STR_LIT>' <EOL> id = sa . Column ( sa . Integer , primary_key = True ) <EOL> email = db . Column ( db . String ( <NUM_LIT> ) , unique = True , nullable = False ) <EOL> password = db . Column ( db . String ( <NUM_LIT> ) , nullable = False ) <EOL> mastodon_accounts = sa . orm . relationship ( "<STR_LIT>" , back_populates = '<STR_LIT>' ) <EOL> @ staticmethod <EOL> def hash_password ( raw_password ) : <EOL> return security . generate_password_hash ( raw_password ) <EOL> def set_password ( self , raw_password ) : <EOL> self . password = security . generate_password_hash ( raw_password ) <EOL> def check_password ( self , raw_password ) : <EOL> return security . check_password_hash ( self . password , raw_password ) <EOL> class MastodonApp ( db . Model ) : <EOL> __tablename__ = '<STR_LIT>' <EOL> id = sa . Column ( sa . Integer , primary_key = True ) <EOL> api_base_url = sa . Column ( sa . String , nullable = False ) <EOL> client_id = sa . Column ( sa . String , nullable = False ) <EOL> client_secret = sa . Column ( sa . String , nullable = False ) <EOL> accounts = sa . orm . relationship ( "<STR_LIT>" , back_populates = "<STR_LIT>" ) <EOL> @ classmethod <EOL> def get_or_create ( cls , api_base_url ) : <EOL> app = db . session . scalar ( db . select ( MastodonApp ) . filter_by ( api_base_url = api_base_url ) ) <EOL> if not app : <EOL> client_id , client_secret = parsers . mastodon . register_app ( <EOL> api_base_url , cls . _oauth_callback_url ( api_base_url ) ) <EOL> app = cls ( api_base_url = api_base_url , <EOL> client_id = client_id , <EOL> client_secret = client_secret ) <EOL> db . session . add ( app ) <EOL> db . session . commit ( ) <EOL> return app <EOL> def auth_redirect_url ( self ) : <EOL> return parsers . mastodon . auth_redirect_url ( self . api_base_url , <EOL> self . client_id , <EOL> self . client_secret , <EOL> self . _oauth_callback_url ( self . api_base_url ) ) <EOL> def create_account ( self , user_id , oauth_code ) : <EOL> "<STR_LIT>" <EOL> access_token = parsers . mastodon . oauth_login ( self . api_base_url , <EOL> self . client_id , <EOL> self . client_secret , <EOL> self . _oauth_callback_url ( self . api_base_url ) , <EOL> oauth_code ) <EOL> account_data = parsers . mastodon . fetch_account_data ( self . api_base_url , access_token ) <EOL> domain = self . api_base_url . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] <EOL> username = f"<STR_LIT>" <EOL> masto_acct = MastodonAccount ( app_id = self . id , <EOL> user_id = user_id , <EOL> username = username , <EOL> access_token = access_token ) <EOL> db . session . add ( masto_acct ) <EOL> db . session . commit ( ) <EOL> return masto_acct <EOL> @ staticmethod <EOL> def _oauth_callback_url ( api_base_url ) : <EOL> import flask <EOL> return flask . url_for ( '<STR_LIT>' , <EOL> server = api_base_url , <EOL> _external = True ) <EOL> class MastodonAccount ( db . Model ) : <EOL> __tablename__ = '<STR_LIT>' <EOL> id = sa . Column ( sa . Integer , primary_key = True ) <EOL> app_id = sa . orm . mapped_column ( sa . ForeignKey ( "<STR_LIT>" ) , nullable = False ) <EOL> user_id = sa . orm . mapped_column ( sa . ForeignKey ( "<STR_LIT>" ) , nullable = False ) <EOL> access_token = sa . Column ( sa . String , nullable = False ) <EOL> username = sa . Column ( sa . String ) <EOL> app = sa . orm . relationship ( "<STR_LIT>" , lazy = '<STR_LIT>' ) <EOL> user = sa . orm . relationship ( "<STR_LIT>" , back_populates = '<STR_LIT>' ) <EOL> class KindleDevice ( db . Model ) : <EOL> __tablename__ = '<STR_LIT>' <EOL> id = sa . Column ( sa . Integer , primary_key = True ) <EOL> user_id = sa . orm . mapped_column ( sa . ForeignKey ( "<STR_LIT>" ) , nullable = False , unique = True ) <EOL> credentials = sa . Column ( sa . String , nullable = False ) <EOL> @ staticmethod <EOL> def signin_url ( ) : <EOL> auth = stkclient . OAuth2 ( ) <EOL> signin_url = auth . get_signin_url ( ) <EOL> return auth . _verifier , signin_url <EOL> @ classmethod <EOL> def add_from_url ( cls , user_id , verifier , redirect_url ) : <EOL> auth = stkclient . OAuth2 ( ) <EOL> auth . _verifier = verifier <EOL> client = auth . create_client ( redirect_url ) <EOL> values = dict ( user_id = user_id , credentials = client . dumps ( ) ) <EOL> db . session . execute ( <EOL> sqlite . insert ( cls ) . <EOL> values ( ** values ) . <EOL> on_conflict_do_update ( ( "<STR_LIT>" , ) , set_ = values ) <EOL> ) <EOL> def send ( self , path , author , title ) : <EOL> client = stkclient . Client . loads ( self . credentials ) <EOL> serials = [ d . device_serial_number for d in client . get_owned_devices ( ) ] <EOL> client . send_file ( path , serials , <EOL> format = '<STR_LIT>' , <EOL> author = author , <EOL> title = title ) <EOL> User . has_kindle = sa . orm . column_property ( sa . select ( sa . func . count ( KindleDevice . id ) == <NUM_LIT> ) <EOL> . where ( KindleDevice . user_id == User . id ) <EOL> . scalar_subquery ( ) ) <EOL> class Feed ( db . Model ) : <EOL> __tablename__ = '<STR_LIT>' <EOL> TYPE_RSS = '<STR_LIT>' <EOL> TYPE_MASTODON_HOME = '<STR_LIT>' <EOL> TYPE_MASTODON_NOTIFICATIONS = '<STR_LIT>' <EOL> TYPE_CUSTOM = '<STR_LIT>' <EOL> id = sa . Column ( sa . Integer , primary_key = True ) <EOL> user_id = sa . orm . mapped_column ( sa . ForeignKey ( "<STR_LIT>" ) , nullable = False , index = True ) <EOL> url = sa . Column ( sa . String ) <EOL> type = sa . Column ( sa . String , nullable = False ) <EOL> name = sa . Column ( sa . String ) <EOL> icon_url = sa . Column ( sa . String ) <EOL> created = sa . Column ( sa . TIMESTAMP , nullable = False , default = datetime . datetime . utcnow ) <EOL> updated = sa . Column ( sa . TIMESTAMP , nullable = False , <EOL> default = datetime . datetime . utcnow , onupdate = datetime . datetime . utcnow ) <EOL> last_fetch = sa . Column ( sa . TIMESTAMP ) <EOL> entries = sa . orm . relationship ( "<STR_LIT>" , back_populates = "<STR_LIT>" , <EOL> cascade = "<STR_LIT>" , lazy = '<STR_LIT>' ) <EOL> raw_data = sa . orm . deferred ( sa . Column ( sa . String , <EOL> doc = "<STR_LIT>" ) ) <EOL> folder = sa . Column ( sa . String , index = True ) <EOL> __mapper_args__ = { '<STR_LIT>' : type , <EOL> '<STR_LIT>' : '<STR_LIT>' } <EOL> __table_args__ = ( sa . UniqueConstraint ( "<STR_LIT>" , "<STR_LIT>" ) , <EOL> sa . Index ( "<STR_LIT>" , "<STR_LIT>" , "<STR_LIT>" ) ) <EOL> def __repr__ ( self ) : <EOL> return f'<STR_LIT>' <EOL> @ classmethod <EOL> def resolve ( cls , type ) : <EOL> "<STR_LIT>" <EOL> subclasses = { <EOL> cls . TYPE_RSS : RssFeed , <EOL> cls . TYPE_MASTODON_HOME : MastodonHomeFeed , <EOL> cls . TYPE_MASTODON_NOTIFICATIONS : MastodonNotificationsFeed , <EOL> cls . TYPE_CUSTOM : CustomFeed <EOL> } <EOL> subcls = subclasses . get ( type ) <EOL> if not subcls : <EOL> raise ValueError ( f'<STR_LIT>' ) <EOL> return subcls <EOL> @ hybrid_property <EOL> def is_mastodon ( self ) : <EOL> return ( self . type == Feed . TYPE_MASTODON_HOME ) | ( self . type == Feed . TYPE_MASTODON_NOTIFICATIONS ) <EOL> @ classmethod <EOL> def from_valuelist ( cls , type , name , url , folder ) : <EOL> return cls ( ** dict ( type = type , name = name , url = url , folder = folder ) ) <EOL> def to_valuelist ( self ) : <EOL> return [ self . type , self . name , self . url , self . folder ] <EOL> def sync_with_remote ( self , force = False ) : <EOL> from flask import current_app as app <EOL> utcnow = datetime . datetime . utcnow ( ) <EOL> cooldown_minutes = datetime . timedelta ( minutes = app . config [ '<STR_LIT>' ] ) <EOL> if not force and self . last_fetch and ( utcnow - self . last_fetch < cooldown_minutes ) : <EOL> app . logger . info ( '<STR_LIT>' , self . name ) <EOL> return <EOL> entries = self . fetch_entry_data ( force ) <EOL> self . last_fetch = utcnow <EOL> for values in entries : <EOL> values [ '<STR_LIT>' ] = utcnow <EOL> values [ '<STR_LIT>' ] = self . id <EOL> values [ '<STR_LIT>' ] = self . user_id <EOL> db . session . execute ( <EOL> sqlite . insert ( Entry ) . <EOL> values ( ** values ) . <EOL> on_conflict_do_update ( ( "<STR_LIT>" , "<STR_LIT>" ) , set_ = values ) <EOL> ) <EOL> def fetch_entry_data ( self , _force = False ) : <EOL> raise NotImplementedError <EOL> def load_icon ( self ) : <EOL> "<STR_LIT>" <EOL> self . icon_url = scraping . get_favicon ( self . url ) <EOL> @ classmethod <EOL> def frequency_rank_query ( cls ) : <EOL> from flask import current_app as app <EOL> retention_days = app . config [ '<STR_LIT>' ] <EOL> retention_date = datetime . datetime . utcnow ( ) - datetime . timedelta ( days = retention_days ) <EOL> days_since_creation = <NUM_LIT> + sa . func . min ( retention_days , sa . func . round ( <EOL> sa . func . julianday ( '<STR_LIT>' ) - sa . func . julianday ( cls . created ) ) ) <EOL> rank_func = sa . case ( <EOL> ( sa . func . count ( cls . id ) / days_since_creation < <NUM_LIT> / <NUM_LIT> , <NUM_LIT> ) , <EOL> ( sa . func . count ( cls . id ) / days_since_creation < <NUM_LIT> / <NUM_LIT> , <NUM_LIT> ) , <EOL> ( sa . func . count ( cls . id ) / days_since_creation < <NUM_LIT> , <NUM_LIT> ) , <EOL> ( sa . func . count ( cls . id ) / days_since_creation < <NUM_LIT> , <NUM_LIT> ) , <EOL> ( sa . func . count ( cls . id ) / days_since_creation < <NUM_LIT> , <NUM_LIT> ) , <EOL> else_ = <NUM_LIT> <EOL> ) <EOL> return db . select ( cls . id , rank_func . label ( '<STR_LIT>' ) ) . join ( Entry ) . filter ( Entry . sort_date >= retention_date ) . group_by ( cls ) . subquery ( ) <EOL> def frequency_rank ( self ) : <EOL> subquery = self . frequency_rank_query ( ) <EOL> query = db . select ( subquery . c . rank ) . select_from ( Feed ) . join ( subquery , subquery . c . id == self . id ) <EOL> return db . session . scalar ( query ) <EOL> class RssFeed ( Feed ) : <EOL> etag = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> modified_header = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> filters = sa . Column ( sa . String , doc = "<STR_LIT>" ) <EOL> __mapper_args__ = { '<STR_LIT>' : Feed . TYPE_RSS } <EOL> @ classmethod <EOL> def from_valuelist ( cls , _type , name , url , folder , filters ) : <EOL> return cls ( ** dict ( name = name , url = url , folder = folder , filters = filters ) ) <EOL> def to_valuelist ( self ) : <EOL> return [ self . type , self . name , self . url , self . folder , self . filters ] <EOL> def fetch_entry_data ( self , force = False ) : <EOL> from flask import current_app as app <EOL> skip_older_than = datetime . datetime . utcnow ( ) - datetime . timedelta ( days = app . config [ '<STR_LIT>' ] ) <EOL> feed_data , entries , etag , modified = parsers . rss . fetch ( <EOL> self . name , self . url , <EOL> skip_older_than , <EOL> app . config [ '<STR_LIT>' ] , <EOL> None if force else self . last_fetch , <EOL> None if force else self . etag , <EOL> None if force else self . modified_header , <EOL> self . filters ) <EOL> self . etag = etag <EOL> self . modified_header = modified <EOL> if feed_data : <EOL> self . raw_data = json . dumps ( feed_data ) <EOL> return entries <EOL> def load_icon ( self ) : <EOL> self . icon_url = parsers . rss . fetch_icon ( self . url ) <EOL> class MastodonHomeFeed ( Feed ) : <EOL> mastodon_account_id = sa . orm . mapped_column ( sa . ForeignKey ( "<STR_LIT>" ) , nullable = True ) <EOL> account = sa . orm . relationship ( "<STR_LIT>" , lazy = '<STR_LIT>' ) <EOL> @ classmethod <EOL> def from_valuelist ( cls , _type , name , url , folder , access_token ) : <EOL> raise NotImplementedError <EOL> def to_valuelist ( self ) : <EOL> raise NotImplementedError <EOL> def _api_args ( self ) : <EOL> from flask import current_app as app <EOL> latest_entry = self . entries . order_by ( Entry . sort_date . desc ( ) ) . first ( ) <EOL> args = dict ( server_url = self . account . app . api_base_url , <EOL> access_token = self . account . access_token ) <EOL> if latest_entry : <EOL> args [ '<STR_LIT>' ] = latest_entry . remote_id <EOL> else : <EOL> args [ '<STR_LIT>' ] = app . config [ '<STR_LIT>' ] <EOL> return args <EOL> def fetch_entry_data ( self , _force = False ) : <EOL> return parsers . mastodon . fetch_toots ( ** self . _api_args ( ) ) <EOL> def load_icon ( self ) : <EOL> self . icon_url = parsers . mastodon . fetch_account_data ( <EOL> self . account . app . api_base_url , self . account . access_token ) [ '<STR_LIT>' ] <EOL> __mapper_args__ = { '<STR_LIT>' : Feed . TYPE_MASTODON_HOME } <EOL> class MastodonNotificationsFeed ( MastodonHomeFeed ) : <EOL> def fetch_entry_data ( self , _force = False ) : <EOL> return parsers . mastodon . fetch_notifications ( ** self . _api_args ( ) ) <EOL> __mapper_args__ = { '<STR_LIT>' : Feed . TYPE_MASTODON_NOTIFICATIONS } <EOL> class CustomFeed ( Feed ) : <EOL> __mapper_args__ = { '<STR_LIT>' : Feed . TYPE_CUSTOM } <EOL> def fetch_entry_data ( self , _force = False ) : <EOL> return parsers . custom . fetch ( self . name , self . url ) <EOL> class Entry ( db . Model ) : <EOL> "<STR_LIT>" <EOL> ORDER_RECENCY = '<STR_LIT>' <EOL> "<STR_LIT>" <EOL> ORDER_FREQUENCY = '<STR_LIT>' <EOL> __tablename__ = '<STR_LIT>' <EOL> id = sa . Column ( sa . Integer , primary_key = True ) <EOL> feed_id = sa . orm . mapped_column ( sa . ForeignKey ( "<STR_LIT>" ) ) <EOL> user_id = sa . orm . mapped_column ( sa . ForeignKey ( "<STR_LIT>" ) , nullable = False , index = True ) <EOL> feed = sa . orm . relationship ( "<STR_LIT>" , back_populates = "<STR_LIT>" ) <EOL> remote_id = sa . Column ( sa . String , nullable = False , <EOL> doc = "<STR_LIT>" ) <EOL> title = sa . Column ( sa . String ) <EOL> username = sa . Column ( sa . String , index = True ) <EOL> user_url = sa . Column ( sa . String ) <EOL> display_name = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> avatar_url = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> content_short = sa . Column ( sa . String , doc = "<STR_LIT>" ) <EOL> content_full = sa . orm . deferred ( sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) ) <EOL> target_url = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> content_url = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> comments_url = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> media_url = sa . Column ( sa . String , doc = "<STR_LIT>" ) <EOL> created = sa . Column ( sa . TIMESTAMP , nullable = False , default = datetime . datetime . utcnow ) <EOL> updated = sa . Column ( sa . TIMESTAMP , nullable = False , <EOL> default = datetime . datetime . utcnow , onupdate = datetime . datetime . utcnow ) <EOL> display_date = sa . Column ( sa . TIMESTAMP , nullable = False , <EOL> doc = "<STR_LIT>" ) <EOL> sort_date = sa . Column ( sa . TIMESTAMP , nullable = False , <EOL> doc = "<STR_LIT>" ) <EOL> viewed = sa . Column ( sa . TIMESTAMP , index = True ) <EOL> favorited = sa . Column ( sa . TIMESTAMP , index = True ) <EOL> pinned = sa . Column ( sa . TIMESTAMP , index = True ) <EOL> backlogged = sa . Column ( sa . TIMESTAMP , index = True ) <EOL> raw_data = sa . orm . deferred ( sa . Column ( sa . String , <EOL> doc = "<STR_LIT>" ) ) <EOL> header = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> icon_url = sa . Column ( <EOL> sa . String , doc = "<STR_LIT>" ) <EOL> __table_args__ = ( sa . UniqueConstraint ( "<STR_LIT>" , "<STR_LIT>" ) , <EOL> sa . Index ( "<STR_LIT>" , sort_date . desc ( ) ) ) <EOL> @ classmethod <EOL> def from_url ( cls , user_id , url ) : <EOL> "<STR_LIT>" <EOL> entry = db . session . scalar ( db . select ( cls ) <EOL> . filter_by ( content_url = url , user_id = user_id ) ) <EOL> if not entry : <EOL> values = parsers . html . fetch ( url ) <EOL> entry = cls ( user_id = user_id , ** values ) <EOL> return entry <EOL> def __repr__ ( self ) : <EOL> return f'<STR_LIT>' <EOL> @ property <EOL> def is_external_link ( self ) : <EOL> if not self . target_url : <EOL> return False <EOL> if not self . feed : <EOL> return True <EOL> if not self . feed . url : <EOL> return False <EOL> return urllib . parse . urlparse ( self . target_url ) . netloc != urllib . parse . urlparse ( self . feed . url ) <EOL> @ property <EOL> def has_distinct_user ( self ) : <EOL> return self . avatar_url and ( self . display_name or self . username ) <EOL> def fetch_content ( self ) : <EOL> if self . content_url and not self . content_full : <EOL> try : <EOL> self . content_full = scraping . extract ( self . content_url ) [ '<STR_LIT>' ] <EOL> except Exception as e : <EOL> logger . debug ( "<STR_LIT>" , e ) <EOL> def embedded_links ( self ) : <EOL> "<STR_LIT>" <EOL> if self . content_short : <EOL> return [ url for ( url , text ) in scraping . extract_links ( self . target_url , self . content_short ) <EOL> if not text . startswith ( '<STR_LIT>' ) and not text . startswith ( '<STR_LIT>' ) ] <EOL> return [ ] <EOL> def is_unwrappable ( self ) : <EOL> "<STR_LIT>" <EOL> return bool ( self . embedded_links ( ) ) <EOL> def backlog ( self ) : <EOL> "<STR_LIT>" <EOL> self . backlogged = datetime . datetime . utcnow ( ) <EOL> self . pinned = None <EOL> def unbacklog ( self ) : <EOL> "<STR_LIT>" <EOL> self . backlogged = None <EOL> self . viewed = None <EOL> self . sort_date = datetime . datetime . utcnow ( ) <EOL> self . fetch_content ( ) <EOL> @ classmethod <EOL> def _filtered_query ( cls , user_id , hide_seen = False , favorited = None , backlogged = None , <EOL> feed_name = None , username = None , folder = None , older_than = None , <EOL> text = None ) : <EOL> query = db . select ( cls ) . filter_by ( user_id = user_id ) <EOL> if older_than : <EOL> query = query . filter ( cls . created < older_than ) <EOL> if hide_seen : <EOL> query = query . filter ( cls . viewed . is_ ( None ) | <EOL> ( cls . viewed . isnot ( None ) & ( cls . viewed > older_than ) ) ) <EOL> if favorited : <EOL> query = query . filter ( cls . favorited . is_not ( None ) ) <EOL> if backlogged : <EOL> query = query . filter ( cls . backlogged . is_not ( None ) ) <EOL> elif hide_seen : <EOL> query = query . filter ( cls . backlogged . is_ ( None ) ) <EOL> if feed_name : <EOL> query = query . filter ( cls . feed . has ( name = feed_name ) ) <EOL> if folder : <EOL> query = query . filter ( cls . feed . has ( folder = folder ) ) <EOL> if username : <EOL> query = query . filter ( cls . username == username ) <EOL> if text : <EOL> query = query . filter ( cls . title . contains ( text ) | <EOL> cls . username . contains ( text ) | <EOL> cls . content_short . contains ( text ) | <EOL> cls . content_full . contains ( text ) ) <EOL> return query <EOL> @ classmethod <EOL> def select_pinned ( cls , user_id , ** kwargs ) : <EOL> "<STR_LIT>" <EOL> query = cls . _filtered_query ( user_id , ** kwargs ) . filter ( cls . pinned . is_not ( None ) ) . order_by ( cls . pinned . desc ( ) ) <EOL> return db . session . scalars ( query ) . all ( ) <EOL> @ classmethod <EOL> def sorted_by ( cls , user_id , ordering , start_at , ** filters ) : <EOL> query = cls . _filtered_query ( user_id , older_than = start_at , ** filters ) <EOL> if filters . get ( '<STR_LIT>' ) : <EOL> return query . order_by ( cls . favorited . desc ( ) ) <EOL> if filters . get ( '<STR_LIT>' ) : <EOL> return query . order_by ( cls . backlogged ) <EOL> elif ordering == cls . ORDER_RECENCY : <EOL> return query . order_by ( cls . sort_date . desc ( ) ) <EOL> elif ordering == cls . ORDER_FREQUENCY : <EOL> subquery = Feed . frequency_rank_query ( ) <EOL> recency_bucket_date = datetime . datetime . utcnow ( ) - datetime . timedelta ( hours = <NUM_LIT> ) <EOL> return query . join ( Feed , isouter = True ) . join ( subquery , Feed . id == subquery . c . id , isouter = True ) . order_by ( <EOL> ( cls . sort_date >= recency_bucket_date ) . desc ( ) , <EOL> subquery . c . rank , <EOL> cls . sort_date . desc ( ) ) <EOL> else : <EOL> raise ValueError ( '<STR_LIT>' % ordering ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) <EOL> op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) <EOL> op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = True ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) <EOL> op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) <EOL> op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = False , server_default = "<STR_LIT>" ) ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True , server_default = None ) ) <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True , server_default = None ) ) <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True , server_default = None ) ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = None <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True ) ) <EOL> op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . alter_column ( '<STR_LIT>' , <EOL> existing_type = sa . INTEGER ( ) , <EOL> nullable = False ) <EOL> batch_op . drop_index ( '<STR_LIT>' ) <EOL> batch_op . create_index ( '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' ] , unique = False ) <EOL> batch_op . create_unique_constraint ( '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_constraint ( '<STR_LIT>' , type_ = '<STR_LIT>' ) <EOL> batch_op . drop_index ( '<STR_LIT>' ) <EOL> batch_op . create_index ( '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) <EOL> batch_op . alter_column ( '<STR_LIT>' , <EOL> existing_type = sa . INTEGER ( ) , <EOL> nullable = True ) <EOL> </s>
<s> SQLALCHEMY_DATABASE_URI = "<STR_LIT>" <EOL> ENTRY_PAGE_SIZE = <NUM_LIT> <EOL> SYNC_FEEDS_CRON_MINUTES = '<STR_LIT>' <EOL> DELETE_OLD_CRON_HOURS = '<STR_LIT>' <EOL> SKIP_RECENTLY_UPDATED_MINUTES = <NUM_LIT> <EOL> CONTENT_PREFETCH_MINUTES = '<STR_LIT>' <EOL> RSS_SKIP_OLDER_THAN_DAYS = <NUM_LIT> <EOL> DELETE_AFTER_DAYS = <NUM_LIT> <EOL> RSS_MINIMUM_ENTRY_AMOUNT = <NUM_LIT> <EOL> MASTODON_FETCH_LIMIT = <NUM_LIT> <EOL> HUEY_POOL_SIZE = <NUM_LIT> <EOL> DEFAULT_AUTH_USER = '<STR_LIT>' <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = True ) ) <EOL> batch_op . create_index ( batch_op . f ( '<STR_LIT>' ) , [ '<STR_LIT>' ] , unique = False ) <EOL> batch_op . create_foreign_key ( '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] , [ '<STR_LIT>' ] ) <EOL> op . execute ( <EOL> '<STR_LIT>' ) <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . alter_column ( '<STR_LIT>' , nullable = False ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_constraint ( '<STR_LIT>' , type_ = '<STR_LIT>' ) <EOL> batch_op . drop_index ( batch_op . f ( '<STR_LIT>' ) ) <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . alter_column ( '<STR_LIT>' , '<STR_LIT>' , new_column_name = '<STR_LIT>' ) <EOL> def downgrade ( ) -> None : <EOL> op . alter_column ( '<STR_LIT>' , '<STR_LIT>' , new_column_name = '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) <EOL> op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) <EOL> op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) <EOL> op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) <EOL> op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) <EOL> </s>
<s> ENV = '<STR_LIT>' <EOL> SECRET_KEY = b'<STR_LIT>' <EOL> TESTING = True <EOL> SQLALCHEMY_DATABASE_URI = "<STR_LIT>" <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . drop_index ( '<STR_LIT>' , table_name = '<STR_LIT>' ) <EOL> with op . batch_alter_table ( "<STR_LIT>" ) as batch_op : <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> def downgrade ( ) -> None : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True ) ) <EOL> op . create_index ( '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = True , server_default = "<STR_LIT>" ) ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = False , server_default = '<STR_LIT>' ) ) <EOL> batch_op . create_index ( batch_op . f ( '<STR_LIT>' ) , [ '<STR_LIT>' ] , unique = False ) <EOL> batch_op . create_foreign_key ( '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] , [ '<STR_LIT>' ] ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_constraint ( '<STR_LIT>' , type_ = '<STR_LIT>' ) <EOL> batch_op . drop_index ( batch_op . f ( '<STR_LIT>' ) ) <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' ) as batch_op : <EOL> batch_op . alter_column ( '<STR_LIT>' , <EOL> existing_type = sa . String ( ) , <EOL> nullable = False ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' ) as batch_op : <EOL> batch_op . alter_column ( '<STR_LIT>' , <EOL> existing_type = sa . String ( ) , <EOL> nullable = True ) <EOL> </s>
<s> import csv <EOL> import datetime <EOL> from functools import wraps <EOL> import click <EOL> import flask <EOL> import opml <EOL> import sqlalchemy as sa <EOL> from huey import crontab <EOL> from huey . contrib . mini import MiniHuey <EOL> import feedi . models as models <EOL> import feedi . parsers as parsers <EOL> from feedi . app import create_huey_app <EOL> from feedi . models import db <EOL> app = create_huey_app ( ) <EOL> huey = MiniHuey ( pool_size = app . config [ '<STR_LIT>' ] ) <EOL> feed_cli = flask . cli . AppGroup ( '<STR_LIT>' ) <EOL> user_cli = flask . cli . AppGroup ( '<STR_LIT>' ) <EOL> flask . current_app . cli . add_command ( feed_cli ) <EOL> flask . current_app . cli . add_command ( user_cli ) <EOL> def huey_task ( * huey_args ) : <EOL> "<STR_LIT>" <EOL> huey_decorator = huey . task ( * huey_args ) <EOL> def with_context ( f ) : <EOL> @ wraps ( f ) <EOL> def decorator ( * args , ** kwargs ) : <EOL> with app . app_context ( ) : <EOL> fargs = '<STR_LIT>' . join ( [ str ( arg ) for arg in args ] ) <EOL> fkwargs = '<STR_LIT>' . join ( [ f'<STR_LIT>' for ( k , v ) in kwargs . items ( ) ] ) <EOL> app . logger . info ( "<STR_LIT>" , f . __name__ , fargs , fkwargs ) <EOL> try : <EOL> f ( * args , ** kwargs ) <EOL> app . logger . info ( "<STR_LIT>" , f . __name__ , fargs , fkwargs ) <EOL> except Exception : <EOL> app . logger . exception ( "<STR_LIT>" , f . __name__ , fargs , fkwargs ) <EOL> return decorator <EOL> def composed_decorator ( f ) : <EOL> return huey_decorator ( with_context ( f ) ) <EOL> return composed_decorator <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ huey_task ( crontab ( minute = app . config [ '<STR_LIT>' ] ) ) <EOL> def sync_all_feeds ( ) : <EOL> feeds = db . session . execute ( db . select ( models . Feed . id , models . Feed . name ) ) . all ( ) <EOL> tasks = [ ] <EOL> for feed in feeds : <EOL> tasks . append ( ( feed . name , sync_feed ( feed . id , feed . name ) ) ) <EOL> for name , task in tasks : <EOL> try : <EOL> task . get ( ) <EOL> except Exception : <EOL> app . logger . exception ( "<STR_LIT>" , name ) <EOL> continue <EOL> @ huey_task ( ) <EOL> def sync_feed ( feed_id , _feed_name , force = False ) : <EOL> db_feed = db . session . get ( models . Feed , feed_id ) <EOL> db_feed . sync_with_remote ( force = force ) <EOL> db . session . commit ( ) <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ huey_task ( crontab ( minute = app . config [ '<STR_LIT>' ] ) ) <EOL> def content_prefetch ( ) : <EOL> for user_id in db . session . scalars ( db . select ( models . User . id ) ) : <EOL> start_at = datetime . datetime . utcnow ( ) <EOL> query = models . Entry . sorted_by ( <EOL> user_id , models . Entry . ORDER_FREQUENCY , start_at , hide_seen = True ) . filter ( models . Entry . content_full . is_ ( None ) , models . Entry . content_url . isnot ( None ) ) . limit ( <NUM_LIT> ) <EOL> for entry in db . session . scalars ( query ) : <EOL> app . logger . debug ( '<STR_LIT>' , entry . content_url ) <EOL> entry . fetch_content ( ) <EOL> db . session . commit ( ) <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ huey_task ( crontab ( minute = '<STR_LIT>' , hour = app . config [ '<STR_LIT>' ] ) ) <EOL> def delete_old_entries ( ) : <EOL> older_than_date = ( datetime . datetime . utcnow ( ) - <EOL> datetime . timedelta ( days = app . config [ '<STR_LIT>' ] ) ) <EOL> minimum = app . config [ '<STR_LIT>' ] <EOL> feeds_q = db . select ( models . Feed . id , models . Feed . name ) . join ( models . Feed . entries ) . filter ( models . Entry . sort_date < older_than_date , <EOL> models . Entry . favorited . is_ ( None ) , <EOL> models . Entry . backlogged . is_ ( None ) , <EOL> models . Entry . pinned . is_ ( None ) <EOL> ) . group_by ( models . Feed . id ) . having ( sa . func . count ( models . Feed . entries ) > <NUM_LIT> ) <EOL> for ( feed_id , feed_name ) in db . session . execute ( feeds_q ) . all ( ) : <EOL> min_sort_date = db . session . scalar ( <EOL> db . select ( models . Entry . sort_date ) <EOL> . filter_by ( feed_id = feed_id ) <EOL> . order_by ( models . Entry . sort_date . desc ( ) ) <EOL> . limit ( <NUM_LIT> ) <EOL> . offset ( minimum - <NUM_LIT> ) ) <EOL> if not min_sort_date : <EOL> continue <EOL> q = db . delete ( models . Entry ) . where ( <EOL> models . Entry . favorited . is_ ( None ) , <EOL> models . Entry . backlogged . is_ ( None ) , <EOL> models . Entry . pinned . is_ ( None ) , <EOL> models . Entry . feed_id == feed_id , <EOL> models . Entry . sort_date < min_sort_date , <EOL> models . Entry . sort_date < older_than_date ) <EOL> res = db . session . execute ( q ) <EOL> db . session . commit ( ) <EOL> if res . rowcount : <EOL> app . logger . info ( "<STR_LIT>" , res . rowcount , feed_id , feed_name ) <EOL> q = db . delete ( models . Entry ) . where ( <EOL> models . Entry . feed_id . is_ ( None ) , <EOL> models . Entry . favorited . is_ ( None ) , <EOL> models . Entry . pinned . is_ ( None ) , <EOL> models . Entry . sort_date < older_than_date ) <EOL> res = db . session . execute ( q ) <EOL> db . session . commit ( ) <EOL> if res . rowcount : <EOL> app . logger . info ( "<STR_LIT>" , res . rowcount ) <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ huey_task ( crontab ( minute = '<STR_LIT>' , hour = '<STR_LIT>' ) ) <EOL> def pop_backlog ( ) : <EOL> "<STR_LIT>" <EOL> week_ago = datetime . datetime . utcnow ( ) - datetime . timedelta ( days = <NUM_LIT> ) <EOL> backlogged_date = sa . func . min ( models . Entry . backlogged ) . label ( '<STR_LIT>' ) <EOL> query = db . select ( models . Entry ) . group_by ( models . Entry . user_id ) . having ( backlogged_date < week_ago ) <EOL> for entry in db . session . scalars ( query ) : <EOL> entry . unbacklog ( ) <EOL> app . logger . info ( "<STR_LIT>" , entry . user_id , entry . target_url ) <EOL> db . session . commit ( ) <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ click . argument ( '<STR_LIT>' ) <EOL> def debug_feed ( url ) : <EOL> parsers . rss . pretty_print ( url ) <EOL> def load_user_arg ( _ctx , _param , email ) : <EOL> if not email : <EOL> email = app . config . get ( '<STR_LIT>' ) <EOL> if not email : <EOL> raise click . UsageError ( '<STR_LIT>' ) <EOL> user = db . session . scalar ( db . select ( models . User ) . filter_by ( email = email ) ) <EOL> if not user : <EOL> raise click . UsageError ( f'<STR_LIT>' ) <EOL> return user <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ click . argument ( "<STR_LIT>" ) <EOL> @ click . argument ( '<STR_LIT>' , required = False , callback = load_user_arg ) <EOL> def csv_load ( file , user ) : <EOL> "<STR_LIT>" <EOL> with open ( file ) as csv_file : <EOL> for values in csv . reader ( csv_file ) : <EOL> cls = models . Feed . resolve ( values [ <NUM_LIT> ] ) <EOL> feed = cls . from_valuelist ( * values ) <EOL> feed . user_id = user . id <EOL> add_if_not_exists ( feed ) <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ click . argument ( "<STR_LIT>" ) <EOL> @ click . argument ( '<STR_LIT>' , required = False , callback = load_user_arg ) <EOL> def csv_dump ( file , user ) : <EOL> "<STR_LIT>" <EOL> with open ( file , '<STR_LIT>' ) as csv_file : <EOL> feed_writer = csv . writer ( csv_file ) <EOL> for feed in db . session . execute ( db . select ( models . Feed ) <EOL> . filter_by ( user_id = user . id , is_mastodon = False ) ) . scalars ( ) : <EOL> feed_writer . writerow ( feed . to_valuelist ( ) ) <EOL> app . logger . info ( '<STR_LIT>' , feed ) <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ click . argument ( "<STR_LIT>" ) <EOL> @ click . argument ( '<STR_LIT>' , required = False , callback = load_user_arg ) <EOL> def opml_load ( file , user ) : <EOL> document = opml . OpmlDocument . load ( file ) <EOL> for outline in document . outlines : <EOL> if outline . outlines : <EOL> folder = outline . text <EOL> for feed in outline . outlines : <EOL> add_if_not_exists ( models . RssFeed ( name = feed . title or feed . text , <EOL> user_id = user . id , <EOL> url = feed . xml_url , <EOL> folder = folder ) ) <EOL> else : <EOL> add_if_not_exists ( models . RssFeed ( name = feed . title or feed . text , <EOL> user_id = user . id , <EOL> url = feed . xml_url ) ) <EOL> @ feed_cli . command ( '<STR_LIT>' ) <EOL> @ click . argument ( "<STR_LIT>" ) <EOL> @ click . argument ( '<STR_LIT>' , required = False , callback = load_user_arg ) <EOL> def opml_dump ( file , user ) : <EOL> document = opml . OpmlDocument ( ) <EOL> folder_outlines = { } <EOL> for feed in db . session . execute ( db . select ( models . RssFeed ) <EOL> . filter_by ( user_id = user . id ) <EOL> ) . scalars ( ) : <EOL> if feed . folder : <EOL> if feed . folder in folder_outlines : <EOL> folder_outlines [ feed . folder ] = document . add_outline ( feed . folder ) <EOL> target = folder_outlines [ feed . folder ] <EOL> else : <EOL> target = document <EOL> target . add_rss ( feed . name , <EOL> feed . url , <EOL> title = feed . name , <EOL> categories = [ feed . folder ] if feed . folder else [ ] , <EOL> created = datetime . datetime . now ( ) ) <EOL> document . dump ( file ) <EOL> def add_if_not_exists ( feed ) : <EOL> query = db . select ( db . exists ( models . Feed ) <EOL> . where ( models . Feed . name == feed . name , models . Feed . user_id == feed . user_id ) ) <EOL> if db . session . execute ( query ) . scalar ( ) : <EOL> app . logger . info ( '<STR_LIT>' , feed . name ) <EOL> return <EOL> db . session . add ( feed ) <EOL> db . session . commit ( ) <EOL> feed . load_icon ( ) <EOL> db . session . commit ( ) <EOL> app . logger . info ( '<STR_LIT>' , feed ) <EOL> @ user_cli . command ( '<STR_LIT>' ) <EOL> @ click . argument ( '<STR_LIT>' ) <EOL> @ click . password_option ( ) <EOL> def user_add ( email , password ) : <EOL> user = models . User ( email = email ) <EOL> user . set_password ( password ) <EOL> db . session . add ( user ) <EOL> db . session . commit ( ) <EOL> @ user_cli . command ( '<STR_LIT>' ) <EOL> @ click . argument ( '<STR_LIT>' ) <EOL> def user_delete ( email ) : <EOL> stmt = db . delete ( models . User ) . where ( models . User . email == email ) <EOL> db . session . execute ( stmt ) <EOL> db . session . commit ( ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> pass <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> pass <EOL> </s>
<s> from typing import Sequence , Union <EOL> import sqlalchemy as sa <EOL> from alembic import op <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = True ) ) <EOL> batch_op . create_foreign_key ( '<STR_LIT>' , '<STR_LIT>' , [ <EOL> '<STR_LIT>' ] , [ '<STR_LIT>' ] ) <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . VARCHAR ( ) , nullable = True ) ) <EOL> batch_op . drop_constraint ( '<STR_LIT>' , type_ = '<STR_LIT>' ) <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) <EOL> def downgrade ( ) -> None : <EOL> op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> </s>
<s> import datetime <EOL> import json <EOL> import dateparser <EOL> from bs4 import BeautifulSoup <EOL> from feedi import scraping <EOL> from feedi . requests import requests <EOL> def fetch ( url ) : <EOL> response = requests . get ( url ) <EOL> response . raise_for_status ( ) <EOL> if not response . ok : <EOL> raise Exception ( ) <EOL> soup = BeautifulSoup ( response . content , '<STR_LIT>' ) <EOL> metadata = scraping . all_meta ( soup ) <EOL> title = metadata . get ( '<STR_LIT>' , metadata . get ( '<STR_LIT>' , getattr ( soup . title , '<STR_LIT>' ) ) ) <EOL> if not title : <EOL> raise ValueError ( f"<STR_LIT>" ) <EOL> if '<STR_LIT>' in metadata : <EOL> display_date = dateparser . parse ( metadata [ '<STR_LIT>' ] ) <EOL> else : <EOL> display_date = datetime . datetime . utcnow ( ) <EOL> username = metadata . get ( '<STR_LIT>' , '<STR_LIT>' ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] <EOL> icon_url = scraping . get_favicon ( url , html = response . content ) <EOL> entry = { <EOL> '<STR_LIT>' : url , <EOL> '<STR_LIT>' : title , <EOL> '<STR_LIT>' : username , <EOL> '<STR_LIT>' : display_date , <EOL> '<STR_LIT>' : datetime . datetime . utcnow ( ) , <EOL> '<STR_LIT>' : metadata . get ( '<STR_LIT>' , metadata . get ( '<STR_LIT>' ) ) , <EOL> '<STR_LIT>' : metadata . get ( '<STR_LIT>' , metadata . get ( '<STR_LIT>' ) ) , <EOL> '<STR_LIT>' : url , <EOL> '<STR_LIT>' : url , <EOL> '<STR_LIT>' : json . dumps ( metadata ) , <EOL> '<STR_LIT>' : icon_url } <EOL> return entry <EOL> </s>
<s> from typing import Sequence , Union <EOL> from alembic import op <EOL> import sqlalchemy as sa <EOL> revision : str = '<STR_LIT>' <EOL> down_revision : Union [ str , None ] = '<STR_LIT>' <EOL> branch_labels : Union [ str , Sequence [ str ] , None ] = None <EOL> depends_on : Union [ str , Sequence [ str ] , None ] = None <EOL> def upgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True ) ) <EOL> batch_op . create_index ( batch_op . f ( '<STR_LIT>' ) , [ '<STR_LIT>' ] , unique = False ) <EOL> def downgrade ( ) -> None : <EOL> with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : <EOL> batch_op . drop_index ( batch_op . f ( '<STR_LIT>' ) ) <EOL> batch_op . drop_column ( '<STR_LIT>' ) <EOL> </s>
