[{"input": "import sys \n import asyncio \n import edge_tts \n async def main ( ) : \n text = sys . argv [ <NUM_LIT> ] \n voice = sys . argv [ <NUM_LIT> ] \n output_file = sys . argv [ <NUM_LIT> ] \n await edge_tts . Communicate ( text , voice ) . save ( output_file )", "output": "print ( f\"<STR_LIT>\" ) \n if __name__ == \"<STR_LIT>\" : \n asyncio . run ( main ( ) )"}, {"input": "import gradio as gr \n from core import run_model_information_script \n from assets . i18n . i18n import I18nAuto \n i18n = I18nAuto ( ) \n def model_information_tab ( ) : \n with gr . Column ( ) : \n model_name = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n interactive = True , \n ) \n model_information_output_info = gr . Textbox (", "output": "label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n max_lines = <NUM_LIT> , \n interactive = False , \n ) \n model_information_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n model_information_button . click ( \n run_model_information_script , \n [ model_name ] , \n model_information_output_info , \n api_name = \"<STR_LIT>\" , \n )"}, {"input": "import os , sys \n import gradio as gr \n import shutil \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n from assets . i18n . i18n import I18nAuto \n from core import run_model_blender_script \n i18n = I18nAuto ( ) \n def update_model_fusion ( dropbox ) : \n return dropbox , None \n def voice_blender_tab ( ) : \n gr . Markdown ( i18n ( \"<STR_LIT>\" ) ) \n gr . Markdown ( \n i18n ( \n \"<STR_LIT>\" \n ) \n ) \n with gr . Column ( ) : \n model_fusion_name = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n max_lines = <NUM_LIT> , \n interactive = True , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n ) \n with gr . Row ( ) : \n with gr . Column ( ) : \n model_fusion_a_dropbox = gr . File ( \n label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" \n ) \n model_fusion_a = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n interactive = True , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) ,", "output": ") \n with gr . Column ( ) : \n model_fusion_b_dropbox = gr . File ( \n label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" \n ) \n model_fusion_b = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n interactive = True , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n ) \n alpha_a = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n value = <NUM_LIT> , \n interactive = True , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n ) \n model_fusion_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) \n with gr . Row ( ) : \n model_fusion_output_info = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n ) \n model_fusion_pth_output = gr . File ( \n label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , interactive = False \n ) \n model_fusion_button . click ( \n fn = run_model_blender_script , \n inputs = [ \n model_fusion_name , \n model_fusion_a , \n model_fusion_b , \n alpha_a , \n ] , \n outputs = [ model_fusion_output_info , model_fusion_pth_output ] , \n ) \n model_fusion_a_dropbox . upload ( \n fn = update_model_fusion , \n inputs = model_fusion_a_dropbox , \n outputs = [ model_fusion_a , model_fusion_a_dropbox ] , \n ) \n model_fusion_b_dropbox . upload ( \n fn = update_model_fusion , \n inputs = model_fusion_b_dropbox , \n outputs = [ model_fusion_b , model_fusion_b_dropbox ] , \n )"}, {"input": "import os , sys \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n from core import run_model_information_script \n from assets . i18n . i18n import I18nAuto \n i18n = I18nAuto ( ) \n import gradio as gr \n def processing ( ) : \n with gr . Accordion ( label = i18n ( \"<STR_LIT>\" ) ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n model_view_model_path = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n interactive = True , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n ) \n model_view_output_info = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) ,", "output": "value = \"<STR_LIT>\" , \n max_lines = <NUM_LIT> , \n ) \n model_view_button = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) \n model_view_button . click ( \n run_model_information_script , \n [ model_view_model_path ] , \n model_view_output_info , \n api_name = \"<STR_LIT>\" , \n )"}, {"input": "import os \n import sys \n import base64 \n import pathlib \n import tempfile \n import gradio as gr \n from assets . i18n . i18n import I18nAuto \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n i18n = I18nAuto ( ) \n recorder_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n main_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n record_button_js_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n recorder_js = pathlib . Path ( recorder_js_path ) . read_text ( ) \n main_js = pathlib . Path ( main_js_path ) . read_text ( ) \n record_button_js = ( \n pathlib . Path ( record_button_js_path )", "output": ". read_text ( ) \n . replace ( \"<STR_LIT>\" , recorder_js ) \n . replace ( \"<STR_LIT>\" , main_js ) \n ) \n def save_base64_video ( base64_string ) : \n base64_video = base64_string \n video_data = base64 . b64decode ( base64_video ) \n with tempfile . NamedTemporaryFile ( suffix = \"<STR_LIT>\" , delete = False ) as temp_file : \n temp_filename = temp_file . name \n temp_file . write ( video_data ) \n print ( f\"<STR_LIT>\" ) \n return temp_filename \n def report_tab ( ) : \n instructions = [ \n i18n ( \"<STR_LIT>\" ) , \n i18n ( \n \"<STR_LIT>\" \n ) , \n i18n ( \n \"<STR_LIT>\" \n ) , \n i18n ( \n \"<STR_LIT>\" \n ) , \n i18n ( \n \"<STR_LIT>\" \n ) , \n ] \n components = [ gr . Markdown ( value = instruction ) for instruction in instructions ] \n start_button = gr . Button ( \"<STR_LIT>\" ) \n video_component = gr . Video ( interactive = False ) \n def toggle_button_label ( returned_string ) : \n if returned_string . startswith ( \"<STR_LIT>\" ) : \n return gr . Button ( value = \"<STR_LIT>\" ) , None \n else : \n try : \n temp_filename = save_base64_video ( returned_string ) \n except Exception as error : \n return gr . Button ( value = \"<STR_LIT>\" ) , gr . Warning ( \n f\"<STR_LIT>\" \n ) \n return gr . Button ( value = \"<STR_LIT>\" ) , gr . Video ( \n value = temp_filename , interactive = False \n ) \n start_button . click ( \n toggle_button_label , \n start_button , \n [ start_button , video_component ] , \n js = record_button_js , \n )"}, {"input": "import os \n import glob \n import json \n import torch \n import argparse \n import numpy as np \n from scipy . io . wavfile import read \n def load_checkpoint ( checkpoint_path , model , optimizer = None , load_opt = <NUM_LIT> ) : \n assert os . path . isfile ( checkpoint_path ) \n checkpoint_dict = torch . load ( checkpoint_path , map_location = \"<STR_LIT>\" ) \n saved_state_dict = checkpoint_dict [ \"<STR_LIT>\" ] \n if hasattr ( model , \"<STR_LIT>\" ) : \n state_dict = model . module . state_dict ( ) \n else : \n state_dict = model . state_dict ( ) \n new_state_dict = { } \n for k , v in state_dict . items ( ) : \n try : \n new_state_dict [ k ] = saved_state_dict [ k ] \n if saved_state_dict [ k ] . shape != state_dict [ k ] . shape : \n print ( \n \"<STR_LIT>\" , \n k , \n state_dict [ k ] . shape , \n saved_state_dict [ k ] . shape , \n ) \n raise KeyError \n except : \n print ( \"<STR_LIT>\" , k ) \n new_state_dict [ k ] = v \n if hasattr ( model , \"<STR_LIT>\" ) : \n model . module . load_state_dict ( new_state_dict , strict = False ) \n else : \n model . load_state_dict ( new_state_dict , strict = False ) \n iteration = checkpoint_dict [ \"<STR_LIT>\" ] \n learning_rate = checkpoint_dict [ \"<STR_LIT>\" ] \n if optimizer is not None and load_opt == <NUM_LIT> : \n optimizer . load_state_dict ( checkpoint_dict [ \"<STR_LIT>\" ] ) \n print ( f\"<STR_LIT>\" ) \n return model , optimizer , learning_rate , iteration \n def save_checkpoint ( model , optimizer , learning_rate , iteration , checkpoint_path ) : \n print ( f\"<STR_LIT>\" ) \n if hasattr ( model , \"<STR_LIT>\" ) : \n state_dict = model . module . state_dict ( ) \n else : \n state_dict = model . state_dict ( ) \n torch . save ( \n { \n \"<STR_LIT>\" : state_dict , \n \"<STR_LIT>\" : iteration , \n \"<STR_LIT>\" : optimizer . state_dict ( ) , \n \"<STR_LIT>\" : learning_rate , \n } , \n checkpoint_path , \n ) \n def summarize ( \n writer , \n global_step , \n scalars = { } , \n histograms = { } , \n images = { } , \n audios = { } , \n audio_sampling_rate = <NUM_LIT> , \n ) : \n for k , v in scalars . items ( ) : \n writer . add_scalar ( k , v , global_step ) \n for k , v in histograms . items ( ) : \n writer . add_histogram ( k , v , global_step ) \n for k , v in images . items ( ) : \n writer . add_image ( k , v , global_step , dataformats = \"<STR_LIT>\" ) \n for k , v in audios . items ( ) : \n writer . add_audio ( k , v , global_step , audio_sampling_rate ) \n def latest_checkpoint_path ( dir_path , regex = \"<STR_LIT>\" ) :", "output": "f_list = glob . glob ( os . path . join ( dir_path , regex ) ) \n f_list . sort ( key = lambda f : int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , f ) ) ) ) \n x = f_list [ - <NUM_LIT> ] \n return x \n def plot_spectrogram_to_numpy ( spectrogram ) : \n import matplotlib . pylab as plt \n import numpy as np \n fig , ax = plt . subplots ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) \n im = ax . imshow ( spectrogram , aspect = \"<STR_LIT>\" , origin = \"<STR_LIT>\" , interpolation = \"<STR_LIT>\" ) \n plt . colorbar ( im , ax = ax ) \n plt . xlabel ( \"<STR_LIT>\" ) \n plt . ylabel ( \"<STR_LIT>\" ) \n plt . tight_layout ( ) \n fig . canvas . draw ( ) \n data = np . fromstring ( fig . canvas . tostring_rgb ( ) , dtype = np . uint8 , sep = \"<STR_LIT>\" ) \n data = data . reshape ( fig . canvas . get_width_height ( ) [ : : - <NUM_LIT> ] + ( <NUM_LIT> , ) ) \n plt . close ( ) \n return data \n def load_wav_to_torch ( full_path ) : \n sampling_rate , data = read ( full_path ) \n return torch . FloatTensor ( data . astype ( np . float32 ) ) , sampling_rate \n def load_filepaths_and_text ( filename , split = \"<STR_LIT>\" ) : \n with open ( filename , encoding = \"<STR_LIT>\" ) as f : \n filepaths_and_text = [ line . strip ( ) . split ( split ) for line in f ] \n return filepaths_and_text \n def get_hparams ( ) : \n parser = argparse . ArgumentParser ( ) \n parser . add_argument ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n type = int , \n required = True , \n help = \"<STR_LIT>\" , \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" \n ) \n parser . add_argument ( \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , default = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) \n parser . add_argument ( \n \"<STR_LIT>\" , \"<STR_LIT>\" , type = int , required = True , help = \"<STR_LIT>\" \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n type = str , \n default = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \"<STR_LIT>\" , type = str , required = True , help = \"<STR_LIT>\" \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n type = int , \n required = True , \n help = \"<STR_LIT>\" , \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n type = int , \n required = True , \n help = \"<STR_LIT>\" , \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n type = int , \n required = True , \n help = \"<STR_LIT>\" , \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n type = int , \n required = True , \n help = \"<STR_LIT>\" , \n ) \n parser . add_argument ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n type = int , \n default = <NUM_LIT> , \n help = \"<STR_LIT>\" , \n ) \n args = parser . parse_args ( ) \n name = args . experiment_dir \n experiment_dir = os . path . join ( \"<STR_LIT>\" , args . experiment_dir ) \n config_save_path = os . path . join ( experiment_dir , \"<STR_LIT>\" ) \n with open ( config_save_path , \"<STR_LIT>\" ) as f : \n config = json . load ( f ) \n hparams = HParams ( ** config ) \n hparams . model_dir = hparams . experiment_dir = experiment_dir \n hparams . save_every_epoch = args . save_every_epoch \n hparams . name = name \n hparams . total_epoch = args . total_epoch \n hparams . pretrainG = args . pretrainG \n hparams . pretrainD = args . pretrainD \n hparams . version = args . version \n hparams . gpus = args . gpus \n hparams . train . batch_size = args . batch_size \n hparams . sample_rate = args . sample_rate \n hparams . if_f0 = args . if_f0 \n hparams . if_latest = args . if_latest \n hparams . save_every_weights = args . save_every_weights \n hparams . if_cache_data_in_gpu = args . if_cache_data_in_gpu \n hparams . data . training_files = f\"<STR_LIT>\" \n hparams . overtraining_detector = args . overtraining_detector \n hparams . overtraining_threshold = args . overtraining_threshold \n return hparams \n class HParams : \n def __init__ ( self , ** kwargs ) : \n for k , v in kwargs . items ( ) : \n if type ( v ) == dict : \n v = HParams ( ** v ) \n self [ k ] = v \n def keys ( self ) : \n return self . __dict__ . keys ( ) \n def items ( self ) : \n return self . __dict__ . items ( ) \n def values ( self ) : \n return self . __dict__ . values ( ) \n def __len__ ( self ) : \n return len ( self . __dict__ ) \n def __getitem__ ( self , key ) : \n return getattr ( self , key ) \n def __setitem__ ( self , key , value ) : \n return setattr ( self , key , value ) \n def __contains__ ( self , key ) : \n return key in self . __dict__ \n def __repr__ ( self ) : \n return self . __dict__ . __repr__ ( )"}, {"input": "import gradio as gr \n import os \n import sys \n now_dir = os . getcwd ( ) \n pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def restart_applio ( ) :", "output": "if os . name != \"<STR_LIT>\" : \n os . system ( \"<STR_LIT>\" ) \n else : \n os . system ( \"<STR_LIT>\" ) \n try : \n with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : \n pids = [ int ( pid ) for pid in pid_file . readlines ( ) ] \n for pid in pids : \n os . kill ( pid , <NUM_LIT> ) \n os . remove ( pid_file_path ) \n except : \n pass \n python = sys . executable \n os . execl ( python , python , * sys . argv ) \n from assets . i18n . i18n import I18nAuto \n i18n = I18nAuto ( ) \n def restart_tab ( ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n restart_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n restart_button . click ( \n fn = restart_applio , \n inputs = [ ] , \n outputs = [ ] , \n )"}, {"input": "from pydub . silence import detect_nonsilent \n from pydub import AudioSegment \n import numpy as np \n import re \n import os \n from rvc . lib . utils import format_title \n def process_audio ( file_path ) : \n try : \n song = AudioSegment . from_file ( file_path ) \n silence_thresh = - <NUM_LIT>", "output": "min_silence_len = <NUM_LIT> \n nonsilent_parts = detect_nonsilent ( \n song , min_silence_len = min_silence_len , silence_thresh = silence_thresh \n ) \n file_dir = os . path . dirname ( file_path ) \n file_name = os . path . basename ( file_path ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n file_name = format_title ( file_name ) \n new_dir_path = os . path . join ( file_dir , file_name ) \n os . makedirs ( new_dir_path , exist_ok = True ) \n timestamps_file = os . path . join ( file_dir , f\"<STR_LIT>\" ) \n if os . path . isfile ( timestamps_file ) : \n os . remove ( timestamps_file ) \n segment_count = <NUM_LIT> \n for i , ( start_i , end_i ) in enumerate ( nonsilent_parts ) : \n chunk = song [ start_i : end_i ] \n chunk_file_path = os . path . join ( new_dir_path , f\"<STR_LIT>\" ) \n chunk . export ( chunk_file_path , format = \"<STR_LIT>\" ) \n print ( f\"<STR_LIT>\" ) \n segment_count += <NUM_LIT> \n with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : \n f . write ( f\"<STR_LIT>\" ) \n print ( f\"<STR_LIT>\" ) \n print ( f\"<STR_LIT>\" ) \n return \"<STR_LIT>\" , new_dir_path \n except Exception as e : \n print ( f\"<STR_LIT>\" ) \n return \"<STR_LIT>\" , None \n def merge_audio ( timestamps_file ) : \n try : \n prefix = os . path . basename ( timestamps_file ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n timestamps_dir = os . path . dirname ( timestamps_file ) \n with open ( timestamps_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : \n lines = f . readlines ( ) \n audio_segments = [ ] \n last_end_time = <NUM_LIT> \n print ( f\"<STR_LIT>\" ) \n for line in lines : \n match = re . search ( r\"<STR_LIT>\" , line ) \n if match : \n filename , start_time = match . groups ( ) \n start_time = int ( start_time ) \n chunk_file = os . path . join ( timestamps_dir , prefix , filename ) \n silence_duration = max ( start_time - last_end_time , <NUM_LIT> ) \n silence = AudioSegment . silent ( duration = silence_duration ) \n audio_segments . append ( silence ) \n audio = AudioSegment . from_wav ( chunk_file ) \n audio_segments . append ( audio ) \n last_end_time = start_time + len ( audio ) \n print ( f\"<STR_LIT>\" ) \n merged_audio = sum ( audio_segments ) \n merged_audio_np = np . array ( merged_audio . get_array_of_samples ( ) ) \n return merged_audio . frame_rate , merged_audio_np \n except Exception as e : \n print ( f\"<STR_LIT>\" )"}, {"input": "import torch \n import json \n import os \n version_config_list = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n def singleton_variable ( func ) : \n def wrapper ( * args , ** kwargs ) : \n if not wrapper . instance : \n wrapper . instance = func ( * args , ** kwargs ) \n return wrapper . instance \n wrapper . instance = None \n return wrapper \n @ singleton_variable \n class Config : \n def __init__ ( self ) : \n self . device = \"<STR_LIT>\" \n self . is_half = True \n self . use_jit = False \n self . n_cpu = <NUM_LIT> \n self . gpu_name = None \n self . json_config = self . load_config_json ( ) \n self . gpu_mem = None \n self . instead = \"<STR_LIT>\" \n self . x_pad , self . x_query , self . x_center , self . x_max = self . device_config ( ) \n @ staticmethod \n def load_config_json ( ) -> dict : \n d = { } \n for config_file in version_config_list : \n with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : \n d [ config_file ] = json . load ( f ) \n return d \n @ staticmethod \n def has_mps ( ) -> bool : \n if not torch . backends . mps . is_available ( ) : \n return False \n try : \n torch . zeros ( <NUM_LIT> ) . to ( torch . device ( \"<STR_LIT>\" ) ) \n return True \n except Exception : \n return False \n @ staticmethod \n def has_xpu ( ) -> bool : \n if hasattr ( torch , \"<STR_LIT>\" ) and torch . xpu . is_available ( ) : \n return True \n else : \n return False \n def use_fp32_config ( self ) : \n print ( \n f\"<STR_LIT>\" \n ) \n for config_file in version_config_list : \n self . json_config [ config_file ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False \n with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : \n strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : \n f . write ( strr ) \n with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : \n strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : \n f . write ( strr ) \n def device_config ( self ) -> tuple : \n if torch . cuda . is_available ( ) : \n if self . has_xpu ( ) : \n self . device = self . instead = \"<STR_LIT>\" \n self . is_half = True \n i_device = int ( self . device . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) \n self . gpu_name = torch . cuda . get_device_name ( i_device ) \n if ( \n ( \"<STR_LIT>\" in self . gpu_name and \"<STR_LIT>\" not in self . gpu_name . upper ( ) ) \n or \"<STR_LIT>\" in self . gpu_name . upper ( ) \n or \"<STR_LIT>\" in self . gpu_name . upper ( ) \n or \"<STR_LIT>\" in self . gpu_name \n or \"<STR_LIT>\" in self . gpu_name \n or \"<STR_LIT>\" in self . gpu_name \n ) : \n self . is_half = False \n self . use_fp32_config ( ) \n self . gpu_mem = int ( \n torch . cuda . get_device_properties ( i_device ) . total_memory \n / <NUM_LIT> \n / <NUM_LIT> \n / <NUM_LIT> \n + <NUM_LIT> \n )", "output": "if self . gpu_mem <= <NUM_LIT> : \n with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : \n strr = f . read ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n with open ( \"<STR_LIT>\" , \"<STR_LIT>\" ) as f : \n f . write ( strr ) \n elif self . has_mps ( ) : \n print ( \"<STR_LIT>\" ) \n self . device = self . instead = \"<STR_LIT>\" \n self . is_half = False \n self . use_fp32_config ( ) \n else : \n print ( \"<STR_LIT>\" ) \n self . device = self . instead = \"<STR_LIT>\" \n self . is_half = False \n self . use_fp32_config ( ) \n if self . n_cpu == <NUM_LIT> : \n self . n_cpu = os . cpu_count ( ) \n if self . is_half : \n x_pad = <NUM_LIT> \n x_query = <NUM_LIT> \n x_center = <NUM_LIT> \n x_max = <NUM_LIT> \n else : \n x_pad = <NUM_LIT> \n x_query = <NUM_LIT> \n x_center = <NUM_LIT> \n x_max = <NUM_LIT> \n if self . gpu_mem is not None and self . gpu_mem <= <NUM_LIT> : \n x_pad = <NUM_LIT> \n x_query = <NUM_LIT> \n x_center = <NUM_LIT> \n x_max = <NUM_LIT> \n return x_pad , x_query , x_center , x_max \n def max_vram_gpu ( gpu ) : \n if torch . cuda . is_available ( ) : \n gpu_properties = torch . cuda . get_device_properties ( gpu ) \n total_memory_gb = round ( gpu_properties . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> ) \n return total_memory_gb \n else : \n return \"<STR_LIT>\" \n def get_gpu_info ( ) : \n ngpu = torch . cuda . device_count ( ) \n gpu_infos = [ ] \n if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : \n for i in range ( ngpu ) : \n gpu_name = torch . cuda . get_device_name ( i ) \n mem = int ( \n torch . cuda . get_device_properties ( i ) . total_memory / <NUM_LIT> / <NUM_LIT> / <NUM_LIT> \n + <NUM_LIT> \n ) \n gpu_infos . append ( \"<STR_LIT>\" % ( i , gpu_name , mem ) ) \n if len ( gpu_infos ) > <NUM_LIT> : \n gpu_info = \"<STR_LIT>\" . join ( gpu_infos ) \n else : \n gpu_info = \"<STR_LIT>\" \n return gpu_info"}, {"input": "import os \n import sys \n import gradio as gr \n import json \n from assets . i18n . i18n import I18nAuto \n from assets . discord_presence import RPCManager \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n i18n = I18nAuto ( ) \n config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def load_config_presence ( ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file :", "output": "config = json . load ( file ) \n return config [ \"<STR_LIT>\" ] \n def save_config ( value ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n config = json . load ( file ) \n config [ \"<STR_LIT>\" ] = value \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n json . dump ( config , file , indent = <NUM_LIT> ) \n def presence_tab ( ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n presence = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n interactive = True , \n value = load_config_presence ( ) , \n ) \n presence . change ( \n fn = toggle , \n inputs = [ presence ] , \n outputs = [ ] , \n ) \n def toggle ( checkbox ) : \n save_config ( bool ( checkbox ) ) \n if load_config_presence ( ) == True : \n try : \n RPCManager . start_presence ( ) \n except KeyboardInterrupt : \n RPCManager . stop_presence ( ) \n else : \n RPCManager . stop_presence ( )"}, {"input": "import math \n import numpy as np \n import torch \n from torch import nn \n from torch . nn import functional as F \n def init_weights ( m , mean = <NUM_LIT> , std = <NUM_LIT> ) : \n classname = m . __class__ . __name__ \n if classname . find ( \"<STR_LIT>\" ) != - <NUM_LIT> : \n m . weight . data . normal_ ( mean , std ) \n def get_padding ( kernel_size , dilation = <NUM_LIT> ) : \n return int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) \n def convert_pad_shape ( pad_shape ) :", "output": "l = pad_shape [ : : - <NUM_LIT> ] \n pad_shape = [ item for sublist in l for item in sublist ] \n return pad_shape \n def kl_divergence ( m_p , logs_p , m_q , logs_q ) : \n kl = ( logs_q - logs_p ) - <NUM_LIT> \n kl += ( \n <NUM_LIT> * ( torch . exp ( <NUM_LIT> * logs_p ) + ( ( m_p - m_q ) ** <NUM_LIT> ) ) * torch . exp ( - <NUM_LIT> * logs_q ) \n ) \n return kl \n def rand_gumbel ( shape ) : \n uniform_samples = torch . rand ( shape ) * <NUM_LIT> + <NUM_LIT> \n return - torch . log ( - torch . log ( uniform_samples ) ) \n def rand_gumbel_like ( x ) : \n g = rand_gumbel ( x . size ( ) ) . to ( dtype = x . dtype , device = x . device ) \n return g \n def slice_segments ( x , ids_str , segment_size = <NUM_LIT> ) : \n ret = torch . zeros_like ( x [ : , : , : segment_size ] ) \n for i in range ( x . size ( <NUM_LIT> ) ) : \n idx_str = ids_str [ i ] \n idx_end = idx_str + segment_size \n ret [ i ] = x [ i , : , idx_str : idx_end ] \n return ret \n def slice_segments2 ( x , ids_str , segment_size = <NUM_LIT> ) : \n ret = torch . zeros_like ( x [ : , : segment_size ] ) \n for i in range ( x . size ( <NUM_LIT> ) ) : \n idx_str = ids_str [ i ] \n idx_end = idx_str + segment_size \n ret [ i ] = x [ i , idx_str : idx_end ] \n return ret \n def rand_slice_segments ( x , x_lengths = None , segment_size = <NUM_LIT> ) : \n b , d , t = x . size ( ) \n if x_lengths is None : \n x_lengths = t \n ids_str_max = x_lengths - segment_size + <NUM_LIT> \n ids_str = ( torch . rand ( [ b ] ) . to ( device = x . device ) * ids_str_max ) . to ( dtype = torch . long ) \n ret = slice_segments ( x , ids_str , segment_size ) \n return ret , ids_str \n def get_timing_signal_1d ( length , channels , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : \n position = torch . arange ( length , dtype = torch . float ) \n num_timescales = channels // <NUM_LIT> \n log_timescale_increment = math . log ( float ( max_timescale ) / float ( min_timescale ) ) / ( \n num_timescales - <NUM_LIT> \n ) \n inv_timescales = min_timescale * torch . exp ( \n torch . arange ( num_timescales , dtype = torch . float ) * - log_timescale_increment \n ) \n scaled_time = position . unsqueeze ( <NUM_LIT> ) * inv_timescales . unsqueeze ( <NUM_LIT> ) \n signal = torch . cat ( [ torch . sin ( scaled_time ) , torch . cos ( scaled_time ) ] , <NUM_LIT> ) \n signal = F . pad ( signal , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , channels % <NUM_LIT> ] ) \n signal = signal . view ( <NUM_LIT> , channels , length ) \n return signal \n def add_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> ) : \n b , channels , length = x . size ( ) \n signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) \n return x + signal . to ( dtype = x . dtype , device = x . device ) \n def cat_timing_signal_1d ( x , min_timescale = <NUM_LIT> , max_timescale = <NUM_LIT> , axis = <NUM_LIT> ) : \n b , channels , length = x . size ( ) \n signal = get_timing_signal_1d ( length , channels , min_timescale , max_timescale ) \n return torch . cat ( [ x , signal . to ( dtype = x . dtype , device = x . device ) ] , axis ) \n def subsequent_mask ( length ) : \n mask = torch . tril ( torch . ones ( length , length ) ) . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) \n return mask \n @ torch . jit . script \n def fused_add_tanh_sigmoid_multiply ( input_a , input_b , n_channels ) : \n n_channels_int = n_channels [ <NUM_LIT> ] \n in_act = input_a + input_b \n t_act = torch . tanh ( in_act [ : , : n_channels_int , : ] ) \n s_act = torch . sigmoid ( in_act [ : , n_channels_int : , : ] ) \n acts = t_act * s_act \n return acts \n def convert_pad_shape ( pad_shape ) : \n l = pad_shape [ : : - <NUM_LIT> ] \n pad_shape = [ item for sublist in l for item in sublist ] \n return pad_shape \n def shift_1d ( x ) : \n x = F . pad ( x , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : , : - <NUM_LIT> ] \n return x \n def sequence_mask ( length , max_length = None ) : \n if max_length is None : \n max_length = length . max ( ) \n x = torch . arange ( max_length , dtype = length . dtype , device = length . device ) \n return x . unsqueeze ( <NUM_LIT> ) < length . unsqueeze ( <NUM_LIT> ) \n def generate_path ( duration , mask ) : \n device = duration . device \n b , _ , t_y , t_x = mask . shape \n cum_duration = torch . cumsum ( duration , - <NUM_LIT> ) \n cum_duration_flat = cum_duration . view ( b * t_x ) \n path = sequence_mask ( cum_duration_flat , t_y ) . to ( mask . dtype ) \n path = path . view ( b , t_x , t_y ) \n path = path - F . pad ( path , convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) [ : , : - <NUM_LIT> ] \n path = path . unsqueeze ( <NUM_LIT> ) . transpose ( <NUM_LIT> , <NUM_LIT> ) * mask \n return path \n def clip_grad_value_ ( parameters , clip_value , norm_type = <NUM_LIT> ) : \n if isinstance ( parameters , torch . Tensor ) : \n parameters = [ parameters ] \n parameters = list ( filter ( lambda p : p . grad is not None , parameters ) ) \n norm_type = float ( norm_type ) \n if clip_value is not None : \n clip_value = float ( clip_value ) \n total_norm = <NUM_LIT> \n for p in parameters : \n param_norm = p . grad . data . norm ( norm_type ) \n total_norm += param_norm . item ( ) ** norm_type \n if clip_value is not None : \n p . grad . data . clamp_ ( min = - clip_value , max = clip_value ) \n total_norm = total_norm ** ( <NUM_LIT> / norm_type ) \n return total_norm"}, {"input": "import ffmpeg \n import numpy as np \n import re \n import unicodedata \n def load_audio ( file , sampling_rate ) : \n try : \n file = file . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) \n out , _ = ( \n ffmpeg . input ( file , threads = <NUM_LIT> ) \n . output ( \"<STR_LIT>\" , format = \"<STR_LIT>\" , acodec = \"<STR_LIT>\" , ac = <NUM_LIT> , ar = sampling_rate ) \n . run ( cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_stdout = True , capture_stderr = True ) \n ) \n except Exception as error : \n raise RuntimeError ( f\"<STR_LIT>\" ) \n return np . frombuffer ( out , np . float32 ) . flatten ( ) \n def format_title ( title ) : \n formatted_title = ( \n unicodedata . normalize ( \"<STR_LIT>\" , title ) . encode ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . decode ( \"<STR_LIT>\" ) \n ) \n formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title ) \n formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title )", "output": "formatted_title = re . sub ( r\"<STR_LIT>\" , \"<STR_LIT>\" , formatted_title ) \n return formatted_title"}, {"input": "import os \n import subprocess \n import sys \n import shutil \n import gradio as gr \n from assets . i18n . i18n import I18nAuto \n from core import ( \n run_preprocess_script , \n run_extract_script , \n run_train_script , \n run_index_script , \n run_prerequisites_script , \n ) \n from rvc . configs . config import max_vram_gpu , get_gpu_info \n from rvc . lib . utils import format_title \n from tabs . settings . restart import restart_applio \n i18n = I18nAuto ( ) \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n pretraineds_v1 = [ \n ( \n \"<STR_LIT>\" , \n [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n ) , \n ] \n folder_mapping = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n sup_audioext = { \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n } \n pretraineds_custom_path = os . path . join ( \n now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" \n ) \n pretraineds_custom_path_relative = os . path . relpath ( pretraineds_custom_path , now_dir ) \n if not os . path . exists ( pretraineds_custom_path_relative ) : \n os . makedirs ( pretraineds_custom_path_relative ) \n def get_pretrained_list ( suffix ) : \n return [ \n os . path . join ( dirpath , filename ) \n for dirpath , _ , filenames in os . walk ( pretraineds_custom_path_relative ) \n for filename in filenames \n if filename . endswith ( \"<STR_LIT>\" ) and suffix in filename \n ] \n pretraineds_list_d = get_pretrained_list ( \"<STR_LIT>\" ) \n pretraineds_list_g = get_pretrained_list ( \"<STR_LIT>\" ) \n def refresh_custom_pretraineds ( ) : \n return ( \n { \"<STR_LIT>\" : sorted ( get_pretrained_list ( \"<STR_LIT>\" ) ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : sorted ( get_pretrained_list ( \"<STR_LIT>\" ) ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) \n datasets_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if not os . path . exists ( datasets_path ) : \n os . makedirs ( datasets_path ) \n datasets_path_relative = os . path . relpath ( datasets_path , now_dir ) \n def get_datasets_list ( ) : \n return [ \n dirpath \n for dirpath , _ , filenames in os . walk ( datasets_path_relative ) \n if any ( filename . endswith ( tuple ( sup_audioext ) ) for filename in filenames ) \n ] \n def refresh_datasets ( ) : \n return { \"<STR_LIT>\" : sorted ( get_datasets_list ( ) ) , \"<STR_LIT>\" : \"<STR_LIT>\" } \n models_path = os . path . join ( now_dir , \"<STR_LIT>\" ) \n def get_models_list ( ) : \n return [ \n os . path . basename ( dirpath ) \n for dirpath in os . listdir ( models_path ) \n if os . path . isdir ( os . path . join ( models_path , dirpath ) ) \n and all ( excluded not in dirpath for excluded in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n ] \n def refresh_models ( ) : \n return { \"<STR_LIT>\" : sorted ( get_models_list ( ) ) , \"<STR_LIT>\" : \"<STR_LIT>\" } \n def refresh_models_and_datasets ( ) : \n return ( \n { \"<STR_LIT>\" : sorted ( get_models_list ( ) ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : sorted ( get_datasets_list ( ) ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) \n def save_drop_model ( dropbox ) : \n if \"<STR_LIT>\" not in dropbox : \n gr . Info ( \n i18n ( \n \"<STR_LIT>\" \n ) \n ) \n else : \n file_name = os . path . basename ( dropbox ) \n pretrained_path = os . path . join ( pretraineds_custom_path_relative , file_name ) \n if os . path . exists ( pretrained_path ) : \n os . remove ( pretrained_path ) \n os . rename ( dropbox , pretrained_path ) \n gr . Info ( \n i18n ( \n \"<STR_LIT>\" \n ) \n ) \n return None \n def save_drop_dataset_audio ( dropbox , dataset_name ) : \n if not dataset_name : \n gr . Info ( \"<STR_LIT>\" ) \n return None , None \n else : \n file_extension = os . path . splitext ( dropbox ) [ <NUM_LIT> ] [ <NUM_LIT> : ] . lower ( ) \n if file_extension not in sup_audioext : \n gr . Info ( \"<STR_LIT>\" ) \n else : \n dataset_name = format_title ( dataset_name ) \n audio_file = format_title ( os . path . basename ( dropbox ) ) \n dataset_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , dataset_name ) \n if not os . path . exists ( dataset_path ) : \n os . makedirs ( dataset_path ) \n destination_path = os . path . join ( dataset_path , audio_file ) \n if os . path . exists ( destination_path ) : \n os . remove ( destination_path ) \n os . rename ( dropbox , destination_path ) \n gr . Info ( \n i18n ( \n \"<STR_LIT>\" \n ) \n ) \n dataset_path = os . path . dirname ( destination_path ) \n relative_dataset_path = os . path . relpath ( dataset_path , now_dir ) \n return None , relative_dataset_path \n def get_pth_list ( ) : \n return [ \n os . path . relpath ( os . path . join ( dirpath , filename ) , now_dir ) \n for dirpath , _ , filenames in os . walk ( models_path ) \n for filename in filenames \n if filename . endswith ( \"<STR_LIT>\" ) \n ] \n def get_index_list ( ) : \n return [ \n os . path . relpath ( os . path . join ( dirpath , filename ) , now_dir ) \n for dirpath , _ , filenames in os . walk ( models_path ) \n for filename in filenames \n if filename . endswith ( \"<STR_LIT>\" ) and \"<STR_LIT>\" not in filename \n ] \n def refresh_pth_and_index_list ( ) : \n return ( \n { \"<STR_LIT>\" : sorted ( get_pth_list ( ) ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : sorted ( get_index_list ( ) ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) \n def export_pth ( pth_path ) : \n if pth_path and os . path . exists ( pth_path ) : \n return pth_path \n return None \n def export_index ( index_path ) : \n if index_path and os . path . exists ( index_path ) : \n return index_path \n return None \n def upload_to_google_drive ( pth_path , index_path ) : \n def upload_file ( file_path ) : \n if file_path : \n try : \n gr . Info ( f\"<STR_LIT>\" ) \n google_drive_folder = \"<STR_LIT>\" \n if not os . path . exists ( google_drive_folder ) : \n os . makedirs ( google_drive_folder ) \n google_drive_file_path = os . path . join ( \n google_drive_folder , os . path . basename ( file_path ) \n ) \n if os . path . exists ( google_drive_file_path ) : \n os . remove ( google_drive_file_path ) \n shutil . copy2 ( file_path , google_drive_file_path ) \n gr . Info ( \"<STR_LIT>\" ) \n except Exception as error : \n print ( error ) \n gr . Info ( \"<STR_LIT>\" ) \n upload_file ( pth_path ) \n upload_file ( index_path ) \n def train_tab ( ) : \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n model_name = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = get_models_list ( ) , \n value = \"<STR_LIT>\" , \n interactive = True , \n allow_custom_value = True , \n ) \n dataset_path = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = get_datasets_list ( ) , \n allow_custom_value = True , \n interactive = True , \n ) \n refresh = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n dataset_creator = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n value = False , \n interactive = True , \n visible = True , \n ) \n with gr . Column ( visible = False ) as dataset_creator_settings : \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) ) : \n dataset_name = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n interactive = True , \n ) \n upload_audio_dataset = gr . File ( \n label = i18n ( \"<STR_LIT>\" ) , \n type = \"<STR_LIT>\" , \n interactive = True , \n ) \n with gr . Column ( ) : \n sampling_rate = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n rvc_version = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n preprocess_output_info = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n max_lines = <NUM_LIT> , \n interactive = False , \n ) \n with gr . Row ( ) : \n preprocess_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n preprocess_button . click ( \n run_preprocess_script , \n [ model_name , dataset_path , sampling_rate ] , \n preprocess_output_info , \n api_name = \"<STR_LIT>\" , \n ) \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) ) : \n with gr . Row ( ) : \n hop_length = gr . Slider ( \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n interactive = True , \n visible = False , \n ) \n with gr . Row ( ) : \n with gr . Column ( ) : \n f0method = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n choices = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n )", "output": "extract_output_info = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n max_lines = <NUM_LIT> , \n interactive = False , \n ) \n extract_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n extract_button . click ( \n run_extract_script , \n [ model_name , rvc_version , f0method , hop_length , sampling_rate ] , \n extract_output_info , \n api_name = \"<STR_LIT>\" , \n ) \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) ) : \n with gr . Row ( ) : \n batch_size = gr . Slider ( \n <NUM_LIT> , \n <NUM_LIT> , \n max_vram_gpu ( <NUM_LIT> ) , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n interactive = True , \n ) \n save_every_epoch = gr . Slider ( \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n interactive = True , \n ) \n total_epoch = gr . Slider ( \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n interactive = True , \n ) \n with gr . Row ( ) : \n pitch_guidance = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = True , \n interactive = True , \n ) \n pretrained = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = True , \n interactive = True , \n ) \n save_only_latest = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = False , \n interactive = True , \n ) \n save_every_weights = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = True , \n interactive = True , \n ) \n custom_pretrained = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = False , \n interactive = True , \n ) \n multiple_gpu = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = ( \n i18n ( \n \"<STR_LIT>\" \n ) \n ) , \n value = False , \n interactive = True , \n ) \n overtraining_detector = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = False , \n interactive = True , \n ) \n with gr . Row ( ) : \n with gr . Column ( visible = False ) as pretrained_custom_settings : \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) ) : \n upload_pretrained = gr . File ( \n label = i18n ( \"<STR_LIT>\" ) , \n type = \"<STR_LIT>\" , \n interactive = True , \n ) \n refresh_custom_pretaineds_button = gr . Button ( \n i18n ( \"<STR_LIT>\" ) \n ) \n g_pretrained_path = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n choices = sorted ( pretraineds_list_g ) , \n interactive = True , \n allow_custom_value = True , \n ) \n d_pretrained_path = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n choices = sorted ( pretraineds_list_d ) , \n interactive = True , \n allow_custom_value = True , \n ) \n with gr . Column ( visible = False ) as gpu_custom_settings : \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) ) : \n gpu = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n value = get_gpu_info ( ) , \n interactive = False , \n ) \n with gr . Column ( visible = False ) as overtraining_settings : \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) ) : \n overtraining_threshold = gr . Slider ( \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n interactive = True , \n ) \n with gr . Row ( ) : \n train_output_info = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n value = \"<STR_LIT>\" , \n max_lines = <NUM_LIT> , \n interactive = False , \n ) \n with gr . Row ( ) : \n train_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n train_button . click ( \n run_train_script , \n [ \n model_name , \n rvc_version , \n save_every_epoch , \n save_only_latest , \n save_every_weights , \n total_epoch , \n sampling_rate , \n batch_size , \n gpu , \n pitch_guidance , \n overtraining_detector , \n overtraining_threshold , \n pretrained , \n custom_pretrained , \n g_pretrained_path , \n d_pretrained_path , \n ] , \n train_output_info , \n api_name = \"<STR_LIT>\" , \n ) \n stop_train_button = gr . Button ( \n i18n ( \"<STR_LIT>\" ) , visible = False \n ) \n stop_train_button . click ( \n fn = restart_applio , \n inputs = [ ] , \n outputs = [ ] , \n ) \n index_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n index_button . click ( \n run_index_script , \n [ model_name , rvc_version ] , \n train_output_info , \n api_name = \"<STR_LIT>\" , \n ) \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) , open = False ) : \n if not os . name == \"<STR_LIT>\" : \n gr . Markdown ( \n i18n ( \n \"<STR_LIT>\" \n ) \n ) \n with gr . Row ( ) : \n with gr . Column ( ) : \n pth_file_export = gr . File ( \n label = i18n ( \"<STR_LIT>\" ) , \n type = \"<STR_LIT>\" , \n value = None , \n interactive = False , \n ) \n pth_dropdown_export = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = get_pth_list ( ) , \n value = None , \n interactive = True , \n allow_custom_value = True , \n ) \n with gr . Column ( ) : \n index_file_export = gr . File ( \n label = i18n ( \"<STR_LIT>\" ) , \n type = \"<STR_LIT>\" , \n value = None , \n interactive = False , \n ) \n index_dropdown_export = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = get_index_list ( ) , \n value = None , \n interactive = True , \n allow_custom_value = True , \n ) \n with gr . Row ( ) : \n with gr . Column ( ) : \n refresh_export = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n if not os . name == \"<STR_LIT>\" : \n upload_exported = gr . Button ( i18n ( \"<STR_LIT>\" ) , variant = \"<STR_LIT>\" ) \n upload_exported . click ( \n fn = upload_to_google_drive , \n inputs = [ pth_dropdown_export , index_dropdown_export ] , \n outputs = [ ] , \n ) \n def toggle_visible ( checkbox ) : \n return { \"<STR_LIT>\" : checkbox , \"<STR_LIT>\" : \"<STR_LIT>\" } \n def toggle_visible_hop_length ( f0method ) : \n if f0method == \"<STR_LIT>\" or f0method == \"<STR_LIT>\" : \n return { \"<STR_LIT>\" : True , \"<STR_LIT>\" : \"<STR_LIT>\" } \n return { \"<STR_LIT>\" : False , \"<STR_LIT>\" : \"<STR_LIT>\" } \n def toggle_pretrained ( pretrained , custom_pretrained ) : \n if custom_pretrained == False : \n return { \"<STR_LIT>\" : pretrained , \"<STR_LIT>\" : \"<STR_LIT>\" } , { \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n else : \n return { \"<STR_LIT>\" : pretrained , \"<STR_LIT>\" : \"<STR_LIT>\" } , { \n \"<STR_LIT>\" : pretrained , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n def enable_stop_train_button ( ) : \n return { \"<STR_LIT>\" : False , \"<STR_LIT>\" : \"<STR_LIT>\" } , { \n \"<STR_LIT>\" : True , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n def disable_stop_train_button ( ) : \n return { \"<STR_LIT>\" : True , \"<STR_LIT>\" : \"<STR_LIT>\" } , { \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n def download_prerequisites ( version ) : \n for remote_folder , file_list in pretraineds_v1 : \n local_folder = folder_mapping . get ( remote_folder , \"<STR_LIT>\" ) \n missing = False \n for file in file_list : \n destination_path = os . path . join ( local_folder , file ) \n if not os . path . exists ( destination_path ) : \n missing = True \n if version == \"<STR_LIT>\" and missing == True : \n gr . Info ( \n \"<STR_LIT>\" \n ) \n run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n gr . Info ( \n \"<STR_LIT>\" \n ) \n rvc_version . change ( \n fn = download_prerequisites , \n inputs = [ rvc_version ] , \n outputs = [ ] , \n ) \n refresh . click ( \n fn = refresh_models_and_datasets , \n inputs = [ ] , \n outputs = [ model_name , dataset_path ] , \n ) \n dataset_creator . change ( \n fn = toggle_visible , \n inputs = [ dataset_creator ] , \n outputs = [ dataset_creator_settings ] , \n ) \n upload_audio_dataset . upload ( \n fn = save_drop_dataset_audio , \n inputs = [ upload_audio_dataset , dataset_name ] , \n outputs = [ upload_audio_dataset , dataset_path ] , \n ) \n f0method . change ( \n fn = toggle_visible_hop_length , \n inputs = [ f0method ] , \n outputs = [ hop_length ] , \n ) \n pretrained . change ( \n fn = toggle_pretrained , \n inputs = [ pretrained , custom_pretrained ] , \n outputs = [ custom_pretrained , pretrained_custom_settings ] , \n ) \n custom_pretrained . change ( \n fn = toggle_visible , \n inputs = [ custom_pretrained ] , \n outputs = [ pretrained_custom_settings ] , \n ) \n refresh_custom_pretaineds_button . click ( \n fn = refresh_custom_pretraineds , \n inputs = [ ] , \n outputs = [ g_pretrained_path , d_pretrained_path ] , \n ) \n upload_pretrained . upload ( \n fn = save_drop_model , \n inputs = [ upload_pretrained ] , \n outputs = [ upload_pretrained ] , \n ) \n overtraining_detector . change ( \n fn = toggle_visible , \n inputs = [ overtraining_detector ] , \n outputs = [ overtraining_settings ] , \n ) \n multiple_gpu . change ( \n fn = toggle_visible , \n inputs = [ multiple_gpu ] , \n outputs = [ gpu_custom_settings ] , \n ) \n train_button . click ( \n fn = enable_stop_train_button , \n inputs = [ ] , \n outputs = [ train_button , stop_train_button ] , \n ) \n train_output_info . change ( \n fn = disable_stop_train_button , \n inputs = [ ] , \n outputs = [ train_button , stop_train_button ] , \n ) \n pth_dropdown_export . change ( \n fn = export_pth , \n inputs = [ pth_dropdown_export ] , \n outputs = [ pth_file_export ] , \n ) \n index_dropdown_export . change ( \n fn = export_index , \n inputs = [ index_dropdown_export ] , \n outputs = [ index_file_export ] , \n ) \n refresh_export . click ( \n fn = refresh_pth_and_index_list , \n inputs = [ ] , \n outputs = [ pth_dropdown_export , index_dropdown_export ] , \n )"}, {"input": "import os \n import torch", "output": "def change_info ( path , info , name ) : \n try : \n ckpt = torch . load ( path , map_location = \"<STR_LIT>\" ) \n ckpt [ \"<STR_LIT>\" ] = info \n if name == \"<STR_LIT>\" : \n name = os . path . basename ( path ) \n torch . save ( ckpt , f\"<STR_LIT>\" ) \n return \"<STR_LIT>\" \n except Exception as error : \n print ( error )"}, {"input": "import torch \n from datetime import datetime \n def prettify_date ( date_str ) :", "output": "date_time_obj = datetime . strptime ( date_str , \"<STR_LIT>\" ) \n return date_time_obj . strftime ( \"<STR_LIT>\" ) \n def model_information ( path ) : \n model_data = torch . load ( path , map_location = \"<STR_LIT>\" ) \n print ( f\"<STR_LIT>\" ) \n epochs = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n steps = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n sr = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n f0 = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n version = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n creation_date = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n model_hash = model_data . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n pitch_guidance = \"<STR_LIT>\" if f0 == <NUM_LIT> else \"<STR_LIT>\" \n return ( \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n )"}, {"input": "import os \n import torch \n from collections import OrderedDict \n def extract ( ckpt ) : \n a = ckpt [ \"<STR_LIT>\" ] \n opt = OrderedDict ( ) \n opt [ \"<STR_LIT>\" ] = { } \n for key in a . keys ( ) : \n if \"<STR_LIT>\" in key : \n continue \n opt [ \"<STR_LIT>\" ] [ key ] = a [ key ]", "output": "return opt \n def model_blender ( name , path1 , path2 , ratio ) : \n try : \n message = f\"<STR_LIT>\" \n ckpt1 = torch . load ( path1 , map_location = \"<STR_LIT>\" ) \n ckpt2 = torch . load ( path2 , map_location = \"<STR_LIT>\" ) \n cfg = ckpt1 [ \"<STR_LIT>\" ] \n cfg_f0 = ckpt1 [ \"<STR_LIT>\" ] \n cfg_version = ckpt1 [ \"<STR_LIT>\" ] \n if \"<STR_LIT>\" in ckpt1 : \n ckpt1 = extract ( ckpt1 ) \n else : \n ckpt1 = ckpt1 [ \"<STR_LIT>\" ] \n if \"<STR_LIT>\" in ckpt2 : \n ckpt2 = extract ( ckpt2 ) \n else : \n ckpt2 = ckpt2 [ \"<STR_LIT>\" ] \n if sorted ( list ( ckpt1 . keys ( ) ) ) != sorted ( list ( ckpt2 . keys ( ) ) ) : \n return \"<STR_LIT>\" \n opt = OrderedDict ( ) \n opt [ \"<STR_LIT>\" ] = { } \n for key in ckpt1 . keys ( ) : \n if key == \"<STR_LIT>\" and ckpt1 [ key ] . shape != ckpt2 [ key ] . shape : \n min_shape0 = min ( ckpt1 [ key ] . shape [ <NUM_LIT> ] , ckpt2 [ key ] . shape [ <NUM_LIT> ] ) \n opt [ \"<STR_LIT>\" ] [ key ] = ( \n ratio * ( ckpt1 [ key ] [ : min_shape0 ] . float ( ) ) \n + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] [ : min_shape0 ] . float ( ) ) \n ) . half ( ) \n else : \n opt [ \"<STR_LIT>\" ] [ key ] = ( \n ratio * ( ckpt1 [ key ] . float ( ) ) + ( <NUM_LIT> - ratio ) * ( ckpt2 [ key ] . float ( ) ) \n ) . half ( ) \n opt [ \"<STR_LIT>\" ] = cfg \n opt [ \"<STR_LIT>\" ] = message \n opt [ \"<STR_LIT>\" ] = cfg_f0 \n opt [ \"<STR_LIT>\" ] = cfg_version \n opt [ \"<STR_LIT>\" ] = message \n torch . save ( opt , os . path . join ( \"<STR_LIT>\" , \"<STR_LIT>\" % name ) ) \n print ( message ) \n return message , os . path . join ( \"<STR_LIT>\" , \"<STR_LIT>\" % name ) \n except Exception as error : \n print ( error ) \n return error"}, {"input": "import torch . nn as nn \n import torch , numpy as np \n import torch . nn . functional as F \n from librosa . filters import mel \n class BiGRU ( nn . Module ) : \n def __init__ ( self , input_features , hidden_features , num_layers ) : \n super ( BiGRU , self ) . __init__ ( ) \n self . gru = nn . GRU ( \n input_features , \n hidden_features , \n num_layers = num_layers , \n batch_first = True , \n bidirectional = True , \n ) \n def forward ( self , x ) : \n return self . gru ( x ) [ <NUM_LIT> ] \n class ConvBlockRes ( nn . Module ) : \n def __init__ ( self , in_channels , out_channels , momentum = <NUM_LIT> ) : \n super ( ConvBlockRes , self ) . __init__ ( ) \n self . conv = nn . Sequential ( \n nn . Conv2d ( \n in_channels = in_channels , \n out_channels = out_channels , \n kernel_size = ( <NUM_LIT> , <NUM_LIT> ) , \n stride = ( <NUM_LIT> , <NUM_LIT> ) , \n padding = ( <NUM_LIT> , <NUM_LIT> ) , \n bias = False , \n ) , \n nn . BatchNorm2d ( out_channels , momentum = momentum ) , \n nn . ReLU ( ) , \n nn . Conv2d ( \n in_channels = out_channels , \n out_channels = out_channels , \n kernel_size = ( <NUM_LIT> , <NUM_LIT> ) , \n stride = ( <NUM_LIT> , <NUM_LIT> ) , \n padding = ( <NUM_LIT> , <NUM_LIT> ) , \n bias = False , \n ) , \n nn . BatchNorm2d ( out_channels , momentum = momentum ) , \n nn . ReLU ( ) , \n ) \n if in_channels != out_channels : \n self . shortcut = nn . Conv2d ( in_channels , out_channels , ( <NUM_LIT> , <NUM_LIT> ) ) \n self . is_shortcut = True \n else : \n self . is_shortcut = False \n def forward ( self , x ) : \n if self . is_shortcut : \n return self . conv ( x ) + self . shortcut ( x ) \n else : \n return self . conv ( x ) + x \n class Encoder ( nn . Module ) : \n def __init__ ( \n self , \n in_channels , \n in_size , \n n_encoders , \n kernel_size , \n n_blocks , \n out_channels = <NUM_LIT> , \n momentum = <NUM_LIT> , \n ) : \n super ( Encoder , self ) . __init__ ( ) \n self . n_encoders = n_encoders \n self . bn = nn . BatchNorm2d ( in_channels , momentum = momentum ) \n self . layers = nn . ModuleList ( ) \n self . latent_channels = [ ] \n for i in range ( self . n_encoders ) : \n self . layers . append ( \n ResEncoderBlock ( \n in_channels , out_channels , kernel_size , n_blocks , momentum = momentum \n ) \n ) \n self . latent_channels . append ( [ out_channels , in_size ] ) \n in_channels = out_channels \n out_channels *= <NUM_LIT> \n in_size //= <NUM_LIT> \n self . out_size = in_size \n self . out_channel = out_channels \n def forward ( self , x ) : \n concat_tensors = [ ] \n x = self . bn ( x ) \n for i in range ( self . n_encoders ) : \n _ , x = self . layers [ i ] ( x ) \n concat_tensors . append ( _ ) \n return x , concat_tensors \n class ResEncoderBlock ( nn . Module ) : \n def __init__ ( \n self , in_channels , out_channels , kernel_size , n_blocks = <NUM_LIT> , momentum = <NUM_LIT> \n ) : \n super ( ResEncoderBlock , self ) . __init__ ( ) \n self . n_blocks = n_blocks \n self . conv = nn . ModuleList ( ) \n self . conv . append ( ConvBlockRes ( in_channels , out_channels , momentum ) ) \n for i in range ( n_blocks - <NUM_LIT> ) : \n self . conv . append ( ConvBlockRes ( out_channels , out_channels , momentum ) ) \n self . kernel_size = kernel_size \n if self . kernel_size is not None : \n self . pool = nn . AvgPool2d ( kernel_size = kernel_size ) \n def forward ( self , x ) : \n for i in range ( self . n_blocks ) : \n x = self . conv [ i ] ( x ) \n if self . kernel_size is not None : \n return x , self . pool ( x ) \n else : \n return x \n class Intermediate ( nn . Module ) : \n def __init__ ( self , in_channels , out_channels , n_inters , n_blocks , momentum = <NUM_LIT> ) : \n super ( Intermediate , self ) . __init__ ( ) \n self . n_inters = n_inters \n self . layers = nn . ModuleList ( ) \n self . layers . append ( \n ResEncoderBlock ( in_channels , out_channels , None , n_blocks , momentum ) \n ) \n for i in range ( self . n_inters - <NUM_LIT> ) : \n self . layers . append ( \n ResEncoderBlock ( out_channels , out_channels , None , n_blocks , momentum ) \n ) \n def forward ( self , x ) : \n for i in range ( self . n_inters ) : \n x = self . layers [ i ] ( x ) \n return x \n class ResDecoderBlock ( nn . Module ) : \n def __init__ ( self , in_channels , out_channels , stride , n_blocks = <NUM_LIT> , momentum = <NUM_LIT> ) : \n super ( ResDecoderBlock , self ) . __init__ ( ) \n out_padding = ( <NUM_LIT> , <NUM_LIT> ) if stride == ( <NUM_LIT> , <NUM_LIT> ) else ( <NUM_LIT> , <NUM_LIT> ) \n self . n_blocks = n_blocks \n self . conv1 = nn . Sequential ( \n nn . ConvTranspose2d ( \n in_channels = in_channels , \n out_channels = out_channels , \n kernel_size = ( <NUM_LIT> , <NUM_LIT> ) , \n stride = stride , \n padding = ( <NUM_LIT> , <NUM_LIT> ) , \n output_padding = out_padding , \n bias = False , \n ) , \n nn . BatchNorm2d ( out_channels , momentum = momentum ) , \n nn . ReLU ( ) , \n ) \n self . conv2 = nn . ModuleList ( ) \n self . conv2 . append ( ConvBlockRes ( out_channels * <NUM_LIT> , out_channels , momentum ) ) \n for i in range ( n_blocks - <NUM_LIT> ) : \n self . conv2 . append ( ConvBlockRes ( out_channels , out_channels , momentum ) ) \n def forward ( self , x , concat_tensor ) : \n x = self . conv1 ( x ) \n x = torch . cat ( ( x , concat_tensor ) , dim = <NUM_LIT> ) \n for i in range ( self . n_blocks ) : \n x = self . conv2 [ i ] ( x ) \n return x \n class Decoder ( nn . Module ) : \n def __init__ ( self , in_channels , n_decoders , stride , n_blocks , momentum = <NUM_LIT> ) : \n super ( Decoder , self ) . __init__ ( ) \n self . layers = nn . ModuleList ( ) \n self . n_decoders = n_decoders \n for i in range ( self . n_decoders ) : \n out_channels = in_channels // <NUM_LIT> \n self . layers . append ( \n ResDecoderBlock ( in_channels , out_channels , stride , n_blocks , momentum ) \n ) \n in_channels = out_channels \n def forward ( self , x , concat_tensors ) : \n for i in range ( self . n_decoders ) : \n x = self . layers [ i ] ( x , concat_tensors [ - <NUM_LIT> - i ] ) \n return x \n class DeepUnet ( nn . Module ) : \n def __init__ ( \n self , \n kernel_size , \n n_blocks , \n en_de_layers = <NUM_LIT> , \n inter_layers = <NUM_LIT> , \n in_channels = <NUM_LIT> , \n en_out_channels = <NUM_LIT> , \n ) : \n super ( DeepUnet , self ) . __init__ ( ) \n self . encoder = Encoder ( \n in_channels , <NUM_LIT> , en_de_layers , kernel_size , n_blocks , en_out_channels \n ) \n self . intermediate = Intermediate ( \n self . encoder . out_channel // <NUM_LIT> , \n self . encoder . out_channel , \n inter_layers , \n n_blocks , \n ) \n self . decoder = Decoder ( \n self . encoder . out_channel , en_de_layers , kernel_size , n_blocks \n ) \n def forward ( self , x ) : \n x , concat_tensors = self . encoder ( x ) \n x = self . intermediate ( x ) \n x = self . decoder ( x , concat_tensors ) \n return x \n class E2E ( nn . Module ) : \n def __init__ ( \n self , \n n_blocks , \n n_gru , \n kernel_size , \n en_de_layers = <NUM_LIT> , \n inter_layers = <NUM_LIT> , \n in_channels = <NUM_LIT> , \n en_out_channels = <NUM_LIT> , \n ) : \n super ( E2E , self ) . __init__ ( ) \n self . unet = DeepUnet ( \n kernel_size , \n n_blocks , \n en_de_layers , \n inter_layers , \n in_channels , \n en_out_channels , \n ) \n self . cnn = nn . Conv2d ( en_out_channels , <NUM_LIT> , ( <NUM_LIT> , <NUM_LIT> ) , padding = ( <NUM_LIT> , <NUM_LIT> ) ) \n if n_gru : \n self . fc = nn . Sequential ( \n BiGRU ( <NUM_LIT> * <NUM_LIT> , <NUM_LIT> , n_gru ) , \n nn . Linear ( <NUM_LIT> , <NUM_LIT> ) , \n nn . Dropout ( <NUM_LIT> ) , \n nn . Sigmoid ( ) , \n ) \n def forward ( self , mel ) : \n mel = mel . transpose ( - <NUM_LIT> , - <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) \n x = self . cnn ( self . unet ( mel ) ) . transpose ( <NUM_LIT> , <NUM_LIT> ) . flatten ( - <NUM_LIT> ) \n x = self . fc ( x ) \n return x \n class MelSpectrogram ( torch . nn . Module ) : \n def __init__ ( \n self , \n is_half , \n n_mel_channels , \n sampling_rate , \n win_length , \n hop_length , \n n_fft = None , \n mel_fmin = <NUM_LIT> , \n mel_fmax = None , \n clamp = <NUM_LIT> , \n ) : \n super ( ) . __init__ ( ) \n n_fft = win_length if n_fft is None else n_fft \n self . hann_window = { } \n mel_basis = mel ( \n sr = sampling_rate ,", "output": "n_fft = n_fft , \n n_mels = n_mel_channels , \n fmin = mel_fmin , \n fmax = mel_fmax , \n htk = True , \n ) \n mel_basis = torch . from_numpy ( mel_basis ) . float ( ) \n self . register_buffer ( \"<STR_LIT>\" , mel_basis ) \n self . n_fft = win_length if n_fft is None else n_fft \n self . hop_length = hop_length \n self . win_length = win_length \n self . sampling_rate = sampling_rate \n self . n_mel_channels = n_mel_channels \n self . clamp = clamp \n self . is_half = is_half \n def forward ( self , audio , keyshift = <NUM_LIT> , speed = <NUM_LIT> , center = True ) : \n factor = <NUM_LIT> ** ( keyshift / <NUM_LIT> ) \n n_fft_new = int ( np . round ( self . n_fft * factor ) ) \n win_length_new = int ( np . round ( self . win_length * factor ) ) \n hop_length_new = int ( np . round ( self . hop_length * speed ) ) \n keyshift_key = str ( keyshift ) + \"<STR_LIT>\" + str ( audio . device ) \n if keyshift_key not in self . hann_window : \n self . hann_window [ keyshift_key ] = torch . hann_window ( win_length_new ) . to ( \n audio . device \n ) \n fft = torch . stft ( \n audio , \n n_fft = n_fft_new , \n hop_length = hop_length_new , \n win_length = win_length_new , \n window = self . hann_window [ keyshift_key ] , \n center = center , \n return_complex = True , \n ) \n magnitude = torch . sqrt ( fft . real . pow ( <NUM_LIT> ) + fft . imag . pow ( <NUM_LIT> ) ) \n if keyshift != <NUM_LIT> : \n size = self . n_fft // <NUM_LIT> + <NUM_LIT> \n resize = magnitude . size ( <NUM_LIT> ) \n if resize < size : \n magnitude = F . pad ( magnitude , ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , size - resize ) ) \n magnitude = magnitude [ : , : size , : ] * self . win_length / win_length_new \n mel_output = torch . matmul ( self . mel_basis , magnitude ) \n if self . is_half == True : \n mel_output = mel_output . half ( ) \n log_mel_spec = torch . log ( torch . clamp ( mel_output , min = self . clamp ) ) \n return log_mel_spec \n class RMVPE : \n def __init__ ( self , model_path , is_half , device = None ) : \n self . resample_kernel = { } \n model = E2E ( <NUM_LIT> , <NUM_LIT> , ( <NUM_LIT> , <NUM_LIT> ) ) \n ckpt = torch . load ( model_path , map_location = \"<STR_LIT>\" ) \n model . load_state_dict ( ckpt ) \n model . eval ( ) \n if is_half == True : \n model = model . half ( ) \n self . model = model \n self . resample_kernel = { } \n self . is_half = is_half \n if device is None : \n device = \"<STR_LIT>\" if torch . cuda . is_available ( ) else \"<STR_LIT>\" \n self . device = device \n self . mel_extractor = MelSpectrogram ( \n is_half , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , None , <NUM_LIT> , <NUM_LIT> \n ) . to ( device ) \n self . model = self . model . to ( device ) \n cents_mapping = <NUM_LIT> * np . arange ( <NUM_LIT> ) + <NUM_LIT> \n self . cents_mapping = np . pad ( cents_mapping , ( <NUM_LIT> , <NUM_LIT> ) ) \n def mel2hidden ( self , mel ) : \n with torch . no_grad ( ) : \n n_frames = mel . shape [ - <NUM_LIT> ] \n mel = F . pad ( \n mel , ( <NUM_LIT> , <NUM_LIT> * ( ( n_frames - <NUM_LIT> ) // <NUM_LIT> + <NUM_LIT> ) - n_frames ) , mode = \"<STR_LIT>\" \n ) \n hidden = self . model ( mel ) \n return hidden [ : , : n_frames ] \n def decode ( self , hidden , thred = <NUM_LIT> ) : \n cents_pred = self . to_local_average_cents ( hidden , thred = thred ) \n f0 = <NUM_LIT> * ( <NUM_LIT> ** ( cents_pred / <NUM_LIT> ) ) \n f0 [ f0 == <NUM_LIT> ] = <NUM_LIT> \n return f0 \n def infer_from_audio ( self , audio , thred = <NUM_LIT> ) : \n audio = torch . from_numpy ( audio ) . float ( ) . to ( self . device ) . unsqueeze ( <NUM_LIT> ) \n mel = self . mel_extractor ( audio , center = True ) \n hidden = self . mel2hidden ( mel ) \n hidden = hidden . squeeze ( <NUM_LIT> ) . cpu ( ) . numpy ( ) \n if self . is_half == True : \n hidden = hidden . astype ( \"<STR_LIT>\" ) \n f0 = self . decode ( hidden , thred = thred ) \n return f0 \n def to_local_average_cents ( self , salience , thred = <NUM_LIT> ) : \n center = np . argmax ( salience , axis = <NUM_LIT> ) \n salience = np . pad ( salience , ( ( <NUM_LIT> , <NUM_LIT> ) , ( <NUM_LIT> , <NUM_LIT> ) ) ) \n center += <NUM_LIT> \n todo_salience = [ ] \n todo_cents_mapping = [ ] \n starts = center - <NUM_LIT> \n ends = center + <NUM_LIT> \n for idx in range ( salience . shape [ <NUM_LIT> ] ) : \n todo_salience . append ( salience [ : , starts [ idx ] : ends [ idx ] ] [ idx ] ) \n todo_cents_mapping . append ( self . cents_mapping [ starts [ idx ] : ends [ idx ] ] ) \n todo_salience = np . array ( todo_salience ) \n todo_cents_mapping = np . array ( todo_cents_mapping ) \n product_sum = np . sum ( todo_salience * todo_cents_mapping , <NUM_LIT> ) \n weight_sum = np . sum ( todo_salience , <NUM_LIT> ) \n devided = product_sum / weight_sum \n maxx = np . max ( salience , axis = <NUM_LIT> ) \n devided [ maxx <= thred ] = <NUM_LIT> \n return devided"}, {"input": "import torch \n from torch . nn import functional as F \n import numpy as np \n DEFAULT_MIN_BIN_WIDTH = <NUM_LIT> \n DEFAULT_MIN_BIN_HEIGHT = <NUM_LIT> \n DEFAULT_MIN_DERIVATIVE = <NUM_LIT> \n def piecewise_rational_quadratic_transform ( \n inputs , \n unnormalized_widths , \n unnormalized_heights , \n unnormalized_derivatives , \n inverse = False , \n tails = None , \n tail_bound = <NUM_LIT> , \n min_bin_width = DEFAULT_MIN_BIN_WIDTH , \n min_bin_height = DEFAULT_MIN_BIN_HEIGHT , \n min_derivative = DEFAULT_MIN_DERIVATIVE , \n ) : \n if tails is None : \n spline_fn = rational_quadratic_spline \n spline_kwargs = { } \n else : \n spline_fn = unconstrained_rational_quadratic_spline \n spline_kwargs = { \"<STR_LIT>\" : tails , \"<STR_LIT>\" : tail_bound } \n outputs , logabsdet = spline_fn ( \n inputs = inputs , \n unnormalized_widths = unnormalized_widths , \n unnormalized_heights = unnormalized_heights , \n unnormalized_derivatives = unnormalized_derivatives , \n inverse = inverse , \n min_bin_width = min_bin_width , \n min_bin_height = min_bin_height , \n min_derivative = min_derivative , \n ** spline_kwargs \n ) \n return outputs , logabsdet \n def searchsorted ( bin_locations , inputs , eps = <NUM_LIT> ) : \n bin_locations [ ... , - <NUM_LIT> ] += eps \n return torch . sum ( inputs [ ... , None ] >= bin_locations , dim = - <NUM_LIT> ) - <NUM_LIT> \n def unconstrained_rational_quadratic_spline ( \n inputs , \n unnormalized_widths , \n unnormalized_heights , \n unnormalized_derivatives , \n inverse = False , \n tails = \"<STR_LIT>\" , \n tail_bound = <NUM_LIT> , \n min_bin_width = DEFAULT_MIN_BIN_WIDTH , \n min_bin_height = DEFAULT_MIN_BIN_HEIGHT , \n min_derivative = DEFAULT_MIN_DERIVATIVE , \n ) : \n inside_interval_mask = ( inputs >= - tail_bound ) & ( inputs <= tail_bound ) \n outside_interval_mask = ~ inside_interval_mask \n outputs = torch . zeros_like ( inputs ) \n logabsdet = torch . zeros_like ( inputs ) \n if tails == \"<STR_LIT>\" : \n unnormalized_derivatives = F . pad ( unnormalized_derivatives , pad = ( <NUM_LIT> , <NUM_LIT> ) ) \n constant = np . log ( np . exp ( <NUM_LIT> - min_derivative ) - <NUM_LIT> ) \n unnormalized_derivatives [ ... , <NUM_LIT> ] = constant \n unnormalized_derivatives [ ... , - <NUM_LIT> ] = constant \n outputs [ outside_interval_mask ] = inputs [ outside_interval_mask ] \n logabsdet [ outside_interval_mask ] = <NUM_LIT> \n else : \n raise RuntimeError ( \"<STR_LIT>\" . format ( tails ) ) \n ( \n outputs [ inside_interval_mask ] , \n logabsdet [ inside_interval_mask ] , \n ) = rational_quadratic_spline ( \n inputs = inputs [ inside_interval_mask ] , \n unnormalized_widths = unnormalized_widths [ inside_interval_mask , : ] , \n unnormalized_heights = unnormalized_heights [ inside_interval_mask , : ] , \n unnormalized_derivatives = unnormalized_derivatives [ inside_interval_mask , : ] , \n inverse = inverse , \n left = - tail_bound , \n right = tail_bound , \n bottom = - tail_bound , \n top = tail_bound , \n min_bin_width = min_bin_width , \n min_bin_height = min_bin_height , \n min_derivative = min_derivative , \n ) \n return outputs , logabsdet \n def rational_quadratic_spline ( \n inputs , \n unnormalized_widths , \n unnormalized_heights , \n unnormalized_derivatives , \n inverse = False , \n left = <NUM_LIT> , \n right = <NUM_LIT> , \n bottom = <NUM_LIT> , \n top = <NUM_LIT> , \n min_bin_width = DEFAULT_MIN_BIN_WIDTH , \n min_bin_height = DEFAULT_MIN_BIN_HEIGHT , \n min_derivative = DEFAULT_MIN_DERIVATIVE , \n ) : \n if torch . min ( inputs ) < left or torch . max ( inputs ) > right : \n raise ValueError ( \"<STR_LIT>\" ) \n num_bins = unnormalized_widths . shape [ - <NUM_LIT> ] \n if min_bin_width * num_bins > <NUM_LIT> : \n raise ValueError ( \"<STR_LIT>\" ) \n if min_bin_height * num_bins > <NUM_LIT> : \n raise ValueError ( \"<STR_LIT>\" ) \n widths = F . softmax ( unnormalized_widths , dim = - <NUM_LIT> ) \n widths = min_bin_width + ( <NUM_LIT> - min_bin_width * num_bins ) * widths \n cumwidths = torch . cumsum ( widths , dim = - <NUM_LIT> ) \n cumwidths = F . pad ( cumwidths , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) \n cumwidths = ( right - left ) * cumwidths + left \n cumwidths [ ... , <NUM_LIT> ] = left \n cumwidths [ ... , - <NUM_LIT> ] = right \n widths = cumwidths [ ... , <NUM_LIT> : ] - cumwidths [ ... , : - <NUM_LIT> ] \n derivatives = min_derivative + F . softplus ( unnormalized_derivatives ) \n heights = F . softmax ( unnormalized_heights , dim = - <NUM_LIT> ) \n heights = min_bin_height + ( <NUM_LIT> - min_bin_height * num_bins ) * heights \n cumheights = torch . cumsum ( heights , dim = - <NUM_LIT> ) \n cumheights = F . pad ( cumheights , pad = ( <NUM_LIT> , <NUM_LIT> ) , mode = \"<STR_LIT>\" , value = <NUM_LIT> ) \n cumheights = ( top - bottom ) * cumheights + bottom \n cumheights [ ... , <NUM_LIT> ] = bottom \n cumheights [ ... , - <NUM_LIT> ] = top \n heights = cumheights [ ... , <NUM_LIT> : ] - cumheights [ ... , : - <NUM_LIT> ] \n if inverse : \n bin_idx = searchsorted ( cumheights , inputs ) [ ... , None ] \n else : \n bin_idx = searchsorted ( cumwidths , inputs ) [ ... , None ] \n input_cumwidths = cumwidths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] \n input_bin_widths = widths . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] \n input_cumheights = cumheights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] \n delta = heights / widths \n input_delta = delta . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] \n input_derivatives = derivatives . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] \n input_derivatives_plus_one = derivatives [ ... , <NUM_LIT> : ] . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] \n input_heights = heights . gather ( - <NUM_LIT> , bin_idx ) [ ... , <NUM_LIT> ] \n if inverse : \n a = ( inputs - input_cumheights ) * ( \n input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta \n ) + input_heights * ( input_delta - input_derivatives )", "output": "b = input_heights * input_derivatives - ( inputs - input_cumheights ) * ( \n input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta \n ) \n c = - input_delta * ( inputs - input_cumheights ) \n discriminant = b . pow ( <NUM_LIT> ) - <NUM_LIT> * a * c \n assert ( discriminant >= <NUM_LIT> ) . all ( ) \n root = ( <NUM_LIT> * c ) / ( - b - torch . sqrt ( discriminant ) ) \n outputs = root * input_bin_widths + input_cumwidths \n theta_one_minus_theta = root * ( <NUM_LIT> - root ) \n denominator = input_delta + ( \n ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) \n * theta_one_minus_theta \n ) \n derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( \n input_derivatives_plus_one * root . pow ( <NUM_LIT> ) \n + <NUM_LIT> * input_delta * theta_one_minus_theta \n + input_derivatives * ( <NUM_LIT> - root ) . pow ( <NUM_LIT> ) \n ) \n logabsdet = torch . log ( derivative_numerator ) - <NUM_LIT> * torch . log ( denominator ) \n return outputs , - logabsdet \n else : \n theta = ( inputs - input_cumwidths ) / input_bin_widths \n theta_one_minus_theta = theta * ( <NUM_LIT> - theta ) \n numerator = input_heights * ( \n input_delta * theta . pow ( <NUM_LIT> ) + input_derivatives * theta_one_minus_theta \n ) \n denominator = input_delta + ( \n ( input_derivatives + input_derivatives_plus_one - <NUM_LIT> * input_delta ) \n * theta_one_minus_theta \n ) \n outputs = input_cumheights + numerator / denominator \n derivative_numerator = input_delta . pow ( <NUM_LIT> ) * ( \n input_derivatives_plus_one * theta . pow ( <NUM_LIT> ) \n + <NUM_LIT> * input_delta * theta_one_minus_theta \n + input_derivatives * ( <NUM_LIT> - theta ) . pow ( <NUM_LIT> ) \n ) \n logabsdet = torch . log ( derivative_numerator ) - <NUM_LIT> * torch . log ( denominator ) \n return outputs , logabsdet"}, {"input": "import math \n import torch \n from torch import nn \n from torch . nn import functional as F \n from . import commons \n from . modules import LayerNorm \n class Encoder ( nn . Module ) : \n def __init__ ( \n self , \n hidden_channels , \n filter_channels , \n n_heads , \n n_layers , \n kernel_size = <NUM_LIT> , \n p_dropout = <NUM_LIT> , \n window_size = <NUM_LIT> , \n ** kwargs \n ) : \n super ( ) . __init__ ( ) \n self . hidden_channels = hidden_channels", "output": "self . filter_channels = filter_channels \n self . n_heads = n_heads \n self . n_layers = n_layers \n self . kernel_size = kernel_size \n self . p_dropout = p_dropout \n self . window_size = window_size \n self . drop = nn . Dropout ( p_dropout ) \n self . attn_layers = nn . ModuleList ( ) \n self . norm_layers_1 = nn . ModuleList ( ) \n self . ffn_layers = nn . ModuleList ( ) \n self . norm_layers_2 = nn . ModuleList ( ) \n for i in range ( self . n_layers ) : \n self . attn_layers . append ( \n MultiHeadAttention ( \n hidden_channels , \n hidden_channels , \n n_heads , \n p_dropout = p_dropout , \n window_size = window_size , \n ) \n ) \n self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) \n self . ffn_layers . append ( \n FFN ( \n hidden_channels , \n hidden_channels , \n filter_channels , \n kernel_size , \n p_dropout = p_dropout , \n ) \n ) \n self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) \n def forward ( self , x , x_mask ) : \n attn_mask = x_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) \n x = x * x_mask \n for i in range ( self . n_layers ) : \n y = self . attn_layers [ i ] ( x , x , attn_mask ) \n y = self . drop ( y ) \n x = self . norm_layers_1 [ i ] ( x + y ) \n y = self . ffn_layers [ i ] ( x , x_mask ) \n y = self . drop ( y ) \n x = self . norm_layers_2 [ i ] ( x + y ) \n x = x * x_mask \n return x \n class Decoder ( nn . Module ) : \n def __init__ ( \n self , \n hidden_channels , \n filter_channels , \n n_heads , \n n_layers , \n kernel_size = <NUM_LIT> , \n p_dropout = <NUM_LIT> , \n proximal_bias = False , \n proximal_init = True , \n ** kwargs \n ) : \n super ( ) . __init__ ( ) \n self . hidden_channels = hidden_channels \n self . filter_channels = filter_channels \n self . n_heads = n_heads \n self . n_layers = n_layers \n self . kernel_size = kernel_size \n self . p_dropout = p_dropout \n self . proximal_bias = proximal_bias \n self . proximal_init = proximal_init \n self . drop = nn . Dropout ( p_dropout ) \n self . self_attn_layers = nn . ModuleList ( ) \n self . norm_layers_0 = nn . ModuleList ( ) \n self . encdec_attn_layers = nn . ModuleList ( ) \n self . norm_layers_1 = nn . ModuleList ( ) \n self . ffn_layers = nn . ModuleList ( ) \n self . norm_layers_2 = nn . ModuleList ( ) \n for i in range ( self . n_layers ) : \n self . self_attn_layers . append ( \n MultiHeadAttention ( \n hidden_channels , \n hidden_channels , \n n_heads , \n p_dropout = p_dropout , \n proximal_bias = proximal_bias , \n proximal_init = proximal_init , \n ) \n ) \n self . norm_layers_0 . append ( LayerNorm ( hidden_channels ) ) \n self . encdec_attn_layers . append ( \n MultiHeadAttention ( \n hidden_channels , hidden_channels , n_heads , p_dropout = p_dropout \n ) \n ) \n self . norm_layers_1 . append ( LayerNorm ( hidden_channels ) ) \n self . ffn_layers . append ( \n FFN ( \n hidden_channels , \n hidden_channels , \n filter_channels , \n kernel_size , \n p_dropout = p_dropout , \n causal = True , \n ) \n ) \n self . norm_layers_2 . append ( LayerNorm ( hidden_channels ) ) \n def forward ( self , x , x_mask , h , h_mask ) : \n self_attn_mask = commons . subsequent_mask ( x_mask . size ( <NUM_LIT> ) ) . to ( \n device = x . device , dtype = x . dtype \n ) \n encdec_attn_mask = h_mask . unsqueeze ( <NUM_LIT> ) * x_mask . unsqueeze ( - <NUM_LIT> ) \n x = x * x_mask \n for i in range ( self . n_layers ) : \n y = self . self_attn_layers [ i ] ( x , x , self_attn_mask ) \n y = self . drop ( y ) \n x = self . norm_layers_0 [ i ] ( x + y ) \n y = self . encdec_attn_layers [ i ] ( x , h , encdec_attn_mask ) \n y = self . drop ( y ) \n x = self . norm_layers_1 [ i ] ( x + y ) \n y = self . ffn_layers [ i ] ( x , x_mask ) \n y = self . drop ( y ) \n x = self . norm_layers_2 [ i ] ( x + y ) \n x = x * x_mask \n return x \n class MultiHeadAttention ( nn . Module ) : \n def __init__ ( \n self , \n channels , \n out_channels , \n n_heads , \n p_dropout = <NUM_LIT> , \n window_size = None , \n heads_share = True , \n block_length = None , \n proximal_bias = False , \n proximal_init = False , \n ) : \n super ( ) . __init__ ( ) \n assert channels % n_heads == <NUM_LIT> \n self . channels = channels \n self . out_channels = out_channels \n self . n_heads = n_heads \n self . p_dropout = p_dropout \n self . window_size = window_size \n self . heads_share = heads_share \n self . block_length = block_length \n self . proximal_bias = proximal_bias \n self . proximal_init = proximal_init \n self . attn = None \n self . k_channels = channels // n_heads \n self . conv_q = nn . Conv1d ( channels , channels , <NUM_LIT> ) \n self . conv_k = nn . Conv1d ( channels , channels , <NUM_LIT> ) \n self . conv_v = nn . Conv1d ( channels , channels , <NUM_LIT> ) \n self . conv_o = nn . Conv1d ( channels , out_channels , <NUM_LIT> ) \n self . drop = nn . Dropout ( p_dropout ) \n if window_size is not None : \n n_heads_rel = <NUM_LIT> if heads_share else n_heads \n rel_stddev = self . k_channels ** - <NUM_LIT> \n self . emb_rel_k = nn . Parameter ( \n torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) \n * rel_stddev \n ) \n self . emb_rel_v = nn . Parameter ( \n torch . randn ( n_heads_rel , window_size * <NUM_LIT> + <NUM_LIT> , self . k_channels ) \n * rel_stddev \n ) \n nn . init . xavier_uniform_ ( self . conv_q . weight ) \n nn . init . xavier_uniform_ ( self . conv_k . weight ) \n nn . init . xavier_uniform_ ( self . conv_v . weight ) \n if proximal_init : \n with torch . no_grad ( ) : \n self . conv_k . weight . copy_ ( self . conv_q . weight ) \n self . conv_k . bias . copy_ ( self . conv_q . bias ) \n def forward ( self , x , c , attn_mask = None ) : \n q = self . conv_q ( x ) \n k = self . conv_k ( c ) \n v = self . conv_v ( c ) \n x , self . attn = self . attention ( q , k , v , mask = attn_mask ) \n x = self . conv_o ( x ) \n return x \n def attention ( self , query , key , value , mask = None ) : \n b , d , t_s , t_t = ( * key . size ( ) , query . size ( <NUM_LIT> ) ) \n query = query . view ( b , self . n_heads , self . k_channels , t_t ) . transpose ( <NUM_LIT> , <NUM_LIT> ) \n key = key . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) \n value = value . view ( b , self . n_heads , self . k_channels , t_s ) . transpose ( <NUM_LIT> , <NUM_LIT> ) \n scores = torch . matmul ( query / math . sqrt ( self . k_channels ) , key . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) \n if self . window_size is not None : \n assert ( \n t_s == t_t \n ) , \"<STR_LIT>\" \n key_relative_embeddings = self . _get_relative_embeddings ( self . emb_rel_k , t_s ) \n rel_logits = self . _matmul_with_relative_keys ( \n query / math . sqrt ( self . k_channels ) , key_relative_embeddings \n ) \n scores_local = self . _relative_position_to_absolute_position ( rel_logits ) \n scores = scores + scores_local \n if self . proximal_bias : \n assert t_s == t_t , \"<STR_LIT>\" \n scores = scores + self . _attention_bias_proximal ( t_s ) . to ( \n device = scores . device , dtype = scores . dtype \n ) \n if mask is not None : \n scores = scores . masked_fill ( mask == <NUM_LIT> , - <NUM_LIT> ) \n if self . block_length is not None : \n assert ( \n t_s == t_t \n ) , \"<STR_LIT>\" \n block_mask = ( \n torch . ones_like ( scores ) \n . triu ( - self . block_length ) \n . tril ( self . block_length ) \n ) \n scores = scores . masked_fill ( block_mask == <NUM_LIT> , - <NUM_LIT> ) \n p_attn = F . softmax ( scores , dim = - <NUM_LIT> ) \n p_attn = self . drop ( p_attn ) \n output = torch . matmul ( p_attn , value ) \n if self . window_size is not None : \n relative_weights = self . _absolute_position_to_relative_position ( p_attn ) \n value_relative_embeddings = self . _get_relative_embeddings ( \n self . emb_rel_v , t_s \n ) \n output = output + self . _matmul_with_relative_values ( \n relative_weights , value_relative_embeddings \n ) \n output = output . transpose ( <NUM_LIT> , <NUM_LIT> ) . contiguous ( ) . view ( b , d , t_t ) \n return output , p_attn \n def _matmul_with_relative_values ( self , x , y ) : \n ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) ) \n return ret \n def _matmul_with_relative_keys ( self , x , y ) : \n ret = torch . matmul ( x , y . unsqueeze ( <NUM_LIT> ) . transpose ( - <NUM_LIT> , - <NUM_LIT> ) ) \n return ret \n def _get_relative_embeddings ( self , relative_embeddings , length ) : \n pad_length = max ( length - ( self . window_size + <NUM_LIT> ) , <NUM_LIT> ) \n slice_start_position = max ( ( self . window_size + <NUM_LIT> ) - length , <NUM_LIT> ) \n slice_end_position = slice_start_position + <NUM_LIT> * length - <NUM_LIT> \n if pad_length > <NUM_LIT> : \n padded_relative_embeddings = F . pad ( \n relative_embeddings , \n commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ pad_length , pad_length ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) , \n ) \n else : \n padded_relative_embeddings = relative_embeddings \n used_relative_embeddings = padded_relative_embeddings [ \n : , slice_start_position : slice_end_position \n ] \n return used_relative_embeddings \n def _relative_position_to_absolute_position ( self , x ) : \n batch , heads , length , _ = x . size ( ) \n x = F . pad ( x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] ] ) ) \n x_flat = x . view ( [ batch , heads , length * <NUM_LIT> * length ] ) \n x_flat = F . pad ( \n x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) \n ) \n x_final = x_flat . view ( [ batch , heads , length + <NUM_LIT> , <NUM_LIT> * length - <NUM_LIT> ] ) [ \n : , : , : length , length - <NUM_LIT> : \n ] \n return x_final \n def _absolute_position_to_relative_position ( self , x ) : \n batch , heads , length , _ = x . size ( ) \n x = F . pad ( \n x , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , length - <NUM_LIT> ] ] ) \n ) \n x_flat = x . view ( [ batch , heads , length ** <NUM_LIT> + length * ( length - <NUM_LIT> ) ] ) \n x_flat = F . pad ( x_flat , commons . convert_pad_shape ( [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ length , <NUM_LIT> ] ] ) ) \n x_final = x_flat . view ( [ batch , heads , length , <NUM_LIT> * length ] ) [ : , : , : , <NUM_LIT> : ] \n return x_final \n def _attention_bias_proximal ( self , length ) : \n r = torch . arange ( length , dtype = torch . float32 ) \n diff = torch . unsqueeze ( r , <NUM_LIT> ) - torch . unsqueeze ( r , <NUM_LIT> ) \n return torch . unsqueeze ( torch . unsqueeze ( - torch . log1p ( torch . abs ( diff ) ) , <NUM_LIT> ) , <NUM_LIT> ) \n class FFN ( nn . Module ) : \n def __init__ ( \n self , \n in_channels , \n out_channels , \n filter_channels , \n kernel_size , \n p_dropout = <NUM_LIT> , \n activation = None , \n causal = False , \n ) : \n super ( ) . __init__ ( ) \n self . in_channels = in_channels \n self . out_channels = out_channels \n self . filter_channels = filter_channels \n self . kernel_size = kernel_size \n self . p_dropout = p_dropout \n self . activation = activation \n self . causal = causal \n if causal : \n self . padding = self . _causal_padding \n else : \n self . padding = self . _same_padding \n self . conv_1 = nn . Conv1d ( in_channels , filter_channels , kernel_size ) \n self . conv_2 = nn . Conv1d ( filter_channels , out_channels , kernel_size ) \n self . drop = nn . Dropout ( p_dropout ) \n def forward ( self , x , x_mask ) : \n x = self . conv_1 ( self . padding ( x * x_mask ) ) \n if self . activation == \"<STR_LIT>\" : \n x = x * torch . sigmoid ( <NUM_LIT> * x ) \n else : \n x = torch . relu ( x ) \n x = self . drop ( x ) \n x = self . conv_2 ( self . padding ( x * x_mask ) ) \n return x * x_mask \n def _causal_padding ( self , x ) : \n if self . kernel_size == <NUM_LIT> : \n return x \n pad_l = self . kernel_size - <NUM_LIT> \n pad_r = <NUM_LIT> \n padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] \n x = F . pad ( x , commons . convert_pad_shape ( padding ) ) \n return x \n def _same_padding ( self , x ) : \n if self . kernel_size == <NUM_LIT> : \n return x \n pad_l = ( self . kernel_size - <NUM_LIT> ) // <NUM_LIT> \n pad_r = self . kernel_size // <NUM_LIT> \n padding = [ [ <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> ] , [ pad_l , pad_r ] ] \n x = F . pad ( x , commons . convert_pad_shape ( padding ) ) \n return x"}, {"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor \n import pyworld \n import numpy as np \n class HarvestF0Predictor ( F0Predictor ) : \n def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : \n self . hop_length = hop_length \n self . f0_min = f0_min \n self . f0_max = f0_max \n self . sampling_rate = sampling_rate \n def interpolate_f0 ( self , f0 ) : \n data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) \n vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) \n vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> \n vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> \n ip_data = data \n frame_number = data . size \n last_value = <NUM_LIT> \n for i in range ( frame_number ) : \n if data [ i ] <= <NUM_LIT> : \n j = i + <NUM_LIT> \n for j in range ( i + <NUM_LIT> , frame_number ) : \n if data [ j ] > <NUM_LIT> : \n break", "output": "if j < frame_number - <NUM_LIT> : \n if last_value > <NUM_LIT> : \n step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) \n for k in range ( i , j ) : \n ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) \n else : \n for k in range ( i , j ) : \n ip_data [ k ] = data [ j ] \n else : \n for k in range ( i , frame_number ) : \n ip_data [ k ] = last_value \n else : \n ip_data [ i ] = data [ i ] \n last_value = data [ i ] \n return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] \n def resize_f0 ( self , x , target_len ) : \n source = np . array ( x ) \n source [ source < <NUM_LIT> ] = np . nan \n target = np . interp ( \n np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , \n np . arange ( <NUM_LIT> , len ( source ) ) , \n source , \n ) \n res = np . nan_to_num ( target ) \n return res \n def compute_f0 ( self , wav , p_len = None ) : \n if p_len is None : \n p_len = wav . shape [ <NUM_LIT> ] // self . hop_length \n f0 , t = pyworld . harvest ( \n wav . astype ( np . double ) , \n fs = self . sampling_rate , \n f0_ceil = self . f0_max , \n f0_floor = self . f0_min , \n frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , \n ) \n f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . fs ) \n return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] \n def compute_f0_uv ( self , wav , p_len = None ) : \n if p_len is None : \n p_len = wav . shape [ <NUM_LIT> ] // self . hop_length \n f0 , t = pyworld . harvest ( \n wav . astype ( np . double ) , \n fs = self . sampling_rate , \n f0_floor = self . f0_min , \n f0_ceil = self . f0_max , \n frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , \n ) \n f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) \n return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) )"}, {"input": "import os \n import sys \n import numpy as np \n import pyworld \n import torchcrepe \n import torch \n import parselmouth \n import tqdm \n from multiprocessing import Process , cpu_count \n current_directory = os . getcwd ( ) \n sys . path . append ( current_directory ) \n from rvc . lib . utils import load_audio \n exp_dir = sys . argv [ <NUM_LIT> ] \n f0_method = sys . argv [ <NUM_LIT> ] \n num_processes = cpu_count ( ) \n try : \n hop_length = int ( sys . argv [ <NUM_LIT> ] ) \n except ValueError : \n hop_length = <NUM_LIT> \n DoFormant = False \n Quefrency = <NUM_LIT> \n Timbre = <NUM_LIT> \n class FeatureInput : \n def __init__ ( self , sample_rate = <NUM_LIT> , hop_size = <NUM_LIT> ) : \n self . fs = sample_rate \n self . hop = hop_size \n self . f0_method_dict = self . get_f0_method_dict ( ) \n self . f0_bin = <NUM_LIT> \n self . f0_max = <NUM_LIT> \n self . f0_min = <NUM_LIT> \n self . f0_mel_min = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_min / <NUM_LIT> ) \n self . f0_mel_max = <NUM_LIT> * np . log ( <NUM_LIT> + self . f0_max / <NUM_LIT> ) \n def mncrepe ( self , method , x , p_len , hop_length ) : \n f0 = None \n torch_device_index = <NUM_LIT> \n torch_device = ( \n torch . device ( f\"<STR_LIT>\" ) \n if torch . cuda . is_available ( ) \n else ( \n torch . device ( \"<STR_LIT>\" ) \n if torch . backends . mps . is_available ( ) \n else torch . device ( \"<STR_LIT>\" ) \n ) \n ) \n audio = torch . from_numpy ( x . astype ( np . float32 ) ) . to ( torch_device , copy = True ) \n audio /= torch . quantile ( torch . abs ( audio ) , <NUM_LIT> ) \n audio = torch . unsqueeze ( audio , dim = <NUM_LIT> ) \n if audio . ndim == <NUM_LIT> and audio . shape [ <NUM_LIT> ] > <NUM_LIT> : \n audio = torch . mean ( audio , dim = <NUM_LIT> , keepdim = True ) . detach ( ) \n audio = audio . detach ( ) \n if method == \"<STR_LIT>\" : \n pitch = torchcrepe . predict ( \n audio , \n self . fs , \n hop_length , \n self . f0_min , \n self . f0_max , \n \"<STR_LIT>\" , \n batch_size = hop_length * <NUM_LIT> , \n device = torch_device , \n pad = True , \n )", "output": "p_len = p_len or x . shape [ <NUM_LIT> ] // hop_length \n source = np . array ( pitch . squeeze ( <NUM_LIT> ) . cpu ( ) . float ( ) . numpy ( ) ) \n source [ source < <NUM_LIT> ] = np . nan \n target = np . interp ( \n np . arange ( <NUM_LIT> , len ( source ) * p_len , len ( source ) ) / p_len , \n np . arange ( <NUM_LIT> , len ( source ) ) , \n source , \n ) \n f0 = np . nan_to_num ( target ) \n return f0 \n def get_pm ( self , x , p_len ) : \n f0 = ( \n parselmouth . Sound ( x , self . fs ) \n . to_pitch_ac ( \n time_step = <NUM_LIT> / <NUM_LIT> , \n voicing_threshold = <NUM_LIT> , \n pitch_floor = self . f0_min , \n pitch_ceiling = self . f0_max , \n ) \n . selected_array [ \"<STR_LIT>\" ] \n ) \n return np . pad ( \n f0 , \n [ \n [ \n max ( <NUM_LIT> , ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , \n max ( <NUM_LIT> , p_len - len ( f0 ) - ( p_len - len ( f0 ) + <NUM_LIT> ) // <NUM_LIT> ) , \n ] \n ] , \n mode = \"<STR_LIT>\" , \n ) \n def get_harvest ( self , x ) : \n f0_spectral = pyworld . harvest ( \n x . astype ( np . double ) , \n fs = self . fs , \n f0_ceil = self . f0_max , \n f0_floor = self . f0_min , \n frame_period = <NUM_LIT> * self . hop / self . fs , \n ) \n return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) \n def get_dio ( self , x ) : \n f0_spectral = pyworld . dio ( \n x . astype ( np . double ) , \n fs = self . fs , \n f0_ceil = self . f0_max , \n f0_floor = self . f0_min , \n frame_period = <NUM_LIT> * self . hop / self . fs , \n ) \n return pyworld . stonemask ( x . astype ( np . double ) , * f0_spectral , self . fs ) \n def get_rmvpe ( self , x ) : \n if not hasattr ( self , \"<STR_LIT>\" ) : \n from rvc . lib . rmvpe import RMVPE \n self . model_rmvpe = RMVPE ( \"<STR_LIT>\" , is_half = False , device = \"<STR_LIT>\" ) \n return self . model_rmvpe . infer_from_audio ( x , thred = <NUM_LIT> ) \n def get_f0_method_dict ( self ) : \n return { \n \"<STR_LIT>\" : self . get_pm , \n \"<STR_LIT>\" : self . get_harvest , \n \"<STR_LIT>\" : self . get_dio , \n \"<STR_LIT>\" : self . get_rmvpe , \n } \n def compute_f0 ( self , path , f0_method , hop_length ) : \n x = load_audio ( path , self . fs ) \n p_len = x . shape [ <NUM_LIT> ] // self . hop \n if f0_method in self . f0_method_dict : \n f0 = ( \n self . f0_method_dict [ f0_method ] ( x , p_len ) \n if f0_method == \"<STR_LIT>\" \n else self . f0_method_dict [ f0_method ] ( x ) \n ) \n elif f0_method == \"<STR_LIT>\" : \n f0 = self . mncrepe ( f0_method , x , p_len , hop_length ) \n return f0 \n def coarse_f0 ( self , f0 ) : \n f0_mel = <NUM_LIT> * np . log ( <NUM_LIT> + f0 / <NUM_LIT> ) \n f0_mel [ f0_mel > <NUM_LIT> ] = ( f0_mel [ f0_mel > <NUM_LIT> ] - self . f0_mel_min ) * ( \n self . f0_bin - <NUM_LIT> \n ) / ( self . f0_mel_max - self . f0_mel_min ) + <NUM_LIT> \n f0_mel [ f0_mel <= <NUM_LIT> ] = <NUM_LIT> \n f0_mel [ f0_mel > self . f0_bin - <NUM_LIT> ] = self . f0_bin - <NUM_LIT> \n f0_coarse = np . rint ( f0_mel ) . astype ( int ) \n assert f0_coarse . max ( ) <= <NUM_LIT> and f0_coarse . min ( ) >= <NUM_LIT> , ( \n f0_coarse . max ( ) , \n f0_coarse . min ( ) , \n ) \n return f0_coarse \n def process_paths ( self , paths , f0_method , hop_length , thread_n ) : \n if len ( paths ) == <NUM_LIT> : \n print ( \"<STR_LIT>\" ) \n return \n with tqdm . tqdm ( total = len ( paths ) , leave = True , position = thread_n ) as pbar : \n description = f\"<STR_LIT>\" \n pbar . set_description ( description ) \n for idx , ( inp_path , opt_path1 , opt_path2 ) in enumerate ( paths ) : \n try : \n if os . path . exists ( opt_path1 + \"<STR_LIT>\" ) and os . path . exists ( \n opt_path2 + \"<STR_LIT>\" \n ) : \n pbar . update ( <NUM_LIT> ) \n continue \n feature_pit = self . compute_f0 ( inp_path , f0_method , hop_length ) \n np . save ( \n opt_path2 , \n feature_pit , \n allow_pickle = False , \n ) \n coarse_pit = self . coarse_f0 ( feature_pit ) \n np . save ( \n opt_path1 , \n coarse_pit , \n allow_pickle = False , \n ) \n pbar . update ( <NUM_LIT> ) \n except Exception as error : \n print ( f\"<STR_LIT>\" ) \n if __name__ == \"<STR_LIT>\" : \n feature_input = FeatureInput ( ) \n paths = [ ] \n input_root = f\"<STR_LIT>\" \n output_root1 = f\"<STR_LIT>\" \n output_root2 = f\"<STR_LIT>\" \n os . makedirs ( output_root1 , exist_ok = True ) \n os . makedirs ( output_root2 , exist_ok = True ) \n for name in sorted ( list ( os . listdir ( input_root ) ) ) : \n input_path = f\"<STR_LIT>\" \n if \"<STR_LIT>\" in input_path : \n continue \n output_path1 = f\"<STR_LIT>\" \n output_path2 = f\"<STR_LIT>\" \n paths . append ( [ input_path , output_path1 , output_path2 ] ) \n processes = [ ] \n print ( \"<STR_LIT>\" + f0_method ) \n for i in range ( num_processes ) : \n p = Process ( \n target = feature_input . process_paths , \n args = ( paths [ i : : num_processes ] , f0_method , hop_length , i ) , \n ) \n processes . append ( p ) \n p . start ( ) \n for i in range ( num_processes ) : \n processes [ i ] . join ( )"}, {"input": "import numpy as np \n import matplotlib . pyplot as plt \n import librosa . display \n import librosa \n def calculate_features ( y , sr ) : \n stft = np . abs ( librosa . stft ( y ) ) \n duration = librosa . get_duration ( y = y , sr = sr ) \n cent = librosa . feature . spectral_centroid ( S = stft , sr = sr ) [ <NUM_LIT> ] \n bw = librosa . feature . spectral_bandwidth ( S = stft , sr = sr ) [ <NUM_LIT> ] \n rolloff = librosa . feature . spectral_rolloff ( S = stft , sr = sr ) [ <NUM_LIT> ] \n return stft , duration , cent , bw , rolloff \n def plot_title ( title ) : \n plt . suptitle ( title , fontsize = <NUM_LIT> , fontweight = \"<STR_LIT>\" ) \n def plot_spectrogram ( y , sr , stft , duration , cmap = \"<STR_LIT>\" ) : \n plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n plt . imshow ( \n librosa . amplitude_to_db ( stft , ref = np . max ) , \n origin = \"<STR_LIT>\" , \n extent = [ <NUM_LIT> , duration , <NUM_LIT> , sr / <NUM_LIT> ] , \n aspect = \"<STR_LIT>\" , \n cmap = cmap , \n ) \n plt . colorbar ( format = \"<STR_LIT>\" ) \n plt . xlabel ( \"<STR_LIT>\" ) \n plt . ylabel ( \"<STR_LIT>\" ) \n plt . title ( \"<STR_LIT>\" ) \n def plot_waveform ( y , sr , duration ) : \n plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n librosa . display . waveshow ( y , sr = sr ) \n plt . xlabel ( \"<STR_LIT>\" ) \n plt . ylabel ( \"<STR_LIT>\" ) \n plt . title ( \"<STR_LIT>\" ) \n def plot_features ( times , cent , bw , rolloff , duration ) : \n plt . subplot ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n plt . plot ( times , cent , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) \n plt . plot ( times , bw , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" ) \n plt . plot ( times , rolloff , label = \"<STR_LIT>\" , color = \"<STR_LIT>\" )", "output": "plt . xlabel ( \"<STR_LIT>\" ) \n plt . title ( \"<STR_LIT>\" ) \n plt . legend ( ) \n def analyze_audio ( audio_file , save_plot_path = \"<STR_LIT>\" ) : \n y , sr = librosa . load ( audio_file ) \n stft , duration , cent , bw , rolloff = calculate_features ( y , sr ) \n plt . figure ( figsize = ( <NUM_LIT> , <NUM_LIT> ) ) \n plot_title ( \"<STR_LIT>\" + \"<STR_LIT>\" + audio_file . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] ) \n plot_spectrogram ( y , sr , stft , duration ) \n plot_waveform ( y , sr , duration ) \n plot_features ( librosa . times_like ( cent ) , cent , bw , rolloff , duration ) \n plt . tight_layout ( ) \n if save_plot_path : \n plt . savefig ( save_plot_path , bbox_inches = \"<STR_LIT>\" , dpi = <NUM_LIT> ) \n plt . close ( ) \n audio_info = \n return audio_info , save_plot_path"}, {"input": "import gradio as gr \n from assets . version_checker import compare_version \n from assets . i18n . i18n import I18nAuto \n i18n = I18nAuto ( ) \n def version_tab ( ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n version_check = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n interactive = False , \n ) \n version_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n version_button . click ( \n fn = compare_version , \n inputs = [ ] ,", "output": "outputs = [ version_check ] , \n )"}, {"input": "import os , sys \n import json \n from pathlib import Path \n from locale import getdefaultlocale \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n class I18nAuto : \n LANGUAGE_PATH = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def __init__ ( self , language = None ) : \n with open ( \n os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" \n ) as file : \n config = json . load ( file ) \n override = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n lang_prefix = config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n self . language = lang_prefix \n if override == False : \n language = language or getdefaultlocale ( ) [ <NUM_LIT> ] \n lang_prefix = language [ : <NUM_LIT> ] if language is not None else \"<STR_LIT>\" \n available_languages = self . _get_available_languages ( ) \n matching_languages = [ \n lang for lang in available_languages if lang . startswith ( lang_prefix ) \n ] \n self . language = matching_languages [ <NUM_LIT> ] if matching_languages else \"<STR_LIT>\" \n self . language_map = self . _load_language_list ( ) \n def _load_language_list ( self ) : \n try : \n file_path = Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" \n with open ( file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n return json . load ( file )", "output": "except FileNotFoundError : \n raise FileNotFoundError ( \n f\"<STR_LIT>\" \n ) \n def _get_available_languages ( self ) : \n language_files = [ path . stem for path in Path ( self . LANGUAGE_PATH ) . glob ( \"<STR_LIT>\" ) ] \n return language_files \n def _language_exists ( self , language ) : \n return ( Path ( self . LANGUAGE_PATH ) / f\"<STR_LIT>\" ) . exists ( ) \n def __call__ ( self , key ) : \n return self . language_map . get ( key , key )"}, {"input": "import os \n import socket \n import subprocess \n import time \n import requests \n import sys \n import json \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n env_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n host = \"<STR_LIT>\" \n port = <NUM_LIT> \n sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) \n sock . settimeout ( <NUM_LIT> ) \n def start_flask ( ) : \n try : \n sock . connect ( ( host , port ) ) \n print ( \n f\"<STR_LIT>\" \n ) \n print ( \"<STR_LIT>\" )", "output": "sock . close ( ) \n requests . post ( \"<STR_LIT>\" ) \n time . sleep ( <NUM_LIT> ) \n script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n try : \n subprocess . Popen ( \n [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE \n ) \n except Exception as e : \n print ( f\"<STR_LIT>\" ) \n print ( e ) \n except Exception as e : \n sock . close ( ) \n script_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n try : \n subprocess . Popen ( \n [ env_path , script_path ] , creationflags = subprocess . CREATE_NEW_CONSOLE \n ) \n except Exception as e : \n print ( \"<STR_LIT>\" ) \n print ( e ) \n def load_config_flask ( ) : \n with open ( config_file , \"<STR_LIT>\" ) as file : \n config = json . load ( file ) \n return config [ \"<STR_LIT>\" ] \n def save_config ( value ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n config = json . load ( file ) \n config [ \"<STR_LIT>\" ] = value \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n json . dump ( config , file , indent = <NUM_LIT> )"}, {"input": "import os , sys \n import gradio as gr \n import regex as re \n import shutil \n import datetime \n import random \n from core import ( \n run_infer_script , \n run_batch_infer_script , \n ) \n from assets . i18n . i18n import I18nAuto \n from rvc . lib . utils import format_title \n i18n = I18nAuto ( ) \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n model_root = os . path . join ( now_dir , \"<STR_LIT>\" ) \n audio_root = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n model_root_relative = os . path . relpath ( model_root , now_dir ) \n audio_root_relative = os . path . relpath ( audio_root , now_dir ) \n sup_audioext = { \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n } \n names = [ \n os . path . join ( root , file ) \n for root , _ , files in os . walk ( model_root_relative , topdown = False ) \n for file in files \n if ( \n file . endswith ( ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n and not ( file . startswith ( \"<STR_LIT>\" ) or file . startswith ( \"<STR_LIT>\" ) ) \n ) \n ] \n indexes_list = [ \n os . path . join ( root , name ) \n for root , _ , files in os . walk ( model_root_relative , topdown = False ) \n for name in files \n if name . endswith ( \"<STR_LIT>\" ) and \"<STR_LIT>\" not in name \n ] \n audio_paths = [ \n os . path . join ( root , name ) \n for root , _ , files in os . walk ( audio_root_relative , topdown = False ) \n for name in files \n if name . endswith ( tuple ( sup_audioext ) ) \n and root == audio_root_relative \n and \"<STR_LIT>\" not in name \n ] \n def output_path_fn ( input_audio_path ) : \n original_name_without_extension = os . path . basename ( input_audio_path ) . rsplit ( \"<STR_LIT>\" , <NUM_LIT> ) [ \n <NUM_LIT> \n ] \n new_name = original_name_without_extension + \"<STR_LIT>\" \n output_path = os . path . join ( os . path . dirname ( input_audio_path ) , new_name ) \n return output_path \n def change_choices ( ) : \n names = [ \n os . path . join ( root , file ) \n for root , _ , files in os . walk ( model_root_relative , topdown = False ) \n for file in files \n if ( \n file . endswith ( ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n and not ( file . startswith ( \"<STR_LIT>\" ) or file . startswith ( \"<STR_LIT>\" ) ) \n ) \n ] \n indexes_list = [ \n os . path . join ( root , name ) \n for root , _ , files in os . walk ( model_root_relative , topdown = False ) \n for name in files \n if name . endswith ( \"<STR_LIT>\" ) and \"<STR_LIT>\" not in name \n ] \n audio_paths = [ \n os . path . join ( root , name ) \n for root , _ , files in os . walk ( audio_root_relative , topdown = False ) \n for name in files \n if name . endswith ( tuple ( sup_audioext ) ) \n and root == audio_root_relative \n and \"<STR_LIT>\" not in name \n ] \n return ( \n { \"<STR_LIT>\" : sorted ( names ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : sorted ( indexes_list ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : sorted ( audio_paths ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) \n def get_indexes ( ) : \n indexes_list = [ \n os . path . join ( dirpath , filename ) \n for dirpath , _ , filenames in os . walk ( model_root_relative ) \n for filename in filenames \n if filename . endswith ( \"<STR_LIT>\" ) and \"<STR_LIT>\" not in filename \n ] \n return indexes_list if indexes_list else \"<STR_LIT>\" \n def save_to_wav ( record_button ) : \n if record_button is None : \n pass \n else : \n path_to_file = record_button \n new_name = datetime . datetime . now ( ) . strftime ( \"<STR_LIT>\" ) + \"<STR_LIT>\" \n target_path = os . path . join ( audio_root_relative , os . path . basename ( new_name ) ) \n shutil . move ( path_to_file , target_path ) \n return target_path , output_path_fn ( target_path ) \n def save_to_wav2 ( upload_audio ) : \n file_path = upload_audio \n formated_name = format_title ( os . path . basename ( file_path ) ) \n target_path = os . path . join ( audio_root_relative , formated_name ) \n if os . path . exists ( target_path ) : \n os . remove ( target_path ) \n shutil . copy ( file_path , target_path ) \n return target_path , output_path_fn ( target_path ) \n def delete_outputs ( ) : \n gr . Info ( f\"<STR_LIT>\" ) \n for root , _ , files in os . walk ( audio_root_relative , topdown = False ) : \n for name in files : \n if name . endswith ( tuple ( sup_audioext ) ) and name . __contains__ ( \"<STR_LIT>\" ) : \n os . remove ( os . path . join ( root , name ) ) \n def match_index ( model_file_value ) : \n if model_file_value : \n model_folder = os . path . dirname ( model_file_value ) \n index_files = get_indexes ( ) \n for index_file in index_files : \n if os . path . dirname ( index_file ) == model_folder : \n return index_file \n return \"<STR_LIT>\" \n def inference_tab ( ) : \n default_weight = random . choice ( names ) if names else None \n with gr . Row ( ) : \n with gr . Row ( ) : \n model_file = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = sorted ( names , key = lambda path : os . path . getsize ( path ) ) , \n interactive = True , \n value = default_weight , \n allow_custom_value = True , \n ) \n index_file = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = get_indexes ( ) , \n value = match_index ( default_weight ) if default_weight else \"<STR_LIT>\" , \n interactive = True , \n allow_custom_value = True , \n ) \n with gr . Column ( ) : \n refresh_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n unload_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n unload_button . click ( \n fn = lambda : ( \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) , \n inputs = [ ] , \n outputs = [ model_file , index_file ] , \n ) \n model_file . select ( \n fn = lambda model_file_value : match_index ( model_file_value ) , \n inputs = [ model_file ] , \n outputs = [ index_file ] , \n ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n with gr . Column ( ) : \n upload_audio = gr . Audio ( \n label = i18n ( \"<STR_LIT>\" ) , type = \"<STR_LIT>\" , editable = False \n ) \n with gr . Row ( ) : \n audio = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = sorted ( audio_paths ) , \n value = audio_paths [ <NUM_LIT> ] if audio_paths else \"<STR_LIT>\" , \n interactive = True , \n allow_custom_value = True , \n ) \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) , open = False ) : \n with gr . Column ( ) : \n clear_outputs_infer = gr . Button ( \n i18n ( \"<STR_LIT>\" ) \n ) \n output_path = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = ( \n output_path_fn ( audio_paths [ <NUM_LIT> ] ) \n if audio_paths \n else os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n ) , \n interactive = True , \n ) \n export_format = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n split_audio = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = False , \n interactive = True , \n ) \n autotune = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = False , \n interactive = True , \n ) \n clean_audio = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = False , \n interactive = True , \n ) \n clean_strength = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = False , \n value = <NUM_LIT> , \n interactive = True , \n ) \n pitch = gr . Slider ( \n minimum = - <NUM_LIT> , \n maximum = <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n filter_radius = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n step = <NUM_LIT> , \n interactive = True , \n ) \n index_rate = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n )", "output": "rms_mix_rate = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n protect = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n hop_length = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = False , \n value = <NUM_LIT> , \n interactive = True , \n ) \n with gr . Column ( ) : \n f0method = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n choices = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n convert_button1 = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n with gr . Row ( ) : \n vc_output1 = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n ) \n vc_output2 = gr . Audio ( label = i18n ( \"<STR_LIT>\" ) ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n input_folder_batch = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n value = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n interactive = True , \n ) \n output_folder_batch = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n value = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n interactive = True , \n ) \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) , open = False ) : \n with gr . Column ( ) : \n clear_outputs_batch = gr . Button ( \n i18n ( \"<STR_LIT>\" ) \n ) \n export_format_batch = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n split_audio_batch = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = False , \n interactive = True , \n ) \n autotune_batch = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = False , \n interactive = True , \n ) \n clean_audio_batch = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = False , \n interactive = True , \n ) \n clean_strength_batch = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = False , \n value = <NUM_LIT> , \n interactive = True , \n ) \n pitch_batch = gr . Slider ( \n minimum = - <NUM_LIT> , \n maximum = <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n filter_radius_batch = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n step = <NUM_LIT> , \n interactive = True , \n ) \n index_rate_batch = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n rms_mix_rate_batch = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n protect_batch = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n hop_length_batch = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = False , \n value = <NUM_LIT> , \n interactive = True , \n ) \n with gr . Column ( ) : \n f0method_batch = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n choices = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n convert_button2 = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n with gr . Row ( ) : \n vc_output3 = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n ) \n def toggle_visible ( checkbox ) : \n return { \"<STR_LIT>\" : checkbox , \"<STR_LIT>\" : \"<STR_LIT>\" } \n def toggle_visible_hop_length ( f0method ) : \n if f0method == \"<STR_LIT>\" or f0method == \"<STR_LIT>\" : \n return { \"<STR_LIT>\" : True , \"<STR_LIT>\" : \"<STR_LIT>\" } \n return { \"<STR_LIT>\" : False , \"<STR_LIT>\" : \"<STR_LIT>\" } \n clean_audio . change ( \n fn = toggle_visible , \n inputs = [ clean_audio ] , \n outputs = [ clean_strength ] , \n ) \n clean_audio_batch . change ( \n fn = toggle_visible , \n inputs = [ clean_audio_batch ] , \n outputs = [ clean_strength_batch ] , \n ) \n f0method . change ( \n fn = toggle_visible_hop_length , \n inputs = [ f0method ] , \n outputs = [ hop_length ] , \n ) \n f0method_batch . change ( \n fn = toggle_visible_hop_length , \n inputs = [ f0method_batch ] , \n outputs = [ hop_length_batch ] , \n ) \n refresh_button . click ( \n fn = change_choices , \n inputs = [ ] , \n outputs = [ model_file , index_file , audio ] , \n ) \n audio . change ( \n fn = output_path_fn , \n inputs = [ audio ] , \n outputs = [ output_path ] , \n ) \n upload_audio . upload ( \n fn = save_to_wav2 , \n inputs = [ upload_audio ] , \n outputs = [ audio , output_path ] , \n ) \n upload_audio . stop_recording ( \n fn = save_to_wav , \n inputs = [ upload_audio ] , \n outputs = [ audio , output_path ] , \n ) \n clear_outputs_infer . click ( \n fn = delete_outputs , \n inputs = [ ] , \n outputs = [ ] , \n ) \n clear_outputs_batch . click ( \n fn = delete_outputs , \n inputs = [ ] , \n outputs = [ ] , \n ) \n convert_button1 . click ( \n fn = run_infer_script , \n inputs = [ \n pitch , \n filter_radius , \n index_rate , \n rms_mix_rate , \n protect , \n hop_length , \n f0method , \n audio , \n output_path , \n model_file , \n index_file , \n split_audio , \n autotune , \n clean_audio , \n clean_strength , \n export_format , \n ] , \n outputs = [ vc_output1 , vc_output2 ] , \n ) \n convert_button2 . click ( \n fn = run_batch_infer_script , \n inputs = [ \n pitch_batch , \n filter_radius_batch , \n index_rate_batch , \n rms_mix_rate_batch , \n protect_batch , \n hop_length_batch , \n f0method_batch , \n input_folder_batch , \n output_folder_batch , \n model_file , \n index_file , \n split_audio_batch , \n autotune_batch , \n clean_audio_batch , \n clean_strength_batch , \n export_format_batch , \n ] , \n outputs = [ vc_output3 ] , \n )"}, {"input": "import torch \n import sys \n import os \n import datetime \n from utils import ( \n get_hparams , \n plot_spectrogram_to_numpy , \n summarize , \n load_checkpoint , \n save_checkpoint , \n latest_checkpoint_path , \n ) \n from random import randint , shuffle \n from time import sleep \n from time import time as ttime \n from torch . cuda . amp import GradScaler , autocast \n from torch . nn import functional as F \n from torch . nn . parallel import DistributedDataParallel as DDP \n from torch . utils . data import DataLoader \n from torch . utils . tensorboard import SummaryWriter \n import torch . distributed as dist \n import torch . multiprocessing as mp \n now_dir = os . getcwd ( ) \n sys . path . append ( os . path . join ( now_dir ) ) \n from data_utils import ( \n DistributedBucketSampler , \n TextAudioCollate , \n TextAudioCollateMultiNSFsid , \n TextAudioLoader , \n TextAudioLoaderMultiNSFsid , \n ) \n from losses import ( \n discriminator_loss , \n feature_loss , \n generator_loss , \n kl_loss , \n ) \n from mel_processing import mel_spectrogram_torch , spec_to_mel_torch \n from rvc . train . process . extract_model import extract_model \n from rvc . lib . infer_pack import commons \n hps = get_hparams ( ) \n if hps . version == \"<STR_LIT>\" : \n from rvc . lib . infer_pack . models import MultiPeriodDiscriminator \n from rvc . lib . infer_pack . models import SynthesizerTrnMs256NSFsid as RVC_Model_f0 \n from rvc . lib . infer_pack . models import ( \n SynthesizerTrnMs256NSFsid_nono as RVC_Model_nof0 , \n ) \n elif hps . version == \"<STR_LIT>\" : \n from rvc . lib . infer_pack . models import ( \n SynthesizerTrnMs768NSFsid as RVC_Model_f0 , \n SynthesizerTrnMs768NSFsid_nono as RVC_Model_nof0 , \n MultiPeriodDiscriminatorV2 as MultiPeriodDiscriminator , \n ) \n os . environ [ \"<STR_LIT>\" ] = hps . gpus . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n n_gpus = len ( hps . gpus . split ( \"<STR_LIT>\" ) ) \n torch . backends . cudnn . deterministic = False \n torch . backends . cudnn . benchmark = False \n global_step = <NUM_LIT> \n lowest_value = { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : float ( \"<STR_LIT>\" ) , \"<STR_LIT>\" : <NUM_LIT> } \n last_loss_gen_all = <NUM_LIT> \n epochs_since_last_lowest = <NUM_LIT> \n class EpochRecorder : \n def __init__ ( self ) : \n self . last_time = ttime ( ) \n def record ( self ) : \n now_time = ttime ( ) \n elapsed_time = now_time - self . last_time \n self . last_time = now_time", "output": "elapsed_time = round ( elapsed_time , <NUM_LIT> ) \n elapsed_time_str = str ( datetime . timedelta ( seconds = int ( elapsed_time ) ) ) \n current_time = datetime . datetime . now ( ) . strftime ( \"<STR_LIT>\" ) \n return f\"<STR_LIT>\" \n def main ( ) : \n n_gpus = torch . cuda . device_count ( ) \n if torch . cuda . is_available ( ) == False and torch . backends . mps . is_available ( ) == True : \n n_gpus = <NUM_LIT> \n if n_gpus < <NUM_LIT> : \n print ( \"<STR_LIT>\" ) \n n_gpus = <NUM_LIT> \n children = [ ] \n pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n with open ( pid_file_path , \"<STR_LIT>\" ) as pid_file : \n for i in range ( n_gpus ) : \n subproc = mp . Process ( \n target = run , \n args = ( i , n_gpus , hps ) , \n ) \n children . append ( subproc ) \n subproc . start ( ) \n pid_file . write ( str ( subproc . pid ) + \"<STR_LIT>\" ) \n for i in range ( n_gpus ) : \n children [ i ] . join ( ) \n def run ( \n rank , \n n_gpus , \n hps , \n ) : \n global global_step \n if rank == <NUM_LIT> : \n writer = SummaryWriter ( log_dir = hps . model_dir ) \n writer_eval = SummaryWriter ( log_dir = os . path . join ( hps . model_dir , \"<STR_LIT>\" ) ) \n os . environ [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n os . environ [ \"<STR_LIT>\" ] = str ( randint ( <NUM_LIT> , <NUM_LIT> ) ) \n dist . init_process_group ( \n backend = \"<STR_LIT>\" , init_method = \"<STR_LIT>\" , world_size = n_gpus , rank = rank \n ) \n torch . manual_seed ( hps . train . seed ) \n if torch . cuda . is_available ( ) : \n torch . cuda . set_device ( rank ) \n if hps . if_f0 == <NUM_LIT> : \n train_dataset = TextAudioLoaderMultiNSFsid ( hps . data ) \n else : \n train_dataset = TextAudioLoader ( hps . data ) \n train_sampler = DistributedBucketSampler ( \n train_dataset , \n hps . train . batch_size * n_gpus , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n num_replicas = n_gpus , \n rank = rank , \n shuffle = True , \n ) \n if hps . if_f0 == <NUM_LIT> : \n collate_fn = TextAudioCollateMultiNSFsid ( ) \n else : \n collate_fn = TextAudioCollate ( ) \n train_loader = DataLoader ( \n train_dataset , \n num_workers = <NUM_LIT> , \n shuffle = False , \n pin_memory = True , \n collate_fn = collate_fn , \n batch_sampler = train_sampler , \n persistent_workers = True , \n prefetch_factor = <NUM_LIT> , \n ) \n if hps . if_f0 == <NUM_LIT> : \n net_g = RVC_Model_f0 ( \n hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , \n hps . train . segment_size // hps . data . hop_length , \n ** hps . model , \n is_half = hps . train . fp16_run , \n sr = hps . sample_rate , \n ) \n else : \n net_g = RVC_Model_nof0 ( \n hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , \n hps . train . segment_size // hps . data . hop_length , \n ** hps . model , \n is_half = hps . train . fp16_run , \n ) \n if torch . cuda . is_available ( ) : \n net_g = net_g . cuda ( rank ) \n net_d = MultiPeriodDiscriminator ( hps . model . use_spectral_norm ) \n if torch . cuda . is_available ( ) : \n net_d = net_d . cuda ( rank ) \n optim_g = torch . optim . AdamW ( \n net_g . parameters ( ) , \n hps . train . learning_rate , \n betas = hps . train . betas , \n eps = hps . train . eps , \n ) \n optim_d = torch . optim . AdamW ( \n net_d . parameters ( ) , \n hps . train . learning_rate , \n betas = hps . train . betas , \n eps = hps . train . eps , \n ) \n if torch . cuda . is_available ( ) : \n net_g = DDP ( net_g , device_ids = [ rank ] ) \n net_d = DDP ( net_d , device_ids = [ rank ] ) \n else : \n net_g = DDP ( net_g ) \n net_d = DDP ( net_d ) \n try : \n print ( \"<STR_LIT>\" ) \n _ , _ , _ , epoch_str = load_checkpoint ( \n latest_checkpoint_path ( hps . model_dir , \"<STR_LIT>\" ) , net_d , optim_d \n ) \n _ , _ , _ , epoch_str = load_checkpoint ( \n latest_checkpoint_path ( hps . model_dir , \"<STR_LIT>\" ) , net_g , optim_g \n ) \n global_step = ( epoch_str - <NUM_LIT> ) * len ( train_loader ) \n except : \n epoch_str = <NUM_LIT> \n global_step = <NUM_LIT> \n if hps . pretrainG != \"<STR_LIT>\" : \n if rank == <NUM_LIT> : \n print ( f\"<STR_LIT>\" ) \n if hasattr ( net_g , \"<STR_LIT>\" ) : \n print ( \n net_g . module . load_state_dict ( \n torch . load ( hps . pretrainG , map_location = \"<STR_LIT>\" ) [ \"<STR_LIT>\" ] \n ) \n ) \n else : \n print ( \n net_g . load_state_dict ( \n torch . load ( hps . pretrainG , map_location = \"<STR_LIT>\" ) [ \"<STR_LIT>\" ] \n ) \n ) \n if hps . pretrainD != \"<STR_LIT>\" : \n if rank == <NUM_LIT> : \n print ( f\"<STR_LIT>\" ) \n if hasattr ( net_d , \"<STR_LIT>\" ) : \n print ( \n net_d . module . load_state_dict ( \n torch . load ( hps . pretrainD , map_location = \"<STR_LIT>\" ) [ \"<STR_LIT>\" ] \n ) \n ) \n else : \n print ( \n net_d . load_state_dict ( \n torch . load ( hps . pretrainD , map_location = \"<STR_LIT>\" ) [ \"<STR_LIT>\" ] \n ) \n ) \n scheduler_g = torch . optim . lr_scheduler . ExponentialLR ( \n optim_g , gamma = hps . train . lr_decay , last_epoch = epoch_str - <NUM_LIT> \n ) \n scheduler_d = torch . optim . lr_scheduler . ExponentialLR ( \n optim_d , gamma = hps . train . lr_decay , last_epoch = epoch_str - <NUM_LIT> \n ) \n scaler = GradScaler ( enabled = hps . train . fp16_run ) \n cache = [ ] \n for epoch in range ( epoch_str , hps . train . epochs + <NUM_LIT> ) : \n if rank == <NUM_LIT> : \n train_and_evaluate ( \n rank , \n epoch , \n hps , \n [ net_g , net_d ] , \n [ optim_g , optim_d ] , \n scaler , \n [ train_loader , None ] , \n [ writer , writer_eval ] , \n cache , \n ) \n else : \n train_and_evaluate ( \n rank , \n epoch , \n hps , \n [ net_g , net_d ] , \n [ optim_g , optim_d ] , \n scaler , \n [ train_loader , None ] , \n None , \n cache , \n ) \n scheduler_g . step ( ) \n scheduler_d . step ( ) \n def train_and_evaluate ( rank , epoch , hps , nets , optims , scaler , loaders , writers , cache ) : \n global global_step , last_loss_gen_all , lowest_value , epochs_since_last_lowest \n if epoch == <NUM_LIT> : \n lowest_value = { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : float ( \"<STR_LIT>\" ) , \"<STR_LIT>\" : <NUM_LIT> } \n last_loss_gen_all = <NUM_LIT> \n epochs_since_last_lowest = <NUM_LIT> \n net_g , net_d = nets \n optim_g , optim_d = optims \n train_loader = loaders [ <NUM_LIT> ] if loaders is not None else None \n if writers is not None : \n writer = writers [ <NUM_LIT> ] \n train_loader . batch_sampler . set_epoch ( epoch ) \n net_g . train ( ) \n net_d . train ( ) \n if hps . if_cache_data_in_gpu == True : \n data_iterator = cache \n if cache == [ ] : \n for batch_idx , info in enumerate ( train_loader ) : \n if hps . if_f0 == <NUM_LIT> : \n ( \n phone , \n phone_lengths , \n pitch , \n pitchf , \n spec , \n spec_lengths , \n wave , \n wave_lengths , \n sid , \n ) = info \n else : \n ( \n phone , \n phone_lengths , \n spec , \n spec_lengths , \n wave , \n wave_lengths , \n sid , \n ) = info \n if torch . cuda . is_available ( ) : \n phone = phone . cuda ( rank , non_blocking = True ) \n phone_lengths = phone_lengths . cuda ( rank , non_blocking = True ) \n if hps . if_f0 == <NUM_LIT> : \n pitch = pitch . cuda ( rank , non_blocking = True ) \n pitchf = pitchf . cuda ( rank , non_blocking = True ) \n sid = sid . cuda ( rank , non_blocking = True ) \n spec = spec . cuda ( rank , non_blocking = True ) \n spec_lengths = spec_lengths . cuda ( rank , non_blocking = True ) \n wave = wave . cuda ( rank , non_blocking = True ) \n wave_lengths = wave_lengths . cuda ( rank , non_blocking = True ) \n if hps . if_f0 == <NUM_LIT> : \n cache . append ( \n ( \n batch_idx , \n ( \n phone , \n phone_lengths , \n pitch , \n pitchf , \n spec , \n spec_lengths , \n wave , \n wave_lengths , \n sid , \n ) , \n ) \n ) \n else : \n cache . append ( \n ( \n batch_idx , \n ( \n phone , \n phone_lengths , \n spec , \n spec_lengths , \n wave , \n wave_lengths , \n sid , \n ) , \n ) \n ) \n else : \n shuffle ( cache ) \n else : \n data_iterator = enumerate ( train_loader ) \n epoch_recorder = EpochRecorder ( ) \n for batch_idx , info in data_iterator : \n if hps . if_f0 == <NUM_LIT> : \n ( \n phone , \n phone_lengths , \n pitch , \n pitchf , \n spec , \n spec_lengths , \n wave , \n wave_lengths , \n sid , \n ) = info \n else : \n phone , phone_lengths , spec , spec_lengths , wave , wave_lengths , sid = info \n if ( hps . if_cache_data_in_gpu == False ) and torch . cuda . is_available ( ) : \n phone = phone . cuda ( rank , non_blocking = True ) \n phone_lengths = phone_lengths . cuda ( rank , non_blocking = True ) \n if hps . if_f0 == <NUM_LIT> : \n pitch = pitch . cuda ( rank , non_blocking = True ) \n pitchf = pitchf . cuda ( rank , non_blocking = True ) \n sid = sid . cuda ( rank , non_blocking = True ) \n spec = spec . cuda ( rank , non_blocking = True ) \n spec_lengths = spec_lengths . cuda ( rank , non_blocking = True ) \n wave = wave . cuda ( rank , non_blocking = True ) \n with autocast ( enabled = hps . train . fp16_run ) : \n if hps . if_f0 == <NUM_LIT> : \n ( \n y_hat , \n ids_slice , \n x_mask , \n z_mask , \n ( z , z_p , m_p , logs_p , m_q , logs_q ) , \n ) = net_g ( phone , phone_lengths , pitch , pitchf , spec , spec_lengths , sid ) \n else : \n ( \n y_hat , \n ids_slice , \n x_mask , \n z_mask , \n ( z , z_p , m_p , logs_p , m_q , logs_q ) , \n ) = net_g ( phone , phone_lengths , spec , spec_lengths , sid ) \n mel = spec_to_mel_torch ( \n spec , \n hps . data . filter_length , \n hps . data . n_mel_channels , \n hps . data . sampling_rate , \n hps . data . mel_fmin , \n hps . data . mel_fmax , \n ) \n y_mel = commons . slice_segments ( \n mel , ids_slice , hps . train . segment_size // hps . data . hop_length \n ) \n with autocast ( enabled = False ) : \n y_hat_mel = mel_spectrogram_torch ( \n y_hat . float ( ) . squeeze ( <NUM_LIT> ) , \n hps . data . filter_length , \n hps . data . n_mel_channels , \n hps . data . sampling_rate , \n hps . data . hop_length , \n hps . data . win_length , \n hps . data . mel_fmin , \n hps . data . mel_fmax , \n ) \n if hps . train . fp16_run == True : \n y_hat_mel = y_hat_mel . half ( ) \n wave = commons . slice_segments ( \n wave , ids_slice * hps . data . hop_length , hps . train . segment_size \n ) \n y_d_hat_r , y_d_hat_g , _ , _ = net_d ( wave , y_hat . detach ( ) ) \n with autocast ( enabled = False ) : \n loss_disc , losses_disc_r , losses_disc_g = discriminator_loss ( \n y_d_hat_r , y_d_hat_g \n ) \n optim_d . zero_grad ( ) \n scaler . scale ( loss_disc ) . backward ( ) \n scaler . unscale_ ( optim_d ) \n grad_norm_d = commons . clip_grad_value_ ( net_d . parameters ( ) , None ) \n scaler . step ( optim_d ) \n with autocast ( enabled = hps . train . fp16_run ) : \n y_d_hat_r , y_d_hat_g , fmap_r , fmap_g = net_d ( wave , y_hat ) \n with autocast ( enabled = False ) : \n loss_mel = F . l1_loss ( y_mel , y_hat_mel ) * hps . train . c_mel \n loss_kl = kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) * hps . train . c_kl \n loss_fm = feature_loss ( fmap_r , fmap_g ) \n loss_gen , losses_gen = generator_loss ( y_d_hat_g ) \n loss_gen_all = loss_gen + loss_fm + loss_mel + loss_kl \n if loss_gen_all < lowest_value [ \"<STR_LIT>\" ] : \n lowest_value [ \"<STR_LIT>\" ] = loss_gen_all \n lowest_value [ \"<STR_LIT>\" ] = global_step \n lowest_value [ \"<STR_LIT>\" ] = epoch \n if epoch > lowest_value [ \"<STR_LIT>\" ] : \n print ( \n \"<STR_LIT>\" \n ) \n optim_g . zero_grad ( ) \n scaler . scale ( loss_gen_all ) . backward ( ) \n scaler . unscale_ ( optim_g ) \n grad_norm_g = commons . clip_grad_value_ ( net_g . parameters ( ) , None ) \n scaler . step ( optim_g ) \n scaler . update ( ) \n if rank == <NUM_LIT> : \n if global_step % hps . train . log_interval == <NUM_LIT> : \n lr = optim_g . param_groups [ <NUM_LIT> ] [ \"<STR_LIT>\" ] \n if loss_mel > <NUM_LIT> : \n loss_mel = <NUM_LIT> \n if loss_kl > <NUM_LIT> : \n loss_kl = <NUM_LIT> \n scalar_dict = { \n \"<STR_LIT>\" : loss_gen_all , \n \"<STR_LIT>\" : loss_disc , \n \"<STR_LIT>\" : lr , \n \"<STR_LIT>\" : grad_norm_d , \n \"<STR_LIT>\" : grad_norm_g , \n } \n scalar_dict . update ( \n { \n \"<STR_LIT>\" : loss_fm , \n \"<STR_LIT>\" : loss_mel , \n \"<STR_LIT>\" : loss_kl , \n } \n ) \n scalar_dict . update ( \n { \"<STR_LIT>\" . format ( i ) : v for i , v in enumerate ( losses_gen ) } \n ) \n scalar_dict . update ( \n { \"<STR_LIT>\" . format ( i ) : v for i , v in enumerate ( losses_disc_r ) } \n ) \n scalar_dict . update ( \n { \"<STR_LIT>\" . format ( i ) : v for i , v in enumerate ( losses_disc_g ) } \n ) \n image_dict = { \n \"<STR_LIT>\" : plot_spectrogram_to_numpy ( \n y_mel [ <NUM_LIT> ] . data . cpu ( ) . numpy ( ) \n ) , \n \"<STR_LIT>\" : plot_spectrogram_to_numpy ( \n y_hat_mel [ <NUM_LIT> ] . data . cpu ( ) . numpy ( ) \n ) , \n \"<STR_LIT>\" : plot_spectrogram_to_numpy ( mel [ <NUM_LIT> ] . data . cpu ( ) . numpy ( ) ) , \n } \n summarize ( \n writer = writer , \n global_step = global_step , \n images = image_dict , \n scalars = scalar_dict , \n ) \n global_step += <NUM_LIT> \n if epoch % hps . save_every_epoch == <NUM_LIT> and rank == <NUM_LIT> : \n checkpoint_suffix = \"<STR_LIT>\" . format ( \n global_step if hps . if_latest == <NUM_LIT> else <NUM_LIT> \n ) \n save_checkpoint ( \n net_g , \n optim_g , \n hps . train . learning_rate , \n epoch , \n os . path . join ( hps . model_dir , \"<STR_LIT>\" + checkpoint_suffix ) , \n ) \n save_checkpoint ( \n net_d , \n optim_d , \n hps . train . learning_rate , \n epoch , \n os . path . join ( hps . model_dir , \"<STR_LIT>\" + checkpoint_suffix ) , \n ) \n if rank == <NUM_LIT> and hps . save_every_weights == \"<STR_LIT>\" : \n if hasattr ( net_g , \"<STR_LIT>\" ) : \n ckpt = net_g . module . state_dict ( ) \n else : \n ckpt = net_g . state_dict ( ) \n extract_model ( \n ckpt , \n hps . sample_rate , \n hps . if_f0 , \n hps . name , \n os . path . join ( \n hps . model_dir , \"<STR_LIT>\" . format ( hps . name , epoch , global_step ) \n ) , \n epoch , \n global_step , \n hps . version , \n hps , \n ) \n if hps . overtraining_detector == <NUM_LIT> : \n if lowest_value [ \"<STR_LIT>\" ] < last_loss_gen_all : \n epochs_since_last_lowest += <NUM_LIT> \n else : \n epochs_since_last_lowest = <NUM_LIT> \n if epochs_since_last_lowest >= hps . overtraining_threshold : \n print ( \n \"<STR_LIT>\" . format ( \n lowest_value [ \"<STR_LIT>\" ] , lowest_value [ \"<STR_LIT>\" ] , lowest_value [ \"<STR_LIT>\" ] \n ) \n ) \n os . _exit ( <NUM_LIT> ) \n if rank == <NUM_LIT> : \n if epoch > <NUM_LIT> : \n print ( hps . overtraining_threshold ) \n print ( \n f\"<STR_LIT>\" \n ) \n else : \n print ( \n f\"<STR_LIT>\" \n ) \n last_loss_gen_all = loss_gen_all \n if epoch >= hps . total_epoch and rank == <NUM_LIT> : \n print ( \n f\"<STR_LIT>\" \n ) \n print ( \n f\"<STR_LIT>\" \n ) \n pid_file_path = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n os . remove ( pid_file_path ) \n if hasattr ( net_g , \"<STR_LIT>\" ) : \n ckpt = net_g . module . state_dict ( ) \n else : \n ckpt = net_g . state_dict ( ) \n extract_model ( \n ckpt , \n hps . sample_rate , \n hps . if_f0 , \n hps . name , \n os . path . join ( \n hps . model_dir , \"<STR_LIT>\" . format ( hps . name , epoch , global_step ) \n ) , \n epoch , \n global_step , \n hps . version , \n hps , \n ) \n sleep ( <NUM_LIT> ) \n os . _exit ( <NUM_LIT> ) \n if __name__ == \"<STR_LIT>\" : \n torch . multiprocessing . set_start_method ( \"<STR_LIT>\" ) \n main ( )"}, {"input": "from multiprocessing import cpu_count \n import os \n import sys \n from scipy import signal \n from scipy . io import wavfile \n import librosa \n import numpy as np \n now_directory = os . getcwd ( ) \n sys . path . append ( now_directory ) \n from rvc . lib . utils import load_audio \n from rvc . train . slicer import Slicer \n experiment_directory = sys . argv [ <NUM_LIT> ] \n input_root = sys . argv [ <NUM_LIT> ] \n sampling_rate = int ( sys . argv [ <NUM_LIT> ] ) \n percentage = float ( sys . argv [ <NUM_LIT> ] ) \n num_processes = cpu_count ( ) \n import multiprocessing \n class PreProcess : \n def __init__ ( self , sr , exp_dir , per = <NUM_LIT> ) : \n self . slicer = Slicer ( \n sr = sr , \n threshold = - <NUM_LIT> , \n min_length = <NUM_LIT> , \n min_interval = <NUM_LIT> , \n hop_size = <NUM_LIT> , \n max_sil_kept = <NUM_LIT> , \n ) \n self . sr = sr \n self . b_high , self . a_high = signal . butter ( N = <NUM_LIT> , Wn = <NUM_LIT> , btype = \"<STR_LIT>\" , fs = self . sr ) \n self . per = per \n self . overlap = <NUM_LIT> \n self . tail = self . per + self . overlap \n self . max_amplitude = <NUM_LIT> \n self . alpha = <NUM_LIT> \n self . exp_dir = exp_dir \n self . gt_wavs_dir = f\"<STR_LIT>\" \n self . wavs16k_dir = f\"<STR_LIT>\" \n os . makedirs ( self . exp_dir , exist_ok = True ) \n os . makedirs ( self . gt_wavs_dir , exist_ok = True ) \n os . makedirs ( self . wavs16k_dir , exist_ok = True ) \n def normalize_and_write ( self , tmp_audio , idx0 , idx1 ) : \n tmp_max = np . abs ( tmp_audio ) . max ( ) \n if tmp_max > <NUM_LIT> : \n print ( f\"<STR_LIT>\" ) \n return \n tmp_audio = ( tmp_audio / tmp_max * ( self . max_amplitude * self . alpha ) ) + ( \n <NUM_LIT> - self . alpha \n ) * tmp_audio \n wavfile . write ( \n f\"<STR_LIT>\" , \n self . sr , \n tmp_audio . astype ( np . float32 ) , \n ) \n tmp_audio = librosa . resample ( \n tmp_audio , orig_sr = self . sr , target_sr = <NUM_LIT> \n ) \n wavfile . write ( \n f\"<STR_LIT>\" , \n <NUM_LIT> , \n tmp_audio . astype ( np . float32 ) , \n ) \n def process_audio ( self , path , idx0 ) : \n try : \n audio = load_audio ( path , self . sr ) \n audio = signal . lfilter ( self . b_high , self . a_high , audio ) \n idx1 = <NUM_LIT> \n for audio_segment in self . slicer . slice ( audio ) : \n i = <NUM_LIT> \n while <NUM_LIT> : \n start = int ( self . sr * ( self . per - self . overlap ) * i ) \n i += <NUM_LIT> \n if len ( audio_segment [ start : ] ) > self . tail * self . sr : \n tmp_audio = audio_segment [ \n start : start + int ( self . per * self . sr ) \n ]", "output": "self . normalize_and_write ( tmp_audio , idx0 , idx1 ) \n idx1 += <NUM_LIT> \n else : \n tmp_audio = audio_segment [ start : ] \n idx1 += <NUM_LIT> \n break \n self . normalize_and_write ( tmp_audio , idx0 , idx1 ) \n except Exception as error : \n print ( f\"<STR_LIT>\" ) \n def process_audio_multiprocessing ( self , infos ) : \n for path , idx0 in infos : \n self . process_audio ( path , idx0 ) \n def process_audio_multiprocessing_input_directory ( self , input_root , num_processes ) : \n try : \n infos = [ \n ( f\"<STR_LIT>\" , idx ) \n for idx , name in enumerate ( sorted ( list ( os . listdir ( input_root ) ) ) ) \n ] \n processes = [ ] \n for i in range ( num_processes ) : \n p = multiprocessing . Process ( \n target = self . process_audio_multiprocessing , \n args = ( infos [ i : : num_processes ] , ) , \n ) \n processes . append ( p ) \n p . start ( ) \n for i in range ( num_processes ) : \n processes [ i ] . join ( ) \n except Exception as error : \n print ( error ) \n def preprocess_training_set ( input_root , sr , num_processes , exp_dir , per ) : \n pp = PreProcess ( sr , exp_dir , per ) \n print ( \"<STR_LIT>\" ) \n pp . process_audio_multiprocessing_input_directory ( input_root , num_processes ) \n print ( \"<STR_LIT>\" ) \n if __name__ == \"<STR_LIT>\" : \n preprocess_training_set ( \n input_root , sampling_rate , num_processes , experiment_directory , percentage \n )"}, {"input": "import gradio as gr \n import sys \n import os \n import logging \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n from tabs . inference . inference import inference_tab \n from tabs . train . train import train_tab \n from tabs . extra . extra import extra_tab \n from tabs . report . report import report_tab \n from tabs . download . download import download_tab \n from tabs . tts . tts import tts_tab \n from tabs . voice_blender . voice_blender import voice_blender_tab \n from tabs . settings . presence import presence_tab , load_config_presence \n from tabs . settings . flask_server import flask_server_tab \n from tabs . settings . fake_gpu import fake_gpu_tab , gpu_available , load_fake_gpu \n from tabs . settings . themes import theme_tab \n from tabs . plugins . plugins import plugins_tab \n from tabs . settings . version import version_tab \n from tabs . settings . lang import lang_tab \n from tabs . settings . restart import restart_tab \n import assets . themes . loadThemes as loadThemes \n from assets . i18n . i18n import I18nAuto \n import assets . installation_checker as installation_checker \n from assets . discord_presence import RPCManager \n from assets . flask . server import start_flask , load_config_flask \n from core import run_prerequisites_script \n run_prerequisites_script ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n i18n = I18nAuto ( ) \n if load_config_presence ( ) == True : \n RPCManager . start_presence ( ) \n installation_checker . check_installation ( ) \n logging . getLogger ( \"<STR_LIT>\" ) . disabled = True \n logging . getLogger ( \"<STR_LIT>\" ) . disabled = True \n if load_config_flask ( ) == True : \n print ( \"<STR_LIT>\" ) \n start_flask ( ) \n my_applio = loadThemes . load_json ( ) \n if my_applio : \n pass \n else : \n my_applio = \"<STR_LIT>\" \n with gr . Blocks ( theme = my_applio , title = \"<STR_LIT>\" ) as Applio : \n gr . Markdown ( \"<STR_LIT>\" ) \n gr . Markdown ( \n i18n ( \n \"<STR_LIT>\" \n ) \n ) \n gr . Markdown ( \n i18n ( \n \"<STR_LIT>\" \n ) \n )", "output": "with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n inference_tab ( ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n if gpu_available ( ) or load_fake_gpu ( ) : \n train_tab ( ) \n else : \n gr . Markdown ( \n i18n ( \n \"<STR_LIT>\" \n ) \n ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n tts_tab ( ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n voice_blender_tab ( ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n plugins_tab ( ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n download_tab ( ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n report_tab ( ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n extra_tab ( ) \n with gr . Tab ( i18n ( \"<STR_LIT>\" ) ) : \n presence_tab ( ) \n flask_server_tab ( ) \n if not gpu_available ( ) : \n fake_gpu_tab ( ) \n theme_tab ( ) \n version_tab ( ) \n lang_tab ( ) \n restart_tab ( ) \n if __name__ == \"<STR_LIT>\" : \n port = <NUM_LIT> \n if \"<STR_LIT>\" in sys . argv : \n port_index = sys . argv . index ( \"<STR_LIT>\" ) + <NUM_LIT> \n if port_index < len ( sys . argv ) : \n port = int ( sys . argv [ port_index ] ) \n Applio . launch ( \n favicon_path = \"<STR_LIT>\" , \n share = \"<STR_LIT>\" in sys . argv , \n inbrowser = \"<STR_LIT>\" in sys . argv , \n server_port = port , \n )"}, {"input": "import os \n import torch \n import hashlib \n import datetime \n from collections import OrderedDict \n def replace_keys_in_dict ( d , old_key_part , new_key_part ) : \n if isinstance ( d , OrderedDict ) : \n updated_dict = OrderedDict ( ) \n else : \n updated_dict = { } \n for key , value in d . items ( ) : \n new_key = key . replace ( old_key_part , new_key_part ) \n if isinstance ( value , dict ) : \n value = replace_keys_in_dict ( value , old_key_part , new_key_part ) \n updated_dict [ new_key ] = value \n return updated_dict \n def extract_model ( ckpt , sr , if_f0 , name , model_dir , epoch , step , version , hps ) : \n try :", "output": "print ( f\"<STR_LIT>\" ) \n pth_file = f\"<STR_LIT>\" \n pth_file_old_version_path = os . path . join ( \n model_dir , f\"<STR_LIT>\" \n ) \n opt = OrderedDict ( \n weight = { \n key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key \n } \n ) \n opt [ \"<STR_LIT>\" ] = [ \n hps . data . filter_length // <NUM_LIT> + <NUM_LIT> , \n <NUM_LIT> , \n hps . model . inter_channels , \n hps . model . hidden_channels , \n hps . model . filter_channels , \n hps . model . n_heads , \n hps . model . n_layers , \n hps . model . kernel_size , \n hps . model . p_dropout , \n hps . model . resblock , \n hps . model . resblock_kernel_sizes , \n hps . model . resblock_dilation_sizes , \n hps . model . upsample_rates , \n hps . model . upsample_initial_channel , \n hps . model . upsample_kernel_sizes , \n hps . model . spk_embed_dim , \n hps . model . gin_channels , \n hps . data . sampling_rate , \n ] \n opt [ \"<STR_LIT>\" ] = epoch \n opt [ \"<STR_LIT>\" ] = step \n opt [ \"<STR_LIT>\" ] = sr \n opt [ \"<STR_LIT>\" ] = if_f0 \n opt [ \"<STR_LIT>\" ] = version \n opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) \n hash_input = f\"<STR_LIT>\" \n model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) \n opt [ \"<STR_LIT>\" ] = model_hash \n torch . save ( opt , model_dir ) \n model = torch . load ( model_dir , map_location = torch . device ( \"<STR_LIT>\" ) ) \n torch . save ( \n replace_keys_in_dict ( \n replace_keys_in_dict ( \n model , \"<STR_LIT>\" , \"<STR_LIT>\" \n ) , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n pth_file_old_version_path , \n ) \n os . remove ( model_dir ) \n os . rename ( pth_file_old_version_path , model_dir ) \n except Exception as error : \n print ( error )"}, {"input": "import torch \n def feature_loss ( fmap_r , fmap_g ) : \n loss = <NUM_LIT> \n for dr , dg in zip ( fmap_r , fmap_g ) : \n for rl , gl in zip ( dr , dg ) : \n rl = rl . float ( ) . detach ( ) \n gl = gl . float ( ) \n loss += torch . mean ( torch . abs ( rl - gl ) ) \n return loss * <NUM_LIT> \n def discriminator_loss ( disc_real_outputs , disc_generated_outputs ) : \n loss = <NUM_LIT> \n r_losses = [ ] \n g_losses = [ ] \n for dr , dg in zip ( disc_real_outputs , disc_generated_outputs ) : \n dr = dr . float ( ) \n dg = dg . float ( ) \n r_loss = torch . mean ( ( <NUM_LIT> - dr ) ** <NUM_LIT> ) \n g_loss = torch . mean ( dg ** <NUM_LIT> ) \n loss += r_loss + g_loss \n r_losses . append ( r_loss . item ( ) ) \n g_losses . append ( g_loss . item ( ) ) \n return loss , r_losses , g_losses \n def generator_loss ( disc_outputs ) : \n loss = <NUM_LIT> \n gen_losses = [ ] \n for dg in disc_outputs : \n dg = dg . float ( ) \n l = torch . mean ( ( <NUM_LIT> - dg ) ** <NUM_LIT> ) \n gen_losses . append ( l ) \n loss += l", "output": "return loss , gen_losses \n def kl_loss ( z_p , logs_q , m_p , logs_p , z_mask ) : \n z_p = z_p . float ( ) \n logs_q = logs_q . float ( ) \n m_p = m_p . float ( ) \n logs_p = logs_p . float ( ) \n z_mask = z_mask . float ( ) \n kl = logs_p - logs_q - <NUM_LIT> \n kl += <NUM_LIT> * ( ( z_p - m_p ) ** <NUM_LIT> ) * torch . exp ( - <NUM_LIT> * logs_p ) \n kl = torch . sum ( kl * z_mask ) \n l = kl / torch . sum ( z_mask ) \n return l"}, {"input": "import os , sys \n import gradio as gr \n import regex as re \n import json \n import random \n from core import ( \n run_tts_script , \n ) \n from assets . i18n . i18n import I18nAuto \n i18n = I18nAuto ( ) \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n model_root = os . path . join ( now_dir , \"<STR_LIT>\" ) \n model_root_relative = os . path . relpath ( model_root , now_dir ) \n names = [ \n os . path . join ( root , file ) \n for root , _ , files in os . walk ( model_root_relative , topdown = False ) \n for file in files \n if ( \n file . endswith ( ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n and not ( file . startswith ( \"<STR_LIT>\" ) or file . startswith ( \"<STR_LIT>\" ) ) \n ) \n ] \n indexes_list = [ \n os . path . join ( root , name ) \n for root , _ , files in os . walk ( model_root_relative , topdown = False ) \n for name in files \n if name . endswith ( \"<STR_LIT>\" ) and \"<STR_LIT>\" not in name \n ] \n def change_choices ( ) : \n names = [ \n os . path . join ( root , file ) \n for root , _ , files in os . walk ( model_root_relative , topdown = False ) \n for file in files \n if ( \n file . endswith ( ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n and not ( file . startswith ( \"<STR_LIT>\" ) or file . startswith ( \"<STR_LIT>\" ) ) \n ) \n ] \n indexes_list = [ \n os . path . join ( root , name ) \n for root , _ , files in os . walk ( model_root_relative , topdown = False ) \n for name in files \n if name . endswith ( \"<STR_LIT>\" ) and \"<STR_LIT>\" not in name \n ] \n return ( \n { \"<STR_LIT>\" : sorted ( names ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : sorted ( indexes_list ) , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) \n def get_indexes ( ) : \n indexes_list = [ \n os . path . join ( dirpath , filename ) \n for dirpath , _ , filenames in os . walk ( model_root_relative ) \n for filename in filenames \n if filename . endswith ( \"<STR_LIT>\" ) and \"<STR_LIT>\" not in filename \n ] \n return indexes_list if indexes_list else \"<STR_LIT>\" \n def process_input ( file_path ) : \n with open ( file_path , \"<STR_LIT>\" ) as file : \n file_contents = file . read ( ) \n gr . Info ( f\"<STR_LIT>\" ) \n return file_contents , None \n def match_index ( model_file_value ) : \n if model_file_value : \n model_folder = os . path . dirname ( model_file_value ) \n index_files = get_indexes ( ) \n for index_file in index_files : \n if os . path . dirname ( index_file ) == model_folder : \n return index_file \n return \"<STR_LIT>\" \n def tts_tab ( ) : \n default_weight = random . choice ( names ) if names else \"<STR_LIT>\" \n with gr . Row ( ) : \n with gr . Row ( ) : \n model_file = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = sorted ( names , key = lambda path : os . path . getsize ( path ) ) , \n interactive = True , \n value = default_weight , \n allow_custom_value = True , \n ) \n best_default_index_path = match_index ( model_file . value ) \n index_file = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = get_indexes ( ) , \n value = best_default_index_path , \n interactive = True , \n allow_custom_value = True , \n ) \n with gr . Column ( ) : \n refresh_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n unload_button = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n unload_button . click ( \n fn = lambda : ( \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) , \n inputs = [ ] , \n outputs = [ model_file , index_file ] , \n ) \n model_file . select ( \n fn = lambda model_file_value : match_index ( model_file_value ) , \n inputs = [ model_file ] , \n outputs = [ index_file ] , \n ) \n json_path = os . path . join ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n with open ( json_path , \"<STR_LIT>\" ) as file : \n tts_voices_data = json . load ( file ) \n short_names = [ voice . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) for voice in tts_voices_data ] \n tts_voice = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = short_names , \n interactive = True , \n value = None , \n ) \n tts_text = gr . Textbox (", "output": "label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n lines = <NUM_LIT> , \n ) \n txt_file = gr . File ( \n label = i18n ( \"<STR_LIT>\" ) , \n type = \"<STR_LIT>\" , \n ) \n with gr . Accordion ( i18n ( \"<STR_LIT>\" ) , open = False ) : \n with gr . Column ( ) : \n output_tts_path = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n value = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n interactive = True , \n ) \n output_rvc_path = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n placeholder = i18n ( \"<STR_LIT>\" ) , \n value = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n interactive = True , \n ) \n export_format = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n choices = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n split_audio = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = False , \n interactive = True , \n ) \n autotune = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = False , \n interactive = True , \n ) \n clean_audio = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = True , \n interactive = True , \n ) \n clean_strength = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n value = <NUM_LIT> , \n interactive = True , \n ) \n pitch = gr . Slider ( \n minimum = - <NUM_LIT> , \n maximum = <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n filter_radius = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n step = <NUM_LIT> , \n interactive = True , \n ) \n index_rate = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n rms_mix_rate = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n protect = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n hop_length = gr . Slider ( \n minimum = <NUM_LIT> , \n maximum = <NUM_LIT> , \n step = <NUM_LIT> , \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = <NUM_LIT> , \n interactive = True , \n ) \n with gr . Column ( ) : \n f0method = gr . Radio ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n choices = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n value = \"<STR_LIT>\" , \n interactive = True , \n ) \n convert_button1 = gr . Button ( i18n ( \"<STR_LIT>\" ) ) \n with gr . Row ( ) : \n vc_output1 = gr . Textbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \"<STR_LIT>\" ) , \n ) \n vc_output2 = gr . Audio ( label = i18n ( \"<STR_LIT>\" ) ) \n def toggle_visible ( checkbox ) : \n return { \"<STR_LIT>\" : checkbox , \"<STR_LIT>\" : \"<STR_LIT>\" } \n clean_audio . change ( \n fn = toggle_visible , \n inputs = [ clean_audio ] , \n outputs = [ clean_strength ] , \n ) \n refresh_button . click ( \n fn = change_choices , \n inputs = [ ] , \n outputs = [ model_file , index_file ] , \n ) \n txt_file . upload ( \n fn = process_input , \n inputs = [ txt_file ] , \n outputs = [ tts_text , txt_file ] , \n ) \n convert_button1 . click ( \n fn = run_tts_script , \n inputs = [ \n tts_text , \n tts_voice , \n pitch , \n filter_radius , \n index_rate , \n rms_mix_rate , \n protect , \n hop_length , \n f0method , \n output_tts_path , \n output_rvc_path , \n model_file , \n index_file , \n split_audio , \n autotune , \n clean_audio , \n clean_strength , \n export_format , \n ] , \n outputs = [ vc_output1 , vc_output2 ] , \n )"}, {"input": "import os \n import wget \n url_base = \"<STR_LIT>\" \n pretraineds_v1_list = [ \n ( \n \"<STR_LIT>\" , \n [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n ) , \n ] \n pretraineds_v2_list = [ \n ( \n \"<STR_LIT>\" , \n [", "output": "\"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n ) , \n ] \n models_list = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n executables_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n folder_mapping_list = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n def prequisites_download_pipeline ( pretraineds_v1 , pretraineds_v2 , models , exe ) : \n def download_files ( file_list ) : \n for file_name in file_list : \n destination_path = os . path . join ( file_name ) \n url = f\"<STR_LIT>\" \n if not os . path . exists ( destination_path ) : \n os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) \n print ( f\"<STR_LIT>\" ) \n wget . download ( url , out = destination_path ) \n if models == \"<STR_LIT>\" : \n download_files ( models_list ) \n if exe == \"<STR_LIT>\" and os . name == \"<STR_LIT>\" : \n download_files ( executables_list ) \n if pretraineds_v1 == \"<STR_LIT>\" : \n for remote_folder , file_list in pretraineds_v1_list : \n local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) \n for file in file_list : \n destination_path = os . path . join ( local_folder , file ) \n url = f\"<STR_LIT>\" \n if not os . path . exists ( destination_path ) : \n os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) \n print ( f\"<STR_LIT>\" ) \n wget . download ( url , out = destination_path ) \n if pretraineds_v2 == \"<STR_LIT>\" : \n for remote_folder , file_list in pretraineds_v2_list : \n local_folder = folder_mapping_list . get ( remote_folder , \"<STR_LIT>\" ) \n for file in file_list : \n destination_path = os . path . join ( local_folder , file ) \n url = f\"<STR_LIT>\" \n if not os . path . exists ( destination_path ) : \n os . makedirs ( os . path . dirname ( destination_path ) or \"<STR_LIT>\" , exist_ok = True ) \n print ( f\"<STR_LIT>\" ) \n wget . download ( url , out = destination_path )"}, {"input": "import os \n import numpy as np \n import torch \n import torch . utils . data \n from mel_processing import spectrogram_torch \n from utils import load_filepaths_and_text , load_wav_to_torch \n class TextAudioLoaderMultiNSFsid ( torch . utils . data . Dataset ) : \n def __init__ ( self , hparams ) : \n self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) \n self . max_wav_value = hparams . max_wav_value \n self . sampling_rate = hparams . sampling_rate \n self . filter_length = hparams . filter_length \n self . hop_length = hparams . hop_length \n self . win_length = hparams . win_length \n self . sampling_rate = hparams . sampling_rate \n self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) \n self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) \n self . _filter ( ) \n def _filter ( self ) : \n audiopaths_and_text_new = [ ] \n lengths = [ ] \n for audiopath , text , pitch , pitchf , dv in self . audiopaths_and_text : \n if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : \n audiopaths_and_text_new . append ( [ audiopath , text , pitch , pitchf , dv ] ) \n lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) \n self . audiopaths_and_text = audiopaths_and_text_new \n self . lengths = lengths \n def get_sid ( self , sid ) : \n sid = torch . LongTensor ( [ int ( sid ) ] ) \n return sid \n def get_audio_text_pair ( self , audiopath_and_text ) : \n file = audiopath_and_text [ <NUM_LIT> ] \n phone = audiopath_and_text [ <NUM_LIT> ] \n pitch = audiopath_and_text [ <NUM_LIT> ] \n pitchf = audiopath_and_text [ <NUM_LIT> ] \n dv = audiopath_and_text [ <NUM_LIT> ] \n phone , pitch , pitchf = self . get_labels ( phone , pitch , pitchf ) \n spec , wav = self . get_audio ( file ) \n dv = self . get_sid ( dv ) \n len_phone = phone . size ( ) [ <NUM_LIT> ] \n len_spec = spec . size ( ) [ - <NUM_LIT> ] \n if len_phone != len_spec : \n len_min = min ( len_phone , len_spec ) \n len_wav = len_min * self . hop_length \n spec = spec [ : , : len_min ] \n wav = wav [ : , : len_wav ] \n phone = phone [ : len_min , : ] \n pitch = pitch [ : len_min ] \n pitchf = pitchf [ : len_min ] \n return ( spec , wav , phone , pitch , pitchf , dv ) \n def get_labels ( self , phone , pitch , pitchf ) : \n phone = np . load ( phone ) \n phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) \n pitch = np . load ( pitch ) \n pitchf = np . load ( pitchf ) \n n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) \n phone = phone [ : n_num , : ] \n pitch = pitch [ : n_num ] \n pitchf = pitchf [ : n_num ] \n phone = torch . FloatTensor ( phone ) \n pitch = torch . LongTensor ( pitch ) \n pitchf = torch . FloatTensor ( pitchf ) \n return phone , pitch , pitchf \n def get_audio ( self , filename ) : \n audio , sampling_rate = load_wav_to_torch ( filename ) \n if sampling_rate != self . sampling_rate : \n raise ValueError ( \n \"<STR_LIT>\" . format ( \n sampling_rate , self . sampling_rate \n ) \n ) \n audio_norm = audio \n audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) \n spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if os . path . exists ( spec_filename ) : \n try : \n spec = torch . load ( spec_filename ) \n except Exception as error : \n print ( f\"<STR_LIT>\" ) \n spec = spectrogram_torch ( \n audio_norm , \n self . filter_length , \n self . hop_length , \n self . win_length , \n center = False , \n )", "output": "spec = torch . squeeze ( spec , <NUM_LIT> ) \n torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) \n else : \n spec = spectrogram_torch ( \n audio_norm , \n self . filter_length , \n self . hop_length , \n self . win_length , \n center = False , \n ) \n spec = torch . squeeze ( spec , <NUM_LIT> ) \n torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) \n return spec , audio_norm \n def __getitem__ ( self , index ) : \n return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) \n def __len__ ( self ) : \n return len ( self . audiopaths_and_text ) \n class TextAudioCollateMultiNSFsid : \n def __init__ ( self , return_ids = False ) : \n self . return_ids = return_ids \n def __call__ ( self , batch ) : \n _ , ids_sorted_decreasing = torch . sort ( \n torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True \n ) \n max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) \n max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) \n spec_lengths = torch . LongTensor ( len ( batch ) ) \n wave_lengths = torch . LongTensor ( len ( batch ) ) \n spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) \n wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) \n spec_padded . zero_ ( ) \n wave_padded . zero_ ( ) \n max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) \n phone_lengths = torch . LongTensor ( len ( batch ) ) \n phone_padded = torch . FloatTensor ( \n len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] \n ) \n pitch_padded = torch . LongTensor ( len ( batch ) , max_phone_len ) \n pitchf_padded = torch . FloatTensor ( len ( batch ) , max_phone_len ) \n phone_padded . zero_ ( ) \n pitch_padded . zero_ ( ) \n pitchf_padded . zero_ ( ) \n sid = torch . LongTensor ( len ( batch ) ) \n for i in range ( len ( ids_sorted_decreasing ) ) : \n row = batch [ ids_sorted_decreasing [ i ] ] \n spec = row [ <NUM_LIT> ] \n spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec \n spec_lengths [ i ] = spec . size ( <NUM_LIT> ) \n wave = row [ <NUM_LIT> ] \n wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave \n wave_lengths [ i ] = wave . size ( <NUM_LIT> ) \n phone = row [ <NUM_LIT> ] \n phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone \n phone_lengths [ i ] = phone . size ( <NUM_LIT> ) \n pitch = row [ <NUM_LIT> ] \n pitch_padded [ i , : pitch . size ( <NUM_LIT> ) ] = pitch \n pitchf = row [ <NUM_LIT> ] \n pitchf_padded [ i , : pitchf . size ( <NUM_LIT> ) ] = pitchf \n sid [ i ] = row [ <NUM_LIT> ] \n return ( \n phone_padded , \n phone_lengths , \n pitch_padded , \n pitchf_padded , \n spec_padded , \n spec_lengths , \n wave_padded , \n wave_lengths , \n sid , \n ) \n class TextAudioLoader ( torch . utils . data . Dataset ) : \n def __init__ ( self , hparams ) : \n self . audiopaths_and_text = load_filepaths_and_text ( hparams . training_files ) \n self . max_wav_value = hparams . max_wav_value \n self . sampling_rate = hparams . sampling_rate \n self . filter_length = hparams . filter_length \n self . hop_length = hparams . hop_length \n self . win_length = hparams . win_length \n self . sampling_rate = hparams . sampling_rate \n self . min_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) \n self . max_text_len = getattr ( hparams , \"<STR_LIT>\" , <NUM_LIT> ) \n self . _filter ( ) \n def _filter ( self ) : \n audiopaths_and_text_new = [ ] \n lengths = [ ] \n for entry in self . audiopaths_and_text : \n if len ( entry ) >= <NUM_LIT> : \n audiopath , text , dv = entry [ : <NUM_LIT> ] \n if self . min_text_len <= len ( text ) and len ( text ) <= self . max_text_len : \n audiopaths_and_text_new . append ( [ audiopath , text , dv ] ) \n lengths . append ( os . path . getsize ( audiopath ) // ( <NUM_LIT> * self . hop_length ) ) \n self . audiopaths_and_text = audiopaths_and_text_new \n self . lengths = lengths \n def get_sid ( self , sid ) : \n sid = os . path . basename ( os . path . dirname ( sid ) ) \n try : \n sid = torch . LongTensor ( [ int ( \"<STR_LIT>\" . join ( filter ( str . isdigit , sid ) ) ) ] ) \n except ValueError as error : \n print ( f\"<STR_LIT>\" ) \n sid = torch . LongTensor ( [ <NUM_LIT> ] ) \n return sid \n def get_audio_text_pair ( self , audiopath_and_text ) : \n file = audiopath_and_text [ <NUM_LIT> ] \n phone = audiopath_and_text [ <NUM_LIT> ] \n dv = audiopath_and_text [ <NUM_LIT> ] \n phone = self . get_labels ( phone ) \n spec , wav = self . get_audio ( file ) \n dv = self . get_sid ( dv ) \n len_phone = phone . size ( ) [ <NUM_LIT> ] \n len_spec = spec . size ( ) [ - <NUM_LIT> ] \n if len_phone != len_spec : \n len_min = min ( len_phone , len_spec ) \n len_wav = len_min * self . hop_length \n spec = spec [ : , : len_min ] \n wav = wav [ : , : len_wav ] \n phone = phone [ : len_min , : ] \n return ( spec , wav , phone , dv ) \n def get_labels ( self , phone ) : \n phone = np . load ( phone ) \n phone = np . repeat ( phone , <NUM_LIT> , axis = <NUM_LIT> ) \n n_num = min ( phone . shape [ <NUM_LIT> ] , <NUM_LIT> ) \n phone = phone [ : n_num , : ] \n phone = torch . FloatTensor ( phone ) \n return phone \n def get_audio ( self , filename ) : \n audio , sampling_rate = load_wav_to_torch ( filename ) \n if sampling_rate != self . sampling_rate : \n raise ValueError ( \n \"<STR_LIT>\" . format ( \n sampling_rate , self . sampling_rate \n ) \n ) \n audio_norm = audio \n audio_norm = audio_norm . unsqueeze ( <NUM_LIT> ) \n spec_filename = filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if os . path . exists ( spec_filename ) : \n try : \n spec = torch . load ( spec_filename ) \n except Exception as error : \n print ( f\"<STR_LIT>\" ) \n spec = spectrogram_torch ( \n audio_norm , \n self . filter_length , \n self . hop_length , \n self . win_length , \n center = False , \n ) \n spec = torch . squeeze ( spec , <NUM_LIT> ) \n torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) \n else : \n spec = spectrogram_torch ( \n audio_norm , \n self . filter_length , \n self . hop_length , \n self . win_length , \n center = False , \n ) \n spec = torch . squeeze ( spec , <NUM_LIT> ) \n torch . save ( spec , spec_filename , _use_new_zipfile_serialization = False ) \n return spec , audio_norm \n def __getitem__ ( self , index ) : \n return self . get_audio_text_pair ( self . audiopaths_and_text [ index ] ) \n def __len__ ( self ) : \n return len ( self . audiopaths_and_text ) \n class TextAudioCollate : \n def __init__ ( self , return_ids = False ) : \n self . return_ids = return_ids \n def __call__ ( self , batch ) : \n _ , ids_sorted_decreasing = torch . sort ( \n torch . LongTensor ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) , dim = <NUM_LIT> , descending = True \n ) \n max_spec_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) \n max_wave_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) \n spec_lengths = torch . LongTensor ( len ( batch ) ) \n wave_lengths = torch . LongTensor ( len ( batch ) ) \n spec_padded = torch . FloatTensor ( len ( batch ) , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . size ( <NUM_LIT> ) , max_spec_len ) \n wave_padded = torch . FloatTensor ( len ( batch ) , <NUM_LIT> , max_wave_len ) \n spec_padded . zero_ ( ) \n wave_padded . zero_ ( ) \n max_phone_len = max ( [ x [ <NUM_LIT> ] . size ( <NUM_LIT> ) for x in batch ] ) \n phone_lengths = torch . LongTensor ( len ( batch ) ) \n phone_padded = torch . FloatTensor ( \n len ( batch ) , max_phone_len , batch [ <NUM_LIT> ] [ <NUM_LIT> ] . shape [ <NUM_LIT> ] \n ) \n phone_padded . zero_ ( ) \n sid = torch . LongTensor ( len ( batch ) ) \n for i in range ( len ( ids_sorted_decreasing ) ) : \n row = batch [ ids_sorted_decreasing [ i ] ] \n spec = row [ <NUM_LIT> ] \n spec_padded [ i , : , : spec . size ( <NUM_LIT> ) ] = spec \n spec_lengths [ i ] = spec . size ( <NUM_LIT> ) \n wave = row [ <NUM_LIT> ] \n wave_padded [ i , : , : wave . size ( <NUM_LIT> ) ] = wave \n wave_lengths [ i ] = wave . size ( <NUM_LIT> ) \n phone = row [ <NUM_LIT> ] \n phone_padded [ i , : phone . size ( <NUM_LIT> ) , : ] = phone \n phone_lengths [ i ] = phone . size ( <NUM_LIT> ) \n sid [ i ] = row [ <NUM_LIT> ] \n return ( \n phone_padded , \n phone_lengths , \n spec_padded , \n spec_lengths , \n wave_padded , \n wave_lengths , \n sid , \n ) \n class DistributedBucketSampler ( torch . utils . data . distributed . DistributedSampler ) : \n def __init__ ( \n self , \n dataset , \n batch_size , \n boundaries , \n num_replicas = None , \n rank = None , \n shuffle = True , \n ) : \n super ( ) . __init__ ( dataset , num_replicas = num_replicas , rank = rank , shuffle = shuffle ) \n self . lengths = dataset . lengths \n self . batch_size = batch_size \n self . boundaries = boundaries \n self . buckets , self . num_samples_per_bucket = self . _create_buckets ( ) \n self . total_size = sum ( self . num_samples_per_bucket ) \n self . num_samples = self . total_size // self . num_replicas \n def _create_buckets ( self ) : \n buckets = [ [ ] for _ in range ( len ( self . boundaries ) - <NUM_LIT> ) ] \n for i in range ( len ( self . lengths ) ) : \n length = self . lengths [ i ] \n idx_bucket = self . _bisect ( length ) \n if idx_bucket != - <NUM_LIT> : \n buckets [ idx_bucket ] . append ( i ) \n for i in range ( len ( buckets ) - <NUM_LIT> , - <NUM_LIT> , - <NUM_LIT> ) : \n if len ( buckets [ i ] ) == <NUM_LIT> : \n buckets . pop ( i ) \n self . boundaries . pop ( i + <NUM_LIT> ) \n num_samples_per_bucket = [ ] \n for i in range ( len ( buckets ) ) : \n len_bucket = len ( buckets [ i ] ) \n total_batch_size = self . num_replicas * self . batch_size \n rem = ( \n total_batch_size - ( len_bucket % total_batch_size ) \n ) % total_batch_size \n num_samples_per_bucket . append ( len_bucket + rem ) \n return buckets , num_samples_per_bucket \n def __iter__ ( self ) : \n g = torch . Generator ( ) \n g . manual_seed ( self . epoch ) \n indices = [ ] \n if self . shuffle : \n for bucket in self . buckets : \n indices . append ( torch . randperm ( len ( bucket ) , generator = g ) . tolist ( ) ) \n else : \n for bucket in self . buckets : \n indices . append ( list ( range ( len ( bucket ) ) ) ) \n batches = [ ] \n for i in range ( len ( self . buckets ) ) : \n bucket = self . buckets [ i ] \n len_bucket = len ( bucket ) \n ids_bucket = indices [ i ] \n num_samples_bucket = self . num_samples_per_bucket [ i ] \n rem = num_samples_bucket - len_bucket \n ids_bucket = ( \n ids_bucket \n + ids_bucket * ( rem // len_bucket ) \n + ids_bucket [ : ( rem % len_bucket ) ] \n ) \n ids_bucket = ids_bucket [ self . rank : : self . num_replicas ] \n for j in range ( len ( ids_bucket ) // self . batch_size ) : \n batch = [ \n bucket [ idx ] \n for idx in ids_bucket [ \n j * self . batch_size : ( j + <NUM_LIT> ) * self . batch_size \n ] \n ] \n batches . append ( batch ) \n if self . shuffle : \n batch_ids = torch . randperm ( len ( batches ) , generator = g ) . tolist ( ) \n batches = [ batches [ i ] for i in batch_ids ] \n self . batches = batches \n assert len ( self . batches ) * self . batch_size == self . num_samples \n return iter ( self . batches ) \n def _bisect ( self , x , lo = <NUM_LIT> , hi = None ) : \n if hi is None : \n hi = len ( self . boundaries ) - <NUM_LIT> \n if hi > lo : \n mid = ( hi + lo ) // <NUM_LIT> \n if self . boundaries [ mid ] < x and x <= self . boundaries [ mid + <NUM_LIT> ] : \n return mid \n elif x <= self . boundaries [ mid ] : \n return self . _bisect ( x , lo , mid ) \n else : \n return self . _bisect ( x , mid + <NUM_LIT> , hi ) \n else : \n return - <NUM_LIT> \n def __len__ ( self ) : \n return self . num_samples // self . batch_size"}, {"input": "import gradio as gr \n import tabs . extra . processing . processing as processing \n import tabs . extra . analyzer . analyzer as analyzer \n from assets . i18n . i18n import I18nAuto \n i18n = I18nAuto ( )", "output": "def extra_tab ( ) : \n gr . Markdown ( \n value = i18n ( \n \"<STR_LIT>\" \n ) \n ) \n with gr . TabItem ( i18n ( \"<STR_LIT>\" ) ) : \n processing . processing ( ) \n with gr . TabItem ( i18n ( \"<STR_LIT>\" ) ) : \n analyzer . analyzer ( )"}, {"input": "import os , sys \n import json \n import gradio as gr \n from assets . i18n . i18n import I18nAuto \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n i18n = I18nAuto ( ) \n config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def get_language_settings ( ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n config = json . load ( file ) \n if config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] == False : \n return \"<STR_LIT>\" \n else : \n return config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n def save_lang_settings ( selected_language ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n config = json . load ( file ) \n if selected_language == \"<STR_LIT>\" : \n config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = False \n else : \n config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = True \n config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_language \n gr . Info ( \"<STR_LIT>\" ) \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n json . dump ( config , file , indent = <NUM_LIT> ) \n def lang_tab ( ) : \n with gr . Column ( ) :", "output": "selected_language = gr . Dropdown ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n value = get_language_settings ( ) , \n choices = [ \"<STR_LIT>\" ] \n + i18n . _get_available_languages ( ) , \n interactive = True , \n ) \n selected_language . change ( \n fn = save_lang_settings , \n inputs = [ selected_language ] , \n outputs = [ ] , \n )"}, {"input": "import os , sys \n import json \n import requests \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def load_local_version ( ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n config = json . load ( file )", "output": "return config [ \"<STR_LIT>\" ] \n def obtain_tag_name ( ) : \n url = \"<STR_LIT>\" \n try : \n response = requests . get ( url ) \n response . raise_for_status ( ) \n data = response . json ( ) \n tag_name = data [ \"<STR_LIT>\" ] \n return tag_name \n except requests . exceptions . RequestException as e : \n print ( f\"<STR_LIT>\" ) \n return None \n def compare_version ( ) : \n local_version = load_local_version ( ) \n online_version = obtain_tag_name ( ) \n elements_online_version = list ( map ( int , online_version . split ( \"<STR_LIT>\" ) ) ) \n elements_local_version = list ( map ( int , local_version . split ( \"<STR_LIT>\" ) ) ) \n for online , local in zip ( elements_online_version , elements_local_version ) : \n if local < online : \n return f\"<STR_LIT>\" \n return f\"<STR_LIT>\""}, {"input": "import torch \n import torch . utils . data \n from librosa . filters import mel as librosa_mel_fn \n def dynamic_range_compression_torch ( x , C = <NUM_LIT> , clip_val = <NUM_LIT> ) : \n return torch . log ( torch . clamp ( x , min = clip_val ) * C ) \n def dynamic_range_decompression_torch ( x , C = <NUM_LIT> ) : \n return torch . exp ( x ) / C \n def spectral_normalize_torch ( magnitudes ) : \n return dynamic_range_compression_torch ( magnitudes ) \n def spectral_de_normalize_torch ( magnitudes ) : \n return dynamic_range_decompression_torch ( magnitudes ) \n mel_basis = { } \n hann_window = { } \n def spectrogram_torch ( y , n_fft , hop_size , win_size , center = False ) : \n global hann_window \n dtype_device = str ( y . dtype ) + \"<STR_LIT>\" + str ( y . device ) \n wnsize_dtype_device = str ( win_size ) + \"<STR_LIT>\" + dtype_device", "output": "if wnsize_dtype_device not in hann_window : \n hann_window [ wnsize_dtype_device ] = torch . hann_window ( win_size ) . to ( \n dtype = y . dtype , device = y . device \n ) \n y = torch . nn . functional . pad ( \n y . unsqueeze ( <NUM_LIT> ) , \n ( int ( ( n_fft - hop_size ) / <NUM_LIT> ) , int ( ( n_fft - hop_size ) / <NUM_LIT> ) ) , \n mode = \"<STR_LIT>\" , \n ) \n y = y . squeeze ( <NUM_LIT> ) \n spec = torch . stft ( \n y , \n n_fft , \n hop_length = hop_size , \n win_length = win_size , \n window = hann_window [ wnsize_dtype_device ] , \n center = center , \n pad_mode = \"<STR_LIT>\" , \n normalized = False , \n onesided = True , \n return_complex = True , \n ) \n spec = torch . sqrt ( spec . real . pow ( <NUM_LIT> ) + spec . imag . pow ( <NUM_LIT> ) + <NUM_LIT> ) \n return spec \n def spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) : \n global mel_basis \n dtype_device = str ( spec . dtype ) + \"<STR_LIT>\" + str ( spec . device ) \n fmax_dtype_device = str ( fmax ) + \"<STR_LIT>\" + dtype_device \n if fmax_dtype_device not in mel_basis : \n mel = librosa_mel_fn ( \n sr = sampling_rate , n_fft = n_fft , n_mels = num_mels , fmin = fmin , fmax = fmax \n ) \n mel_basis [ fmax_dtype_device ] = torch . from_numpy ( mel ) . to ( \n dtype = spec . dtype , device = spec . device \n ) \n melspec = torch . matmul ( mel_basis [ fmax_dtype_device ] , spec ) \n melspec = spectral_normalize_torch ( melspec ) \n return melspec \n def mel_spectrogram_torch ( \n y , n_fft , num_mels , sampling_rate , hop_size , win_size , fmin , fmax , center = False \n ) : \n spec = spectrogram_torch ( y , n_fft , hop_size , win_size , center ) \n melspec = spec_to_mel_torch ( spec , n_fft , num_mels , sampling_rate , fmin , fmax ) \n return melspec"}, {"input": "from infer_pack . modules . F0Predictor . F0Predictor import F0Predictor \n import pyworld \n import numpy as np \n class DioF0Predictor ( F0Predictor ) : \n def __init__ ( self , hop_length = <NUM_LIT> , f0_min = <NUM_LIT> , f0_max = <NUM_LIT> , sampling_rate = <NUM_LIT> ) : \n self . hop_length = hop_length \n self . f0_min = f0_min \n self . f0_max = f0_max \n self . sampling_rate = sampling_rate \n def interpolate_f0 ( self , f0 ) : \n data = np . reshape ( f0 , ( f0 . size , <NUM_LIT> ) ) \n vuv_vector = np . zeros ( ( data . size , <NUM_LIT> ) , dtype = np . float32 ) \n vuv_vector [ data > <NUM_LIT> ] = <NUM_LIT> \n vuv_vector [ data <= <NUM_LIT> ] = <NUM_LIT> \n ip_data = data \n frame_number = data . size \n last_value = <NUM_LIT> \n for i in range ( frame_number ) : \n if data [ i ] <= <NUM_LIT> : \n j = i + <NUM_LIT> \n for j in range ( i + <NUM_LIT> , frame_number ) : \n if data [ j ] > <NUM_LIT> : \n break \n if j < frame_number - <NUM_LIT> : \n if last_value > <NUM_LIT> : \n step = ( data [ j ] - data [ i - <NUM_LIT> ] ) / float ( j - i ) \n for k in range ( i , j ) : \n ip_data [ k ] = data [ i - <NUM_LIT> ] + step * ( k - i + <NUM_LIT> ) \n else : \n for k in range ( i , j ) : \n ip_data [ k ] = data [ j ] \n else : \n for k in range ( i , frame_number ) : \n ip_data [ k ] = last_value \n else : \n ip_data [ i ] = data [ i ] \n last_value = data [ i ] \n return ip_data [ : , <NUM_LIT> ] , vuv_vector [ : , <NUM_LIT> ] \n def resize_f0 ( self , x , target_len ) : \n source = np . array ( x ) \n source [ source < <NUM_LIT> ] = np . nan \n target = np . interp ( \n np . arange ( <NUM_LIT> , len ( source ) * target_len , len ( source ) ) / target_len , \n np . arange ( <NUM_LIT> , len ( source ) ) , \n source , \n ) \n res = np . nan_to_num ( target ) \n return res \n def compute_f0 ( self , wav , p_len = None ) : \n if p_len is None : \n p_len = wav . shape [ <NUM_LIT> ] // self . hop_length \n f0 , t = pyworld . dio ( \n wav . astype ( np . double ) , \n fs = self . sampling_rate , \n f0_floor = self . f0_min , \n f0_ceil = self . f0_max , \n frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , \n ) \n f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) \n for index , pitch in enumerate ( f0 ) : \n f0 [ index ] = round ( pitch , <NUM_LIT> ) \n return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) ) [ <NUM_LIT> ] \n def compute_f0_uv ( self , wav , p_len = None ) : \n if p_len is None : \n p_len = wav . shape [ <NUM_LIT> ] // self . hop_length \n f0 , t = pyworld . dio ( \n wav . astype ( np . double ) , \n fs = self . sampling_rate , \n f0_floor = self . f0_min , \n f0_ceil = self . f0_max , \n frame_period = <NUM_LIT> * self . hop_length / self . sampling_rate , \n ) \n f0 = pyworld . stonemask ( wav . astype ( np . double ) , f0 , t , self . sampling_rate ) \n for index , pitch in enumerate ( f0 ) : \n f0 [ index ] = round ( pitch , <NUM_LIT> )", "output": "return self . interpolate_f0 ( self . resize_f0 ( f0 , p_len ) )"}, {"input": "import os \n import sys \n import tqdm \n import torch \n import torch . nn . functional as F \n import fairseq \n import soundfile as sf \n import numpy as np \n import logging \n logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) \n device = sys . argv [ <NUM_LIT> ] \n n_parts = int ( sys . argv [ <NUM_LIT> ] ) \n i_part = int ( sys . argv [ <NUM_LIT> ] ) \n if len ( sys . argv ) == <NUM_LIT> : \n exp_dir , version , is_half = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) \n else : \n i_gpu , exp_dir = sys . argv [ <NUM_LIT> ] , sys . argv [ <NUM_LIT> ] \n os . environ [ \"<STR_LIT>\" ] = str ( i_gpu ) \n version , is_half = sys . argv [ <NUM_LIT> ] , bool ( sys . argv [ <NUM_LIT> ] ) \n def forward_dml ( ctx , x , scale ) : \n ctx . scale = scale \n res = x . clone ( ) . detach ( ) \n return res \n fairseq . modules . grad_multiply . GradMultiply . forward = forward_dml \n model_path = \"<STR_LIT>\" \n wav_path = f\"<STR_LIT>\" \n out_path = f\"<STR_LIT>\" if version == \"<STR_LIT>\" else f\"<STR_LIT>\" \n os . makedirs ( out_path , exist_ok = True ) \n def read_wave ( wav_path , normalize = False ) : \n wav , sr = sf . read ( wav_path ) \n assert sr == <NUM_LIT> \n feats = torch . from_numpy ( wav ) \n feats = feats . half ( ) if is_half else feats . float ( ) \n feats = feats . mean ( - <NUM_LIT> ) if feats . dim ( ) == <NUM_LIT> else feats \n feats = feats . view ( <NUM_LIT> , - <NUM_LIT> ) \n if normalize : \n with torch . no_grad ( ) : \n feats = F . layer_norm ( feats , feats . shape ) \n return feats \n print ( \"<STR_LIT>\" ) \n models , saved_cfg , task = fairseq . checkpoint_utils . load_model_ensemble_and_task ( \n [ model_path ] , \n suffix = \"<STR_LIT>\" , \n ) \n model = models [ <NUM_LIT> ] \n model = model . to ( device ) \n if device not in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n model = model . half ( ) \n model . eval ( ) \n todo = sorted ( os . listdir ( wav_path ) ) [ i_part : : n_parts ] \n n = max ( <NUM_LIT> , len ( todo ) // <NUM_LIT> ) \n if len ( todo ) == <NUM_LIT> : \n print (", "output": "\"<STR_LIT>\" \n ) \n else : \n print ( f\"<STR_LIT>\" ) \n with tqdm . tqdm ( total = len ( todo ) ) as pbar : \n for idx , file in enumerate ( todo ) : \n try : \n if file . endswith ( \"<STR_LIT>\" ) : \n wav_file_path = os . path . join ( wav_path , file ) \n out_file_path = os . path . join ( out_path , file . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n if os . path . exists ( out_file_path ) : \n continue \n feats = read_wave ( wav_file_path , normalize = saved_cfg . task . normalize ) \n padding_mask = torch . BoolTensor ( feats . shape ) . fill_ ( False ) \n inputs = { \n \"<STR_LIT>\" : feats . to ( device ) , \n \"<STR_LIT>\" : padding_mask . to ( device ) , \n \"<STR_LIT>\" : <NUM_LIT> if version == \"<STR_LIT>\" else <NUM_LIT> , \n } \n with torch . no_grad ( ) : \n logits = model . extract_features ( ** inputs ) \n feats = ( \n model . final_proj ( logits [ <NUM_LIT> ] ) \n if version == \"<STR_LIT>\" \n else logits [ <NUM_LIT> ] \n ) \n feats = feats . squeeze ( <NUM_LIT> ) . float ( ) . cpu ( ) . numpy ( ) \n if np . isnan ( feats ) . sum ( ) == <NUM_LIT> : \n np . save ( out_file_path , feats , allow_pickle = False ) \n else : \n print ( f\"<STR_LIT>\" ) \n pbar . set_description ( f\"<STR_LIT>\" ) \n except Exception as error : \n print ( error ) \n pbar . update ( <NUM_LIT> ) \n print ( \"<STR_LIT>\" )"}, {"input": "import os , sys \n import torch \n import json \n import gradio as gr \n from assets . i18n . i18n import I18nAuto \n from tabs . settings . restart import restart_applio", "output": "now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n i18n = I18nAuto ( ) \n ngpu = torch . cuda . device_count ( ) \n config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def gpu_available ( ) : \n if torch . cuda . is_available ( ) or ngpu != <NUM_LIT> : \n return True \n def load_fake_gpu ( ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n config = json . load ( file ) \n return config [ \"<STR_LIT>\" ] \n def save_config ( value ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n config = json . load ( file ) \n config [ \"<STR_LIT>\" ] = value \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n json . dump ( config , file , indent = <NUM_LIT> ) \n def fake_gpu_tab ( ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n presence = gr . Checkbox ( \n label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n interactive = True , \n value = load_fake_gpu ( ) , \n ) \n presence . change ( \n fn = toggle , \n inputs = [ presence ] , \n outputs = [ ] , \n ) \n def toggle ( checkbox ) : \n save_config ( bool ( checkbox ) ) \n restart_applio ( )"}, {"input": "import os \n import sys \n import time \n import torch \n import logging \n import numpy as np \n import soundfile as sf \n import librosa \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n from rvc . infer . pipeline import VC \n from scipy . io import wavfile \n import noisereduce as nr \n from rvc . lib . utils import load_audio \n from rvc . lib . tools . split_audio import process_audio , merge_audio \n from fairseq import checkpoint_utils \n from rvc . lib . infer_pack . models import ( \n SynthesizerTrnMs256NSFsid , \n SynthesizerTrnMs256NSFsid_nono , \n SynthesizerTrnMs768NSFsid , \n SynthesizerTrnMs768NSFsid_nono , \n ) \n from rvc . configs . config import Config \n logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) \n logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) \n logging . getLogger ( \"<STR_LIT>\" ) . setLevel ( logging . WARNING ) \n config = Config ( ) \n hubert_model = None \n tgt_sr = None \n net_g = None \n vc = None \n cpt = None \n version = None \n n_spk = None \n def load_hubert ( ) : \n global hubert_model \n models , _ , _ = checkpoint_utils . load_model_ensemble_and_task ( \n [ \"<STR_LIT>\" ] , \n suffix = \"<STR_LIT>\" , \n ) \n hubert_model = models [ <NUM_LIT> ] \n hubert_model = hubert_model . to ( config . device ) \n if config . is_half : \n hubert_model = hubert_model . half ( ) \n else : \n hubert_model = hubert_model . float ( ) \n hubert_model . eval ( ) \n def remove_audio_noise ( input_audio_path , reduction_strength = <NUM_LIT> ) : \n try : \n rate , data = wavfile . read ( input_audio_path ) \n reduced_noise = nr . reduce_noise ( \n y = data , \n sr = rate , \n prop_decrease = reduction_strength , \n ) \n return reduced_noise \n except Exception as error : \n print ( f\"<STR_LIT>\" ) \n return None \n def convert_audio_format ( input_path , output_path , output_format ) : \n try : \n if output_format != \"<STR_LIT>\" : \n print ( f\"<STR_LIT>\" ) \n audio , sample_rate = librosa . load ( input_path , sr = None ) \n common_sample_rates = [ \n <NUM_LIT> ,", "output": "<NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n ] \n target_sr = min ( common_sample_rates , key = lambda x : abs ( x - sample_rate ) ) \n audio = librosa . resample ( audio , orig_sr = sample_rate , target_sr = target_sr ) \n sf . write ( output_path , audio , target_sr , format = output_format . lower ( ) ) \n return output_path \n except Exception as error : \n print ( f\"<STR_LIT>\" ) \n def vc_single ( \n sid = <NUM_LIT> , \n input_audio_path = None , \n f0_up_key = None , \n f0_file = None , \n f0_method = None , \n file_index = None , \n index_rate = None , \n resample_sr = <NUM_LIT> , \n rms_mix_rate = None , \n protect = None , \n hop_length = None , \n output_path = None , \n split_audio = False , \n f0autotune = False , \n filter_radius = None , \n ) : \n global tgt_sr , net_g , vc , hubert_model , version \n f0_up_key = int ( f0_up_key ) \n try : \n audio = load_audio ( input_audio_path , <NUM_LIT> ) \n audio_max = np . abs ( audio ) . max ( ) / <NUM_LIT> \n if audio_max > <NUM_LIT> : \n audio /= audio_max \n if not hubert_model : \n load_hubert ( ) \n if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) \n file_index = ( \n file_index . strip ( \"<STR_LIT>\" ) \n . strip ( '<STR_LIT>' ) \n . strip ( \"<STR_LIT>\" ) \n . strip ( '<STR_LIT>' ) \n . strip ( \"<STR_LIT>\" ) \n . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n ) \n if tgt_sr != resample_sr >= <NUM_LIT> : \n tgt_sr = resample_sr \n if split_audio == \"<STR_LIT>\" : \n result , new_dir_path = process_audio ( input_audio_path ) \n if result == \"<STR_LIT>\" : \n return \"<STR_LIT>\" , None \n dir_path = ( \n new_dir_path . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) . strip ( '<STR_LIT>' ) . strip ( \"<STR_LIT>\" ) \n ) \n if dir_path != \"<STR_LIT>\" : \n paths = [ \n os . path . join ( root , name ) \n for root , _ , files in os . walk ( dir_path , topdown = False ) \n for name in files \n if name . endswith ( \"<STR_LIT>\" ) and root == dir_path \n ] \n try : \n for path in paths : \n vc_single ( \n sid , \n path , \n f0_up_key , \n None , \n f0_method , \n file_index , \n index_rate , \n resample_sr , \n rms_mix_rate , \n protect , \n hop_length , \n path , \n False , \n f0autotune , \n ) \n except Exception as error : \n print ( error ) \n return f\"<STR_LIT>\" \n print ( \"<STR_LIT>\" ) \n merge_timestamps_file = os . path . join ( \n os . path . dirname ( new_dir_path ) , \n f\"<STR_LIT>\" , \n ) \n tgt_sr , audio_opt = merge_audio ( merge_timestamps_file ) \n os . remove ( merge_timestamps_file ) \n else : \n audio_opt = vc . pipeline ( \n hubert_model , \n net_g , \n sid , \n audio , \n input_audio_path , \n f0_up_key , \n f0_method , \n file_index , \n index_rate , \n if_f0 , \n filter_radius , \n tgt_sr , \n resample_sr , \n rms_mix_rate , \n version , \n protect , \n hop_length , \n f0autotune , \n f0_file = f0_file , \n ) \n if output_path is not None : \n sf . write ( output_path , audio_opt , tgt_sr , format = \"<STR_LIT>\" ) \n return ( tgt_sr , audio_opt ) \n except Exception as error : \n print ( error ) \n def get_vc ( weight_root , sid ) : \n global n_spk , tgt_sr , net_g , vc , cpt , version \n if sid == \"<STR_LIT>\" or sid == [ ] : \n global hubert_model \n if hubert_model is not None : \n print ( \"<STR_LIT>\" ) \n del net_g , n_spk , vc , hubert_model , tgt_sr \n hubert_model = net_g = n_spk = vc = hubert_model = tgt_sr = None \n if torch . cuda . is_available ( ) : \n torch . cuda . empty_cache ( ) \n if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) \n version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if version == \"<STR_LIT>\" : \n if if_f0 == <NUM_LIT> : \n net_g = SynthesizerTrnMs256NSFsid ( \n * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half \n ) \n else : \n net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) \n elif version == \"<STR_LIT>\" : \n if if_f0 == <NUM_LIT> : \n net_g = SynthesizerTrnMs768NSFsid ( \n * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half \n ) \n else : \n net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) \n del net_g , cpt \n if torch . cuda . is_available ( ) : \n torch . cuda . empty_cache ( ) \n cpt = None \n person = weight_root \n cpt = torch . load ( person , map_location = \"<STR_LIT>\" ) \n tgt_sr = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] \n cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] = cpt [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] . shape [ <NUM_LIT> ] \n if_f0 = cpt . get ( \"<STR_LIT>\" , <NUM_LIT> ) \n version = cpt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if version == \"<STR_LIT>\" : \n if if_f0 == <NUM_LIT> : \n net_g = SynthesizerTrnMs256NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) \n else : \n net_g = SynthesizerTrnMs256NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) \n elif version == \"<STR_LIT>\" : \n if if_f0 == <NUM_LIT> : \n net_g = SynthesizerTrnMs768NSFsid ( * cpt [ \"<STR_LIT>\" ] , is_half = config . is_half ) \n else : \n net_g = SynthesizerTrnMs768NSFsid_nono ( * cpt [ \"<STR_LIT>\" ] ) \n del net_g . enc_q \n print ( net_g . load_state_dict ( cpt [ \"<STR_LIT>\" ] , strict = False ) ) \n net_g . eval ( ) . to ( config . device ) \n if config . is_half : \n net_g = net_g . half ( ) \n else : \n net_g = net_g . float ( ) \n vc = VC ( tgt_sr , config ) \n n_spk = cpt [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] \n def infer_pipeline ( \n f0up_key , \n filter_radius , \n index_rate , \n rms_mix_rate , \n protect , \n hop_length , \n f0method , \n audio_input_path , \n audio_output_path , \n model_path , \n index_path , \n split_audio , \n f0autotune , \n clean_audio , \n clean_strength , \n export_format , \n ) : \n global tgt_sr , net_g , vc , cpt \n get_vc ( model_path , <NUM_LIT> ) \n try : \n start_time = time . time ( ) \n vc_single ( \n sid = <NUM_LIT> , \n input_audio_path = audio_input_path , \n f0_up_key = f0up_key , \n f0_file = None , \n f0_method = f0method , \n file_index = index_path , \n index_rate = index_rate , \n rms_mix_rate = rms_mix_rate , \n protect = protect , \n hop_length = hop_length , \n output_path = audio_output_path , \n split_audio = split_audio , \n f0autotune = f0autotune , \n filter_radius = filter_radius , \n ) \n if clean_audio == \"<STR_LIT>\" : \n cleaned_audio = remove_audio_noise ( audio_output_path , clean_strength ) \n if cleaned_audio is not None : \n sf . write ( audio_output_path , cleaned_audio , tgt_sr , format = \"<STR_LIT>\" ) \n output_path_format = audio_output_path . replace ( \n \"<STR_LIT>\" , f\"<STR_LIT>\" \n ) \n audio_output_path = convert_audio_format ( \n audio_output_path , output_path_format , export_format \n ) \n end_time = time . time ( ) \n elapsed_time = end_time - start_time \n print ( \n f\"<STR_LIT>\" \n ) \n except Exception as error : \n print ( f\"<STR_LIT>\" )"}, {"input": "import os \n import json \n import pathlib \n from random import shuffle \n from rvc . configs . config import Config \n config = Config ( ) \n current_directory = os . getcwd ( ) \n def generate_config ( rvc_version , sampling_rate , model_path ) :", "output": "if rvc_version == \"<STR_LIT>\" or sampling_rate == \"<STR_LIT>\" : \n config_path = f\"<STR_LIT>\" \n else : \n config_path = f\"<STR_LIT>\" \n config_save_path = os . path . join ( model_path , \"<STR_LIT>\" ) \n if not pathlib . Path ( config_save_path ) . exists ( ) : \n with open ( config_save_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as f : \n json . dump ( \n config . json_config [ config_path ] , \n f , \n ensure_ascii = False , \n indent = <NUM_LIT> , \n sort_keys = True , \n ) \n f . write ( \"<STR_LIT>\" ) \n def generate_filelist ( f0_method , model_path , rvc_version , sampling_rate ) : \n gt_wavs_dir = f\"<STR_LIT>\" \n feature_dir = ( \n f\"<STR_LIT>\" \n if rvc_version == \"<STR_LIT>\" \n else f\"<STR_LIT>\" \n ) \n if f0_method : \n f0_dir = f\"<STR_LIT>\" \n f0nsf_dir = f\"<STR_LIT>\" \n names = ( \n set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) \n & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] ) \n & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0_dir ) ] ) \n & set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( f0nsf_dir ) ] ) \n ) \n else : \n names = set ( [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( gt_wavs_dir ) ] ) & set ( \n [ name . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] for name in os . listdir ( feature_dir ) ] \n ) \n options = [ ] \n for name in names : \n if f0_method : \n options . append ( \n f\"<STR_LIT>\" \n ) \n else : \n options . append ( f\"<STR_LIT>\" ) \n fea_dim = <NUM_LIT> if rvc_version == \"<STR_LIT>\" else <NUM_LIT> \n if f0_method : \n for _ in range ( <NUM_LIT> ) : \n options . append ( \n f\"<STR_LIT>\" \n ) \n else : \n for _ in range ( <NUM_LIT> ) : \n options . append ( \n f\"<STR_LIT>\" \n ) \n shuffle ( options ) \n with open ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) as f : \n f . write ( \"<STR_LIT>\" . join ( options ) )"}, {"input": "import os \n import sys \n import wget \n import zipfile \n from bs4 import BeautifulSoup \n import requests \n from urllib . parse import unquote , urlencode , parse_qs , urlparse \n import re \n import shutil \n import six \n def find_folder_parent ( search_dir , folder_name ) : \n for dirpath , dirnames , _ in os . walk ( search_dir ) : \n if folder_name in dirnames : \n return os . path . abspath ( dirpath ) \n return None \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n from rvc . lib . utils import format_title \n from rvc . lib . tools import gdown \n file_path = find_folder_parent ( now_dir , \"<STR_LIT>\" ) \n zips_path = os . getcwd ( ) + \"<STR_LIT>\" \n def search_pth_index ( folder ) : \n pth_paths = [ \n os . path . join ( folder , file ) \n for file in os . listdir ( folder ) \n if os . path . isfile ( os . path . join ( folder , file ) ) and file . endswith ( \"<STR_LIT>\" ) \n ] \n index_paths = [ \n os . path . join ( folder , file ) \n for file in os . listdir ( folder ) \n if os . path . isfile ( os . path . join ( folder , file ) ) and file . endswith ( \"<STR_LIT>\" ) \n ] \n return pth_paths , index_paths \n def get_mediafire_download_link ( url ) : \n response = requests . get ( url ) \n response . raise_for_status ( ) \n soup = BeautifulSoup ( response . text , \"<STR_LIT>\" ) \n download_button = soup . find ( \n \"<STR_LIT>\" , { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } \n ) \n if download_button : \n download_link = download_button . get ( \"<STR_LIT>\" ) \n return download_link \n else : \n return None \n def download_from_url ( url ) : \n os . makedirs ( zips_path , exist_ok = True ) \n if url != \"<STR_LIT>\" : \n if \"<STR_LIT>\" in url : \n if \"<STR_LIT>\" in url : \n file_id = url . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n elif \"<STR_LIT>\" in url : \n file_id = url . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n else : \n return None \n if file_id : \n os . chdir ( zips_path ) \n try : \n gdown . download ( \n f\"<STR_LIT>\" , \n quiet = True , \n fuzzy = True , \n ) \n except Exception as error : \n error_message = str ( error ) \n if ( \n \"<STR_LIT>\" \n in error_message \n ) : \n os . chdir ( now_dir ) \n return \"<STR_LIT>\" \n elif ( \n \"<STR_LIT>\" in error_message \n ) : \n os . chdir ( now_dir ) \n return \"<STR_LIT>\" \n else : \n print ( error_message ) \n os . chdir ( now_dir ) \n return None \n elif \"<STR_LIT>\" in url : \n base_url = \"<STR_LIT>\" \n public_key = url \n final_url = base_url + urlencode ( dict ( public_key = public_key ) ) \n response = requests . get ( final_url ) \n download_url = response . json ( ) [ \"<STR_LIT>\" ] \n download_response = requests . get ( download_url ) \n if download_response . status_code == <NUM_LIT> : \n filename = parse_qs ( urlparse ( unquote ( download_url ) ) . query ) . get ( \n \"<STR_LIT>\" , [ \"<STR_LIT>\" ] \n ) [ <NUM_LIT> ] \n if filename : \n os . chdir ( zips_path ) \n with open ( filename , \"<STR_LIT>\" ) as f : \n f . write ( download_response . content ) \n else : \n print ( \"<STR_LIT>\" ) \n return None \n elif \"<STR_LIT>\" in url : \n try : \n file_id = url . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n os . chdir ( zips_path ) \n print ( file_id ) \n response = requests . get ( f\"<STR_LIT>\" ) \n if response . status_code == <NUM_LIT> : \n file_name = ( \n response . headers . get ( \"<STR_LIT>\" ) \n . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] \n . strip ( '<STR_LIT>' ) \n ) \n os . makedirs ( zips_path , exist_ok = True ) \n with open ( os . path . join ( zips_path , file_name ) , \"<STR_LIT>\" ) as newfile : \n newfile . write ( response . content ) \n os . chdir ( file_path ) \n return \"<STR_LIT>\" \n else : \n os . chdir ( file_path ) \n return None \n except Exception as e : \n print ( e ) \n os . chdir ( file_path ) \n return None \n elif \"<STR_LIT>\" in url : \n file = requests . get ( url ) \n os . chdir ( zips_path ) \n if file . status_code == <NUM_LIT> : \n name = url . split ( \"<STR_LIT>\" ) \n with open ( os . path . join ( name [ - <NUM_LIT> ] ) , \"<STR_LIT>\" ) as newfile : \n newfile . write ( file . content ) \n else : \n return None \n elif \"<STR_LIT>\" in url or \"<STR_LIT>\" in url : \n os . chdir ( zips_path ) \n if \"<STR_LIT>\" in url : \n url = url . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n response = requests . get ( url , stream = True ) \n if response . status_code == <NUM_LIT> : \n content_disposition = six . moves . urllib_parse . unquote ( \n response . headers [ \"<STR_LIT>\" ] \n ) \n m = re . search ( r'<STR_LIT>' , content_disposition ) \n file_name = m . groups ( ) [ <NUM_LIT> ] \n file_name = file_name . replace ( os . path . sep , \"<STR_LIT>\" ) \n total_size_in_bytes = int ( response . headers . get ( \"<STR_LIT>\" , <NUM_LIT> ) ) \n block_size = <NUM_LIT> \n progress_bar_length = <NUM_LIT> \n progress = <NUM_LIT> \n with open ( os . path . join ( zips_path , file_name ) , \"<STR_LIT>\" ) as file : \n for data in response . iter_content ( block_size ) : \n file . write ( data ) \n progress += len ( data ) \n progress_percent = int ( ( progress / total_size_in_bytes ) * <NUM_LIT> ) \n num_dots = int ( \n ( progress / total_size_in_bytes ) * progress_bar_length \n ) \n progress_bar = ( \n \"<STR_LIT>\" \n + \"<STR_LIT>\" * num_dots \n + \"<STR_LIT>\" * ( progress_bar_length - num_dots ) \n + \"<STR_LIT>\" \n ) \n print ( \n f\"<STR_LIT>\" ,", "output": "end = \"<STR_LIT>\" , \n ) \n if progress_percent == <NUM_LIT> : \n print ( \"<STR_LIT>\" ) \n else : \n os . chdir ( now_dir ) \n return None \n elif \"<STR_LIT>\" in url : \n os . chdir ( zips_path ) \n response = requests . get ( url ) \n soup = BeautifulSoup ( response . content , \"<STR_LIT>\" ) \n temp_url = \"<STR_LIT>\" \n for link in soup . find_all ( \"<STR_LIT>\" , href = True ) : \n if link [ \"<STR_LIT>\" ] . endswith ( \"<STR_LIT>\" ) : \n temp_url = link [ \"<STR_LIT>\" ] \n break \n if temp_url : \n url = temp_url \n url = url . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if \"<STR_LIT>\" not in url : \n url = \"<STR_LIT>\" + url \n wget . download ( url ) \n else : \n os . chdir ( now_dir ) \n return None \n elif \"<STR_LIT>\" in url : \n parts = url . split ( \"<STR_LIT>\" ) \n id_with_query = parts [ - <NUM_LIT> ] \n id_parts = id_with_query . split ( \"<STR_LIT>\" ) \n id_number = id_parts [ <NUM_LIT> ] \n url = \"<STR_LIT>\" \n headers = { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n params = { \"<STR_LIT>\" : f\"<STR_LIT>\" } \n response = requests . get ( url , headers = headers , params = params ) \n if response . status_code == <NUM_LIT> : \n json_response = response . json ( ) \n print ( json_response ) \n if json_response : \n link = json_response [ <NUM_LIT> ] [ \"<STR_LIT>\" ] \n verify = download_from_url ( link ) \n if verify == \"<STR_LIT>\" : \n return \"<STR_LIT>\" \n else : \n return None \n else : \n return None \n else : \n try : \n os . chdir ( zips_path ) \n wget . download ( url ) \n except Exception as error : \n os . chdir ( now_dir ) \n print ( error ) \n return None \n for currentPath , _ , zipFiles in os . walk ( zips_path ) : \n for Files in zipFiles : \n filePart = Files . split ( \"<STR_LIT>\" ) \n extensionFile = filePart [ len ( filePart ) - <NUM_LIT> ] \n filePart . pop ( ) \n nameFile = \"<STR_LIT>\" . join ( filePart ) \n realPath = os . path . join ( currentPath , Files ) \n os . rename ( realPath , nameFile + \"<STR_LIT>\" + extensionFile ) \n os . chdir ( now_dir ) \n return \"<STR_LIT>\" \n os . chdir ( now_dir ) \n return None \n def extract_and_show_progress ( zipfile_path , unzips_path ) : \n try : \n with zipfile . ZipFile ( zipfile_path , \"<STR_LIT>\" ) as zip_ref : \n for file_info in zip_ref . infolist ( ) : \n zip_ref . extract ( file_info , unzips_path ) \n os . remove ( zipfile_path ) \n return True \n except Exception as error : \n print ( error ) \n return False \n def unzip_file ( zip_path , zip_file_name ) : \n zip_file_path = os . path . join ( zip_path , zip_file_name + \"<STR_LIT>\" ) \n extract_path = os . path . join ( file_path , zip_file_name ) \n with zipfile . ZipFile ( zip_file_path , \"<STR_LIT>\" ) as zip_ref : \n zip_ref . extractall ( extract_path ) \n os . remove ( zip_file_path ) \n def model_download_pipeline ( url ) : \n verify = download_from_url ( url ) \n if verify == \"<STR_LIT>\" : \n extract_folder_path = \"<STR_LIT>\" \n for filename in os . listdir ( zips_path ) : \n if filename . endswith ( \"<STR_LIT>\" ) : \n zipfile_path = os . path . join ( zips_path , filename ) \n print ( \"<STR_LIT>\" ) \n model_zip = os . path . basename ( zipfile_path ) \n model_name = format_title ( model_zip . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] ) \n extract_folder_path = os . path . join ( \n \"<STR_LIT>\" , \n os . path . normpath ( model_name ) , \n ) \n success = extract_and_show_progress ( zipfile_path , extract_folder_path ) \n subfolders = [ \n f \n for f in os . listdir ( extract_folder_path ) \n if os . path . isdir ( os . path . join ( extract_folder_path , f ) ) \n ] \n if len ( subfolders ) == <NUM_LIT> : \n subfolder_path = os . path . join ( extract_folder_path , subfolders [ <NUM_LIT> ] ) \n for item in os . listdir ( subfolder_path ) : \n s = os . path . join ( subfolder_path , item ) \n d = os . path . join ( extract_folder_path , item ) \n shutil . move ( s , d ) \n os . rmdir ( subfolder_path ) \n for item in os . listdir ( extract_folder_path ) : \n if \"<STR_LIT>\" in item : \n file_name = item . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n if file_name != model_name : \n os . rename ( \n os . path . join ( extract_folder_path , item ) , \n os . path . join ( extract_folder_path , model_name + \"<STR_LIT>\" ) , \n ) \n else : \n if \"<STR_LIT>\" not in item : \n file_name = item . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n if file_name != model_name : \n new_file_name = ( \n item . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n + \"<STR_LIT>\" \n + model_name \n + \"<STR_LIT>\" \n ) \n os . rename ( \n os . path . join ( extract_folder_path , item ) , \n os . path . join ( \n extract_folder_path , new_file_name + \"<STR_LIT>\" \n ) , \n ) \n else : \n file_name = item . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n if file_name != model_name : \n new_file_name = ( \n item . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n + \"<STR_LIT>\" \n + model_name \n + \"<STR_LIT>\" \n ) \n os . rename ( \n os . path . join ( extract_folder_path , item ) , \n os . path . join ( \n extract_folder_path , new_file_name + \"<STR_LIT>\" \n ) , \n ) \n if success : \n print ( f\"<STR_LIT>\" ) \n else : \n print ( f\"<STR_LIT>\" ) \n sys . exit ( ) \n if extract_folder_path == \"<STR_LIT>\" : \n print ( \"<STR_LIT>\" ) \n sys . exit ( ) \n result = search_pth_index ( extract_folder_path ) \n else : \n message = \"<STR_LIT>\""}, {"input": "import json \n import os \n import importlib \n import gradio as gr \n now_dir = os . getcwd ( ) \n folder = os . path . dirname ( os . path . abspath ( __file__ ) ) \n folder = os . path . dirname ( folder ) \n folder = os . path . dirname ( folder ) \n folder = os . path . join ( folder , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n config_file = os . path . join ( now_dir , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n import sys \n sys . path . append ( folder ) \n def get_class ( filename ) : \n with open ( filename , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as file : \n for line_number , line in enumerate ( file , start = <NUM_LIT> ) : \n if \"<STR_LIT>\" in line : \n found = line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . strip ( ) \n return found \n break \n return None \n def get_list ( ) : \n themes_from_files = [ \n os . path . splitext ( name ) [ <NUM_LIT> ] \n for root , _ , files in os . walk ( folder , topdown = False ) \n for name in files \n if name . endswith ( \"<STR_LIT>\" ) and root == folder \n ] \n json_file_path = os . path . join ( folder , \"<STR_LIT>\" ) \n try : \n with open ( json_file_path , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : \n themes_from_url = [ item [ \"<STR_LIT>\" ] for item in json . load ( json_file ) ] \n except FileNotFoundError : \n themes_from_url = [ ] \n combined_themes = set ( themes_from_files + themes_from_url ) \n return list ( combined_themes ) \n def select_theme ( name ) : \n selected_file = name + \"<STR_LIT>\" \n full_path = os . path . join ( folder , selected_file ) \n if not os . path . exists ( full_path ) : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : \n config_data = json . load ( json_file ) \n config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = None \n config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = name \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : \n json . dump ( config_data , json_file , indent = <NUM_LIT> ) \n print ( f\"<STR_LIT>\" ) \n gr . Info ( f\"<STR_LIT>\" ) \n return \n class_found = get_class ( full_path ) \n if class_found : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : \n config_data = json . load ( json_file ) \n config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = selected_file \n config_data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = class_found \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : \n json . dump ( config_data , json_file , indent = <NUM_LIT> ) \n print ( f\"<STR_LIT>\" ) \n gr . Info ( f\"<STR_LIT>\" ) \n else : \n print ( f\"<STR_LIT>\" ) \n def read_json ( ) : \n try : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : \n data = json . load ( json_file ) \n selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n if selected_file is not None and class_name : \n return class_name \n elif selected_file == None and class_name : \n return class_name \n else : \n return \"<STR_LIT>\" \n except Exception as e : \n print ( f\"<STR_LIT>\" ) \n return \"<STR_LIT>\" \n def load_json ( ) : \n try : \n with open ( config_file , \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as json_file : \n data = json . load ( json_file ) \n selected_file = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n class_name = data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n if selected_file is not None and class_name : \n module = importlib . import_module ( selected_file [ : - <NUM_LIT> ] ) \n obtained_class = getattr ( module , class_name ) \n instance = obtained_class ( )", "output": "print ( f\"<STR_LIT>\" ) \n return instance \n elif selected_file == None and class_name : \n return class_name \n else : \n print ( \"<STR_LIT>\" ) \n return None \n except Exception as e : \n print ( f\"<STR_LIT>\" ) \n return None"}, {"input": "from pypresence import Presence \n import datetime as dt \n import time \n class RichPresenceManager : \n def __init__ ( self ) : \n self . client_id = \"<STR_LIT>\" \n self . rpc = None \n self . running = False \n def start_presence ( self ) : \n if not self . running : \n self . running = True \n self . rpc = Presence ( self . client_id ) \n try : \n self . rpc . connect ( ) \n self . update_presence ( ) \n except KeyboardInterrupt as error : \n print ( error ) \n self . rpc = None \n self . running = False \n except Exception as e : \n print ( f\"<STR_LIT>\" ) \n self . rpc = None \n self . running = False \n def update_presence ( self ) : \n if self . rpc : \n self . rpc . update ( \n state = \"<STR_LIT>\" , \n details = \"<STR_LIT>\" ,", "output": "buttons = [ \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ] , \n large_image = \"<STR_LIT>\" , \n large_text = \"<STR_LIT>\" , \n start = dt . datetime . now ( ) . timestamp ( ) , \n ) \n def stop_presence ( self ) : \n self . running = False \n if self . rpc : \n self . rpc . close ( ) \n self . rpc = None \n RPCManager = RichPresenceManager ( )"}, {"input": "import os \n import sys \n import base64 \n import pathlib \n import tempfile \n import gradio as gr \n from assets . i18n . i18n import I18nAuto \n import assets . themes . loadThemes as loadThemes \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n i18n = I18nAuto ( ) \n def theme_tab ( ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n themes_select = gr . Dropdown ( \n loadThemes . get_list ( ) , \n value = loadThemes . read_json ( ) ,", "output": "label = i18n ( \"<STR_LIT>\" ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n visible = True , \n ) \n themes_select . change ( \n fn = loadThemes . select_theme , \n inputs = themes_select , \n outputs = [ ] , \n )"}, {"input": "from __future__ import annotations \n from typing import Iterable \n import gradio as gr \n from gradio . themes . base import Base \n from gradio . themes . utils import colors , fonts , sizes \n import time \n class Applio ( Base ) : \n def __init__ ( \n self , \n * , \n primary_hue : colors . Color | str = colors . green , \n secondary_hue : colors . Color | str = colors . emerald , \n neutral_hue : colors . Color | str = colors . neutral , \n spacing_size : sizes . Size | str = sizes . spacing_md , \n radius_size : sizes . Size | str = sizes . radius_md , \n text_size : sizes . Size | str = sizes . text_lg , \n font : fonts . Font | str | Iterable [ fonts . Font | str ] = ( \n \"<STR_LIT>\" , \n fonts . GoogleFont ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n font_mono : fonts . Font | str | Iterable [ fonts . Font | str ] = ( \n \"<STR_LIT>\" , \n fonts . GoogleFont ( \"<STR_LIT>\" ) , \n ) , \n ) : \n super ( ) . __init__ ( \n primary_hue = primary_hue , \n secondary_hue = secondary_hue , \n neutral_hue = neutral_hue , \n spacing_size = spacing_size , \n radius_size = radius_size , \n text_size = text_size , \n font = font , \n font_mono = font_mono , \n ) \n self . name = ( \"<STR_LIT>\" , ) \n self . secondary_100 = ( \"<STR_LIT>\" , ) \n self . secondary_200 = ( \"<STR_LIT>\" , ) \n self . secondary_300 = ( \"<STR_LIT>\" , ) \n self . secondary_400 = ( \"<STR_LIT>\" , ) \n self . secondary_50 = ( \"<STR_LIT>\" , ) \n self . secondary_500 = ( \"<STR_LIT>\" , ) \n self . secondary_600 = ( \"<STR_LIT>\" , ) \n self . secondary_700 = ( \"<STR_LIT>\" , ) \n self . secondary_800 = ( \"<STR_LIT>\" , ) \n self . secondary_900 = ( \"<STR_LIT>\" , ) \n self . secondary_950 = ( \"<STR_LIT>\" , ) \n super ( ) . set ( \n background_fill_primary = \"<STR_LIT>\" , \n background_fill_primary_dark = \"<STR_LIT>\" , \n background_fill_secondary = \"<STR_LIT>\" , \n background_fill_secondary_dark = \"<STR_LIT>\" , \n block_background_fill = \"<STR_LIT>\" , \n block_background_fill_dark = \"<STR_LIT>\" , \n block_border_color = \"<STR_LIT>\" , \n block_border_color_dark = \"<STR_LIT>\" , \n block_border_width = \"<STR_LIT>\" , \n block_border_width_dark = \"<STR_LIT>\" , \n block_info_text_color = \"<STR_LIT>\" , \n block_info_text_color_dark = \"<STR_LIT>\" , \n block_info_text_size = \"<STR_LIT>\" , \n block_info_text_weight = \"<STR_LIT>\" , \n block_label_background_fill = \"<STR_LIT>\" , \n block_label_background_fill_dark = \"<STR_LIT>\" , \n block_label_border_color = \"<STR_LIT>\" , \n block_label_border_color_dark = \"<STR_LIT>\" , \n block_label_border_width = \"<STR_LIT>\" , \n block_label_border_width_dark = \"<STR_LIT>\" , \n block_label_margin = \"<STR_LIT>\" , \n block_label_padding = \"<STR_LIT>\" , \n block_label_radius = \"<STR_LIT>\" , \n block_label_right_radius = \"<STR_LIT>\" , \n block_label_shadow = \"<STR_LIT>\" , \n block_label_text_color = \"<STR_LIT>\" , \n block_label_text_color_dark = \"<STR_LIT>\" , \n block_label_text_weight = \"<STR_LIT>\" , \n block_padding = \"<STR_LIT>\" , \n block_radius = \"<STR_LIT>\" , \n block_shadow = \"<STR_LIT>\" , \n block_shadow_dark = \"<STR_LIT>\" , \n block_title_background_fill = \"<STR_LIT>\" , \n block_title_background_fill_dark = \"<STR_LIT>\" , \n block_title_border_color = \"<STR_LIT>\" , \n block_title_border_color_dark = \"<STR_LIT>\" , \n block_title_border_width = \"<STR_LIT>\" , \n block_title_padding = \"<STR_LIT>\" , \n block_title_radius = \"<STR_LIT>\" , \n block_title_text_color = \"<STR_LIT>\" , \n block_title_text_color_dark = \"<STR_LIT>\" , \n block_title_text_size = \"<STR_LIT>\" , \n block_title_text_weight = \"<STR_LIT>\" , \n body_background_fill = \"<STR_LIT>\" , \n body_background_fill_dark = \"<STR_LIT>\" , \n body_text_color = \"<STR_LIT>\" , \n body_text_color_dark = \"<STR_LIT>\" , \n body_text_color_subdued = \"<STR_LIT>\" , \n body_text_color_subdued_dark = \"<STR_LIT>\" , \n body_text_size = \"<STR_LIT>\" , \n body_text_weight = \"<STR_LIT>\" , \n border_color_accent = \"<STR_LIT>\" , \n border_color_accent_dark = \"<STR_LIT>\" , \n border_color_primary = \"<STR_LIT>\" , \n border_color_primary_dark = \"<STR_LIT>\" , \n button_border_width = \"<STR_LIT>\" , \n button_border_width_dark = \"<STR_LIT>\" , \n button_cancel_background_fill = \"<STR_LIT>\" , \n button_cancel_background_fill_dark = \"<STR_LIT>\" , \n button_cancel_background_fill_hover = \"<STR_LIT>\" , \n button_cancel_background_fill_hover_dark = \"<STR_LIT>\" , \n button_cancel_border_color = \"<STR_LIT>\" , \n button_cancel_border_color_dark = \"<STR_LIT>\" , \n button_cancel_border_color_hover = \"<STR_LIT>\" , \n button_cancel_border_color_hover_dark = \"<STR_LIT>\" , \n button_cancel_text_color = \"<STR_LIT>\" , \n button_cancel_text_color_dark = \"<STR_LIT>\" , \n button_cancel_text_color_hover = \"<STR_LIT>\" , \n button_cancel_text_color_hover_dark = \"<STR_LIT>\" , \n button_large_padding = \"<STR_LIT>\" , \n button_large_radius = \"<STR_LIT>\" , \n button_large_text_size = \"<STR_LIT>\" , \n button_large_text_weight = \"<STR_LIT>\" , \n button_primary_background_fill = \"<STR_LIT>\" , \n button_primary_background_fill_dark = \"<STR_LIT>\" , \n button_primary_background_fill_hover = \"<STR_LIT>\" , \n button_primary_background_fill_hover_dark = \"<STR_LIT>\" , \n button_primary_border_color = \"<STR_LIT>\" , \n button_primary_border_color_dark = \"<STR_LIT>\" , \n button_primary_border_color_hover = \"<STR_LIT>\" , \n button_primary_border_color_hover_dark = \"<STR_LIT>\" , \n button_primary_text_color = \"<STR_LIT>\" , \n button_primary_text_color_dark = \"<STR_LIT>\" , \n button_primary_text_color_hover = \"<STR_LIT>\" , \n button_primary_text_color_hover_dark = \"<STR_LIT>\" , \n button_secondary_background_fill = \"<STR_LIT>\" , \n button_secondary_background_fill_dark = \"<STR_LIT>\" , \n button_secondary_background_fill_hover = \"<STR_LIT>\" , \n button_secondary_background_fill_hover_dark = \"<STR_LIT>\" , \n button_secondary_border_color = \"<STR_LIT>\" , \n button_secondary_border_color_dark = \"<STR_LIT>\" , \n button_secondary_border_color_hover = \"<STR_LIT>\" , \n button_secondary_border_color_hover_dark = \"<STR_LIT>\" , \n button_secondary_text_color = \"<STR_LIT>\" , \n button_secondary_text_color_dark = \"<STR_LIT>\" , \n button_secondary_text_color_hover = \"<STR_LIT>\" , \n button_secondary_text_color_hover_dark = \"<STR_LIT>\" , \n button_shadow = \"<STR_LIT>\" , \n button_shadow_active = \"<STR_LIT>\" , \n button_shadow_hover = \"<STR_LIT>\" , \n button_small_padding = \"<STR_LIT>\" , \n button_small_radius = \"<STR_LIT>\" , \n button_small_text_size = \"<STR_LIT>\" , \n button_small_text_weight = \"<STR_LIT>\" , \n button_transition = \"<STR_LIT>\" , \n checkbox_background_color = \"<STR_LIT>\" , \n checkbox_background_color_dark = \"<STR_LIT>\" , \n checkbox_background_color_focus = \"<STR_LIT>\" , \n checkbox_background_color_focus_dark = \"<STR_LIT>\" , \n checkbox_background_color_hover = \"<STR_LIT>\" , \n checkbox_background_color_hover_dark = \"<STR_LIT>\" , \n checkbox_background_color_selected = \"<STR_LIT>\" , \n checkbox_background_color_selected_dark = \"<STR_LIT>\" , \n checkbox_border_color = \"<STR_LIT>\" , \n checkbox_border_color_dark = \"<STR_LIT>\" , \n checkbox_border_color_focus = \"<STR_LIT>\" , \n checkbox_border_color_focus_dark = \"<STR_LIT>\" , \n checkbox_border_color_hover = \"<STR_LIT>\" , \n checkbox_border_color_hover_dark = \"<STR_LIT>\" , \n checkbox_border_color_selected = \"<STR_LIT>\" , \n checkbox_border_color_selected_dark = \"<STR_LIT>\" , \n checkbox_border_radius = \"<STR_LIT>\" , \n checkbox_border_width = \"<STR_LIT>\" , \n checkbox_border_width_dark = \"<STR_LIT>\" , \n checkbox_check = \"<STR_LIT>\" , \n checkbox_label_background_fill = \"<STR_LIT>\" , \n checkbox_label_background_fill_dark = \"<STR_LIT>\" , \n checkbox_label_background_fill_hover = \"<STR_LIT>\" , \n checkbox_label_background_fill_hover_dark = \"<STR_LIT>\" , \n checkbox_label_background_fill_selected = \"<STR_LIT>\" , \n checkbox_label_background_fill_selected_dark = \"<STR_LIT>\" , \n checkbox_label_border_color = \"<STR_LIT>\" , \n checkbox_label_border_color_dark = \"<STR_LIT>\" , \n checkbox_label_border_color_hover = \"<STR_LIT>\" , \n checkbox_label_border_color_hover_dark = \"<STR_LIT>\" , \n checkbox_label_border_width = \"<STR_LIT>\" , \n checkbox_label_border_width_dark = \"<STR_LIT>\" , \n checkbox_label_gap = \"<STR_LIT>\" , \n checkbox_label_padding = \"<STR_LIT>\" , \n checkbox_label_shadow = \"<STR_LIT>\" , \n checkbox_label_text_color = \"<STR_LIT>\" , \n checkbox_label_text_color_dark = \"<STR_LIT>\" , \n checkbox_label_text_color_selected = \"<STR_LIT>\" , \n checkbox_label_text_color_selected_dark = \"<STR_LIT>\" , \n checkbox_label_text_size = \"<STR_LIT>\" , \n checkbox_label_text_weight = \"<STR_LIT>\" , \n checkbox_shadow = \"<STR_LIT>\" , \n color_accent = \"<STR_LIT>\" , \n color_accent_soft = \"<STR_LIT>\" , \n color_accent_soft_dark = \"<STR_LIT>\" , \n container_radius = \"<STR_LIT>\" , \n embed_radius = \"<STR_LIT>\" , \n error_background_fill = \"<STR_LIT>\" , \n error_background_fill_dark = \"<STR_LIT>\" , \n error_border_color = \"<STR_LIT>\" , \n error_border_color_dark = \"<STR_LIT>\" , \n error_border_width = \"<STR_LIT>\" , \n error_border_width_dark = \"<STR_LIT>\" , \n error_text_color = \"<STR_LIT>\" , \n error_text_color_dark = \"<STR_LIT>\" , \n form_gap_width = \"<STR_LIT>\" , \n input_background_fill = \"<STR_LIT>\" , \n input_background_fill_dark = \"<STR_LIT>\" , \n input_background_fill_focus = \"<STR_LIT>\" , \n input_background_fill_focus_dark = \"<STR_LIT>\" , \n input_background_fill_hover = \"<STR_LIT>\" , \n input_background_fill_hover_dark = \"<STR_LIT>\" , \n input_border_color = \"<STR_LIT>\" , \n input_border_color_dark = \"<STR_LIT>\" , \n input_border_color_focus = \"<STR_LIT>\" , \n input_border_color_focus_dark = \"<STR_LIT>\" , \n input_border_color_hover = \"<STR_LIT>\" , \n input_border_color_hover_dark = \"<STR_LIT>\" , \n input_border_width = \"<STR_LIT>\" , \n input_border_width_dark = \"<STR_LIT>\" , \n input_padding = \"<STR_LIT>\" , \n input_placeholder_color = \"<STR_LIT>\" ,", "output": "input_placeholder_color_dark = \"<STR_LIT>\" , \n input_radius = \"<STR_LIT>\" , \n input_shadow = \"<STR_LIT>\" , \n input_shadow_dark = \"<STR_LIT>\" , \n input_shadow_focus = \"<STR_LIT>\" , \n input_shadow_focus_dark = \"<STR_LIT>\" , \n input_text_size = \"<STR_LIT>\" , \n input_text_weight = \"<STR_LIT>\" , \n layout_gap = \"<STR_LIT>\" , \n link_text_color = \"<STR_LIT>\" , \n link_text_color_active = \"<STR_LIT>\" , \n link_text_color_active_dark = \"<STR_LIT>\" , \n link_text_color_dark = \"<STR_LIT>\" , \n link_text_color_hover = \"<STR_LIT>\" , \n link_text_color_hover_dark = \"<STR_LIT>\" , \n link_text_color_visited = \"<STR_LIT>\" , \n link_text_color_visited_dark = \"<STR_LIT>\" , \n loader_color = \"<STR_LIT>\" , \n loader_color_dark = \"<STR_LIT>\" , \n panel_background_fill = \"<STR_LIT>\" , \n panel_background_fill_dark = \"<STR_LIT>\" , \n panel_border_color = \"<STR_LIT>\" , \n panel_border_color_dark = \"<STR_LIT>\" , \n panel_border_width = \"<STR_LIT>\" , \n panel_border_width_dark = \"<STR_LIT>\" , \n prose_header_text_weight = \"<STR_LIT>\" , \n prose_text_size = \"<STR_LIT>\" , \n prose_text_weight = \"<STR_LIT>\" , \n radio_circle = \"<STR_LIT>\" , \n section_header_text_size = \"<STR_LIT>\" , \n section_header_text_weight = \"<STR_LIT>\" , \n shadow_drop = \"<STR_LIT>\" , \n shadow_drop_lg = \"<STR_LIT>\" , \n shadow_inset = \"<STR_LIT>\" , \n shadow_spread = \"<STR_LIT>\" , \n shadow_spread_dark = \"<STR_LIT>\" , \n slider_color = \"<STR_LIT>\" , \n slider_color_dark = \"<STR_LIT>\" , \n stat_background_fill = \"<STR_LIT>\" , \n stat_background_fill_dark = \"<STR_LIT>\" , \n table_border_color = \"<STR_LIT>\" , \n table_border_color_dark = \"<STR_LIT>\" , \n table_even_background_fill = \"<STR_LIT>\" , \n table_even_background_fill_dark = \"<STR_LIT>\" , \n table_odd_background_fill = \"<STR_LIT>\" , \n table_odd_background_fill_dark = \"<STR_LIT>\" , \n table_radius = \"<STR_LIT>\" , \n table_row_focus = \"<STR_LIT>\" , \n table_row_focus_dark = \"<STR_LIT>\" , \n )"}, {"input": "def pretrained_selector ( pitch_guidance ) : \n if pitch_guidance : \n return { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ,", "output": ") , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n } , \n } \n else : \n return { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n } , \n }"}, {"input": "import os \n import sys \n import gradio as gr \n from assets . i18n . i18n import I18nAuto \n import requests \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n from assets . flask . server import start_flask , load_config_flask , save_config \n i18n = I18nAuto ( ) \n def flask_server_tab ( ) : \n with gr . Row ( ) : \n with gr . Column ( ) : \n flask_checkbox = gr . Checkbox ( \n label = i18n ( \n \"<STR_LIT>\" \n ) , \n info = i18n ( \n \"<STR_LIT>\" \n ) , \n interactive = True , \n value = load_config_flask ( ) , \n ) \n flask_checkbox . change ( \n fn = toggle , \n inputs = [ flask_checkbox ] , \n outputs = [ ] , \n ) \n def toggle ( checkbox ) :", "output": "save_config ( bool ( checkbox ) ) \n if load_config_flask ( ) == True : \n start_flask ( ) \n else : \n try : \n requests . post ( \"<STR_LIT>\" ) \n except requests . exceptions . ConnectionError : \n pass"}, {"input": "import os , sys \n import signal \n from flask import Flask , request , redirect \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n from core import run_download_script \n app = Flask ( __name__ ) \n @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) \n def download ( url ) : \n file_path = run_download_script ( url ) \n if file_path == \"<STR_LIT>\" :", "output": "if \"<STR_LIT>\" in request . headers . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : \n return redirect ( \"<STR_LIT>\" , code = <NUM_LIT> ) \n else : \n return \"<STR_LIT>\" \n else : \n return \"<STR_LIT>\" , <NUM_LIT> \n @ app . route ( \"<STR_LIT>\" , methods = [ \"<STR_LIT>\" ] ) \n def shutdown ( ) : \n print ( \"<STR_LIT>\" ) \n os . kill ( os . getpid ( ) , signal . SIGTERM ) \n if __name__ == \"<STR_LIT>\" : \n app . run ( host = \"<STR_LIT>\" , port = <NUM_LIT> )"}, {"input": "import math \n import torch \n from torch import nn \n from torch . nn import functional as F \n from torch . nn import Conv1d \n from torch . nn . utils import remove_weight_norm \n from torch . nn . utils . parametrizations import weight_norm \n from . import commons \n from . commons import init_weights , get_padding \n from . transforms import piecewise_rational_quadratic_transform \n LRELU_SLOPE = <NUM_LIT> \n class LayerNorm ( nn . Module ) : \n def __init__ ( self , channels , eps = <NUM_LIT> ) : \n super ( ) . __init__ ( ) \n self . channels = channels \n self . eps = eps \n self . gamma = nn . Parameter ( torch . ones ( channels ) ) \n self . beta = nn . Parameter ( torch . zeros ( channels ) ) \n def forward ( self , x ) : \n x = x . transpose ( <NUM_LIT> , - <NUM_LIT> ) \n x = F . layer_norm ( x , ( self . channels , ) , self . gamma , self . beta , self . eps ) \n return x . transpose ( <NUM_LIT> , - <NUM_LIT> ) \n class ConvReluNorm ( nn . Module ) : \n def __init__ ( \n self , \n in_channels , \n hidden_channels , \n out_channels , \n kernel_size , \n n_layers , \n p_dropout , \n ) : \n super ( ) . __init__ ( ) \n self . in_channels = in_channels \n self . hidden_channels = hidden_channels \n self . out_channels = out_channels \n self . kernel_size = kernel_size \n self . n_layers = n_layers \n self . p_dropout = p_dropout \n assert n_layers > <NUM_LIT> , \"<STR_LIT>\" \n self . conv_layers = nn . ModuleList ( ) \n self . norm_layers = nn . ModuleList ( ) \n self . conv_layers . append ( \n nn . Conv1d ( \n in_channels , hidden_channels , kernel_size , padding = kernel_size // <NUM_LIT> \n ) \n ) \n self . norm_layers . append ( LayerNorm ( hidden_channels ) ) \n self . relu_drop = nn . Sequential ( nn . ReLU ( ) , nn . Dropout ( p_dropout ) ) \n for _ in range ( n_layers - <NUM_LIT> ) : \n self . conv_layers . append ( \n nn . Conv1d ( \n hidden_channels , \n hidden_channels , \n kernel_size , \n padding = kernel_size // <NUM_LIT> , \n ) \n ) \n self . norm_layers . append ( LayerNorm ( hidden_channels ) ) \n self . proj = nn . Conv1d ( hidden_channels , out_channels , <NUM_LIT> ) \n self . proj . weight . data . zero_ ( ) \n self . proj . bias . data . zero_ ( ) \n def forward ( self , x , x_mask ) : \n x_org = x \n for i in range ( self . n_layers ) : \n x = self . conv_layers [ i ] ( x * x_mask ) \n x = self . norm_layers [ i ] ( x ) \n x = self . relu_drop ( x ) \n x = x_org + self . proj ( x ) \n return x * x_mask \n class DDSConv ( nn . Module ) : \n def __init__ ( self , channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) : \n super ( ) . __init__ ( ) \n self . channels = channels \n self . kernel_size = kernel_size \n self . n_layers = n_layers \n self . p_dropout = p_dropout \n self . drop = nn . Dropout ( p_dropout ) \n self . convs_sep = nn . ModuleList ( ) \n self . convs_1x1 = nn . ModuleList ( ) \n self . norms_1 = nn . ModuleList ( ) \n self . norms_2 = nn . ModuleList ( ) \n for i in range ( n_layers ) : \n dilation = kernel_size ** i \n padding = ( kernel_size * dilation - dilation ) // <NUM_LIT> \n self . convs_sep . append ( \n nn . Conv1d ( \n channels , \n channels , \n kernel_size , \n groups = channels , \n dilation = dilation , \n padding = padding , \n ) \n ) \n self . convs_1x1 . append ( nn . Conv1d ( channels , channels , <NUM_LIT> ) ) \n self . norms_1 . append ( LayerNorm ( channels ) ) \n self . norms_2 . append ( LayerNorm ( channels ) ) \n def forward ( self , x , x_mask , g = None ) : \n if g is not None : \n x = x + g \n for i in range ( self . n_layers ) : \n y = self . convs_sep [ i ] ( x * x_mask ) \n y = self . norms_1 [ i ] ( y ) \n y = F . gelu ( y ) \n y = self . convs_1x1 [ i ] ( y ) \n y = self . norms_2 [ i ] ( y ) \n y = F . gelu ( y ) \n y = self . drop ( y ) \n x = x + y \n return x * x_mask \n class WN ( torch . nn . Module ) : \n def __init__ ( \n self , \n hidden_channels , \n kernel_size , \n dilation_rate , \n n_layers , \n gin_channels = <NUM_LIT> , \n p_dropout = <NUM_LIT> , \n ) : \n super ( WN , self ) . __init__ ( ) \n assert kernel_size % <NUM_LIT> == <NUM_LIT> \n self . hidden_channels = hidden_channels \n self . kernel_size = ( kernel_size , ) \n self . dilation_rate = dilation_rate \n self . n_layers = n_layers \n self . gin_channels = gin_channels \n self . p_dropout = p_dropout \n self . in_layers = torch . nn . ModuleList ( ) \n self . res_skip_layers = torch . nn . ModuleList ( ) \n self . drop = nn . Dropout ( p_dropout ) \n if gin_channels != <NUM_LIT> : \n cond_layer = torch . nn . Conv1d ( \n gin_channels , <NUM_LIT> * hidden_channels * n_layers , <NUM_LIT> \n ) \n self . cond_layer = torch . nn . utils . parametrizations . weight_norm ( \n cond_layer , name = \"<STR_LIT>\" \n ) \n for i in range ( n_layers ) : \n dilation = dilation_rate ** i \n padding = int ( ( kernel_size * dilation - dilation ) / <NUM_LIT> ) \n in_layer = torch . nn . Conv1d ( \n hidden_channels , \n <NUM_LIT> * hidden_channels , \n kernel_size , \n dilation = dilation , \n padding = padding , \n ) \n in_layer = torch . nn . utils . parametrizations . weight_norm ( \n in_layer , name = \"<STR_LIT>\" \n ) \n self . in_layers . append ( in_layer ) \n if i < n_layers - <NUM_LIT> : \n res_skip_channels = <NUM_LIT> * hidden_channels \n else : \n res_skip_channels = hidden_channels \n res_skip_layer = torch . nn . Conv1d ( hidden_channels , res_skip_channels , <NUM_LIT> ) \n res_skip_layer = torch . nn . utils . parametrizations . weight_norm ( \n res_skip_layer , name = \"<STR_LIT>\" \n ) \n self . res_skip_layers . append ( res_skip_layer ) \n def forward ( self , x , x_mask , g = None , ** kwargs ) : \n output = torch . zeros_like ( x ) \n n_channels_tensor = torch . IntTensor ( [ self . hidden_channels ] ) \n if g is not None : \n g = self . cond_layer ( g ) \n for i in range ( self . n_layers ) : \n x_in = self . in_layers [ i ] ( x ) \n if g is not None : \n cond_offset = i * <NUM_LIT> * self . hidden_channels \n g_l = g [ : , cond_offset : cond_offset + <NUM_LIT> * self . hidden_channels , : ] \n else : \n g_l = torch . zeros_like ( x_in ) \n acts = commons . fused_add_tanh_sigmoid_multiply ( x_in , g_l , n_channels_tensor ) \n acts = self . drop ( acts ) \n res_skip_acts = self . res_skip_layers [ i ] ( acts ) \n if i < self . n_layers - <NUM_LIT> : \n res_acts = res_skip_acts [ : , : self . hidden_channels , : ] \n x = ( x + res_acts ) * x_mask \n output = output + res_skip_acts [ : , self . hidden_channels : , : ] \n else : \n output = output + res_skip_acts \n return output * x_mask \n def remove_weight_norm ( self ) : \n if self . gin_channels != <NUM_LIT> : \n torch . nn . utils . remove_weight_norm ( self . cond_layer ) \n for l in self . in_layers : \n torch . nn . utils . remove_weight_norm ( l ) \n for l in self . res_skip_layers : \n torch . nn . utils . remove_weight_norm ( l ) \n class ResBlock1 ( torch . nn . Module ) : \n def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) : \n super ( ResBlock1 , self ) . __init__ ( ) \n self . convs1 = nn . ModuleList ( \n [ \n weight_norm ( \n Conv1d ( \n channels , \n channels , \n kernel_size , \n <NUM_LIT> , \n dilation = dilation [ <NUM_LIT> ] , \n padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , \n ) \n ) , \n weight_norm ( \n Conv1d ( \n channels , \n channels , \n kernel_size , \n <NUM_LIT> , \n dilation = dilation [ <NUM_LIT> ] , \n padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , \n ) \n ) , \n weight_norm ( \n Conv1d ( \n channels , \n channels , \n kernel_size , \n <NUM_LIT> , \n dilation = dilation [ <NUM_LIT> ] , \n padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , \n ) \n ) , \n ] \n ) \n self . convs1 . apply ( init_weights ) \n self . convs2 = nn . ModuleList ( \n [ \n weight_norm ( \n Conv1d ( \n channels , \n channels , \n kernel_size , \n <NUM_LIT> , \n dilation = <NUM_LIT> , \n padding = get_padding ( kernel_size , <NUM_LIT> ) , \n ) \n ) , \n weight_norm ( \n Conv1d ( \n channels , \n channels , \n kernel_size , \n <NUM_LIT> , \n dilation = <NUM_LIT> , \n padding = get_padding ( kernel_size , <NUM_LIT> ) , \n ) \n ) , \n weight_norm ( \n Conv1d ( \n channels , \n channels , \n kernel_size , \n <NUM_LIT> , \n dilation = <NUM_LIT> , \n padding = get_padding ( kernel_size , <NUM_LIT> ) , \n ) \n ) , \n ] \n ) \n self . convs2 . apply ( init_weights ) \n def forward ( self , x , x_mask = None ) : \n for c1 , c2 in zip ( self . convs1 , self . convs2 ) : \n xt = F . leaky_relu ( x , LRELU_SLOPE ) \n if x_mask is not None : \n xt = xt * x_mask \n xt = c1 ( xt ) \n xt = F . leaky_relu ( xt , LRELU_SLOPE ) \n if x_mask is not None : \n xt = xt * x_mask \n xt = c2 ( xt ) \n x = xt + x \n if x_mask is not None : \n x = x * x_mask \n return x \n def remove_weight_norm ( self ) : \n for l in self . convs1 : \n remove_weight_norm ( l ) \n for l in self . convs2 : \n remove_weight_norm ( l ) \n class ResBlock2 ( torch . nn . Module ) : \n def __init__ ( self , channels , kernel_size = <NUM_LIT> , dilation = ( <NUM_LIT> , <NUM_LIT> ) ) : \n super ( ResBlock2 , self ) . __init__ ( ) \n self . convs = nn . ModuleList ( \n [ \n weight_norm ( \n Conv1d ( \n channels , \n channels , \n kernel_size , \n <NUM_LIT> , \n dilation = dilation [ <NUM_LIT> ] , \n padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , \n ) \n ) , \n weight_norm ( \n Conv1d ( \n channels , \n channels , \n kernel_size , \n <NUM_LIT> , \n dilation = dilation [ <NUM_LIT> ] , \n padding = get_padding ( kernel_size , dilation [ <NUM_LIT> ] ) , \n ) \n ) , \n ] \n ) \n self . convs . apply ( init_weights ) \n def forward ( self , x , x_mask = None ) : \n for c in self . convs : \n xt = F . leaky_relu ( x , LRELU_SLOPE ) \n if x_mask is not None :", "output": "xt = xt * x_mask \n xt = c ( xt ) \n x = xt + x \n if x_mask is not None : \n x = x * x_mask \n return x \n def remove_weight_norm ( self ) : \n for l in self . convs : \n remove_weight_norm ( l ) \n class Log ( nn . Module ) : \n def forward ( self , x , x_mask , reverse = False , ** kwargs ) : \n if not reverse : \n y = torch . log ( torch . clamp_min ( x , <NUM_LIT> ) ) * x_mask \n logdet = torch . sum ( - y , [ <NUM_LIT> , <NUM_LIT> ] ) \n return y , logdet \n else : \n x = torch . exp ( x ) * x_mask \n return x \n class Flip ( nn . Module ) : \n def forward ( self , x , * args , reverse = False , ** kwargs ) : \n x = torch . flip ( x , [ <NUM_LIT> ] ) \n if not reverse : \n logdet = torch . zeros ( x . size ( <NUM_LIT> ) ) . to ( dtype = x . dtype , device = x . device ) \n return x , logdet \n else : \n return x \n class ElementwiseAffine ( nn . Module ) : \n def __init__ ( self , channels ) : \n super ( ) . __init__ ( ) \n self . channels = channels \n self . m = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) \n self . logs = nn . Parameter ( torch . zeros ( channels , <NUM_LIT> ) ) \n def forward ( self , x , x_mask , reverse = False , ** kwargs ) : \n if not reverse : \n y = self . m + torch . exp ( self . logs ) * x \n y = y * x_mask \n logdet = torch . sum ( self . logs * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) \n return y , logdet \n else : \n x = ( x - self . m ) * torch . exp ( - self . logs ) * x_mask \n return x \n class ResidualCouplingLayer ( nn . Module ) : \n def __init__ ( \n self , \n channels , \n hidden_channels , \n kernel_size , \n dilation_rate , \n n_layers , \n p_dropout = <NUM_LIT> , \n gin_channels = <NUM_LIT> , \n mean_only = False , \n ) : \n assert channels % <NUM_LIT> == <NUM_LIT> , \"<STR_LIT>\" \n super ( ) . __init__ ( ) \n self . channels = channels \n self . hidden_channels = hidden_channels \n self . kernel_size = kernel_size \n self . dilation_rate = dilation_rate \n self . n_layers = n_layers \n self . half_channels = channels // <NUM_LIT> \n self . mean_only = mean_only \n self . pre = nn . Conv1d ( self . half_channels , hidden_channels , <NUM_LIT> ) \n self . enc = WN ( \n hidden_channels , \n kernel_size , \n dilation_rate , \n n_layers , \n p_dropout = p_dropout , \n gin_channels = gin_channels , \n ) \n self . post = nn . Conv1d ( hidden_channels , self . half_channels * ( <NUM_LIT> - mean_only ) , <NUM_LIT> ) \n self . post . weight . data . zero_ ( ) \n self . post . bias . data . zero_ ( ) \n def forward ( self , x , x_mask , g = None , reverse = False ) : \n x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) \n h = self . pre ( x0 ) * x_mask \n h = self . enc ( h , x_mask , g = g ) \n stats = self . post ( h ) * x_mask \n if not self . mean_only : \n m , logs = torch . split ( stats , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) \n else : \n m = stats \n logs = torch . zeros_like ( m ) \n if not reverse : \n x1 = m + x1 * torch . exp ( logs ) * x_mask \n x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) \n logdet = torch . sum ( logs , [ <NUM_LIT> , <NUM_LIT> ] ) \n return x , logdet \n else : \n x1 = ( x1 - m ) * torch . exp ( - logs ) * x_mask \n x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) \n return x \n def remove_weight_norm ( self ) : \n self . enc . remove_weight_norm ( ) \n class ConvFlow ( nn . Module ) : \n def __init__ ( \n self , \n in_channels , \n filter_channels , \n kernel_size , \n n_layers , \n num_bins = <NUM_LIT> , \n tail_bound = <NUM_LIT> , \n ) : \n super ( ) . __init__ ( ) \n self . in_channels = in_channels \n self . filter_channels = filter_channels \n self . kernel_size = kernel_size \n self . n_layers = n_layers \n self . num_bins = num_bins \n self . tail_bound = tail_bound \n self . half_channels = in_channels // <NUM_LIT> \n self . pre = nn . Conv1d ( self . half_channels , filter_channels , <NUM_LIT> ) \n self . convs = DDSConv ( filter_channels , kernel_size , n_layers , p_dropout = <NUM_LIT> ) \n self . proj = nn . Conv1d ( \n filter_channels , self . half_channels * ( num_bins * <NUM_LIT> - <NUM_LIT> ) , <NUM_LIT> \n ) \n self . proj . weight . data . zero_ ( ) \n self . proj . bias . data . zero_ ( ) \n def forward ( self , x , x_mask , g = None , reverse = False ) : \n x0 , x1 = torch . split ( x , [ self . half_channels ] * <NUM_LIT> , <NUM_LIT> ) \n h = self . pre ( x0 ) \n h = self . convs ( h , x_mask , g = g ) \n h = self . proj ( h ) * x_mask \n b , c , t = x0 . shape \n h = h . reshape ( b , c , - <NUM_LIT> , t ) . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n unnormalized_widths = h [ ... , : self . num_bins ] / math . sqrt ( self . filter_channels ) \n unnormalized_heights = h [ ... , self . num_bins : <NUM_LIT> * self . num_bins ] / math . sqrt ( \n self . filter_channels \n ) \n unnormalized_derivatives = h [ ... , <NUM_LIT> * self . num_bins : ] \n x1 , logabsdet = piecewise_rational_quadratic_transform ( \n x1 , \n unnormalized_widths , \n unnormalized_heights , \n unnormalized_derivatives , \n inverse = reverse , \n tails = \"<STR_LIT>\" , \n tail_bound = self . tail_bound , \n ) \n x = torch . cat ( [ x0 , x1 ] , <NUM_LIT> ) * x_mask \n logdet = torch . sum ( logabsdet * x_mask , [ <NUM_LIT> , <NUM_LIT> ] ) \n if not reverse : \n return x , logdet \n else : \n return x"}, {"input": "import os \n import torch \n import hashlib \n import datetime \n from collections import OrderedDict \n def replace_keys_in_dict ( d , old_key_part , new_key_part ) : \n if isinstance ( d , OrderedDict ) : \n updated_dict = OrderedDict ( ) \n else : \n updated_dict = { } \n for key , value in d . items ( ) : \n new_key = key . replace ( old_key_part , new_key_part ) \n if isinstance ( value , dict ) : \n value = replace_keys_in_dict ( value , old_key_part , new_key_part ) \n updated_dict [ new_key ] = value \n return updated_dict \n def extract_small_model ( path , name , sr , if_f0 , version , epoch , step ) : \n try : \n ckpt = torch . load ( path , map_location = \"<STR_LIT>\" ) \n pth_file = f\"<STR_LIT>\" \n pth_file_old_version_path = os . path . join ( \"<STR_LIT>\" , f\"<STR_LIT>\" ) \n opt = OrderedDict ( \n weight = { \n key : value . half ( ) for key , value in ckpt . items ( ) if \"<STR_LIT>\" not in key \n } \n ) \n if \"<STR_LIT>\" in ckpt : \n ckpt = ckpt [ \"<STR_LIT>\" ] \n opt = OrderedDict ( ) \n opt [ \"<STR_LIT>\" ] = { } \n for key in ckpt . keys ( ) : \n if \"<STR_LIT>\" in key : \n continue \n opt [ \"<STR_LIT>\" ] [ key ] = ckpt [ key ] . half ( ) \n if sr == \"<STR_LIT>\" : \n opt [ \"<STR_LIT>\" ] = [ \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n \"<STR_LIT>\" , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n ] \n elif sr == \"<STR_LIT>\" : \n if version == \"<STR_LIT>\" : \n opt [ \"<STR_LIT>\" ] = [ \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n \"<STR_LIT>\" , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n ] \n else : \n opt [ \"<STR_LIT>\" ] = [ \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n \"<STR_LIT>\" , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] ,", "output": "[ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n ] \n elif sr == \"<STR_LIT>\" : \n if version == \"<STR_LIT>\" : \n opt [ \"<STR_LIT>\" ] = [ \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n \"<STR_LIT>\" , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n ] \n else : \n opt [ \"<STR_LIT>\" ] = [ \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n \"<STR_LIT>\" , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n [ [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] ] , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , \n <NUM_LIT> , \n <NUM_LIT> , \n <NUM_LIT> , \n ] \n opt [ \"<STR_LIT>\" ] = epoch \n opt [ \"<STR_LIT>\" ] = step \n opt [ \"<STR_LIT>\" ] = sr \n opt [ \"<STR_LIT>\" ] = int ( if_f0 ) \n opt [ \"<STR_LIT>\" ] = version \n opt [ \"<STR_LIT>\" ] = datetime . datetime . now ( ) . isoformat ( ) \n hash_input = f\"<STR_LIT>\" \n model_hash = hashlib . sha256 ( hash_input . encode ( ) ) . hexdigest ( ) \n opt [ \"<STR_LIT>\" ] = model_hash \n model = torch . load ( pth_file_old_version_path , map_location = torch . device ( \"<STR_LIT>\" ) ) \n torch . save ( \n replace_keys_in_dict ( \n replace_keys_in_dict ( \n model , \"<STR_LIT>\" , \"<STR_LIT>\" \n ) , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n pth_file_old_version_path , \n ) \n os . remove ( pth_file_old_version_path ) \n os . rename ( pth_file_old_version_path , pth_file ) \n except Exception as error : \n print ( error )"}, {"input": "import sys \n import os \n now_dir = os . getcwd ( ) \n sys . path . append ( now_dir ) \n class InstallationError ( Exception ) : \n def __init__ ( self , message = \"<STR_LIT>\" ) : \n self . message = message \n super ( ) . __init__ ( self . message ) \n def check_installation ( ) : \n try : \n system_drive = os . getenv ( \"<STR_LIT>\" ) \n current_drive = os . path . splitdrive ( now_dir ) [ <NUM_LIT> ] \n if current_drive . upper ( ) != system_drive . upper ( ) : \n raise InstallationError ( \n f\"<STR_LIT>\" \n ) \n except : \n pass \n else : \n if \"<STR_LIT>\" in now_dir : \n raise InstallationError ( \n \"<STR_LIT>\" \n ) \n elif \"<STR_LIT>\" in now_dir : \n raise InstallationError (", "output": "\"<STR_LIT>\" \n ) \n try : \n now_dir . encode ( \"<STR_LIT>\" ) \n except UnicodeEncodeError : \n raise InstallationError ( \n \"<STR_LIT>\" \n )"}]