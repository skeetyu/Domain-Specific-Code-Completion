[{"input": "from enum import Enum \n from django . utils . translation import gettext_lazy as _ \n class TeamType ( Enum ) : \n CLUB = _ ( \"<STR_LIT>\" ) \n NATIONAL = _ ( \"<STR_LIT>\" ) \n class SquadType ( Enum ) : \n SENIOR_MEN = _ ( \"<STR_LIT>\" ) \n SENIOR_WOMEN = _ ( \"<STR_LIT>\" )", "output": "ACADEMY = _ ( \"<STR_LIT>\" ) \n CHARITY = _ ( \"<STR_LIT>\" )"}, {"input": "import torch \n from torch import nn \n from transformers import AutoModel \n import torch . nn . functional as F \n def init_weights ( m ) : \n if isinstance ( m , nn . Linear ) : \n torch . nn . init . xavier_uniform ( m . weight ) \n m . bias . data . fill_ ( <NUM_LIT> ) \n class mainplm ( nn . Module ) : \n def __init__ ( self , args ) : \n super ( mainplm , self ) . __init__ ( ) \n self . args = args \n self . plm_batch_size = <NUM_LIT> \n self . plm = AutoModel . from_pretrained ( self . args [ '<STR_LIT>' ] ) \n for param in self . plm . embeddings . parameters ( ) : \n param . requires_grad = False \n for i in range ( <NUM_LIT> ) : \n for param in self . plm . encoder . layer [ i ] . parameters ( ) : \n param . requires_grad = False \n self . mlp = nn . Sequential ( \n nn . Dropout ( p = <NUM_LIT> ) , \n nn . Linear ( self . plm . config . hidden_size , <NUM_LIT> ) \n ) \n self . mlp . apply ( init_weights ) \n def forward ( self , document_batch : torch . Tensor , device = '<STR_LIT>' ) : \n plm_output = torch . zeros ( size = ( document_batch . shape [ <NUM_LIT> ] , \n min ( document_batch . shape [ <NUM_LIT> ] , self . plm_batch_size ) , \n self . plm . config . hidden_size ) , \n dtype = torch . float , device = device ) \n for doc_id in range ( document_batch . shape [ <NUM_LIT> ] ) : \n all_plm_output = self . plm ( document_batch [ doc_id ] [ : self . plm_batch_size , <NUM_LIT> ] , \n token_type_ids = document_batch [ doc_id ] [ : self . plm_batch_size , <NUM_LIT> ] , \n attention_mask = document_batch [ doc_id ] [ : self . plm_batch_size , <NUM_LIT> ] ) \n plm_output [ doc_id ] [ : self . plm_batch_size ] = all_plm_output . last_hidden_state [ <NUM_LIT> ] [ <NUM_LIT> ] . unsqueeze ( <NUM_LIT> ) \n prediction = self . mlp ( plm_output . view ( plm_output . shape [ <NUM_LIT> ] , - <NUM_LIT> ) ) \n assert prediction . shape [ <NUM_LIT> ] == document_batch . shape [ <NUM_LIT> ] \n return prediction \n class chunkplm ( nn . Module ) : \n def __init__ ( self , args ) : \n super ( chunkplm , self ) . __init__ ( ) \n self . args = args \n self . plm = AutoModel . from_pretrained ( self . args [ '<STR_LIT>' ] ) \n for param in self . plm . embeddings . parameters ( ) : \n param . requires_grad = False \n for i in range ( <NUM_LIT> ) : \n for param in self . plm . encoder . layer [ i ] . parameters ( ) : \n param . requires_grad = False \n self . dropout = nn . Dropout ( p = <NUM_LIT> ) \n self . lstm = nn . LSTM ( self . plm . config . hidden_size , self . plm . config . hidden_size ) \n self . mlp = nn . Sequential ( \n nn . Dropout ( p = <NUM_LIT> ) , \n nn . Linear ( self . plm . config . hidden_size , <NUM_LIT> ) \n )", "output": "self . w_omega = nn . Parameter ( torch . Tensor ( self . plm . config . hidden_size , self . plm . config . hidden_size ) ) \n self . b_omega = nn . Parameter ( torch . Tensor ( <NUM_LIT> , self . plm . config . hidden_size ) ) \n self . u_omega = nn . Parameter ( torch . Tensor ( self . plm . config . hidden_size , <NUM_LIT> ) ) \n nn . init . uniform_ ( self . w_omega , - <NUM_LIT> , <NUM_LIT> ) \n nn . init . uniform_ ( self . u_omega , - <NUM_LIT> , <NUM_LIT> ) \n nn . init . uniform_ ( self . b_omega , - <NUM_LIT> , <NUM_LIT> ) \n self . mlp . apply ( init_weights ) \n def forward ( self , document_batch : torch . Tensor , device = '<STR_LIT>' , plm_batch_size = <NUM_LIT> ) : \n plm_output = torch . zeros ( size = ( document_batch . shape [ <NUM_LIT> ] , \n min ( document_batch . shape [ <NUM_LIT> ] , \n plm_batch_size ) , \n self . plm . config . hidden_size ) , dtype = torch . float , device = device ) \n for doc_id in range ( document_batch . shape [ <NUM_LIT> ] ) : \n plm_output [ doc_id ] [ : plm_batch_size ] = self . dropout ( \n self . plm ( document_batch [ doc_id ] [ : plm_batch_size , <NUM_LIT> ] , \n token_type_ids = document_batch [ doc_id ] [ \n : plm_batch_size , <NUM_LIT> ] , \n attention_mask = document_batch [ doc_id ] [ \n : plm_batch_size , <NUM_LIT> ] ) [ <NUM_LIT> ] ) \n output , ( _ , _ ) = self . lstm ( plm_output . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) \n output = output . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n attention_w = torch . tanh ( torch . matmul ( output , self . w_omega ) + self . b_omega ) \n attention_u = torch . matmul ( attention_w , self . u_omega ) \n attention_score = F . softmax ( attention_u , dim = <NUM_LIT> ) \n attention_hidden = output * attention_score \n attention_hidden = torch . sum ( attention_hidden , dim = <NUM_LIT> ) \n prediction = self . mlp ( attention_hidden ) \n assert prediction . shape [ <NUM_LIT> ] == document_batch . shape [ <NUM_LIT> ] \n return prediction"}, {"input": "from bs4 import BeautifulSoup as bs \n import requests , datetime , os \n from utils . general import headers \n def get_epgs_hks ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n url = '<STR_LIT>' \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n lis = soup . select ( '<STR_LIT>' ) \n for li in lis : \n title = [ text for text in li . a . stripped_strings ] [ <NUM_LIT> ] \n starttime = datetime . datetime . fromtimestamp ( int ( li . a . attrs [ '<STR_LIT>' ] ) ) \n if starttime . date ( ) < dt : \n continue \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : starttime . date ( ) if starttime in locals ( ) else dt , \n }", "output": "epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : starttime . date ( ) , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_hks ( ) : \n channels = [ ] \n channel = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : [ '<STR_LIT>' ] , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' \n '<STR_LIT>' \n '<STR_LIT>' \n '<STR_LIT>' \n '<STR_LIT>' \n '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n channels . append ( channel ) \n return channels"}, {"input": "import decimal \n import logging \n import math \n import re \n from . . types import TextSplitterLengthCalculatorProtocol \n logger = logging . getLogger ( __name__ ) \n class NaiveTextSplitterCalculator ( TextSplitterLengthCalculatorProtocol ) : \n characters_per_token : int | float | decimal . Decimal = <NUM_LIT>", "output": "words_per_token : int | float | decimal . Decimal = <NUM_LIT> \n final_multiplier : int | float | decimal . Decimal = <NUM_LIT> \n def get_splitter_length ( self , text : str ) -> int : \n word_count = len ( re . findall ( r\"<STR_LIT>\" , text ) ) \n char_count = len ( text ) \n token_char_count = math . ceil ( char_count / self . characters_per_token ) \n token_word_count = math . ceil ( word_count * self . words_per_token ) \n logger . debug ( \n \"<STR_LIT>\" , \n token_char_count , \n token_word_count , \n char_count , \n word_count , \n ) \n return math . ceil ( \n max ( token_char_count , token_word_count ) * self . final_multiplier \n )"}, {"input": "import os \n import sys \n from pathlib import Path \n import environ \n BASE_DIR = Path ( __file__ ) . resolve ( ) . parent . parent . parent \n APPLICATIONS_DIR = BASE_DIR / \"<STR_LIT>\" \n sys . path . append ( str ( APPLICATIONS_DIR ) ) \n env = environ . Env ( ) \n ENV_FILE = BASE_DIR / \"<STR_LIT>\" \n if Path . is_file ( ENV_FILE ) : \n env . read_env ( str ( ENV_FILE ) ) \n SECRET_KEY = env ( \"<STR_LIT>\" ) \n DEBUG = True \n ALLOWED_HOSTS = [ ] \n INSTALLED_APPS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n MIDDLEWARE = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n ROOT_URLCONF = \"<STR_LIT>\" \n TEMPLATES = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ ] , \n \"<STR_LIT>\" : True , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n } , \n } , \n ] \n WSGI_APPLICATION = \"<STR_LIT>\" \n AUTH_PASSWORD_VALIDATORS = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" ,", "output": "} , \n ] \n LANGUAGE_CODE = \"<STR_LIT>\" \n TIME_ZONE = \"<STR_LIT>\" \n USE_I18N = True \n USE_TZ = True \n STATIC_URL = \"<STR_LIT>\" \n STATIC_ROOT = BASE_DIR / \"<STR_LIT>\" / \"<STR_LIT>\" \n DEFAULT_AUTO_FIELD = \"<STR_LIT>\" \n CELERY_BROKER_URL = env . str ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n CELERY_ACCEPT_CONTENT = [ \"<STR_LIT>\" ] \n CELERY_TASK_SERIALIZER = \"<STR_LIT>\" \n CELERY_RESULT_SERIALIZER = \"<STR_LIT>\" \n ZEKAI_USERNAME = env ( \"<STR_LIT>\" ) \n ZEKAI_PASSWORD = env ( \"<STR_LIT>\" ) \n LOGGING = { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : os . getenv ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : False , \n } , \n } , \n } \n REST_FRAMEWORK = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n }"}, {"input": "import requests , re , datetime \n from utils . general import headers \n from bs4 import BeautifulSoup as bs \n def get_epgs_zhongshu ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n host = '<STR_LIT>' \n w = <NUM_LIT> \n if dt . weekday ( ) < datetime . datetime . now ( ) . weekday ( ) : \n w = <NUM_LIT> \n url = '<STR_LIT>' % ( host , channel_id , w ) \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n rs = re . findall ( '<STR_LIT>' , res . text ) \n except Exception as e : \n msg = '<STR_LIT>' % e \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n for r in rs : \n try :", "output": "starttime = datetime . datetime . strptime ( '<STR_LIT>' % ( dt . year , int ( r [ <NUM_LIT> ] ) , int ( r [ <NUM_LIT> ] ) , r [ <NUM_LIT> ] ) , '<STR_LIT>' ) \n title = r [ <NUM_LIT> ] \n if starttime . date ( ) < dt : \n continue \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : starttime . date ( ) , \n } \n except Exception as e : \n msg = '<STR_LIT>' % e \n starttime = datetime . datetime . combine ( dt , datetime . time ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) \n continue \n epgs . append ( epg ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : starttime . date ( ) , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_zhongshu ( ) : \n channels = [ ] \n host = '<STR_LIT>' \n res = requests . get ( host , headers = headers ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n uls = soup . select ( '<STR_LIT>' ) \n sorts = [ ] \n spans = soup . select ( '<STR_LIT>' ) \n sort_name_change = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n for span in spans : \n sort = span . text . strip ( ) \n sorts . append ( sort ) \n uls = soup . select ( '<STR_LIT>' ) \n x = <NUM_LIT> \n for ul in uls : \n lis = ul . select ( '<STR_LIT>' ) \n for li in lis : \n name = li . a . text . strip ( ) \n id = li . a [ '<STR_LIT>' ] . strip ( ) \n url = '<STR_LIT>' % ( host , id ) \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : url , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : sort_name_change [ sorts [ x ] ] , \n } \n channels . append ( channel ) \n x += <NUM_LIT> \n return channels"}, {"input": "import os \n import cv2 \n import argparse \n import torch \n import cv2 \n import json \n import pickle as pkl \n from tqdm import tqdm \n import time \n import matplotlib . pyplot \n from PIL import Image \n import numpy as np \n from utils import load_config , load_checkpoint , compute_edit_distance \n from models . infer_model import Inference \n from dataset import Words \n parser = argparse . ArgumentParser ( description = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = False ) \n device = torch . device ( '<STR_LIT>' if torch . cuda . is_available ( ) else '<STR_LIT>' ) \n args = parser . parse_args ( ) \n os . environ [ '<STR_LIT>' ] = '<STR_LIT>' \n config_file = '<STR_LIT>' \n params = load_config ( config_file ) \n params [ '<STR_LIT>' ] = device \n words = Words ( args . word_path ) \n params [ '<STR_LIT>' ] = len ( words ) \n model = Inference ( params , draw_map = False )", "output": "model = model . to ( device ) \n load_checkpoint ( model , None , '<STR_LIT>' ) \n model . eval ( ) \n line_right = <NUM_LIT> \n e1 , e2 , e3 = <NUM_LIT> , <NUM_LIT> , <NUM_LIT> \n bad_case = { } \n model_time = <NUM_LIT> \n mae_sum , mse_sum = <NUM_LIT> , <NUM_LIT> \n with open ( args . label_path ) as f : \n lines = f . readlines ( ) \n with torch . no_grad ( ) : \n for line in tqdm ( lines ) : \n name , * labels = line . split ( ) \n name = name . split ( '<STR_LIT>' ) [ <NUM_LIT> ] if name . endswith ( '<STR_LIT>' ) else name \n input_labels = labels \n labels = '<STR_LIT>' . join ( labels ) \n img_index = name + '<STR_LIT>' \n image = cv2 . imread ( os . path . join ( args . image_path , img_index ) ) \n image = cv2 . cvtColor ( image , cv2 . COLOR_BGR2GRAY ) \n image = np . asarray ( image ) \n print ( np . shape ( image ) ) \n image = torch . Tensor ( <NUM_LIT> - image ) / <NUM_LIT> \n image = image . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) \n image = image . to ( device ) \n input_labels = words . encode ( input_labels ) \n input_labels = torch . LongTensor ( input_labels ) \n input_labels = input_labels . unsqueeze ( <NUM_LIT> ) . to ( device ) \n probs , _ , mae , mse = model ( image , input_labels , os . path . join ( params [ '<STR_LIT>' ] [ '<STR_LIT>' ] , name ) ) \n prediction = words . decode ( probs ) \n print ( prediction ) \n mae_sum += mae \n mse_sum += mse"}, {"input": "from rest_framework . views import APIView \n from django . shortcuts import render \n class PrivacyView ( APIView ) : \n permission_classes = [ ]", "output": "def get ( self , request , * args , ** kwargs ) : \n return render ( request , '<STR_LIT>' ) \n class TermsServiceView ( APIView ) : \n permission_classes = [ ] \n def get ( self , request , * args , ** kwargs ) : \n return render ( request , '<STR_LIT>' )"}, {"input": "import os \n import django \n os . environ . setdefault ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n django . setup ( ) \n from dvadmin . utils . core_initialize import CoreInitialize \n from dvadmin . system . fixtures . initSerializer import ( \n UsersInitSerializer , DeptInitSerializer , RoleInitSerializer ,", "output": "MenuInitSerializer , ApiWhiteListInitSerializer , DictionaryInitSerializer , \n SystemConfigInitSerializer , RoleMenuInitSerializer , RoleMenuButtonInitSerializer \n ) \n class Initialize ( CoreInitialize ) : \n def init_dept ( self ) : \n self . init_base ( DeptInitSerializer , unique_fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) \n def init_role ( self ) : \n self . init_base ( RoleInitSerializer , unique_fields = [ '<STR_LIT>' ] ) \n def init_users ( self ) : \n self . init_base ( UsersInitSerializer , unique_fields = [ '<STR_LIT>' ] ) \n def init_menu ( self ) : \n self . init_base ( MenuInitSerializer , unique_fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) \n def init_role_menu ( self ) : \n self . init_base ( RoleMenuInitSerializer , unique_fields = [ '<STR_LIT>' , '<STR_LIT>' ] ) \n def init_role_menu_button ( self ) : \n self . init_base ( RoleMenuButtonInitSerializer , unique_fields = [ '<STR_LIT>' , '<STR_LIT>' ] ) \n def init_api_white_list ( self ) : \n self . init_base ( ApiWhiteListInitSerializer , unique_fields = [ '<STR_LIT>' , '<STR_LIT>' , ] ) \n def init_dictionary ( self ) : \n self . init_base ( DictionaryInitSerializer , unique_fields = [ '<STR_LIT>' , '<STR_LIT>' , ] ) \n def init_system_config ( self ) : \n self . init_base ( SystemConfigInitSerializer , unique_fields = [ '<STR_LIT>' , '<STR_LIT>' , ] ) \n def run ( self ) : \n self . init_dept ( ) \n self . init_role ( ) \n self . init_users ( ) \n self . init_menu ( ) \n self . init_role_menu ( ) \n self . init_role_menu_button ( ) \n self . init_api_white_list ( ) \n self . init_dictionary ( ) \n self . init_system_config ( ) \n if __name__ == \"<STR_LIT>\" : \n Initialize ( app = '<STR_LIT>' ) . run ( )"}, {"input": "import json \n import os \n from django . apps import apps \n from rest_framework import request \n from application import settings \n from dvadmin . system . models import Users \n class CoreInitialize : \n creator_id = None \n reset = False \n request = request \n file_path = None \n def __init__ ( self , reset = False , creator_id = None , app = None ) : \n self . reset = reset or self . reset", "output": "self . creator_id = creator_id or self . creator_id \n self . app = app or '<STR_LIT>' \n self . request . user = Users . objects . order_by ( '<STR_LIT>' ) . first ( ) \n def init_base ( self , Serializer , unique_fields = None ) : \n model = Serializer . Meta . model \n path_file = os . path . join ( apps . get_app_config ( self . app . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] ) . path , '<STR_LIT>' , \n f'<STR_LIT>' ) \n if not os . path . isfile ( path_file ) : \n print ( \"<STR_LIT>\" ) \n return \n with open ( path_file , encoding = \"<STR_LIT>\" ) as f : \n for data in json . load ( f ) : \n filter_data = { } \n if unique_fields : \n for field in unique_fields : \n if field in data : \n filter_data [ field ] = data [ field ] \n else : \n for key , value in data . items ( ) : \n if isinstance ( value , list ) or value == None or value == '<STR_LIT>' : \n continue \n filter_data [ key ] = value \n instance = model . objects . filter ( ** filter_data ) . first ( ) \n data [ \"<STR_LIT>\" ] = self . reset \n serializer = Serializer ( instance , data = data , request = self . request ) \n serializer . is_valid ( raise_exception = True ) \n serializer . save ( ) \n print ( f\"<STR_LIT>\" ) \n def save ( self , obj , data : list , name = None , no_reset = False ) : \n name = name or obj . _meta . verbose_name \n print ( f\"<STR_LIT>\" ) \n if not no_reset and self . reset and obj not in settings . INITIALIZE_RESET_LIST : \n try : \n obj . objects . all ( ) . delete ( ) \n settings . INITIALIZE_RESET_LIST . append ( obj ) \n except Exception : \n pass \n for ele in data : \n m2m_dict = { } \n new_data = { } \n for key , value in ele . items ( ) : \n if isinstance ( value , list ) and value and isinstance ( value [ <NUM_LIT> ] , int ) : \n m2m_dict [ key ] = value \n else : \n new_data [ key ] = value \n object , _ = obj . objects . get_or_create ( id = ele . get ( \"<STR_LIT>\" ) , defaults = new_data ) \n for key , m2m in m2m_dict . items ( ) : \n m2m = list ( set ( m2m ) ) \n if m2m and len ( m2m ) > <NUM_LIT> and m2m [ <NUM_LIT> ] : \n exec ( ) \n print ( f\"<STR_LIT>\" ) \n def run ( self ) : \n raise NotImplementedError ( '<STR_LIT>' )"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AddField (", "output": "model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . ForeignKey ( blank = True , null = True , on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) , \n ) , \n ]"}, {"input": "import uuid \n from examples . models import Department , Employee \n from examples . views . department_views import DepartmentViewSet \n from ninja_crud import testing \n class TestDepartmentViewSet ( testing . viewsets . ModelViewSetTestCase ) : \n model_viewset_class = DepartmentViewSet \n base_path = \"<STR_LIT>\" \n department_1 : Department \n department_2 : Department \n employee : Employee \n @ classmethod \n def setUpTestData ( cls ) : \n cls . department_1 = Department . objects . create ( title = \"<STR_LIT>\" ) \n cls . department_2 = Department . objects . create ( title = \"<STR_LIT>\" ) \n cls . employee = Employee . objects . create ( \n first_name = \"<STR_LIT>\" , last_name = \"<STR_LIT>\" , department = cls . department_1 \n ) \n @ property \n def path_parameters ( self ) : \n return testing . components . PathParameters ( \n ok = { \"<STR_LIT>\" : self . department_1 . id } , not_found = { \"<STR_LIT>\" : uuid . uuid4 ( ) } \n ) \n department_payloads = testing . components . Payloads ( \n ok = { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n bad_request = { \"<STR_LIT>\" : <NUM_LIT> } , \n conflict = { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) \n test_list_departments = testing . views . ListModelViewTest ( ) \n test_create_department = testing . views . CreateModelViewTest ( \n payloads = department_payloads \n ) \n test_read_department = testing . views . ReadModelViewTest ( path_parameters ) \n test_update_department = testing . views . UpdateModelViewTest ( \n path_parameters , payloads = department_payloads \n ) \n test_delete_department = testing . views . DeleteModelViewTest ( path_parameters ) \n @ property \n def employees_path_parameters ( self ) : \n return testing . components . PathParameters ( ok = { \"<STR_LIT>\" : self . department_1 . id } ) \n employee_payloads = testing . components . Payloads ( \n ok = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n bad_request = { \"<STR_LIT>\" : <NUM_LIT> } , \n ) \n test_list_employees = testing . views . ListModelViewTest ( \n path_parameters = employees_path_parameters \n ) \n test_create_employee = testing . views . CreateModelViewTest (", "output": "path_parameters = employees_path_parameters , payloads = employee_payloads \n )"}, {"input": "from pathlib import Path \n root_dir = Path ( __file__ ) . parent . parent \n readme = root_dir / \"<STR_LIT>\" \n guides = root_dir / \"<STR_LIT>\" \n guides_index = guides / \"<STR_LIT>\" \n def get_rst_doc_title ( file : Path ) : \n title = \"<STR_LIT>\" \n for line in file . read_text ( ) . splitlines ( ) : \n if line . startswith ( \"<STR_LIT>\" ) : \n break \n title = line \n return title \n def guides_files ( ) : \n index_content = guides_index . read_text ( ) \n toc_tree_directive = \"<STR_LIT>\" \n start_index = index_content . find ( toc_tree_directive ) + len ( toc_tree_directive ) \n def valid_line ( line ) : \n return bool ( line ) and not line . strip ( ) . startswith ( \"<STR_LIT>\" ) \n lines = [ line . strip ( ) for line in index_content [ start_index : ] . split ( \"<STR_LIT>\" ) if valid_line ( line ) ] \n return [ guides / f\"<STR_LIT>\" for line in lines ] \n def get_guides_list ( ) : \n guides_md = [ ] \n for file in guides_files ( ) : \n if file . name . startswith ( \"<STR_LIT>\" ) : \n continue \n link = f\"<STR_LIT>\" \n title = get_rst_doc_title ( file ) \n guides_md . append ( f\"<STR_LIT>\" ) \n return \"<STR_LIT>\" + \"<STR_LIT>\" . join ( guides_md ) + \"<STR_LIT>\" \n def update_readme ( start_comment , end_comment , new_content ) : \n text = readme . read_text ( ) \n start_index = text . find ( start_comment ) + len ( start_comment ) \n end_index = text . find ( end_comment ) \n new_content = text [ : start_index ] + new_content + text [ end_index : ] \n readme . write_text ( new_content ) \n def main ( ) : \n update_readme ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ,", "output": "get_guides_list ( ) , \n ) \n print ( \"<STR_LIT>\" ) \n if __name__ == \"<STR_LIT>\" : \n main ( )"}, {"input": "from dvadmin . system . models import ApiWhiteList \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class ApiWhiteListSerializer ( CustomModelSerializer ) : \n class Meta : \n model = ApiWhiteList \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class ApiWhiteListViewSet ( CustomModelViewSet ) : \n queryset = ApiWhiteList . objects . all ( )", "output": "serializer_class = ApiWhiteListSerializer"}, {"input": "from django import forms \n from . models import Vote , User \n from django . contrib . auth . forms import UserCreationForm \n class RegistrationForm ( UserCreationForm ) : \n username = forms . CharField ( max_length = <NUM_LIT> , required = True ) \n email = forms . EmailField ( max_length = <NUM_LIT> , required = True ) \n password1 = forms . CharField ( \n widget = forms . PasswordInput , \n label = \"<STR_LIT>\" , \n strip = False , \n help_text = \"<STR_LIT>\" , \n ) \n password2 = forms . CharField ( \n widget = forms . PasswordInput , \n label = \"<STR_LIT>\" , \n strip = False , \n help_text = \"<STR_LIT>\" , \n ) \n class Meta : \n model = User \n fields = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n def clean_password1 ( self ) : \n password1 = self . cleaned_data . get ( \"<STR_LIT>\" ) \n if len ( password1 ) < <NUM_LIT> : \n raise forms . ValidationError ( \"<STR_LIT>\" ) \n if password1 . isdigit ( ) : \n raise forms . ValidationError ( \"<STR_LIT>\" ) \n if not any ( char . isdigit ( ) for char in password1 ) :", "output": "raise forms . ValidationError ( \"<STR_LIT>\" ) \n if not any ( char . isupper ( ) for char in password1 ) : \n raise forms . ValidationError ( \"<STR_LIT>\" ) \n if not any ( char . islower ( ) for char in password1 ) : \n raise forms . ValidationError ( \"<STR_LIT>\" ) \n if not any ( char in \"<STR_LIT>\" for char in password1 ) : \n raise forms . ValidationError ( \"<STR_LIT>\" ) \n return password1"}, {"input": "import base64 \n import json \n import cv2 \n import numpy as np \n from flask import Flask , request \n from ultralytics import YOLO \n import yaml \n MODEL_CLS_2_REAL_ID = { \n <NUM_LIT> : <NUM_LIT> , \n <NUM_LIT> : <NUM_LIT> , \n <NUM_LIT> : <NUM_LIT> , \n <NUM_LIT> : <NUM_LIT> \n } \n config_file = open ( '<STR_LIT>' ) \n config = yaml . load ( config_file , yaml . loader . SafeLoader ) \n config_file . close ( ) \n app = Flask ( __name__ ) \n model = YOLO ( model = config [ '<STR_LIT>' ] ) \n @ app . route ( '<STR_LIT>' , methods = [ '<STR_LIT>' , '<STR_LIT>' ] ) \n def infer ( ) : \n ret = { \"<STR_LIT>\" : False } \n img = request . files . get ( '<STR_LIT>' ) \n if img is None : \n ret = { '<STR_LIT>' : - <NUM_LIT> , '<STR_LIT>' : '<STR_LIT>' } \n return json . dumps ( ret , ensure_ascii = False ) \n try : \n input_image = img . read ( )", "output": "imBytes = np . frombuffer ( input_image , np . uint8 ) \n in_img = cv2 . imdecode ( imBytes , cv2 . IMREAD_COLOR ) \n result = model . predict ( source = in_img , save = True , imgsz = <NUM_LIT> , device = <NUM_LIT> ) [ <NUM_LIT> ] \n results = [ ] \n for box in result . boxes : \n cls_id = box . cls . cpu ( ) . numpy ( ) [ <NUM_LIT> ] \n ret_id = MODEL_CLS_2_REAL_ID [ cls_id ] \n x , y , w , h = box . xywh . cpu ( ) . numpy ( ) [ <NUM_LIT> ] \n results += [ { \n '<STR_LIT>' : ret_id , \n '<STR_LIT>' : [ float ( x ) , float ( y ) , float ( w ) , float ( h ) ] \n } ] \n ret = { \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : results \n } \n except Exception as e : \n print ( e ) \n return json . dumps ( ret , ensure_ascii = False ) \n if __name__ == \"<STR_LIT>\" : \n port = config [ '<STR_LIT>' ] \n app . run ( debug = False , host = '<STR_LIT>' , port = port )"}, {"input": "from django . apps import apps \n from rest_framework import serializers \n from rest_framework . decorators import action \n from rest_framework . permissions import IsAuthenticated \n from dvadmin . system . models import Role , MenuField \n from dvadmin . utils . models import get_custom_app_models \n from dvadmin . utils . viewset import CustomModelViewSet \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . json_response import DetailResponse , ErrorResponse , SuccessResponse \n class MenuFieldSerializer ( CustomModelSerializer ) : \n class Meta : \n model = MenuField \n fields = '<STR_LIT>' \n read_only_fields = [ '<STR_LIT>' ] \n class MenuFieldViewSet ( CustomModelViewSet ) : \n queryset = MenuField . objects . order_by ( '<STR_LIT>' ) \n serializer_class = MenuFieldSerializer \n def list ( self , request , * args , ** kwargs ) : \n menu = request . query_params . get ( '<STR_LIT>' ) \n if not menu : \n return SuccessResponse ( [ ] ) \n queryset = self . filter_queryset ( self . get_queryset ( ) . filter ( menu = menu ) ) \n serializer = self . get_serializer ( queryset , many = True , request = request ) \n return SuccessResponse ( data = serializer . data , msg = \"<STR_LIT>\" ) \n def create ( self , request , * args , ** kwargs ) : \n payload = request . data \n for model in apps . get_models ( ) : \n if payload . get ( '<STR_LIT>' ) == model . __name__ : \n break \n else : \n return ErrorResponse ( msg = '<STR_LIT>' ) \n if MenuField . objects . filter ( menu = payload . get ( '<STR_LIT>' ) , model = model . __name__ , field_name = payload . get ( '<STR_LIT>' ) ) . exists ( ) : \n return ErrorResponse ( msg = '<STR_LIT>' % payload . get ( '<STR_LIT>' ) ) \n return super ( ) . create ( request , * args , ** kwargs ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def get_models ( self , request ) : \n res = [ ] \n for model in get_custom_app_models ( ) : \n res . append ( { \n '<STR_LIT>' : model [ '<STR_LIT>' ] , \n '<STR_LIT>' : model [ '<STR_LIT>' ] , \n '<STR_LIT>' : model [ '<STR_LIT>' ] \n } ) \n return DetailResponse ( res ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def auto_match_fields ( self , request ) : \n menu_id = request . data . get ( '<STR_LIT>' ) \n model_name = request . data . get ( '<STR_LIT>' ) \n if not menu_id or not model_name : \n return ErrorResponse ( msg = '<STR_LIT>' ) \n for model in get_custom_app_models ( ) : \n if model [ '<STR_LIT>' ] != model_name : \n continue \n for field in model [ '<STR_LIT>' ] : \n if MenuField . objects . filter ( \n menu_id = menu_id , model = model_name , field_name = field [ '<STR_LIT>' ] \n ) . exists ( ) : \n continue \n data = { \n '<STR_LIT>' : menu_id , \n '<STR_LIT>' : model_name , \n '<STR_LIT>' : field [ '<STR_LIT>' ] , \n '<STR_LIT>' : str ( field [ '<STR_LIT>' ] ) , \n } \n serializer = self . get_serializer ( data = data , request = request ) \n serializer . is_valid ( raise_exception = True )", "output": "serializer . save ( ) \n return SuccessResponse ( msg = '<STR_LIT>' )"}, {"input": "from typing import List , Optional , Union \n from ninja_crud . testing . core . components import utils \n class PathParameters :", "output": "def __init__ ( \n self , \n ok : Union [ dict , List [ dict ] ] , \n not_found : Union [ dict , List [ dict ] , None ] = None , \n ) -> None : \n self . ok : List [ dict ] = utils . ensure_list_of_dicts ( ok ) \n self . not_found : Optional [ List [ dict ] ] = ( \n utils . ensure_list_of_dicts ( not_found ) if not_found is not None else None \n )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ]", "output": "operations = [ \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . TextField ( blank = True , null = True ) , \n ) , \n ]"}, {"input": "import pytest \n from django . core . validators import ValidationError \n from django_webhook . models import WebhookTopic , populate_topics_from_settings \n pytestmark = pytest . mark . django_db \n def test_validates_topic_name_regex ( ) : \n t = WebhookTopic ( name = \"<STR_LIT>\" ) \n with pytest . raises ( ValidationError , match = r\"<STR_LIT>\" ) : \n t . clean_fields ( )", "output": "def test_validates_topic_name_in_models ( settings ) : \n settings . DJANGO_WEBHOOK = dict ( MODELS = [ \"<STR_LIT>\" ] ) \n t = WebhookTopic ( name = \"<STR_LIT>\" ) \n with pytest . raises ( \n ValidationError , \n match = r\"<STR_LIT>\" , \n ) : \n t . clean_fields ( ) \n def test_populate_topics_from_settings ( settings ) : \n populate_topics_from_settings ( ) \n assert list ( \n WebhookTopic . objects . values_list ( \"<STR_LIT>\" , flat = True ) . order_by ( \"<STR_LIT>\" ) \n ) == [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n settings . DJANGO_WEBHOOK [ \"<STR_LIT>\" ] = [ \"<STR_LIT>\" ] \n populate_topics_from_settings ( ) \n assert list ( \n WebhookTopic . objects . values_list ( \"<STR_LIT>\" , flat = True ) . order_by ( \"<STR_LIT>\" ) \n ) == [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ]"}, {"input": "import logging \n from datetime import timedelta \n from celery import current_app as app \n from celery import states \n from django . conf import settings \n from django . utils import timezone \n from requests import Session \n from requests . exceptions import RequestException \n from django_webhook . models import Webhook , WebhookEvent \n from . http import prepare_request \n @ app . task ( \n bind = True , \n max_retries = <NUM_LIT> , \n default_retry_delay = <NUM_LIT> , \n retry_backoff = True , \n retry_backoff_max = <NUM_LIT> * <NUM_LIT> , \n retry_jitter = False , \n ) \n def fire_webhook ( self , webhook_id , payload ) : \n webhook = Webhook . objects . get ( id = webhook_id ) \n if not webhook . active : \n logging . warning ( f\"<STR_LIT>\" ) \n return \n req = prepare_request ( webhook , payload ) \n store_events = settings . DJANGO_WEBHOOK [ \"<STR_LIT>\" ] \n if store_events : \n event = WebhookEvent . objects . create ( \n webhook = webhook , \n object = payload , \n object_type = payload . get ( \"<STR_LIT>\" ) , \n status = states . PENDING , \n url = webhook . url , \n topic = payload . get ( \"<STR_LIT>\" ) , \n ) \n try : \n Session ( ) . send ( req ) . raise_for_status ( ) \n if store_events : \n WebhookEvent . objects . filter ( id = event . id ) . update ( status = states . SUCCESS ) \n except RequestException as ex : \n status_code = ex . response . status_code \n logging . warning ( f\"<STR_LIT>\" )", "output": "if store_events : \n WebhookEvent . objects . filter ( id = event . id ) . update ( status = states . FAILURE ) \n raise self . retry ( exc = ex ) \n @ app . task ( \n autoretry_for = ( Exception , ) , \n max_retries = <NUM_LIT> , \n default_retry_delay = <NUM_LIT> , \n retry_backoff = True , \n retry_backoff_max = <NUM_LIT> * <NUM_LIT> , \n retry_jitter = False , \n ) \n def clear_webhook_events ( ) : \n days_ago = settings . DJANGO_WEBHOOK [ \"<STR_LIT>\" ] \n now = timezone . now ( ) \n cutoff_date = now - timedelta ( days = days_ago ) \n qs = WebhookEvent . objects . filter ( created__lt = cutoff_date ) \n logging . info ( \n f\"<STR_LIT>\" \n ) \n qs . delete ( )"}, {"input": "import socket \n import environ \n from . base import * \n env = environ . Env ( ) \n INSTALLED_APPS += [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n MIDDLEWARE += [ \"<STR_LIT>\" ] \n hostname , _ , ips = socket . gethostbyname_ex ( socket . gethostname ( ) ) \n INTERNAL_IPS = [ \"<STR_LIT>\" , \"<STR_LIT>\" ]", "output": "INTERNAL_IPS += [ ip [ : - <NUM_LIT> ] + \"<STR_LIT>\" for ip in ips ] \n SHELL_PLUS_PRINT_SQL = True \n DATABASES = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : env ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : env ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : env ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : env ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n } \n CACHES = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n ] , \n } \n } \n CACHE_MIDDLEWARE_ALIAS = \"<STR_LIT>\" \n CACHE_MIDDLEWARE_SECONDS = <NUM_LIT> \n CACHE_MIDDLEWARE_KEY_PREFIX = \"<STR_LIT>\""}, {"input": "import os \n exclude = [ \"<STR_LIT>\" ] \n for root , dirs , files in os . walk ( '<STR_LIT>' ) : \n dirs [ : ] = list ( set ( dirs ) - set ( exclude ) ) \n if '<STR_LIT>' in dirs : \n dir = dirs [ dirs . index ( '<STR_LIT>' ) ] \n for root_j , dirs_j , files_j in os . walk ( os . path . join ( root , dir ) ) :", "output": "for file_k in files_j : \n if file_k != '<STR_LIT>' : \n dst_file = os . path . join ( root_j , file_k ) \n print ( '<STR_LIT>' , dst_file ) \n os . remove ( dst_file )"}, {"input": "from django . contrib . auth . models import Group , User \n from django . test import TestCase \n from tests . test_app . models import Collection , Item \n class BaseTestCase ( TestCase ) : \n user_1 : User \n user_2 : User \n collection_1 : Collection", "output": "collection_2 : Collection \n item_1 : Item \n item_2 : Item \n @ classmethod \n def setUpTestData ( cls ) : \n super ( ) . setUpTestData ( ) \n cls . user_1 = User . objects . create ( \n username = \"<STR_LIT>\" , password = \"<STR_LIT>\" , email = \"<STR_LIT>\" \n ) \n cls . user_2 = User . objects . create ( \n username = \"<STR_LIT>\" , password = \"<STR_LIT>\" , email = \"<STR_LIT>\" \n ) \n cls . collection_1 = Collection . objects . create ( \n name = \"<STR_LIT>\" , created_by = cls . user_1 \n ) \n cls . collection_2 = Collection . objects . create ( \n name = \"<STR_LIT>\" , created_by = cls . user_2 \n ) \n cls . item_1 = Item . objects . create ( name = \"<STR_LIT>\" , collection = cls . collection_1 ) \n cls . item_2 = Item . objects . create ( name = \"<STR_LIT>\" , collection = cls . collection_2 ) \n cls . group_1 = Group . objects . create ( name = \"<STR_LIT>\" ) \n cls . group_2 = Group . objects . create ( name = \"<STR_LIT>\" )"}, {"input": "from django . urls import path , re_path \n from . import views \n from django . contrib . auth import views as auth_views \n from . views import RegisterView , ActivateView , CustomLoginView , logout_view \n from django . views . generic import TemplateView \n urlpatterns = [ \n path ( '<STR_LIT>' , views . summarize , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , views . robots_txt ) , \n path ( \"<STR_LIT>\" , views . arxividpage , name = \"<STR_LIT>\" ) , \n re_path ( r\"<STR_LIT>\" , views . arxividpage , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . arxividpage , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . tree , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . search_results , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . create_embed , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . about , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . chat , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . faq , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . contact , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . history , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . privacy , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . legal , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . update_cache , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . vote , name = \"<STR_LIT>\" ) , \n path ( '<STR_LIT>' , CustomLoginView . as_view ( ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , logout_view , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , RegisterView . as_view ( ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , auth_views . PasswordResetView . as_view ( template_name = '<STR_LIT>' ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , auth_views . PasswordResetDoneView . as_view ( template_name = '<STR_LIT>' ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , auth_views . PasswordResetConfirmView . as_view ( template_name = '<STR_LIT>' ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , auth_views . PasswordResetCompleteView . as_view ( template_name = '<STR_LIT>' ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , ActivateView . as_view ( ) , name = '<STR_LIT>' ) ,", "output": "path ( '<STR_LIT>' , TemplateView . as_view ( template_name = '<STR_LIT>' ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , TemplateView . as_view ( template_name = '<STR_LIT>' ) , name = '<STR_LIT>' ) , \n ]"}, {"input": "import uuid \n from examples . models import Department , Employee \n from examples . views . employee_views import EmployeeViewSet \n from ninja_crud . testing . core . components import PathParameters , Payloads \n from ninja_crud . testing . views import ( \n DeleteModelViewTest ,", "output": "ReadModelViewTest , \n UpdateModelViewTest , \n ) \n from ninja_crud . testing . viewsets import ModelViewSetTestCase \n class TestEmployeeViewSet ( ModelViewSetTestCase ) : \n model_viewset_class = EmployeeViewSet \n base_path = \"<STR_LIT>\" \n department_1 : Department \n department_2 : Department \n employee : Employee \n @ classmethod \n def setUpTestData ( cls ) : \n cls . department_1 = Department . objects . create ( title = \"<STR_LIT>\" ) \n cls . department_2 = Department . objects . create ( title = \"<STR_LIT>\" ) \n cls . employee = Employee . objects . create ( \n first_name = \"<STR_LIT>\" , last_name = \"<STR_LIT>\" , department = cls . department_1 \n ) \n def get_path_parameters ( self ) : \n return PathParameters ( \n ok = { \"<STR_LIT>\" : self . employee . id } , not_found = { \"<STR_LIT>\" : uuid . uuid4 ( ) } \n ) \n employee_payloads = Payloads ( \n ok = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n bad_request = { \"<STR_LIT>\" : <NUM_LIT> } , \n ) \n test_read_employee = ReadModelViewTest ( path_parameters = get_path_parameters ) \n test_update_employee = UpdateModelViewTest ( \n path_parameters = get_path_parameters , payloads = employee_payloads \n ) \n test_delete_employee = DeleteModelViewTest ( path_parameters = get_path_parameters )"}, {"input": "import os \n from django . db . models . signals import post_migrate \n from django . dispatch import receiver \n from django . db . utils import OperationalError \n from . models import Setting \n @ receiver ( post_migrate ) \n def load_default_settings ( sender , ** kwargs ) : \n if sender . name == '<STR_LIT>' : \n print ( '<STR_LIT>' ) \n if not Setting . objects . filter ( name = '<STR_LIT>' ) . exists ( ) : \n Setting . objects . create ( name = '<STR_LIT>' , value = '<STR_LIT>' ) \n print ( '<STR_LIT>' ) \n if not Setting . objects . filter ( name = '<STR_LIT>' ) . exists ( ) : \n Setting . objects . create ( name = '<STR_LIT>' , value = '<STR_LIT>' ) \n print ( '<STR_LIT>' )", "output": "if not Setting . objects . filter ( name = '<STR_LIT>' ) . exists ( ) : \n Setting . objects . create ( name = '<STR_LIT>' , value = '<STR_LIT>' ) \n print ( '<STR_LIT>' ) \n if not Setting . objects . filter ( name = '<STR_LIT>' ) . exists ( ) : \n Setting . objects . create ( name = '<STR_LIT>' , value = '<STR_LIT>' ) \n print ( '<STR_LIT>' ) \n if not Setting . objects . filter ( name = '<STR_LIT>' ) . exists ( ) : \n env_key_val = os . environ . get ( '<STR_LIT>' , None ) \n if env_key_val : \n Setting . objects . create ( name = '<STR_LIT>' , value = env_key_val ) \n print ( '<STR_LIT>' )"}, {"input": "from django . db import models \n from django . contrib . auth . models import User \n from django . urls import reverse \n class CustomUser ( User ) : \n pass \n class Author ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n name = models . CharField ( max_length = <NUM_LIT> ) \n affiliation = models . CharField ( max_length = <NUM_LIT> , blank = True , null = True ) \n def __str__ ( self ) : \n return self . name + '<STR_LIT>' + self . affiliation \n class PaperHistory ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n arxiv_id = models . CharField ( max_length = <NUM_LIT> ) \n created = models . DateTimeField ( auto_now_add = True ) \n user = models . ForeignKey ( User , blank = True , null = True , on_delete = models . CASCADE ) \n ip_address = models . TextField ( blank = True , null = True ) \n lang = models . CharField ( max_length = <NUM_LIT> , default = '<STR_LIT>' ) \n def __str__ ( self ) : \n return self . arxiv_id \n class PDFHistory ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n arxiv_id = models . CharField ( max_length = <NUM_LIT> ) \n created = models . DateTimeField ( auto_now_add = True ) \n user = models . ForeignKey ( User , blank = True , null = True , on_delete = models . CASCADE ) \n ip_address = models . TextField ( blank = True , null = True ) \n lang = models . CharField ( max_length = <NUM_LIT> , default = '<STR_LIT>' ) \n def __str__ ( self ) : \n return self . arxiv_id \n class ArxivPaper ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n arxiv_id = models . CharField ( max_length = <NUM_LIT> , unique = True ) \n created = models . DateTimeField ( auto_now_add = True ) \n updated = models . DateTimeField ( auto_now = True ) \n title = models . CharField ( max_length = <NUM_LIT> , blank = True , null = True ) \n abstract = models . TextField ( blank = True , null = True ) \n authors = models . ManyToManyField ( Author , blank = True , through = '<STR_LIT>' ) \n link_doi = models . URLField ( blank = True , null = True ) \n link_homepage = models . URLField ( blank = True , null = True ) \n published_arxiv = models . DateField ( blank = True , null = True ) \n journal_ref = models . CharField ( max_length = <NUM_LIT> , blank = True , null = True ) \n comments = models . TextField ( blank = True , null = True ) \n license = models . CharField ( max_length = <NUM_LIT> , blank = True , null = True ) \n category = models . CharField ( max_length = <NUM_LIT> , blank = True , null = True ) \n updated_arxiv = models . DateField ( blank = True , null = True ) \n closest_papers = models . ManyToManyField ( '<STR_LIT>' , through = '<STR_LIT>' , symmetrical = False , related_name = '<STR_LIT>' ) \n def __str__ ( self ) : \n return self . arxiv_id + '<STR_LIT>' + self . title \n def get_absolute_url ( self ) : \n return reverse ( '<STR_LIT>' , args = [ str ( self . arxiv_id ) ] ) \n class PaperScore ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n from_paper = models . ForeignKey ( ArxivPaper , on_delete = models . CASCADE , related_name = '<STR_LIT>' ) \n to_paper = models . ForeignKey ( ArxivPaper , on_delete = models . CASCADE , related_name = '<STR_LIT>' ) \n score = models . FloatField ( ) \n created = models . DateTimeField ( auto_now_add = True ) \n updated = models . DateTimeField ( auto_now = True ) \n active = models . BooleanField ( default = True ) \n def __str__ ( self ) : \n return '<STR_LIT>' + self . from_paper . arxiv_id + '<STR_LIT>' + self . to_paper . arxiv_id + '<STR_LIT>' + str ( self . score ) \n class Search ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n query = models . TextField ( blank = True , null = True ) \n lang = models . CharField ( max_length = <NUM_LIT> , default = '<STR_LIT>' ) \n created = models . DateTimeField ( auto_now_add = True ) \n user = models . ForeignKey ( User , blank = True , null = True , on_delete = models . CASCADE ) \n def __str__ ( self ) : \n return self . query \n class SummaryPaper ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n paper = models . ForeignKey ( ArxivPaper , on_delete = models . CASCADE ) \n summary = models . TextField ( blank = True , null = True ) \n notes = models . TextField ( blank = True , null = True ) \n lay_summary = models . TextField ( blank = True , null = True ) \n blog = models . TextField ( blank = True , null = True ) \n keywords = models . TextField ( blank = True , null = True ) \n created = models . DateTimeField ( auto_now_add = True ) \n updated = models . DateTimeField ( auto_now = True ) \n lang = models . CharField ( max_length = <NUM_LIT> , default = '<STR_LIT>' ) \n def __str__ ( self ) : \n return self . paper . arxiv_id + '<STR_LIT>' + self . lang + '<STR_LIT>' + self . paper . title \n class PaperAuthor ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n author = models . ForeignKey ( Author , on_delete = models . CASCADE ) \n paper = models . ForeignKey ( ArxivPaper , on_delete = models . CASCADE ) \n author_order = models . PositiveSmallIntegerField ( ) \n class Meta : \n unique_together = ( '<STR_LIT>' , '<STR_LIT>' ) \n ordering = [ '<STR_LIT>' ] \n def __str__ ( self ) : \n return self . paper . arxiv_id + '<STR_LIT>' + self . author . name + '<STR_LIT>' + str ( self . author_order ) + '<STR_LIT>' \n class Vote ( models . Model ) : \n UP = <NUM_LIT> \n DOWN = - <NUM_LIT> \n VOTE_CHOICES = (", "output": "( UP , '<STR_LIT>' ) , \n ( DOWN , '<STR_LIT>' ) , \n ) \n id = models . AutoField ( primary_key = True ) \n vote = models . SmallIntegerField ( choices = VOTE_CHOICES ) \n paper = models . ForeignKey ( ArxivPaper , on_delete = models . CASCADE ) \n ip_address = models . TextField ( blank = True , null = True ) \n created_at = models . DateTimeField ( auto_now_add = True ) \n active = models . BooleanField ( default = True ) \n lang = models . CharField ( max_length = <NUM_LIT> , default = '<STR_LIT>' ) \n user = models . ForeignKey ( User , blank = True , null = True , on_delete = models . CASCADE ) \n def __str__ ( self ) : \n return self . paper . arxiv_id + '<STR_LIT>' + str ( self . vote ) + '<STR_LIT>' + str ( self . created_at ) + '<STR_LIT>' + str ( self . user ) \n class PickledData ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n arxiv_id = models . CharField ( max_length = <NUM_LIT> ) \n docstore_pickle = models . BinaryField ( editable = True ) \n buffer = models . BinaryField ( editable = True ) \n index_to_docstore_id_pickle = models . BinaryField ( editable = True ) \n def __str__ ( self ) : \n return self . arxiv_id \n class AIassistant ( models . Model ) : \n id = models . AutoField ( primary_key = True ) \n arxiv_id = models . CharField ( max_length = <NUM_LIT> ) \n query = models . TextField ( blank = True , null = True ) \n response = models . TextField ( blank = True , null = True ) \n user = models . ForeignKey ( User , blank = True , null = True , on_delete = models . CASCADE ) \n ip_address = models . TextField ( blank = True , null = True ) \n created = models . DateTimeField ( auto_now_add = True ) \n active = models . BooleanField ( default = True ) \n lang = models . CharField ( max_length = <NUM_LIT> , default = '<STR_LIT>' ) \n def __str__ ( self ) : \n return self . arxiv_id + '<STR_LIT>' + self . query"}, {"input": "import http \n from typing import Callable , Dict , List , Optional , Type \n from django . db . models import QuerySet \n from django . http import HttpRequest \n from ninja import FilterSchema , Schema \n from ninja . pagination import LimitOffsetPagination , PaginationBase , paginate \n from ninja_crud . views . abstract_model_view import AbstractModelView \n from ninja_crud . views . enums import HTTPMethod \n class ListModelView ( AbstractModelView ) : \n def __init__ ( \n self , \n path : str = \"<STR_LIT>\" , \n path_parameters : Optional [ Type [ Schema ] ] = None , \n query_parameters : Optional [ Type [ Schema ] ] = None , \n response_body : Optional [ Type [ List [ Schema ] ] ] = None , \n decorators : Optional [ List [ Callable ] ] = None , \n router_kwargs : Optional [ Dict ] = None , \n get_queryset : Optional [ \n Callable [ [ HttpRequest , Optional [ Schema ] ] , QuerySet ] \n ] = None , \n filter_queryset : Optional [ \n Callable [ [ QuerySet , Optional [ Schema ] ] , QuerySet ] \n ] = None , \n list_models : Optional [ \n Callable [ [ HttpRequest , Optional [ Schema ] , Optional [ Schema ] ] , QuerySet ] \n ] = None , \n pagination_class : Optional [ Type [ PaginationBase ] ] = LimitOffsetPagination , \n ) -> None : \n super ( ) . __init__ ( \n method = HTTPMethod . GET , \n path = path , \n path_parameters = path_parameters , \n query_parameters = query_parameters , \n request_body = None , \n response_body = response_body , \n response_status = http . HTTPStatus . OK , \n decorators = decorators , \n router_kwargs = router_kwargs , \n ) \n self . get_queryset = get_queryset or self . _default_get_queryset \n self . filter_queryset = filter_queryset or self . _default_filter_queryset \n self . list_models = list_models or self . _default_list_models \n self . pagination_class = pagination_class \n if self . pagination_class : \n self . decorators . append ( paginate ( self . pagination_class ) ) \n def _default_get_queryset ( \n self , request : HttpRequest , path_parameters : Optional [ Schema ] \n ) -> QuerySet : \n return self . model_viewset_class . model . objects . get_queryset ( ) \n @ staticmethod \n def _default_filter_queryset ( \n queryset : QuerySet , \n query_parameters : Optional [ Schema ] , \n ) -> QuerySet : \n if query_parameters : \n if isinstance ( query_parameters , FilterSchema ) : \n queryset = query_parameters . filter ( queryset ) \n else : \n queryset = queryset . filter ( ** query_parameters . dict ( exclude_unset = True ) ) \n return queryset \n def _default_list_models ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] , \n query_parameters : Optional [ Schema ] , \n ) -> QuerySet : \n queryset = self . get_queryset ( request , path_parameters ) \n return self . filter_queryset ( queryset , query_parameters ) \n def handle_request ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] , \n query_parameters : Optional [ Schema ] ,", "output": "request_body : Optional [ Schema ] , \n ) -> QuerySet : \n return self . list_models ( request , path_parameters , query_parameters ) \n def _inherit_model_viewset_class_attributes ( self ) -> None : \n if self . response_body is None : \n default_response_body = self . model_viewset_class . default_response_body \n self . response_body = List [ default_response_body ]"}, {"input": "import os \n import cv2 \n import yaml \n import math \n import torch \n import numpy as np \n from difflib import SequenceMatcher \n def load_config ( yaml_path ) : \n try : \n with open ( yaml_path , '<STR_LIT>' ) as f : \n params = yaml . load ( f , Loader = yaml . FullLoader ) \n except : \n print ( '<STR_LIT>' ) \n with open ( yaml_path , '<STR_LIT>' , encoding = '<STR_LIT>' ) as f : \n params = yaml . load ( f , Loader = yaml . FullLoader ) \n if not params [ '<STR_LIT>' ] : \n print ( '<STR_LIT>' ) \n exit ( - <NUM_LIT> ) \n if not params [ '<STR_LIT>' ] : \n print ( '<STR_LIT>' ) \n exit ( - <NUM_LIT> ) \n if not params [ '<STR_LIT>' ] : \n print ( '<STR_LIT>' ) \n exit ( - <NUM_LIT> ) \n if not params [ '<STR_LIT>' ] : \n print ( '<STR_LIT>' ) \n exit ( - <NUM_LIT> ) \n if '<STR_LIT>' not in params : \n params [ '<STR_LIT>' ] = <NUM_LIT> \n if '<STR_LIT>' not in params : \n params [ '<STR_LIT>' ] = <NUM_LIT> \n if '<STR_LIT>' not in params : \n params [ '<STR_LIT>' ] = <NUM_LIT> \n if '<STR_LIT>' not in params [ '<STR_LIT>' ] : \n params [ '<STR_LIT>' ] [ '<STR_LIT>' ] = <NUM_LIT> \n return params \n def update_lr ( optimizer , current_epoch , current_step , steps , epochs , initial_lr ) : \n if current_epoch < <NUM_LIT> : \n new_lr = initial_lr / steps * ( current_step + <NUM_LIT> ) \n elif <NUM_LIT> <= current_epoch <= <NUM_LIT> : \n new_lr = <NUM_LIT> * ( <NUM_LIT> + math . cos ( ( current_step + <NUM_LIT> + ( current_epoch - <NUM_LIT> ) * steps ) * math . pi / ( <NUM_LIT> * steps ) ) ) * initial_lr \n else : \n new_lr = <NUM_LIT> * ( <NUM_LIT> + math . cos ( ( current_step + <NUM_LIT> + ( current_epoch - <NUM_LIT> ) * steps ) * math . pi / ( epochs * steps ) ) ) * initial_lr \n for param_group in optimizer . param_groups : \n param_group [ '<STR_LIT>' ] = new_lr \n def save_checkpoint ( model , optimizer , word_score , ExpRate_score , epoch , optimizer_save = False , path = '<STR_LIT>' , multi_gpu = False , local_rank = <NUM_LIT> ) : \n filename = f'<STR_LIT>' \n if optimizer_save : \n state = { \n '<STR_LIT>' : model . state_dict ( ) , \n '<STR_LIT>' : optimizer . state_dict ( ) , \n } \n else : \n state = { \n '<STR_LIT>' : model . state_dict ( ) \n } \n torch . save ( state , filename ) \n print ( f'<STR_LIT>' ) \n return filename \n def load_checkpoint ( model , optimizer , path ) : \n state = torch . load ( path , map_location = '<STR_LIT>' ) \n if optimizer is not None and '<STR_LIT>' in state : \n optimizer . load_state_dict ( state [ '<STR_LIT>' ] ) \n else : \n print ( f'<STR_LIT>' ) \n model . load_state_dict ( state [ '<STR_LIT>' ] ) \n class Meter : \n def __init__ ( self , alpha = <NUM_LIT> ) : \n self . nums = [ ] \n self . exp_mean = <NUM_LIT> \n self . alpha = alpha", "output": "@ property \n def mean ( self ) : \n return np . mean ( self . nums ) \n def add ( self , num ) : \n if len ( self . nums ) == <NUM_LIT> : \n self . exp_mean = num \n self . nums . append ( num ) \n self . exp_mean = self . alpha * self . exp_mean + ( <NUM_LIT> - self . alpha ) * num \n def cal_score ( word_probs , word_label , mask ) : \n line_right = <NUM_LIT> \n if word_probs is not None : \n _ , word_pred = word_probs . max ( <NUM_LIT> ) \n word_scores = [ SequenceMatcher ( None , s1 [ : int ( np . sum ( s3 ) ) ] , s2 [ : int ( np . sum ( s3 ) ) ] , autojunk = False ) . ratio ( ) * ( len ( s1 [ : int ( np . sum ( s3 ) ) ] ) + len ( s2 [ : int ( np . sum ( s3 ) ) ] ) ) / len ( s1 [ : int ( np . sum ( s3 ) ) ] ) / <NUM_LIT> \n for s1 , s2 , s3 in zip ( word_label . cpu ( ) . detach ( ) . numpy ( ) , word_pred . cpu ( ) . detach ( ) . numpy ( ) , mask . cpu ( ) . detach ( ) . numpy ( ) ) ] \n batch_size = len ( word_scores ) \n for i in range ( batch_size ) : \n if word_scores [ i ] == <NUM_LIT> : \n line_right += <NUM_LIT> \n ExpRate = line_right / batch_size \n word_scores = np . mean ( word_scores ) \n return word_scores , ExpRate \n def draw_attention_map ( image , attention ) : \n h , w = image . shape \n attention = cv2 . resize ( attention , ( w , h ) ) \n attention_heatmap = ( ( attention - np . min ( attention ) ) / ( np . max ( attention ) - np . min ( attention ) ) * <NUM_LIT> ) . astype ( np . uint8 ) \n attention_heatmap = cv2 . applyColorMap ( attention_heatmap , cv2 . COLORMAP_JET ) \n image_new = np . stack ( ( image , image , image ) , axis = - <NUM_LIT> ) . astype ( np . uint8 ) \n attention_map = cv2 . addWeighted ( attention_heatmap , <NUM_LIT> , image_new , <NUM_LIT> , <NUM_LIT> ) \n return attention_map \n def draw_counting_map ( image , counting_attention ) : \n h , w = image . shape \n counting_attention = torch . clamp ( counting_attention , <NUM_LIT> , <NUM_LIT> ) . numpy ( ) \n counting_attention = cv2 . resize ( counting_attention , ( w , h ) ) \n counting_attention_heatmap = ( counting_attention * <NUM_LIT> ) . astype ( np . uint8 ) \n counting_attention_heatmap = cv2 . applyColorMap ( counting_attention_heatmap , cv2 . COLORMAP_JET ) \n image_new = np . stack ( ( image , image , image ) , axis = - <NUM_LIT> ) . astype ( np . uint8 ) \n counting_map = cv2 . addWeighted ( counting_attention_heatmap , <NUM_LIT> , image_new , <NUM_LIT> , <NUM_LIT> ) \n return counting_map \n def cal_distance ( word1 , word2 ) : \n m = len ( word1 ) \n n = len ( word2 ) \n if m * n == <NUM_LIT> : \n return m + n \n dp = [ [ <NUM_LIT> ] * ( n + <NUM_LIT> ) for _ in range ( m + <NUM_LIT> ) ] \n for i in range ( m + <NUM_LIT> ) : \n dp [ i ] [ <NUM_LIT> ] = i \n for j in range ( n + <NUM_LIT> ) : \n dp [ <NUM_LIT> ] [ j ] = j \n for i in range ( <NUM_LIT> , m + <NUM_LIT> ) : \n for j in range ( <NUM_LIT> , n + <NUM_LIT> ) : \n a = dp [ i - <NUM_LIT> ] [ j ] + <NUM_LIT> \n b = dp [ i ] [ j - <NUM_LIT> ] + <NUM_LIT> \n c = dp [ i - <NUM_LIT> ] [ j - <NUM_LIT> ] \n if word1 [ i - <NUM_LIT> ] != word2 [ j - <NUM_LIT> ] : \n c += <NUM_LIT> \n dp [ i ] [ j ] = min ( a , b , c ) \n return dp [ m ] [ n ] \n def compute_edit_distance ( prediction , label ) : \n prediction = prediction . strip ( ) . split ( '<STR_LIT>' ) \n label = label . strip ( ) . split ( '<STR_LIT>' ) \n distance = cal_distance ( prediction , label ) \n return distance"}, {"input": "from pathlib import Path \n from cappa . testing import CommandRunner \n from falco . config import read_falco_config \n def all_files_are_correctly_generated ( project_name , project_dir : Path ) -> bool : \n required_files = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" , \n \"<STR_LIT>\" , \n f\"<STR_LIT>\" , \n f\"<STR_LIT>\" , \n f\"<STR_LIT>\" , \n ] \n return all ( ( project_dir / file ) . exists ( ) for file in required_files ) \n blueprint_path = Path ( \"<STR_LIT>\" ) . resolve ( strict = True ) \n def test_start_project ( runner : CommandRunner ) : \n runner . invoke ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n str ( blueprint_path ) , \n ) \n assert Path ( \"<STR_LIT>\" ) . exists ( ) \n config = read_falco_config ( Path ( \"<STR_LIT>\" ) ) \n config_keys = config . keys ( ) \n assert \"<STR_LIT>\" in config . get ( \"<STR_LIT>\" ) \n assert \"<STR_LIT>\" in config_keys \n assert \"<STR_LIT>\" in config_keys \n assert \"<STR_LIT>\" in config_keys \n assert all_files_are_correctly_generated ( \"<STR_LIT>\" , project_dir = Path ( \"<STR_LIT>\" ) ) \n def test_start_project_in_directory ( runner : CommandRunner , tmp_path ) : \n runner . invoke ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n str ( blueprint_path ) , \n ) \n project_dir = tmp_path / \"<STR_LIT>\" / \"<STR_LIT>\" \n assert project_dir . exists ( ) \n assert all_files_are_correctly_generated ( \"<STR_LIT>\" , project_dir = project_dir ) \n def test_start_project_in_directory_with_root ( runner : CommandRunner , tmp_path ) : \n runner . invoke ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n str ( blueprint_path ) , \n ) \n project_dir = tmp_path / \"<STR_LIT>\" \n assert project_dir . exists ( ) \n assert all_files_are_correctly_generated ( \"<STR_LIT>\" , project_dir = project_dir ) \n def test_user_name_and_email ( runner : CommandRunner , git_user_infos ) : \n name , email = git_user_infos \n runner . invoke ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n str ( blueprint_path ) , \n ) \n pyproject_content = ( Path ( \"<STR_LIT>\" ) / \"<STR_LIT>\" ) . read_text ( ) \n assert name in pyproject_content \n assert email in pyproject_content"}, {"input": "from django . db import models \n class DepremAddress ( models . Model ) : \n full_text = models . TextField ( ) \n tweet_id = models . CharField ( max_length = <NUM_LIT> )", "output": "screen_name = models . CharField ( max_length = <NUM_LIT> ) \n created_at = models . DateTimeField ( null = True , blank = True ) \n geo_link = models . CharField ( max_length = <NUM_LIT> , default = \"<STR_LIT>\" ) \n intent_result = models . TextField ( null = True ) \n is_done = models . BooleanField ( default = False ) \n class Meta : \n ordering = [ \"<STR_LIT>\" ]"}, {"input": "from torch . utils . data import random_split \n class fivefold : \n def __init__ ( self , dataset ) : \n self . essay_folds = [ ] \n self . score_folds = [ ] \n fold_length = len ( dataset ) // <NUM_LIT> \n fold_last_length = len ( dataset ) - ( len ( dataset ) // <NUM_LIT> ) * <NUM_LIT> \n subsets = random_split ( dataset = dataset , lengths = [ fold_length , fold_length , fold_length , fold_length , fold_last_length ] ) \n for subset in subsets : \n essays = [ ] \n scores = [ ] \n for id , essay , score , prediction_id in subset : \n essays . append ( essay ) \n scores . append ( score ) \n self . essay_folds . append ( essays ) \n self . score_folds . append ( scores ) \n if __name__ == '<STR_LIT>' : \n from asap . makedataset import Dataset \n import pickle \n import matplotlib . pyplot as plt \n with open ( f'<STR_LIT>' , '<STR_LIT>' ) as f : \n dataset = pickle . load ( f ) \n folds = fivefold ( dataset ) \n for scores in folds . score_folds : \n plt . plot ( range ( <NUM_LIT> , <NUM_LIT> ) , [ scores . count ( i ) / len ( scores ) for i in range ( <NUM_LIT> , <NUM_LIT> ) ] , color = '<STR_LIT>' ) \n plt . show ( ) \n plt . close ( ) \n valessays = [ ] \n valscores = [ ] \n testessays = [ ] \n testscores = [ ] \n trainessays = [ ] \n trainscores = [ ] \n for val_index in range ( len ( folds . essay_folds ) ) : \n for test_index in range ( len ( folds . essay_folds ) ) : \n if val_index == test_index : \n continue", "output": "foldname = f'<STR_LIT>' \n for i , ( essays , scores ) in enumerate ( zip ( folds . essay_folds , folds . score_folds ) ) : \n if i == val_index : \n valessays = folds . essay_folds [ i ] \n valscores = folds . score_folds [ i ] \n elif i == test_index : \n testessays = folds . essay_folds [ i ] \n testscores = folds . score_folds [ i ] \n else : \n trainessays = trainessays + folds . essay_folds [ i ] \n trainscores = trainscores + folds . score_folds [ i ] \n plt . plot ( range ( <NUM_LIT> , <NUM_LIT> ) , [ trainscores . count ( i ) / len ( trainscores ) for i in range ( <NUM_LIT> , <NUM_LIT> ) ] , color = '<STR_LIT>' ) \n plt . plot ( range ( <NUM_LIT> , <NUM_LIT> ) , [ testscores . count ( i ) / len ( testscores ) for i in range ( <NUM_LIT> , <NUM_LIT> ) ] , color = '<STR_LIT>' ) \n plt . plot ( range ( <NUM_LIT> , <NUM_LIT> ) , [ valscores . count ( i ) / len ( valscores ) for i in range ( <NUM_LIT> , <NUM_LIT> ) ] , color = '<STR_LIT>' ) \n plt . show ( ) \n plt . close ( ) \n pass"}, {"input": "from ultralytics import YOLO \n import os \n import cv2 \n import random \n CLS_ID_NAME_MAP = { \n <NUM_LIT> : '<STR_LIT>' , \n <NUM_LIT> : '<STR_LIT>' , \n <NUM_LIT> : '<STR_LIT>' , \n <NUM_LIT> : '<STR_LIT>' \n } \n model = YOLO ( model = '<STR_LIT>' ) \n folder = '<STR_LIT>' \n file_names = os . listdir ( folder ) \n random . shuffle ( file_names ) \n imgs = [ ] \n for file_name in file_names [ : <NUM_LIT> ] : \n img_path = os . path . join ( folder , file_name ) \n img = cv2 . imread ( img_path ) \n imgs += [ img ]", "output": "results = model . predict ( source = imgs , save = True , imgsz = <NUM_LIT> )"}, {"input": "import os \n import cv2 \n import torch \n import torch . nn as nn \n import math \n from CAN . models . densenet import DenseNet \n from CAN . models . attention import Attention \n from CAN . models . decoder import PositionEmbeddingSine \n from CAN . models . counting import CountingDecoder as counting_decoder \n from CAN . counting_utils import gen_counting_label \n from CAN . utils import draw_attention_map , draw_counting_map \n class Inference ( nn . Module ) : \n def __init__ ( self , params = None , draw_map = False ) : \n super ( Inference , self ) . __init__ ( ) \n self . params = params \n self . draw_map = draw_map \n self . use_label_mask = params [ '<STR_LIT>' ] \n self . encoder = DenseNet ( params = self . params ) \n self . in_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . out_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . counting_decoder1 = counting_decoder ( self . in_channel , self . out_channel , <NUM_LIT> ) \n self . counting_decoder2 = counting_decoder ( self . in_channel , self . out_channel , <NUM_LIT> ) \n self . device = params [ '<STR_LIT>' ] \n self . decoder = decoder_dict [ params [ '<STR_LIT>' ] [ '<STR_LIT>' ] ] ( params = self . params ) \n self . ratio = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n with open ( params [ '<STR_LIT>' ] ) as f : \n words = f . readlines ( ) \n print ( f'<STR_LIT>' ) \n self . words_index_dict = { i : words [ i ] . strip ( ) for i in range ( len ( words ) ) } \n self . cal_mae = nn . L1Loss ( reduction = '<STR_LIT>' ) \n self . cal_mse = nn . MSELoss ( reduction = '<STR_LIT>' ) \n def forward ( self , images , labels , name , is_train = False ) : \n cnn_features = self . encoder ( images ) \n batch_size , _ , height , width = cnn_features . shape \n counting_preds1 , counting_maps1 = self . counting_decoder1 ( cnn_features , None ) \n counting_preds2 , counting_maps2 = self . counting_decoder2 ( cnn_features , None ) \n counting_preds = ( counting_preds1 + counting_preds2 ) / <NUM_LIT> \n counting_maps = ( counting_maps1 + counting_maps2 ) / <NUM_LIT> \n if labels == None : \n mae , mse = None , None \n else : \n mae = self . cal_mae ( counting_preds , gen_counting_label ( labels , self . out_channel , True ) ) . item ( ) \n mse = math . sqrt ( self . cal_mse ( counting_preds , gen_counting_label ( labels , self . out_channel , True ) ) . item ( ) ) \n word_probs , word_alphas = self . decoder ( cnn_features , counting_preds , is_train = is_train ) \n if self . draw_map : \n if not os . path . exists ( os . path . join ( self . params [ '<STR_LIT>' ] , name ) ) : \n os . makedirs ( os . path . join ( self . params [ '<STR_LIT>' ] , name ) , exist_ok = True ) \n if not os . path . exists ( os . path . join ( self . params [ '<STR_LIT>' ] , name ) ) : \n os . makedirs ( os . path . join ( self . params [ '<STR_LIT>' ] , name ) , exist_ok = True ) \n for i in range ( images . shape [ <NUM_LIT> ] ) : \n img = images [ i ] [ <NUM_LIT> ] . detach ( ) . cpu ( ) . numpy ( ) * <NUM_LIT> \n for step in range ( len ( word_probs ) ) : \n word_atten = word_alphas [ step ] [ <NUM_LIT> ] . detach ( ) . cpu ( ) . numpy ( ) \n word_heatmap = draw_attention_map ( img , word_atten ) \n cv2 . imwrite ( os . path . join ( self . params [ '<STR_LIT>' ] , name , f'<STR_LIT>' ) , word_heatmap ) \n for idx in range ( self . out_channel ) : \n counting_map = counting_maps [ <NUM_LIT> ] . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) [ : , : , idx ] . detach ( ) . cpu ( ) \n counting_heatmap = draw_counting_map ( img , counting_map ) \n img_name = '<STR_LIT>' + self . words_index_dict [ idx ] + '<STR_LIT>' \n cv2 . imwrite ( os . path . join ( self . params [ '<STR_LIT>' ] , name , img_name ) , counting_heatmap ) \n return word_probs , word_alphas , mae , mse \n class AttDecoder ( nn . Module ) : \n def __init__ ( self , params ) : \n super ( AttDecoder , self ) . __init__ ( ) \n self . params = params \n self . input_size = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . hidden_size = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . out_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . attention_dim = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . dropout_prob = params [ '<STR_LIT>' ] \n self . device = params [ '<STR_LIT>' ] \n self . word_num = params [ '<STR_LIT>' ] \n self . ratio = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . init_weight = nn . Linear ( self . out_channel , self . hidden_size ) \n self . embedding = nn . Embedding ( self . word_num , self . input_size ) \n self . word_input_gru = nn . GRUCell ( self . input_size , self . hidden_size ) \n self . encoder_feature_conv = nn . Conv2d ( self . out_channel , self . attention_dim , kernel_size = <NUM_LIT> ) \n self . word_attention = Attention ( params ) \n self . word_state_weight = nn . Linear ( self . hidden_size , self . hidden_size ) \n self . word_embedding_weight = nn . Linear ( self . input_size , self . hidden_size ) \n self . word_context_weight = nn . Linear ( self . out_channel , self . hidden_size ) \n self . counting_context_weight = nn . Linear ( self . word_num , self . hidden_size ) \n self . word_convert = nn . Linear ( self . hidden_size , self . word_num ) \n if params [ '<STR_LIT>' ] : \n self . dropout = nn . Dropout ( params [ '<STR_LIT>' ] )", "output": "def forward ( self , cnn_features , counting_preds , is_train = False ) : \n batch_size , _ , height , width = cnn_features . shape \n image_mask = torch . ones ( ( batch_size , <NUM_LIT> , height , width ) ) . to ( self . device ) \n cnn_features_trans = self . encoder_feature_conv ( cnn_features ) \n position_embedding = PositionEmbeddingSine ( <NUM_LIT> , normalize = True ) \n pos = position_embedding ( cnn_features_trans , image_mask [ : , <NUM_LIT> , : , : ] ) \n cnn_features_trans = cnn_features_trans + pos \n word_alpha_sum = torch . zeros ( ( batch_size , <NUM_LIT> , height , width ) ) . to ( device = self . device ) \n hidden = self . init_hidden ( cnn_features , image_mask ) \n word_embedding = self . embedding ( torch . ones ( [ batch_size ] ) . long ( ) . to ( device = self . device ) ) \n counting_context_weighted = self . counting_context_weight ( counting_preds ) \n word_probs = [ ] \n word_alphas = [ ] \n i = <NUM_LIT> \n while i < <NUM_LIT> : \n hidden = self . word_input_gru ( word_embedding , hidden ) \n word_context_vec , word_alpha , word_alpha_sum = self . word_attention ( cnn_features , cnn_features_trans , hidden , \n word_alpha_sum , image_mask ) \n current_state = self . word_state_weight ( hidden ) \n word_weighted_embedding = self . word_embedding_weight ( word_embedding ) \n word_context_weighted = self . word_context_weight ( word_context_vec ) \n if self . params [ '<STR_LIT>' ] : \n word_out_state = self . dropout ( current_state + word_weighted_embedding + word_context_weighted + counting_context_weighted ) \n else : \n word_out_state = current_state + word_weighted_embedding + word_context_weighted + counting_context_weighted \n word_prob = self . word_convert ( word_out_state ) \n _ , word = word_prob . max ( <NUM_LIT> ) \n word_embedding = self . embedding ( word ) \n if word . item ( ) == <NUM_LIT> : \n return word_probs , word_alphas \n word_alphas . append ( word_alpha ) \n word_probs . append ( word ) \n i += <NUM_LIT> \n return word_probs , word_alphas \n def init_hidden ( self , features , feature_mask ) : \n average = ( features * feature_mask ) . sum ( - <NUM_LIT> ) . sum ( - <NUM_LIT> ) / feature_mask . sum ( - <NUM_LIT> ) . sum ( - <NUM_LIT> ) \n average = self . init_weight ( average ) \n return torch . tanh ( average ) \n decoder_dict = { \n '<STR_LIT>' : AttDecoder \n }"}, {"input": "import pytest \n from falco . commands . work import default_address \n from falco . commands . work import default_server_cmd \n from falco . commands . work import Work \n from falco . config import write_falco_config \n def test_env_resolution ( tmp_path ) : \n assert Work ( ) . resolve_django_env ( ) \n def test_env_resolution_with_env ( tmp_path ) : \n ( tmp_path / \"<STR_LIT>\" ) . write_text ( \"<STR_LIT>\" ) \n assert \"<STR_LIT>\" in Work ( ) . resolve_django_env ( ) \n def test_without_pyproject_file ( ) : \n assert Work ( ) . get_commands ( ) == { \"<STR_LIT>\" : default_server_cmd . format ( address = default_address ) } \n def test_with_pyproject_file ( pyproject_toml ) : \n write_falco_config ( pyproject_path = pyproject_toml , work = { \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n assert Work ( ) . get_commands ( ) == { \n \"<STR_LIT>\" : default_server_cmd . format ( address = default_address ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n def test_override_server ( pyproject_toml ) : \n work = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } \n write_falco_config ( pyproject_path = pyproject_toml , work = work ) \n assert Work ( ) . get_commands ( ) == work", "output": "@ pytest . mark . parametrize ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n def test_override_server_through_arg ( address ) : \n assert Work ( address = address ) . get_commands ( ) == { \"<STR_LIT>\" : default_server_cmd . format ( address = address ) } \n @ pytest . mark . parametrize ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) \n def test_override_server_through_arg_by_pyproject ( pyproject_toml , address ) : \n work = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n write_falco_config ( pyproject_path = pyproject_toml , work = work ) \n assert Work ( address = address ) . get_commands ( ) == { \"<STR_LIT>\" : work [ \"<STR_LIT>\" ] . format ( address = address ) }"}, {"input": "import json \n import datetime \n from typing import List \n from feeds . models import Entry \n from feeds . tasks import process_entry \n from tweets . helpers import fetch_tweets \n from tweets . models import DepremAddress \n from trquake . celery import app \n @ app . task \n def collect_tweets ( ) : \n data = [ ] \n since_time = int ( \n ( datetime . datetime . now ( ) . replace ( second = <NUM_LIT> , microsecond = <NUM_LIT> ) - datetime . timedelta ( minutes = <NUM_LIT> ) ) . timestamp ( ) \n ) \n query = \n for tweet in fetch_tweets ( query = query ) : \n data . append ( \n Entry ( \n full_text = tweet [ \"<STR_LIT>\" ] , \n is_resolved = False , \n channel = \"<STR_LIT>\" , \n extra_parameters = json . dumps ( \n { \n \"<STR_LIT>\" : tweet [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : tweet [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : tweet [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : tweet [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : tweet [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : tweet [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : tweet [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : tweet [ \"<STR_LIT>\" ] ,", "output": "} \n ) , \n ) \n ) \n created_tweets : List [ Entry ] = Entry . objects . bulk_create ( data ) \n for entry in created_tweets : \n process_entry . apply_async ( kwargs = { \"<STR_LIT>\" : entry . id } ) \n @ app . task \n def collect_deprem_address_tweets ( ) : \n data = [ ] \n since_time = int ( \n ( datetime . datetime . now ( ) . replace ( second = <NUM_LIT> , microsecond = <NUM_LIT> ) - datetime . timedelta ( minutes = <NUM_LIT> ) ) . timestamp ( ) \n ) \n query = \n for tweet in fetch_tweets ( query = query ) : \n data . append ( \n DepremAddress ( \n full_text = tweet [ \"<STR_LIT>\" ] , \n tweet_id = tweet [ \"<STR_LIT>\" ] , \n screen_name = tweet [ \"<STR_LIT>\" ] , \n created_at = tweet [ \"<STR_LIT>\" ] , \n geo_link = tweet [ \"<STR_LIT>\" ] , \n ) \n ) \n DepremAddress . objects . bulk_create ( data )"}, {"input": "import os \n import sys \n import pickle \n import json \n import logging \n import hashlib \n from typing import Any , Dict , List , Optional \n import arxiv \n from langchain . schema import Document \n from . models import Conversation , Message , Setting , Prompt , EmbeddingDocument \n from . llm import text_splitter , embedding_model , pickle_faiss \n logger = logging . getLogger ( __name__ ) \n from utils . search_prompt import compile_prompt \n from utils . duckduckgo_search import web_search , SearchRequest \n def _web_search ( message , args ) : \n search_results = web_search ( SearchRequest ( message , ua = args [ '<STR_LIT>' ] ) , num_results = <NUM_LIT> ) \n message_content = compile_prompt ( search_results , message , default_prompt = args [ '<STR_LIT>' ] ) \n return message_content \n arxiv_client = arxiv . Client ( \n page_size = <NUM_LIT> , \n delay_seconds = <NUM_LIT> , \n num_retries = <NUM_LIT> , \n ) \n def _hacky_hash ( some_string ) : \n _hash = hashlib . md5 ( some_string . encode ( \"<STR_LIT>\" ) ) . hexdigest ( ) \n return _hash \n def _arxiv_load ( \n query : Optional [ str ] = '<STR_LIT>' , \n id_list : Optional [ str | List [ str ] ] = [ ] , \n max_results : int = <NUM_LIT> , \n sort_by : Optional [ Any ] = arxiv . SortCriterion . Relevance , \n papers_dir : Optional [ str ] = \"<STR_LIT>\" , \n load_all_available_meta : bool = False ,", "output": ") -> List [ Document ] : \n if isinstance ( id_list , str ) : \n id_list = id_list . split ( '<STR_LIT>' ) \n if query : \n query = query [ : <NUM_LIT> ] \n try : \n import fitz \n except ImportError : \n raise ValueError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) \n try : \n docs : List [ Document ] = [ ] \n arxiv_search = arxiv . Search ( \n query = query , \n id_list = id_list , \n max_results = max_results , \n sort_by = sort_by \n ) \n search_results = list ( arxiv_client . results ( arxiv_search ) ) \n if not os . path . exists ( papers_dir ) : \n os . makedirs ( papers_dir ) \n for result in search_results : \n try : \n paper = result \n filename = f\"<STR_LIT>\" \n doc_file_name : str = os . path . join ( papers_dir , filename ) \n paper . download_pdf ( dirpath = papers_dir , filename = filename ) \n logging . debug ( f\"<STR_LIT>\" ) \n with fitz . open ( doc_file_name ) as doc_file : \n text : str = \"<STR_LIT>\" . join ( page . get_text ( ) for page in doc_file ) \n add_meta = ( \n { \n \"<STR_LIT>\" : result . entry_id , \n \"<STR_LIT>\" : str ( result . published . date ( ) ) , \n \"<STR_LIT>\" : result . comment , \n \"<STR_LIT>\" : result . journal_ref , \n \"<STR_LIT>\" : result . doi , \n \"<STR_LIT>\" : result . primary_category , \n \"<STR_LIT>\" : result . categories , \n \"<STR_LIT>\" : [ link . href for link in result . links ] , \n } \n if load_all_available_meta \n else { } \n ) \n doc = Document ( \n page_content = text , \n metadata = ( \n { \n \"<STR_LIT>\" : str ( result . updated . date ( ) ) , \n \"<STR_LIT>\" : result . title , \n \"<STR_LIT>\" : \"<STR_LIT>\" . join ( \n a . name for a in result . authors \n ) , \n \"<STR_LIT>\" : result . summary , \n ** add_meta , \n } \n ) , \n ) \n docs . append ( doc ) \n except FileNotFoundError as f_ex : \n logger . debug ( f_ex ) \n try : \n for f in os . listdir ( papers_dir ) : \n os . remove ( os . path . join ( papers_dir , f ) ) \n logging . debug ( f\"<STR_LIT>\" ) \n logging . debug ( f\"<STR_LIT>\" ) \n except OSError : \n print ( \"<STR_LIT>\" ) \n return docs \n except Exception as ex : \n logger . debug ( \"<STR_LIT>\" , ex ) \n return [ ] \n def _arxiv ( message , args ) : \n from langchain . vectorstores import FAISS \n ID = message . strip ( ) \n message = '<STR_LIT>' + ID \n logger . debug ( '<STR_LIT>' , message , args ) \n try : \n docs = _arxiv_load ( id_list = [ ID ] , max_results = <NUM_LIT> ) \n if len ( docs ) == <NUM_LIT> : \n raise RuntimeError ( ) \n except Exception as e : \n logger . error ( '<STR_LIT>' , ID ) \n return f'<STR_LIT>' \n logger . debug ( '<STR_LIT>' , len ( docs ) ) \n documents = text_splitter . split_documents ( docs ) \n db = FAISS . from_documents ( documents , embedding_model . function ) \n faiss_store = pickle_faiss ( db ) \n doc_obj = EmbeddingDocument ( \n user = args [ '<STR_LIT>' ] , \n faiss_store = faiss_store , \n title = docs [ <NUM_LIT> ] . metadata [ '<STR_LIT>' ] , \n ) \n doc_obj . save ( ) \n args [ '<STR_LIT>' ] = doc_obj . id \n args [ '<STR_LIT>' ] = docs [ <NUM_LIT> ] . metadata [ '<STR_LIT>' ] \n message += '<STR_LIT>' + docs [ <NUM_LIT> ] . metadata [ '<STR_LIT>' ] \n return message \n TOOL_LIST = { \n '<STR_LIT>' : _web_search , \n '<STR_LIT>' : _arxiv , \n }"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . IntegerField ( default = <NUM_LIT> ) ) ,", "output": "( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) ) , \n ] , \n ) , \n ]"}, {"input": "import hashlib \n import hmac \n import json \n from datetime import datetime , timedelta \n import pytest \n from django . test import override_settings \n from django . utils import timezone \n from freezegun import freeze_time \n from pytest_django . asserts import assertNumQueries \n from django_webhook . test_factories import ( \n WebhookFactory , \n WebhookSecretFactory , \n WebhookTopicFactory , \n ) \n from tests . model_data import TEST_JOIN_DATE , TEST_LAST_ACTIVE , TEST_USER \n from tests . models import Country , User \n pytestmark = pytest . mark . django_db \n @ freeze_time ( \"<STR_LIT>\" ) \n def test_create ( responses ) : \n uuid = \"<STR_LIT>\" \n webhook = WebhookFactory ( \n topics = [ WebhookTopicFactory ( name = \"<STR_LIT>\" ) ] , secrets = [ ] , uuid = uuid \n ) \n secret = WebhookSecretFactory ( webhook = webhook , token = \"<STR_LIT>\" ) \n responses . post ( webhook . url ) \n User . objects . create ( \n name = \"<STR_LIT>\" , \n email = \"<STR_LIT>\" , \n join_date = TEST_JOIN_DATE , \n last_active = TEST_LAST_ACTIVE , \n ) \n assert len ( responses . calls ) == <NUM_LIT> \n req = responses . calls [ <NUM_LIT> ] . request \n now = timezone . now ( ) \n assert req . headers [ \"<STR_LIT>\" ] == \"<STR_LIT>\" \n assert req . headers [ \"<STR_LIT>\" ] == str ( webhook . uuid ) \n assert json . loads ( req . body ) == { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : TEST_USER , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n hmac_msg = f\"<STR_LIT>\" . encode ( ) \n assert ( \n req . headers [ \"<STR_LIT>\" ] \n == hmac . new ( \n key = secret . token . encode ( ) , msg = hmac_msg , digestmod = hashlib . sha256 \n ) . hexdigest ( ) \n ) \n def test_update ( responses ) : \n user = User . objects . create ( \n name = \"<STR_LIT>\" , \n email = \"<STR_LIT>\" , \n join_date = TEST_JOIN_DATE , \n last_active = TEST_LAST_ACTIVE , \n ) \n webhook = WebhookFactory ( \n topics = [ WebhookTopicFactory ( name = \"<STR_LIT>\" ) ] , \n ) \n responses . post ( webhook . url ) \n user . name = \"<STR_LIT>\" \n user . save ( ) \n assert len ( responses . calls ) == <NUM_LIT> \n req = responses . calls [ <NUM_LIT> ] . request \n expected_object = TEST_USER . copy ( ) \n expected_object [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n assert json . loads ( req . body ) == { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : expected_object , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : str ( webhook . uuid ) , \n } \n def test_delete ( responses ) : \n user = User . objects . create ( \n name = \"<STR_LIT>\" , \n email = \"<STR_LIT>\" , \n join_date = TEST_JOIN_DATE , \n last_active = TEST_LAST_ACTIVE , \n ) \n webhook = WebhookFactory ( \n topics = [ WebhookTopicFactory ( name = \"<STR_LIT>\" ) ] , \n ) \n responses . post ( webhook . url ) \n user . delete ( ) \n assert len ( responses . calls ) == <NUM_LIT> \n req = responses . calls [ <NUM_LIT> ] . request \n assert json . loads ( req . body ) == { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : TEST_USER , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : str ( webhook . uuid ) , \n } \n def test_filters_topic_by_type ( responses ) : \n webhook = WebhookFactory ( \n topics = [ WebhookTopicFactory ( name = \"<STR_LIT>\" ) ] , \n ) \n responses . post ( webhook . url ) \n user = User . objects . create ( \n name = \"<STR_LIT>\" , \n email = \"<STR_LIT>\" , \n join_date = TEST_JOIN_DATE , \n last_active = TEST_LAST_ACTIVE , \n ) \n assert len ( responses . calls ) == <NUM_LIT> \n user . save ( ) \n assert len ( responses . calls ) == <NUM_LIT> \n def test_multiple_topic_types ( responses ) : \n user = User . objects . create ( \n name = \"<STR_LIT>\" , \n email = \"<STR_LIT>\" , \n join_date = TEST_JOIN_DATE , \n last_active = TEST_LAST_ACTIVE , \n ) \n webhook = WebhookFactory ( \n topics = [ \n WebhookTopicFactory ( name = \"<STR_LIT>\" ) , \n WebhookTopicFactory ( name = \"<STR_LIT>\" ) , \n WebhookTopicFactory ( name = \"<STR_LIT>\" ) , \n ] , \n ) \n responses . post ( webhook . url ) \n user . delete ( ) \n assert len ( responses . calls ) == <NUM_LIT> \n assert json . loads ( responses . calls [ <NUM_LIT> ] . request . body ) [ \"<STR_LIT>\" ] == \"<STR_LIT>\" \n def test_multiple_topic_models ( responses ) : \n User . objects . create (", "output": "name = \"<STR_LIT>\" , \n email = \"<STR_LIT>\" , \n join_date = TEST_JOIN_DATE , \n last_active = TEST_LAST_ACTIVE , \n ) \n country = Country . objects . create ( name = \"<STR_LIT>\" ) \n webhook = WebhookFactory ( \n topics = [ \n WebhookTopicFactory ( name = \"<STR_LIT>\" ) , \n WebhookTopicFactory ( name = \"<STR_LIT>\" ) , \n ] , \n ) \n responses . post ( webhook . url ) \n country . save ( ) \n assert json . loads ( responses . calls [ <NUM_LIT> ] . request . body ) == { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : str ( webhook . uuid ) , \n } \n @ pytest . mark . skip ( reason = \"<STR_LIT>\" ) \n def test_enriches_payload_with_api_url ( ) : \n pass \n @ pytest . mark . skip ( reason = \"<STR_LIT>\" ) \n def test_enriches_payload_with_app_url ( ) : \n pass \n def test_does_not_fire_inactive_webhooks ( responses ) : \n country = Country . objects . create ( name = \"<STR_LIT>\" ) \n webhook = WebhookFactory ( \n active = False , \n topics = [ \n WebhookTopicFactory ( name = \"<STR_LIT>\" ) , \n ] , \n ) \n responses . post ( webhook . url ) \n country . save ( ) \n assert len ( responses . calls ) == <NUM_LIT> \n @ override_settings ( \n DJANGO_WEBHOOK = dict ( \n MODELS = [ \"<STR_LIT>\" ] , \n USE_CACHE = True , \n ) \n ) \n def test_caches_webhook_query_calls ( mocker ) : \n mocker . patch ( \"<STR_LIT>\" ) \n country = Country . objects . create ( name = \"<STR_LIT>\" ) \n WebhookFactory ( \n topics = [ \n WebhookTopicFactory ( name = \"<STR_LIT>\" ) , \n ] , \n ) \n now = datetime . now ( ) \n with freeze_time ( now ) : \n country . save ( ) \n with assertNumQueries ( <NUM_LIT> ) : \n country . save ( ) \n with freeze_time ( now + timedelta ( minutes = <NUM_LIT> , seconds = <NUM_LIT> ) ) : \n with assertNumQueries ( <NUM_LIT> ) : \n country . save ( )"}, {"input": "from datetime import date , datetime", "output": "TEST_JOIN_DATE = date ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n TEST_LAST_ACTIVE = datetime ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n TEST_USER = { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n }"}, {"input": "import json \n from abc import ABC , abstractmethod \n from typing import TYPE_CHECKING , Type \n import django . http \n import django . utils . http \n from ninja_crud . views import AbstractModelView \n if TYPE_CHECKING : \n from ninja_crud . testing . viewsets import ModelViewSetTestCase \n class AbstractModelViewTest ( ABC ) : \n model_view : AbstractModelView \n model_viewset_test_case : \"<STR_LIT>\" \n def __init__ ( self , model_view_class : Type [ AbstractModelView ] ) -> None : \n self . model_view_class = model_view_class \n def simulate_request ( \n self , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) -> django . http . HttpResponse : \n base_path = self . model_viewset_test_case . base_path . strip ( \"<STR_LIT>\" ) \n endpoint_path = self . model_view . path . lstrip ( \"<STR_LIT>\" ) \n path = f\"<STR_LIT>\" \n return self . model_viewset_test_case . client_class ( ) . generic ( \n method = self . model_view . method . value , \n path = path . format ( ** path_parameters ) , \n QUERY_STRING = django . utils . http . urlencode ( query_parameters , doseq = True ) , \n data = json . dumps ( payload or None ) , \n content_type = \"<STR_LIT>\" , \n ** headers , \n ) \n @ abstractmethod \n def on_successful_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict ,", "output": "payload : dict , \n ) : \n pass \n @ abstractmethod \n def on_failed_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) : \n pass \n def bind_to_model_viewset_test_case ( \n self , model_viewset_test_case : \"<STR_LIT>\" \n ) -> None : \n self . model_viewset_test_case = model_viewset_test_case \n def bind_to_model_view ( self , model_view : AbstractModelView ) -> None : \n self . model_view = model_view"}, {"input": "from rest_framework . response import Response \n from rest_framework import status \n from dj_rest_auth . registration . views import RegisterView \n from chat . models import Setting \n from allauth . account import app_settings as allauth_account_settings \n class RegistrationView ( RegisterView ) : \n def create ( self , request , * args , ** kwargs ) : \n try : \n open_registration = Setting . objects . get ( name = '<STR_LIT>' ) . value == '<STR_LIT>' \n except Setting . DoesNotExist : \n open_registration = True", "output": "if open_registration is False : \n return Response ( { '<STR_LIT>' : '<STR_LIT>' } , status = status . HTTP_403_FORBIDDEN ) \n serializer = self . get_serializer ( data = request . data ) \n serializer . is_valid ( raise_exception = True ) \n user = self . perform_create ( serializer ) \n headers = self . get_success_headers ( serializer . data ) \n data = self . get_response_data ( user ) \n data [ '<STR_LIT>' ] = allauth_account_settings . EMAIL_VERIFICATION \n if data : \n response = Response ( \n data , \n status = status . HTTP_201_CREATED , \n headers = headers , \n ) \n else : \n response = Response ( status = status . HTTP_204_NO_CONTENT , headers = headers ) \n return response"}, {"input": "import os \n import cv2 \n import torch \n import torch . nn as nn \n import math \n from CAN . models . densenet import DenseNet \n from CAN . models . attention import Attention \n from CAN . models . decoder import PositionEmbeddingSine \n from CAN . models . counting import CountingDecoder as counting_decoder \n from CAN . counting_utils import gen_counting_label \n from CAN . utils import draw_attention_map , draw_counting_map \n class Inference ( nn . Module ) : \n def __init__ ( self , params = None , draw_map = False ) : \n super ( Inference , self ) . __init__ ( ) \n self . params = params \n self . draw_map = draw_map \n self . use_label_mask = params [ '<STR_LIT>' ] \n self . encoder = DenseNet ( params = self . params ) \n self . in_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . out_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . counting_decoder1 = counting_decoder ( self . in_channel , self . out_channel , <NUM_LIT> ) \n self . counting_decoder2 = counting_decoder ( self . in_channel , self . out_channel , <NUM_LIT> ) \n self . device = params [ '<STR_LIT>' ] \n self . decoder = decoder_dict [ params [ '<STR_LIT>' ] [ '<STR_LIT>' ] ] ( params = self . params ) \n self . ratio = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n with open ( params [ '<STR_LIT>' ] ) as f : \n words = f . readlines ( ) \n print ( f'<STR_LIT>' ) \n self . words_index_dict = { i : words [ i ] . strip ( ) for i in range ( len ( words ) ) } \n self . cal_mae = nn . L1Loss ( reduction = '<STR_LIT>' ) \n self . cal_mse = nn . MSELoss ( reduction = '<STR_LIT>' ) \n def forward ( self , images , labels , name , is_train = False ) : \n cnn_features = self . encoder ( images ) \n batch_size , _ , height , width = cnn_features . shape \n counting_preds1 , counting_maps1 = self . counting_decoder1 ( cnn_features , None ) \n counting_preds2 , counting_maps2 = self . counting_decoder2 ( cnn_features , None ) \n counting_preds = ( counting_preds1 + counting_preds2 ) / <NUM_LIT> \n counting_maps = ( counting_maps1 + counting_maps2 ) / <NUM_LIT> \n if labels != None : \n mae = self . cal_mae ( counting_preds , gen_counting_label ( labels , self . out_channel , True ) ) . item ( ) \n mse = math . sqrt ( self . cal_mse ( counting_preds , gen_counting_label ( labels , self . out_channel , True ) ) . item ( ) ) \n else : \n mae = <NUM_LIT> \n mse = <NUM_LIT> \n word_probs , word_alphas = self . decoder ( cnn_features , counting_preds , is_train = is_train ) \n if self . draw_map : \n if not os . path . exists ( os . path . join ( self . params [ '<STR_LIT>' ] , name ) ) : \n os . makedirs ( os . path . join ( self . params [ '<STR_LIT>' ] , name ) , exist_ok = True ) \n if not os . path . exists ( os . path . join ( self . params [ '<STR_LIT>' ] , name ) ) : \n os . makedirs ( os . path . join ( self . params [ '<STR_LIT>' ] , name ) , exist_ok = True ) \n for i in range ( images . shape [ <NUM_LIT> ] ) : \n img = images [ i ] [ <NUM_LIT> ] . detach ( ) . cpu ( ) . numpy ( ) * <NUM_LIT> \n for step in range ( len ( word_probs ) ) : \n word_atten = word_alphas [ step ] [ <NUM_LIT> ] . detach ( ) . cpu ( ) . numpy ( ) \n word_heatmap = draw_attention_map ( img , word_atten ) \n cv2 . imwrite ( os . path . join ( self . params [ '<STR_LIT>' ] , name , f'<STR_LIT>' ) , word_heatmap ) \n for idx in range ( self . out_channel ) : \n counting_map = counting_maps [ <NUM_LIT> ] . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) [ : , : , idx ] . detach ( ) . cpu ( ) \n counting_heatmap = draw_counting_map ( img , counting_map ) \n img_name = '<STR_LIT>' + self . words_index_dict [ idx ] + '<STR_LIT>'", "output": "cv2 . imwrite ( os . path . join ( self . params [ '<STR_LIT>' ] , name , img_name ) , counting_heatmap ) \n return word_probs , word_alphas , mae , mse \n class AttDecoder ( nn . Module ) : \n def __init__ ( self , params ) : \n super ( AttDecoder , self ) . __init__ ( ) \n self . params = params \n self . input_size = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . hidden_size = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . out_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . attention_dim = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . dropout_prob = params [ '<STR_LIT>' ] \n self . device = params [ '<STR_LIT>' ] \n self . word_num = params [ '<STR_LIT>' ] \n self . ratio = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . init_weight = nn . Linear ( self . out_channel , self . hidden_size ) \n self . embedding = nn . Embedding ( self . word_num , self . input_size ) \n self . word_input_gru = nn . GRUCell ( self . input_size , self . hidden_size ) \n self . encoder_feature_conv = nn . Conv2d ( self . out_channel , self . attention_dim , kernel_size = <NUM_LIT> ) \n self . word_attention = Attention ( params ) \n self . word_state_weight = nn . Linear ( self . hidden_size , self . hidden_size ) \n self . word_embedding_weight = nn . Linear ( self . input_size , self . hidden_size ) \n self . word_context_weight = nn . Linear ( self . out_channel , self . hidden_size ) \n self . counting_context_weight = nn . Linear ( self . word_num , self . hidden_size ) \n self . word_convert = nn . Linear ( self . hidden_size , self . word_num ) \n if params [ '<STR_LIT>' ] : \n self . dropout = nn . Dropout ( params [ '<STR_LIT>' ] ) \n def forward ( self , cnn_features , counting_preds , is_train = False ) : \n batch_size , _ , height , width = cnn_features . shape \n image_mask = torch . ones ( ( batch_size , <NUM_LIT> , height , width ) ) . to ( self . device ) \n cnn_features_trans = self . encoder_feature_conv ( cnn_features ) \n position_embedding = PositionEmbeddingSine ( <NUM_LIT> , normalize = True ) \n pos = position_embedding ( cnn_features_trans , image_mask [ : , <NUM_LIT> , : , : ] ) \n cnn_features_trans = cnn_features_trans + pos \n word_alpha_sum = torch . zeros ( ( batch_size , <NUM_LIT> , height , width ) ) . to ( device = self . device ) \n hidden = self . init_hidden ( cnn_features , image_mask ) \n word_embedding = self . embedding ( torch . ones ( [ batch_size ] ) . long ( ) . to ( device = self . device ) ) \n counting_context_weighted = self . counting_context_weight ( counting_preds ) \n word_probs = [ ] \n word_alphas = [ ] \n i = <NUM_LIT> \n while i < <NUM_LIT> : \n hidden = self . word_input_gru ( word_embedding , hidden ) \n word_context_vec , word_alpha , word_alpha_sum = self . word_attention ( cnn_features , cnn_features_trans , hidden , \n word_alpha_sum , image_mask ) \n current_state = self . word_state_weight ( hidden ) \n word_weighted_embedding = self . word_embedding_weight ( word_embedding ) \n word_context_weighted = self . word_context_weight ( word_context_vec ) \n if self . params [ '<STR_LIT>' ] : \n word_out_state = self . dropout ( current_state + word_weighted_embedding + word_context_weighted + counting_context_weighted ) \n else : \n word_out_state = current_state + word_weighted_embedding + word_context_weighted + counting_context_weighted \n word_prob = self . word_convert ( word_out_state ) \n _ , word = word_prob . max ( <NUM_LIT> ) \n word_embedding = self . embedding ( word ) \n if word . item ( ) == <NUM_LIT> : \n return word_probs , word_alphas \n word_alphas . append ( word_alpha ) \n word_probs . append ( word ) \n i += <NUM_LIT> \n return word_probs , word_alphas \n def init_hidden ( self , features , feature_mask ) : \n average = ( features * feature_mask ) . sum ( - <NUM_LIT> ) . sum ( - <NUM_LIT> ) / feature_mask . sum ( - <NUM_LIT> ) . sum ( - <NUM_LIT> ) \n average = self . init_weight ( average ) \n return torch . tanh ( average ) \n decoder_dict = { \n '<STR_LIT>' : AttDecoder \n }"}, {"input": "import hashlib \n import hmac \n import json \n from datetime import datetime \n from json import JSONEncoder \n from typing import cast \n from django . conf import settings \n from django . utils import timezone \n from requests import Request \n from django_webhook . models import Webhook \n def prepare_request ( webhook : Webhook , payload : dict ) : \n now = timezone . now ( ) \n timestamp = int ( datetime . timestamp ( now ) ) \n encoder_cls = cast ( \n type [ JSONEncoder ] , settings . DJANGO_WEBHOOK [ \"<STR_LIT>\" ] \n ) \n signatures = [ \n sign_payload ( payload , secret , timestamp , encoder_cls ) \n for secret in webhook . secrets . values_list ( \"<STR_LIT>\" , flat = True ) \n ] \n headers = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : str ( timestamp ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" . join ( signatures ) , \n \"<STR_LIT>\" : str ( webhook . uuid ) , \n } \n r = Request ( \n method = \"<STR_LIT>\" , \n url = webhook . url , \n headers = headers , \n data = json . dumps ( payload , cls = encoder_cls ) . encode ( ) , \n ) \n return r . prepare ( ) \n def sign_payload ( \n payload : dict , secret : str , timestamp : int , encoder_cls : type [ JSONEncoder ] \n ) :", "output": "combined_payload = f\"<STR_LIT>\" \n return hmac . new ( \n key = secret . encode ( ) , msg = combined_payload . encode ( ) , digestmod = hashlib . sha256 \n ) . hexdigest ( )"}, {"input": "import hashlib \n import mimetypes \n from rest_framework import serializers \n from rest_framework . decorators import action \n from application import dispatch \n from dvadmin . system . models import FileList \n from dvadmin . utils . json_response import DetailResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class FileSerializer ( CustomModelSerializer ) : \n url = serializers . SerializerMethodField ( read_only = True ) \n def get_url ( self , instance ) : \n return instance . file_url or ( f'<STR_LIT>' ) \n class Meta : \n model = FileList \n fields = \"<STR_LIT>\" \n def create ( self , validated_data ) : \n file_engine = dispatch . get_system_config_values ( \"<STR_LIT>\" ) or '<STR_LIT>' \n file_backup = dispatch . get_system_config_values ( \"<STR_LIT>\" ) \n file = self . initial_data . get ( '<STR_LIT>' ) \n file_size = file . size \n validated_data [ '<STR_LIT>' ] = str ( file ) \n validated_data [ '<STR_LIT>' ] = file_size \n md5 = hashlib . md5 ( ) \n for chunk in file . chunks ( ) : \n md5 . update ( chunk ) \n validated_data [ '<STR_LIT>' ] = md5 . hexdigest ( ) \n validated_data [ '<STR_LIT>' ] = file_engine", "output": "validated_data [ '<STR_LIT>' ] = file . content_type \n if file_backup : \n validated_data [ '<STR_LIT>' ] = file \n if file_engine == '<STR_LIT>' : \n from dvadmin_cloud_storage . views . aliyun import ali_oss_upload \n file_path = ali_oss_upload ( file ) \n if file_path : \n validated_data [ '<STR_LIT>' ] = file_path \n else : \n raise ValueError ( \"<STR_LIT>\" ) \n elif file_engine == '<STR_LIT>' : \n from dvadmin_cloud_storage . views . tencent import tencent_cos_upload \n file_path = tencent_cos_upload ( file ) \n if file_path : \n validated_data [ '<STR_LIT>' ] = file_path \n else : \n raise ValueError ( \"<STR_LIT>\" ) \n else : \n validated_data [ '<STR_LIT>' ] = file \n try : \n request_user = self . request . user \n validated_data [ '<STR_LIT>' ] = request_user . dept . id \n validated_data [ '<STR_LIT>' ] = request_user . id \n validated_data [ '<STR_LIT>' ] = request_user . id \n except : \n pass \n return super ( ) . create ( validated_data ) \n class FileViewSet ( CustomModelViewSet ) : \n queryset = FileList . objects . all ( ) \n serializer_class = FileSerializer \n filter_fields = [ '<STR_LIT>' , ] \n permission_classes = [ ]"}, {"input": "import logging \n from django . db import models \n from django . contrib . auth . models import User \n logger = logging . getLogger ( __name__ ) \n class EmbeddingDocument ( models . Model ) : \n user = models . ForeignKey ( User , on_delete = models . CASCADE ) \n faiss_store = models . BinaryField ( null = True ) \n title = models . CharField ( max_length = <NUM_LIT> , default = \"<STR_LIT>\" ) \n created_at = models . DateTimeField ( auto_now_add = True ) \n class Conversation ( models . Model ) : \n user = models . ForeignKey ( User , on_delete = models . CASCADE ) \n topic = models . CharField ( max_length = <NUM_LIT> ) \n created_at = models . DateTimeField ( auto_now_add = True ) \n class Message ( models . Model ) : \n conversation = models . ForeignKey ( Conversation , on_delete = models . CASCADE ) \n user = models . ForeignKey ( User , on_delete = models . CASCADE ) \n message = models . TextField ( ) \n messages = models . TextField ( default = '<STR_LIT>' ) \n tokens = models . IntegerField ( default = <NUM_LIT> ) \n is_bot = models . BooleanField ( default = False ) \n is_disabled = models . BooleanField ( default = False )", "output": "message_type = models . IntegerField ( default = <NUM_LIT> ) \n embedding_message_doc = models . ForeignKey ( EmbeddingDocument , on_delete = models . CASCADE , null = True , blank = True ) \n created_at = models . DateTimeField ( auto_now_add = True ) \n plain_message_type = <NUM_LIT> \n hidden_message_type = <NUM_LIT> \n temp_message_type = <NUM_LIT> \n web_search_context_message_type = <NUM_LIT> \n arxiv_context_message_type = <NUM_LIT> \n doc_context_message_type = <NUM_LIT> \n def save ( self , * args , ** kwargs ) : \n super ( ) . save ( * args , ** kwargs ) \n def delete ( self , * args , ** kwargs ) : \n if self . message_type % <NUM_LIT> > <NUM_LIT> : \n pass \n super ( ) . delete ( * args , ** kwargs ) \n class Prompt ( models . Model ) : \n user = models . ForeignKey ( User , on_delete = models . CASCADE ) \n title = models . TextField ( null = True , blank = True ) \n prompt = models . TextField ( ) \n created_at = models . DateTimeField ( auto_now_add = True ) \n updated_at = models . DateTimeField ( auto_now = True ) \n class Setting ( models . Model ) : \n name = models . CharField ( max_length = <NUM_LIT> ) \n value = models . CharField ( max_length = <NUM_LIT> )"}, {"input": "import re \n from django . contrib . auth . models import AnonymousUser \n from django . db . models import F \n from rest_framework . permissions import BasePermission \n from dvadmin . system . models import ApiWhiteList , RoleMenuButtonPermission \n def ValidationApi ( reqApi , validApi ) : \n if validApi is not None : \n valid_api = validApi . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n matchObj = re . match ( valid_api , reqApi , re . M | re . I ) \n if matchObj : \n return True \n else : \n return False \n else : \n return False \n class AnonymousUserPermission ( BasePermission ) : \n def has_permission ( self , request , view ) : \n if isinstance ( request . user , AnonymousUser ) : \n return False \n return True \n def ReUUID ( api ) : \n pattern = re . compile ( r'<STR_LIT>' ) \n m = pattern . search ( api ) \n if m : \n res = api . replace ( m . group ( <NUM_LIT> ) , \"<STR_LIT>\" ) \n return res \n else : \n return None \n class CustomPermission ( BasePermission ) :", "output": "def has_permission ( self , request , view ) : \n if isinstance ( request . user , AnonymousUser ) : \n return False \n if request . user . is_superuser : \n return True \n else : \n api = request . path \n method = request . method \n methodList = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n method = methodList . index ( method ) \n api_white_list = ApiWhiteList . objects . values ( permission__api = F ( '<STR_LIT>' ) , permission__method = F ( '<STR_LIT>' ) ) \n api_white_list = [ \n str ( item . get ( '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) ) + \"<STR_LIT>\" + str ( \n item . get ( '<STR_LIT>' ) ) + '<STR_LIT>' for item in api_white_list if item . get ( '<STR_LIT>' ) ] \n if not hasattr ( request . user , \"<STR_LIT>\" ) : \n return False \n role_id_list = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n userApiList = RoleMenuButtonPermission . objects . filter ( role__in = role_id_list ) . values ( permission__api = F ( '<STR_LIT>' ) , permission__method = F ( '<STR_LIT>' ) ) \n ApiList = [ \n str ( item . get ( '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) ) + \"<STR_LIT>\" + str ( \n item . get ( '<STR_LIT>' ) ) + '<STR_LIT>' for item in userApiList if item . get ( '<STR_LIT>' ) ] \n new_api_ist = api_white_list + ApiList \n new_api = api + \"<STR_LIT>\" + str ( method ) \n for item in new_api_ist : \n matchObj = re . match ( item , new_api , re . M | re . I ) \n if matchObj is None : \n continue \n else : \n return True \n else : \n return False"}, {"input": "from ultralytics import YOLO \n import yaml \n config_file = open ( '<STR_LIT>' ) \n config = yaml . load ( config_file , yaml . loader . SafeLoader ) \n config_file . close ( ) \n model_name = config [ '<STR_LIT>' ]", "output": "weights = config [ '<STR_LIT>' ] \n dataset = config [ '<STR_LIT>' ] \n model = YOLO ( model = model_name ) . load ( weights = weights ) \n model . train ( data = dataset , epochs = <NUM_LIT> , imgsz = <NUM_LIT> )"}, {"input": "from functools import wraps \n from typing import Any , Literal , cast \n from django . conf import settings \n from django . test import override_settings \n from wagtail_ai . ai import AIBackendSettingsDict , TextSplittingSettingsDict \n DEFAULT_ALIAS = \"<STR_LIT>\" \n def custom_ai_backend_settings ( \n * , alias : str = DEFAULT_ALIAS , new_value : AIBackendSettingsDict \n ) : \n def decorator ( func ) : \n @ wraps ( func ) \n def inner ( * args , ** kwargs ) : \n value = { ** settings . WAGTAIL_AI } \n value [ \"<STR_LIT>\" ] [ alias ] = new_value \n return override_settings ( WAGTAIL_AI = value ) ( func ) ( * args , ** kwargs ) \n return inner \n return decorator", "output": "def custom_ai_backend_specific_settings ( \n * , \n settings_key : Literal [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n new_value : Any , \n alias : str = DEFAULT_ALIAS , \n ) : \n def decorator ( func ) : \n @ wraps ( func ) \n def inner ( * args , ** kwargs ) : \n backend_settings = cast ( \n AIBackendSettingsDict , \n { \n ** settings . WAGTAIL_AI [ \"<STR_LIT>\" ] [ alias ] , \n } , \n ) \n backend_settings [ settings_key ] = new_value \n return custom_ai_backend_settings ( new_value = backend_settings , alias = alias ) ( \n func \n ) ( * args , ** kwargs ) \n return inner \n return decorator \n def custom_text_splitting ( new_settings : TextSplittingSettingsDict ) : \n return custom_ai_backend_specific_settings ( \n settings_key = \"<STR_LIT>\" , new_value = new_settings , alias = \"<STR_LIT>\" \n ) \n def custom_ai_backend_class ( new_path : str ) : \n return custom_ai_backend_specific_settings ( settings_key = \"<STR_LIT>\" , new_value = new_path )"}, {"input": "from django . db import migrations \n class Migration ( migrations . Migration ) :", "output": "dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \"<STR_LIT>\" : [ \"<STR_LIT>\" ] } , \n ) , \n ]"}, {"input": "import os \n from application . settings import BASE_DIR \n DATABASE_ENGINE = \"<STR_LIT>\" \n DATABASE_NAME = '<STR_LIT>' \n DATABASE_HOST = '<STR_LIT>' \n DATABASE_PORT = <NUM_LIT> \n DATABASE_USER = \"<STR_LIT>\"", "output": "DATABASE_PASSWORD = \"<STR_LIT>\" \n TABLE_PREFIX = \"<STR_LIT>\" \n REDIS_PASSWORD = '<STR_LIT>' \n REDIS_HOST = '<STR_LIT>' \n REDIS_URL = f'<STR_LIT>' \n DEBUG = True \n ENABLE_LOGIN_ANALYSIS_LOG = True \n LOGIN_NO_CAPTCHA_AUTH = True \n ALLOWED_HOSTS = [ \"<STR_LIT>\" ] \n COLUMN_EXCLUDE_APPS = [ ]"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . DateTimeField ( auto_now_add = True , verbose_name = \"<STR_LIT>\" ) , \n ) ,", "output": "( \n \"<STR_LIT>\" , \n models . DateTimeField ( auto_now = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ] , \n options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . DateTimeField ( auto_now_add = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . DateTimeField ( auto_now_add = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . DateTimeField ( \n blank = True , null = True , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . BooleanField ( \n default = False , \n help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( max_length = <NUM_LIT> , unique = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . BooleanField ( default = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . TextField ( blank = True , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . BooleanField ( default = True , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . ManyToManyField ( \n blank = True , \n help_text = \"<STR_LIT>\" , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ManyToManyField ( \n blank = True , \n help_text = \"<STR_LIT>\" , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ) , \n } , \n ) , \n ]"}, {"input": "import uuid \n import pytest \n from django . urls import reverse \n from wagtail_ai . views import PromptEditForm , prompt_viewset \n pytestmark = pytest . mark . django_db \n def test_prompt_model_admin_form_validation ( test_prompt_values ) : \n form_data = { \n \"<STR_LIT>\" : test_prompt_values [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : test_prompt_values [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : test_prompt_values [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n form = PromptEditForm ( data = form_data ) \n assert not form . is_valid ( ) \n assert \"<STR_LIT>\" in form . errors \n def test_prompt_model_admin_viewset_list_view ( admin_client , setup_prompt_object ) : \n url = reverse ( f\"<STR_LIT>\" ) \n response = admin_client . get ( url ) \n assert response . status_code == <NUM_LIT> \n assert setup_prompt_object . label in str ( response . content ) \n def test_prompt_model_admin_viewset_edit_view ( admin_client , setup_prompt_object ) : \n url = reverse ( f\"<STR_LIT>\" , args = [ setup_prompt_object . id ] ) \n response = admin_client . get ( url ) \n assert response . status_code == <NUM_LIT> \n assert setup_prompt_object . label in str ( response . content ) \n def test_process_view_get_request ( admin_client ) : \n url = reverse ( \"<STR_LIT>\" ) \n response = admin_client . get ( url ) \n assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n \"<STR_LIT>\" \n } \n def test_process_view_post_without_text ( admin_client ) : \n url = reverse ( \"<STR_LIT>\" ) \n response = admin_client . post ( url , data = { } ) \n assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n \"<STR_LIT>\" \n } \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , [ None , \"<STR_LIT>\" , str ( uuid . uuid1 ( ) ) , str ( uuid . uuid4 ( ) ) ] \n ) \n def test_process_view_with_bad_prompt_id ( admin_client , prompt ) : \n url = reverse ( \"<STR_LIT>\" ) \n data = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n if prompt is not None : \n data [ \"<STR_LIT>\" ] = prompt \n response = admin_client . post ( url , data = data )", "output": "assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \"<STR_LIT>\" : \"<STR_LIT>\" } \n def test_process_view_with_correct_prompt ( admin_client , setup_prompt_object ) : \n url = reverse ( \"<STR_LIT>\" ) \n response = admin_client . post ( \n url , data = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : str ( setup_prompt_object . uuid ) } \n ) \n assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \"<STR_LIT>\" : \"<STR_LIT>\" }"}, {"input": "import json \n from asgiref . sync import async_to_sync \n from channels . layers import get_channel_layer \n from django_restql . fields import DynamicSerializerMethodField \n from rest_framework import serializers \n from rest_framework . decorators import action , permission_classes \n from rest_framework . permissions import IsAuthenticated , AllowAny \n from dvadmin . system . models import MessageCenter , Users , MessageCenterTargetUser \n from dvadmin . utils . json_response import SuccessResponse , DetailResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class MessageCenterSerializer ( CustomModelSerializer ) : \n role_info = DynamicSerializerMethodField ( ) \n user_info = DynamicSerializerMethodField ( ) \n dept_info = DynamicSerializerMethodField ( ) \n is_read = serializers . BooleanField ( read_only = True , source = '<STR_LIT>' ) \n def get_role_info ( self , instance , parsed_query ) : \n roles = instance . target_role . all ( ) \n from dvadmin . system . views . role import RoleSerializer \n serializer = RoleSerializer ( \n roles , \n many = True , \n parsed_query = parsed_query \n ) \n return serializer . data \n def get_user_info ( self , instance , parsed_query ) : \n users = instance . target_user . all ( ) \n from dvadmin . system . views . user import UserSerializer \n serializer = UserSerializer ( \n users , \n many = True , \n parsed_query = parsed_query \n ) \n return serializer . data \n def get_dept_info ( self , instance , parsed_query ) : \n dept = instance . target_dept . all ( ) \n from dvadmin . system . views . dept import DeptSerializer \n serializer = DeptSerializer ( \n dept , \n many = True , \n parsed_query = parsed_query \n ) \n return serializer . data \n class Meta : \n model = MessageCenter \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class MessageCenterTargetUserSerializer ( CustomModelSerializer ) : \n class Meta : \n model = MessageCenterTargetUser \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class MessageCenterTargetUserListSerializer ( CustomModelSerializer ) : \n is_read = serializers . SerializerMethodField ( ) \n def get_is_read ( self , instance ) : \n user_id = self . request . user . id \n message_center_id = instance . id \n queryset = MessageCenterTargetUser . objects . filter ( messagecenter__id = message_center_id , users_id = user_id ) . first ( ) \n if queryset : \n return queryset . is_read \n return False \n class Meta : \n model = MessageCenter \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n def websocket_push ( user_id , message ) : \n username = \"<STR_LIT>\" + str ( user_id ) \n channel_layer = get_channel_layer ( ) \n async_to_sync ( channel_layer . group_send ) ( \n username , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : message \n } \n ) \n class MessageCenterCreateSerializer ( CustomModelSerializer ) : \n def save ( self , ** kwargs ) : \n data = super ( ) . save ( ** kwargs ) \n initial_data = self . initial_data \n target_type = initial_data . get ( '<STR_LIT>' ) \n users = initial_data . get ( '<STR_LIT>' , [ ] ) \n if target_type in [ <NUM_LIT> ] : \n target_role = initial_data . get ( '<STR_LIT>' , [ ] ) \n users = Users . objects . filter ( role__id__in = target_role ) . values_list ( '<STR_LIT>' , flat = True ) \n if target_type in [ <NUM_LIT> ] :", "output": "target_dept = initial_data . get ( '<STR_LIT>' , [ ] ) \n users = Users . objects . filter ( dept__id__in = target_dept ) . values_list ( '<STR_LIT>' , flat = True ) \n if target_type in [ <NUM_LIT> ] : \n users = Users . objects . values_list ( '<STR_LIT>' , flat = True ) \n targetuser_data = [ ] \n for user in users : \n targetuser_data . append ( { \n \"<STR_LIT>\" : data . id , \n \"<STR_LIT>\" : user \n } ) \n targetuser_instance = MessageCenterTargetUserSerializer ( data = targetuser_data , many = True , request = self . request ) \n targetuser_instance . is_valid ( raise_exception = True ) \n targetuser_instance . save ( ) \n for user in users : \n unread_count = MessageCenterTargetUser . objects . filter ( users__id = user , is_read = False ) . count ( ) \n websocket_push ( user , message = { \"<STR_LIT>\" : '<STR_LIT>' , \"<STR_LIT>\" : '<STR_LIT>' , \n \"<STR_LIT>\" : '<STR_LIT>' , \"<STR_LIT>\" : unread_count } ) \n return data \n class Meta : \n model = MessageCenter \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class MessageCenterViewSet ( CustomModelViewSet ) : \n queryset = MessageCenter . objects . order_by ( '<STR_LIT>' ) \n serializer_class = MessageCenterSerializer \n create_serializer_class = MessageCenterCreateSerializer \n extra_filter_backends = [ ] \n def get_queryset ( self ) : \n if self . action == '<STR_LIT>' : \n return MessageCenter . objects . filter ( creator = self . request . user . id ) . all ( ) \n return MessageCenter . objects . all ( ) \n def retrieve ( self , request , * args , ** kwargs ) : \n pk = kwargs . get ( '<STR_LIT>' ) \n user_id = self . request . user . id \n queryset = MessageCenterTargetUser . objects . filter ( users__id = user_id , messagecenter__id = pk ) . first ( ) \n if queryset : \n queryset . is_read = True \n queryset . save ( ) \n instance = self . get_object ( ) \n serializer = self . get_serializer ( instance ) \n unread_count = MessageCenterTargetUser . objects . filter ( users__id = user_id , is_read = False ) . count ( ) \n websocket_push ( user_id , message = { \"<STR_LIT>\" : '<STR_LIT>' , \"<STR_LIT>\" : '<STR_LIT>' , \n \"<STR_LIT>\" : '<STR_LIT>' , \"<STR_LIT>\" : unread_count } ) \n return DetailResponse ( data = serializer . data , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def get_self_receive ( self , request ) : \n self_user_id = self . request . user . id \n queryset = MessageCenter . objects . filter ( target_user__id = self_user_id ) \n page = self . paginate_queryset ( queryset ) \n if page is not None : \n serializer = MessageCenterTargetUserListSerializer ( page , many = True , request = request ) \n return self . get_paginated_response ( serializer . data ) \n serializer = MessageCenterTargetUserListSerializer ( queryset , many = True , request = request ) \n return SuccessResponse ( data = serializer . data , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def get_newest_msg ( self , request ) : \n self_user_id = self . request . user . id \n queryset = MessageCenterTargetUser . objects . filter ( users__id = self_user_id ) . order_by ( '<STR_LIT>' ) . last ( ) \n data = None \n if queryset : \n serializer = MessageCenterTargetUserListSerializer ( queryset . messagecenter , many = False , request = request ) \n data = serializer . data \n return DetailResponse ( data = data , msg = \"<STR_LIT>\" )"}, {"input": "import logging \n import textwrap \n from pathlib import Path \n from django . conf import settings \n from langchain import OpenAI \n from llama_index import GPTSimpleVectorIndex , LLMPredictor , ServiceContext \n from delphic . indexes . models import Collection \n logger = logging . getLogger ( __name__ ) \n def format_source ( source ) : \n formatted_source = ( \n f\"<STR_LIT>\" \n ) \n return formatted_source \n async def load_collection_model ( collection_id : str | int ) -> GPTSimpleVectorIndex : \n collection = await Collection . objects . aget ( id = collection_id ) \n logger . info ( f\"<STR_LIT>\" )", "output": "if collection . model . name : \n logger . info ( \"<STR_LIT>\" ) \n cache_dir = Path ( settings . BASE_DIR ) / \"<STR_LIT>\" \n cache_file_path = cache_dir / f\"<STR_LIT>\" \n if not cache_file_path . exists ( ) : \n cache_dir . mkdir ( parents = True , exist_ok = True ) \n with collection . model . open ( \"<STR_LIT>\" ) as model_file : \n with cache_file_path . open ( \"<STR_LIT>\" , encoding = \"<STR_LIT>\" ) as cache_file : \n cache_file . write ( model_file . read ( ) . decode ( \"<STR_LIT>\" ) ) \n logger . info ( \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n ) \n llm_predictor = LLMPredictor ( \n llm = OpenAI ( temperature = <NUM_LIT> , model_name = \"<STR_LIT>\" , max_tokens = <NUM_LIT> ) \n ) \n service_context = ServiceContext . from_defaults ( llm_predictor = llm_predictor ) \n logger . info ( \"<STR_LIT>\" ) \n index = GPTSimpleVectorIndex . load_from_disk ( \n cache_file_path , service_context = service_context \n ) \n logger . info ( \n \"<STR_LIT>\" \n ) \n else : \n logger . error ( \n f\"<STR_LIT>\" \n ) \n raise ValueError ( \"<STR_LIT>\" ) \n return index \n async def query_collection ( collection_id : str | int , query_str : str ) -> str : \n try : \n index = await load_collection_model ( collection_id ) \n response = index . query ( query_str ) \n markdown_response = f\"<STR_LIT>\" \n if response . source_nodes : \n markdown_sources = f\"<STR_LIT>\" \n else : \n markdown_sources = \"<STR_LIT>\" \n formatted_response = f\"<STR_LIT>\" \n except ValueError : \n formatted_response = \"<STR_LIT>\" \n return formatted_response"}, {"input": "import django . core . serializers . json \n import django . db . models . deletion \n import django . utils . timezone \n import model_utils . fields \n from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . JSONField ( \n editable = False , \n encoder = django . core . serializers . json . DjangoJSONEncoder , \n max_length = <NUM_LIT> , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( editable = False , max_length = <NUM_LIT> , null = True ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n choices = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] , \n default = \"<STR_LIT>\" , \n editable = False , \n max_length = <NUM_LIT> , \n ) ,", "output": ") , \n ( \n \"<STR_LIT>\" , \n model_utils . fields . AutoCreatedField ( \n default = django . utils . timezone . now , editable = False \n ) , \n ) , \n ( \"<STR_LIT>\" , models . URLField ( editable = False ) ) , \n ( \"<STR_LIT>\" , models . CharField ( editable = False , max_length = <NUM_LIT> , null = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . ForeignKey ( \n editable = False , \n null = True , \n on_delete = django . db . models . deletion . SET_NULL , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n ) , \n ]"}, {"input": "from ninja_crud . testing . core . components import PathParameters , Payloads \n from ninja_crud . testing . views import ( \n CreateModelViewTest , \n DeleteModelViewTest , \n ListModelViewTest , \n ReadModelViewTest , \n UpdateModelViewTest , \n ) \n from ninja_crud . testing . viewsets import ModelViewSetTestCase \n from tests . test_app . tests . base_test_case import BaseTestCase \n from tests . test_app . views . user_views import UserViewSet \n class TestUserViewSet ( ModelViewSetTestCase , BaseTestCase ) : \n model_viewset_class = UserViewSet \n base_path = \"<STR_LIT>\" \n def get_path_parameters ( self ) : \n return PathParameters ( ok = { \"<STR_LIT>\" : self . user_1 . id } ) \n def get_user_payloads ( self ) : \n return Payloads ( \n ok = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ self . group_1 . id , self . group_2 . id ] , \n } , \n bad_request = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n conflict = { \n \"<STR_LIT>\" : self . user_2 . username , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) \n test_list_users = ListModelViewTest ( ) \n test_create_user = CreateModelViewTest ( payloads = get_user_payloads ) \n test_read_user = ReadModelViewTest ( path_parameters = get_path_parameters ) \n test_update_user = UpdateModelViewTest ( \n path_parameters = get_path_parameters , payloads = get_user_payloads \n ) \n test_delete_user = DeleteModelViewTest ( path_parameters = get_path_parameters )"}, {"input": "import logging \n import os \n import tempfile \n import uuid \n from pathlib import Path \n from django . conf import settings \n from django . core . files import File \n from langchain import OpenAI \n from llama_index import ( \n GPTSimpleVectorIndex , \n LLMPredictor , \n ServiceContext , \n download_loader ,", "output": ") \n from config import celery_app \n from delphic . indexes . models import Collection , CollectionStatus \n logger = logging . getLogger ( __name__ ) \n @ celery_app . task \n def create_index ( collection_id ) : \n try : \n collection = Collection . objects . prefetch_related ( \"<STR_LIT>\" ) . get ( \n id = collection_id \n ) \n collection . status = CollectionStatus . RUNNING \n collection . save ( ) \n try : \n with tempfile . TemporaryDirectory ( ) as tempdir : \n tempdir_path = Path ( tempdir ) \n for document in collection . documents . all ( ) : \n with document . file . open ( \"<STR_LIT>\" ) as f : \n file_data = f . read ( ) \n temp_file_path = tempdir_path / document . file . name \n temp_file_path . parent . mkdir ( parents = True , exist_ok = True ) \n with temp_file_path . open ( \"<STR_LIT>\" ) as f : \n f . write ( file_data ) \n SimpleDirectoryReader = download_loader ( \"<STR_LIT>\" ) \n loader = SimpleDirectoryReader ( \n tempdir_path , recursive = True , exclude_hidden = False \n ) \n documents = loader . load_data ( ) \n llm_predictor = LLMPredictor ( \n llm = OpenAI ( \n temperature = <NUM_LIT> , \n model_name = settings . MODEL_NAME , \n max_tokens = settings . MAX_TOKENS , \n ) \n ) \n service_context = ServiceContext . from_defaults ( \n llm_predictor = llm_predictor \n ) \n index = GPTSimpleVectorIndex . from_documents ( \n documents , service_context = service_context \n ) \n index_str = index . save_to_string ( ) \n with tempfile . NamedTemporaryFile ( delete = False ) as f : \n f . write ( index_str . encode ( ) ) \n f . flush ( ) \n f . seek ( <NUM_LIT> ) \n collection . model . save ( f\"<STR_LIT>\" , File ( f ) ) \n collection . status = CollectionStatus . COMPLETE \n collection . save ( ) \n os . unlink ( f . name ) \n collection . processing = False \n collection . save ( ) \n return True \n except Exception as e : \n logger . error ( f\"<STR_LIT>\" ) \n collection . status = CollectionStatus . ERROR \n collection . save ( ) \n return False \n except Exception as e : \n logger . error ( f\"<STR_LIT>\" ) \n return False"}, {"input": "import django . core . validators \n import django . db . models . deletion \n from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" ,", "output": ") , \n ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True , null = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n help_text = \"<STR_LIT>\" , max_length = <NUM_LIT> \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . SlugField ( \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n unique = True , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : False , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True , null = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . OneToOneField ( \n help_text = \"<STR_LIT>\" , \n on_delete = django . db . models . deletion . CASCADE , \n primary_key = True , \n serialize = False , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n choices = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] , \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n help_text = \"<STR_LIT>\" , max_length = <NUM_LIT> \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . PositiveSmallIntegerField ( \n help_text = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . PositiveSmallIntegerField ( \n default = <NUM_LIT> , \n help_text = \"<STR_LIT>\" , \n validators = [ \n django . core . validators . MaxValueValidator ( <NUM_LIT> ) , \n django . core . validators . MinValueValidator ( <NUM_LIT> ) , \n ] , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . PositiveSmallIntegerField ( \n default = <NUM_LIT> , \n help_text = \"<STR_LIT>\" , \n validators = [ \n django . core . validators . MaxValueValidator ( <NUM_LIT> ) , \n django . core . validators . MinValueValidator ( <NUM_LIT> ) , \n ] , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . PositiveSmallIntegerField ( \n default = <NUM_LIT> , \n help_text = \"<STR_LIT>\" , \n validators = [ \n django . core . validators . MaxValueValidator ( <NUM_LIT> ) , \n django . core . validators . MinValueValidator ( <NUM_LIT> ) , \n ] , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : False , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True , null = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . DateField ( \n help_text = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . PositiveSmallIntegerField ( \n help_text = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . TextField ( help_text = \"<STR_LIT>\" ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ForeignKey ( \n help_text = \"<STR_LIT>\" , \n on_delete = django . db . models . deletion . CASCADE , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : False , \n } , \n ) , \n ]"}, {"input": "from django . conf import settings \n from django . conf . urls . static import static \n from django . contrib import admin \n from django . contrib . staticfiles . urls import staticfiles_urlpatterns \n from django . urls import include , path \n from django . views import defaults as default_views \n from django . views . generic import TemplateView \n from config . api . endpoints import api \n urlpatterns = [ \n path ( \"<STR_LIT>\" , api . urls ) , \n path ( \"<STR_LIT>\" , TemplateView . as_view ( template_name = \"<STR_LIT>\" ) , name = \"<STR_LIT>\" ) , \n path ( settings . ADMIN_URL , admin . site . urls ) , \n ] + static ( settings . MEDIA_URL , document_root = settings . MEDIA_ROOT ) \n if settings . DEBUG : \n urlpatterns += staticfiles_urlpatterns ( ) \n if settings . DEBUG : \n urlpatterns += [ \n path ( \n \"<STR_LIT>\" , \n default_views . bad_request , \n kwargs = { \"<STR_LIT>\" : Exception ( \"<STR_LIT>\" ) } , \n ) , \n path ( \n \"<STR_LIT>\" , \n default_views . permission_denied , \n kwargs = { \"<STR_LIT>\" : Exception ( \"<STR_LIT>\" ) } , \n ) , \n path (", "output": "\"<STR_LIT>\" , \n default_views . page_not_found , \n kwargs = { \"<STR_LIT>\" : Exception ( \"<STR_LIT>\" ) } , \n ) , \n path ( \"<STR_LIT>\" , default_views . server_error ) , \n ] \n if \"<STR_LIT>\" in settings . INSTALLED_APPS : \n import debug_toolbar \n urlpatterns = [ path ( \"<STR_LIT>\" , include ( debug_toolbar . urls ) ) ] + urlpatterns"}, {"input": "import requests , time , datetime , re \n from utils . general import headers \n from bs4 import BeautifulSoup as bs \n headers = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n def get_desc ( url_part ) : \n return '<STR_LIT>' \n try : \n url = '<STR_LIT>' + url_part \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n if soup . select ( '<STR_LIT>' ) : \n desc = soup . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n else : \n desc = soup . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text + soup . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n except Exception as e : \n desc = '<STR_LIT>' \n return desc . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n def get_morning_lis ( url , today ) : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n lis = soup . select ( '<STR_LIT>' ) \n return lis \n def get_token ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n res_json = res . json ( ) \n if res_json [ <NUM_LIT> ] : \n success = <NUM_LIT> \n else : \n success = <NUM_LIT> \n token = res_json [ <NUM_LIT> ] \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : token , \n } \n return ret \n def get_epgs_tvmao ( channel , channel_id , dt , func_arg ) : \n afternoon_url = '<STR_LIT>' \n time . sleep ( <NUM_LIT> ) \n sleep_time = <NUM_LIT> \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n ban = <NUM_LIT> \n today_dt = datetime . datetime . now ( ) \n need_weekday = dt . weekday ( ) + <NUM_LIT> \n epg_url_part = '<STR_LIT>' \n url = '<STR_LIT>' % ( epg_url_part , channel_id , need_weekday ) \n try : \n nn , lis = <NUM_LIT> , [ ] \n while len ( lis ) == <NUM_LIT> : \n today = <NUM_LIT> if today_dt . date ( ) == dt else <NUM_LIT> \n lis = get_morning_lis ( url , today ) \n time . sleep ( <NUM_LIT> ) \n nn += <NUM_LIT> \n if nn > <NUM_LIT> : \n break \n time . sleep ( <NUM_LIT> ) \n except Exception as e : \n msg = '<STR_LIT>' % ( e ) \n success = <NUM_LIT> \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n } \n return ret \n for li in lis : \n if \"<STR_LIT>\" in li . attrs : \n continue \n title = li . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n starttime_str = li . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text . strip ( ) \n if starttime_str == '<STR_LIT>' or '<STR_LIT>' in starttime_str . strip ( ) : \n starttime = today_dt \n else : \n starttime = datetime . datetime . combine ( dt , datetime . time ( int ( starttime_str [ : <NUM_LIT> ] ) , int ( starttime_str [ - <NUM_LIT> : ] ) ) ) \n href = li . a [ '<STR_LIT>' ] if '<STR_LIT>' in str ( li . a ) else '<STR_LIT>' \n desc = get_desc ( href ) \n url = '<STR_LIT>' + href . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg ) \n try : \n tccc = channel_id . split ( '<STR_LIT>' ) \n if len ( tccc ) == <NUM_LIT> : \n tc , cc = tccc \n else : \n tc = '<STR_LIT>' \n cc = '<STR_LIT>' . join ( tccc [ <NUM_LIT> : ] ) \n data = { \n '<STR_LIT>' : tc , \n '<STR_LIT>' : cc , \n '<STR_LIT>' : need_weekday , \n '<STR_LIT>' : get_token ( ) [ '<STR_LIT>' ] , \n } \n res = requests . post ( afternoon_url , headers = headers , data = data , timeout = <NUM_LIT> ) \n lss = res . json ( ) [ <NUM_LIT> ] \n if res . json ( ) [ <NUM_LIT> ] == - <NUM_LIT> : \n msg = '<STR_LIT>' % sleep_time \n time . sleep ( sleep_time ) \n success = <NUM_LIT> \n ban = <NUM_LIT> \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : ban , \n } \n return ret \n if isinstance ( lss , str ) : \n soup = bs ( lss , '<STR_LIT>' ) \n lis1 = soup . select ( '<STR_LIT>' ) \n for tr in lis1 : \n if not tr . find ( '<STR_LIT>' ) : \n continue \n spans = tr . select ( '<STR_LIT>' ) \n if len ( spans ) > <NUM_LIT> : \n if '<STR_LIT>' in spans [ <NUM_LIT> ] . text : \n title = spans [ <NUM_LIT> ] . text \n else : \n title = spans [ <NUM_LIT> ] . text \n starttime_str = spans [ <NUM_LIT> ] . text . replace ( '<STR_LIT>' , '<STR_LIT>' ) . strip ( ) \n starttime = datetime . datetime . combine ( dt , \n datetime . time ( int ( starttime_str [ : <NUM_LIT> ] ) , int ( starttime_str [ - <NUM_LIT> : ] ) ) ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : channel . super_id , \n } \n epgs . append ( epg ) \n else : \n for tr in lss : \n tr1 = bs ( tr [ '<STR_LIT>' ] , '<STR_LIT>' ) \n title = tr1 . text \n starttime_str = tr [ '<STR_LIT>' ] \n starttime = datetime . datetime . combine ( dt , \n datetime . time ( int ( starttime_str [ : <NUM_LIT> ] ) , int ( starttime_str [ - <NUM_LIT> : ] ) ) ) \n href = tr1 . a [ '<STR_LIT>' ] if '<STR_LIT>' in str ( tr1 . a ) else '<STR_LIT>'", "output": "program_url = '<STR_LIT>' + href . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n desc = get_desc ( href ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n msg = '<STR_LIT>' % e \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : '<STR_LIT>' \n } \n return ret \n def get_epgs_tvmao2 ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n desc = '<STR_LIT>' \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n ban = <NUM_LIT> \n now_date = datetime . datetime . now ( ) . date ( ) \n need_date = dt \n delta = need_date - now_date \n now_weekday = now_date . weekday ( ) \n need_weekday = now_weekday + delta . days + <NUM_LIT> \n id_split = channel_id . split ( '<STR_LIT>' ) \n if len ( id_split ) == <NUM_LIT> : \n id = id_split [ <NUM_LIT> ] \n elif len ( id_split ) == <NUM_LIT> : \n id = '<STR_LIT>' . join ( id_split [ <NUM_LIT> : <NUM_LIT> ] ) \n else : \n id = channel_id \n url = \"<STR_LIT>\" % ( id , need_weekday ) \n try : \n res = requests . get ( url , headers = headers ) \n res_j = res . json ( ) \n datas = res_j [ <NUM_LIT> ] [ '<STR_LIT>' ] \n for data in datas : \n title = data [ '<STR_LIT>' ] \n starttime_str = data [ '<STR_LIT>' ] \n starttime = datetime . datetime . combine ( dt , \n datetime . time ( int ( starttime_str [ : <NUM_LIT> ] ) , int ( starttime_str [ - <NUM_LIT> : ] ) ) ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n msg = '<STR_LIT>' % e \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : '<STR_LIT>' \n } \n return ret \n def get_channels_tvmao ( ) : \n url_sort = '<STR_LIT>' \n res = requests . get ( url_sort , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n provinces = { } \n big_sorts = { } \n channels = [ ] \n provinces_more = soup . select ( '<STR_LIT>' ) \n big_sorts_more = soup . select ( '<STR_LIT>' ) \n for province_more in provinces_more : \n province = province_more . text . strip ( ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n province_id = province_more . a [ '<STR_LIT>' ] . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n province = { \n province : province_id , \n } \n provinces . update ( province ) \n for big_sort_more in big_sorts_more : \n sort_name = big_sort_more . text . strip ( ) \n url = big_sort_more . a [ '<STR_LIT>' ] \n sort_id = url . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n if sort_name in provinces or sort_name == '<STR_LIT>' : \n continue \n big_sorts . update ( { sort_name : sort_id } ) \n provinces . update ( big_sorts ) \n sorts = provinces \n n = <NUM_LIT> \n for sort_name in sorts : \n url = '<STR_LIT>' % sorts [ sort_name ] \n time . sleep ( <NUM_LIT> ) \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n channel_trs = soup . select ( '<STR_LIT>' ) \n n += <NUM_LIT> \n for tr in channel_trs : \n tr1 = tr . td . a \n name = tr1 [ '<STR_LIT>' ] \n href = tr1 [ '<STR_LIT>' ] \n id = href . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n id = re . sub ( '<STR_LIT>' , '<STR_LIT>' , id ) \n res1 = tr1 [ '<STR_LIT>' ] \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : '<STR_LIT>' % id , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : sort_name , \n '<STR_LIT>' : res1 , \n } \n channels . append ( channel ) \n print ( '<STR_LIT>' % ( n , sort_name , sorts [ sort_name ] , len ( channel_trs ) ) ) \n return channels"}, {"input": "from unittest import TestCase \n from langconv import * \n class ConvertMapTest ( TestCase ) : \n def test_map ( self ) : \n mapping = { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } \n cm = ConvertMap ( '<STR_LIT>' , mapping ) \n self . assertEqual ( len ( cm ) , <NUM_LIT> ) \n self . failUnless ( '<STR_LIT>' in cm ) \n self . failUnless ( '<STR_LIT>' in cm ) \n self . failIf ( '<STR_LIT>' in cm ) \n self . assertEqual ( cm [ '<STR_LIT>' ] . data , ( True , True , '<STR_LIT>' ) ) \n self . assertEqual ( cm [ '<STR_LIT>' ] . data , ( True , False , '<STR_LIT>' ) ) \n self . assertEqual ( cm [ '<STR_LIT>' ] . data , ( False , True , '<STR_LIT>' ) ) \n self . assertEqual ( cm [ '<STR_LIT>' ] . data , ( False , True , '<STR_LIT>' ) ) \n self . assertEqual ( cm [ '<STR_LIT>' ] . data , ( True , False , '<STR_LIT>' ) ) \n self . assertEqual ( cm [ '<STR_LIT>' ] . data , ( True , False , '<STR_LIT>' ) ) \n class ConverterModelTest ( TestCase ) : \n def test_1 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_2 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_3 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_4 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_5 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' )", "output": "c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_6 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_7 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_8 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_9 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . end ( ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n def test_10 ( self ) : \n registery ( '<STR_LIT>' , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) \n c = Converter ( '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n c . feed ( '<STR_LIT>' ) \n c . end ( ) \n self . assertEqual ( c . get_result ( ) , '<STR_LIT>' ) \n class ConverterTest ( TestCase ) : \n def assertConvert ( self , name , string , converted ) : \n c = Converter ( name ) \n new = c . convert ( string ) \n assert new == converted , ( \n \"<STR_LIT>\" % ( \n repr ( name ) , string , converted , new ) ) . encode ( '<STR_LIT>' ) \n def assertST ( self , trad , simp ) : \n if not py3k : \n trad = trad . decode ( '<STR_LIT>' ) \n simp = simp . decode ( '<STR_LIT>' ) \n self . assertConvert ( '<STR_LIT>' , trad , simp ) \n self . assertConvert ( '<STR_LIT>' , simp , trad ) \n def test_zh1 ( self ) : \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n def test_zh2 ( self ) : \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n def test_zh3 ( self ) : \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n def test_zh4 ( self ) : \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n self . assertST ( '<STR_LIT>' , '<STR_LIT>' ) \n if '<STR_LIT>' == __name__ : \n import unittest \n unittest . main ( )"}, {"input": "import os \n import re \n from datetime import datetime \n import openpyxl \n from django . conf import settings \n from dvadmin . utils . validator import CustomValidationError \n def import_to_data ( file_url , field_data , m2m_fields = None ) : \n file_path_dir = os . path . join ( settings . BASE_DIR , file_url ) \n workbook = openpyxl . load_workbook ( file_path_dir ) \n table = workbook [ workbook . sheetnames [ <NUM_LIT> ] ] \n theader = tuple ( table . values ) [ <NUM_LIT> ] \n is_update = '<STR_LIT>' in theader \n if is_update is False : \n field_data . pop ( '<STR_LIT>' ) \n validation_data_dict = { } \n for key , value in field_data . items ( ) : \n if isinstance ( value , dict ) : \n choices = value . get ( \"<STR_LIT>\" , { } ) \n data_dict = { } \n if choices . get ( \"<STR_LIT>\" ) : \n for k , v in choices . get ( \"<STR_LIT>\" ) . items ( ) : \n data_dict [ k ] = v \n elif choices . get ( \"<STR_LIT>\" ) and choices . get ( \"<STR_LIT>\" ) : \n data_list = choices . get ( \"<STR_LIT>\" ) . values ( choices . get ( \"<STR_LIT>\" ) , \"<STR_LIT>\" ) \n for ele in data_list : \n data_dict [ ele . get ( choices . get ( \"<STR_LIT>\" ) ) ] = ele . get ( \"<STR_LIT>\" ) \n else : \n continue \n validation_data_dict [ key ] = data_dict \n tables = [ ] \n for i , row in enumerate ( range ( table . max_row ) ) : \n if i == <NUM_LIT> : \n continue \n array = { }", "output": "for index , item in enumerate ( field_data . items ( ) ) : \n items = list ( item ) \n key = items [ <NUM_LIT> ] \n values = items [ <NUM_LIT> ] \n value_type = '<STR_LIT>' \n if isinstance ( values , dict ) : \n value_type = values . get ( '<STR_LIT>' , '<STR_LIT>' ) \n cell_value = table . cell ( row = row + <NUM_LIT> , column = index + <NUM_LIT> ) . value \n if cell_value is None or cell_value == '<STR_LIT>' : \n continue \n elif value_type == '<STR_LIT>' : \n print ( <NUM_LIT> , datetime . strptime ( str ( cell_value ) , '<STR_LIT>' ) . date ( ) ) \n try : \n cell_value = datetime . strptime ( str ( cell_value ) , '<STR_LIT>' ) . date ( ) \n except : \n raise CustomValidationError ( '<STR_LIT>' ) \n elif value_type == '<STR_LIT>' : \n cell_value = datetime . strptime ( str ( cell_value ) , '<STR_LIT>' ) \n else : \n if type ( cell_value ) is float and str ( cell_value ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] == \"<STR_LIT>\" : \n cell_value = int ( str ( cell_value ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] ) \n elif type ( cell_value ) is str : \n cell_value = cell_value . strip ( \"<STR_LIT>\" ) \n if key in validation_data_dict : \n array [ key ] = validation_data_dict . get ( key , { } ) . get ( cell_value , None ) \n if key in m2m_fields : \n array [ key ] = list ( \n filter ( \n lambda x : x , \n [ \n validation_data_dict . get ( key , { } ) . get ( value , None ) \n for value in re . split ( r\"<STR_LIT>\" , cell_value ) \n ] , \n ) \n ) \n else : \n array [ key ] = cell_value \n tables . append ( array ) \n return tables"}, {"input": "from django . db import migrations \n from django . db import models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" ,", "output": "models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . EmailField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . ManyToManyField ( to = \"<STR_LIT>\" ) ) , \n ] , \n ) , \n ]"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n def update_message_user ( apps , schema_editor ) : \n Message = apps . get_model ( '<STR_LIT>' , '<STR_LIT>' ) \n Conversation = apps . get_model ( '<STR_LIT>' , '<STR_LIT>' ) \n for message in Message . objects . all ( ) : \n conversation_id = message . conversation_id \n conversation_obj = Conversation . objects . get ( id = conversation_id ) \n user_id = conversation_obj . user_id \n if user_id : \n message . user_id = user_id \n message . save ( ) \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . IntegerField ( default = <NUM_LIT> ) , \n ) , \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . ForeignKey ( default = <NUM_LIT> , on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) , \n preserve_default = False , \n ) , \n migrations . RunPython ( update_message_user ) , \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . BooleanField ( default = False ) , \n ) , \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . BinaryField ( null = True ) ) , \n ( '<STR_LIT>' , models . CharField ( default = '<STR_LIT>' , max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) ) , \n ] , \n ) , \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' ,", "output": "field = models . ForeignKey ( blank = True , null = True , on_delete = django . db . models . deletion . CASCADE , to = '<STR_LIT>' ) , \n ) , \n ]"}, {"input": "import os \n from pathlib import Path \n BASE_DIR = Path ( __file__ ) . resolve ( ) . parent . parent \n if \"<STR_LIT>\" in os . environ : \n CSRF_TRUSTED_ORIGINS = [ os . environ [ \"<STR_LIT>\" ] ] \n else : \n CSRF_TRUSTED_ORIGINS = [ \"<STR_LIT>\" ] \n SECURE_CROSS_ORIGIN_OPENER_POLICY = '<STR_LIT>' \n SECRET_KEY = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n ID_SERVER = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n DEBUG = os . environ . get ( \"<STR_LIT>\" , False ) \n DEFAULT_AUTO_FIELD = '<STR_LIT>' \n ALLOWED_HOSTS = [ \"<STR_LIT>\" ] \n AUTH_USER_MODEL = '<STR_LIT>' \n ALLOW_REGISTRATION = os . environ . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) or os . environ . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) == \"<STR_LIT>\" \n DATABASE_TYPE = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n MYSQL_DBNAME = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n MYSQL_HOST = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n MYSQL_USER = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n MYSQL_PASSWORD = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n MYSQL_PORT = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n LANGUAGE_CODE = os . environ . get ( \"<STR_LIT>\" , '<STR_LIT>' ) \n INSTALLED_APPS = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n MIDDLEWARE = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n ROOT_URLCONF = '<STR_LIT>' \n TEMPLATES = [ \n { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : [ ] , \n '<STR_LIT>' : True , \n '<STR_LIT>' : { \n '<STR_LIT>' : [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] , \n } , \n } , \n ] \n WSGI_APPLICATION = '<STR_LIT>' \n DATABASES = { \n '<STR_LIT>' : { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : BASE_DIR / '<STR_LIT>' , \n } \n } \n if DATABASE_TYPE == '<STR_LIT>' and MYSQL_DBNAME != '<STR_LIT>' and MYSQL_USER != '<STR_LIT>' and MYSQL_PASSWORD != '<STR_LIT>' : \n DATABASES = { \n '<STR_LIT>' : { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : MYSQL_DBNAME , \n '<STR_LIT>' : MYSQL_HOST , \n '<STR_LIT>' : MYSQL_USER , \n '<STR_LIT>' : MYSQL_PASSWORD , \n '<STR_LIT>' : MYSQL_PORT , \n '<STR_LIT>' : { '<STR_LIT>' : '<STR_LIT>' } , \n } \n } \n AUTH_PASSWORD_VALIDATORS = [ \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n ] \n TIME_ZONE = '<STR_LIT>' \n USE_I18N = True \n USE_L10N = True \n USE_TZ = False \n STATIC_URL = '<STR_LIT>' \n if DEBUG : \n STATICFILES_DIRS = [ os . path . join ( BASE_DIR , '<STR_LIT>' ) ] \n else : \n STATIC_ROOT = os . path . join ( BASE_DIR , '<STR_LIT>' )", "output": "LANGUAGES = ( \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ) \n LOCALE_PATHS = ( \n os . path . join ( BASE_DIR , '<STR_LIT>' ) , \n )"}, {"input": "from crawl . spiders . cctv import get_epgs_cctv , get_channels_cctv \n from crawl . spiders . tbc import get_epgs_tbc , get_channels_tbc \n from crawl . spiders . tvmao import get_epgs_tvmao2 , get_channels_tvmao \n from crawl . spiders . zhongshu import get_epgs_zhongshu , get_channels_zhongshu \n from crawl . spiders . cabletv import get_epgs_cabletv , get_channels_cabletv \n from crawl . spiders . g4tv import get_epgs_4gtv , get_channels_4gtv \n from crawl . spiders . mod import get_epgs_mod , get_channels_mod \n from crawl . spiders . tvb import get_epgs_tvb , get_channels_tvb \n from crawl . spiders . nowtv import get_epgs_nowtv , get_channels_nowtv \n from crawl . spiders . gdtv import get_epgs_gdtv , get_channels_gdtv \n from crawl . spiders . icable import get_epgs_icable , get_channels_icable \n from crawl . spiders . btv import get_epgs_btv , get_channels_btv \n from crawl . spiders . tvsou import get_epgs_tvsou , get_channels_tvsou \n from crawl . spiders . hks import get_epgs_hks , get_channels_hks \n from crawl . spiders . viu import get_epgs_viu , get_channels_viu \n from crawl . spiders . chuanliu import get_channels_chuanliu , get_epgs_chuanliu \n from crawl . spiders . mytvsuper import get_epgs_mytvsuper , get_channels_mytvsuper \n from crawl . spiders . gxntv import get_epgs_gxntv , get_channels_gxntv \n from utils . general import chuanliu_Authorization \n from crawl . spiders . sdtv import get_epgs_sdtv , get_channels_sdtv \n epg_funcs = { \n '<STR_LIT>' : get_epgs_tvmao2 , \n '<STR_LIT>' : get_epgs_tbc , \n '<STR_LIT>' : get_epgs_cctv , \n '<STR_LIT>' : get_epgs_zhongshu , \n '<STR_LIT>' : get_epgs_cabletv , \n '<STR_LIT>' : get_epgs_tvsou , \n '<STR_LIT>' : get_epgs_4gtv , \n '<STR_LIT>' : get_epgs_mod , \n '<STR_LIT>' : get_epgs_tvb , \n '<STR_LIT>' : get_epgs_nowtv , \n '<STR_LIT>' : get_epgs_icable , \n '<STR_LIT>' : get_epgs_gdtv , \n '<STR_LIT>' : get_epgs_btv , \n '<STR_LIT>' : get_epgs_hks , \n '<STR_LIT>' : get_epgs_viu , \n '<STR_LIT>' : get_epgs_chuanliu , \n '<STR_LIT>' : get_epgs_mytvsuper , \n '<STR_LIT>' : get_epgs_gxntv , \n '<STR_LIT>' : get_epgs_sdtv , \n } \n epg_source = { \n '<STR_LIT>' : get_channels_tvmao , \n '<STR_LIT>' : get_channels_tbc , \n '<STR_LIT>' : get_channels_cctv , \n '<STR_LIT>' : get_channels_zhongshu , \n '<STR_LIT>' : get_channels_cabletv , \n '<STR_LIT>' : get_channels_tvsou , \n '<STR_LIT>' : get_channels_4gtv , \n '<STR_LIT>' : get_channels_mod , \n '<STR_LIT>' : get_channels_tvb , \n '<STR_LIT>' : get_channels_nowtv , \n '<STR_LIT>' : get_channels_icable , \n '<STR_LIT>' : get_channels_gdtv , \n '<STR_LIT>' : get_channels_btv , \n '<STR_LIT>' : get_channels_hks , \n '<STR_LIT>' : get_channels_viu , \n '<STR_LIT>' : get_channels_chuanliu , \n '<STR_LIT>' : get_channels_mytvsuper , \n '<STR_LIT>' : get_channels_gxntv , \n '<STR_LIT>' : get_channels_sdtv , \n } \n func_args = { \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : chuanliu_Authorization , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n } \n def epg_func ( channel , id , dt , func_arg = <NUM_LIT> , source = <NUM_LIT> ) : \n if source : \n source1 = source \n else :", "output": "source1 = channel . source \n func_arg = func_args [ source1 ] \n return epg_funcs [ source1 ] ( channel , id , dt , func_arg ) \n __all__ = [ '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ]"}, {"input": "import importlib \n import subprocess \n from pathlib import Path \n import cappa \n from falco . utils import simple_progress \n from jinja2 import Template \n IMPORT_START_COMMENT = \"<STR_LIT>\" \n IMPORT_END_COMMENT = \"<STR_LIT>\" \n CODE_START_COMMENT = \"<STR_LIT>\" \n CODE_END_COMMENT = \"<STR_LIT>\" \n def render_to_string ( template_content : str , context : dict ) : \n return Template ( template_content ) . render ( ** context ) \n def get_crud_blueprints_path ( ) -> Path : \n package = importlib . util . find_spec ( \"<STR_LIT>\" ) \n if package is None : \n raise cappa . Exit ( \"<STR_LIT>\" , code = <NUM_LIT> ) \n return Path ( package . submodule_search_locations [ <NUM_LIT> ] ) / \"<STR_LIT>\" \n @ simple_progress ( \"<STR_LIT>\" ) \n def run_python_formatters ( filepath : str | Path ) : \n autoflake = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n filepath , \n ] \n black = [ \"<STR_LIT>\" , filepath ] \n isort = [ \"<STR_LIT>\" , filepath ] \n subprocess . run ( autoflake , stdout = subprocess . DEVNULL , stderr = subprocess . DEVNULL , check = False ) \n subprocess . run ( isort , stdout = subprocess . DEVNULL , stderr = subprocess . DEVNULL , check = False ) \n subprocess . run ( black , stdout = subprocess . DEVNULL , stderr = subprocess . DEVNULL , check = False )", "output": "@ simple_progress ( \"<STR_LIT>\" ) \n def run_html_formatters ( filepath : str | Path ) : \n djlint = [ \"<STR_LIT>\" , filepath , \"<STR_LIT>\" ] \n subprocess . run ( djlint , stdout = subprocess . DEVNULL , stderr = subprocess . DEVNULL , check = False ) \n def extract_python_file_templates ( file_content : str ) -> tuple [ str , str ] : \n imports_template = extract_content_from ( file_content , IMPORT_START_COMMENT , IMPORT_END_COMMENT ) \n code_template = extract_content_from ( file_content , CODE_START_COMMENT , CODE_END_COMMENT ) \n return imports_template , code_template \n def extract_content_from ( text : str , start_comment : str , end_comment : str ) : \n start_index = text . find ( start_comment ) + len ( start_comment ) \n end_index = text . find ( end_comment ) \n return text [ start_index : end_index ]"}, {"input": "import torch \n import torch . nn as nn \n class Attention ( nn . Module ) :", "output": "def __init__ ( self , params ) : \n super ( Attention , self ) . __init__ ( ) \n self . params = params \n self . hidden = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . attention_dim = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . hidden_weight = nn . Linear ( self . hidden , self . attention_dim ) \n self . attention_conv = nn . Conv2d ( <NUM_LIT> , <NUM_LIT> , kernel_size = <NUM_LIT> , padding = <NUM_LIT> , bias = False ) \n self . attention_weight = nn . Linear ( <NUM_LIT> , self . attention_dim , bias = False ) \n self . alpha_convert = nn . Linear ( self . attention_dim , <NUM_LIT> ) \n def forward ( self , cnn_features , cnn_features_trans , hidden , alpha_sum , image_mask = None ) : \n query = self . hidden_weight ( hidden ) \n alpha_sum_trans = self . attention_conv ( alpha_sum ) \n coverage_alpha = self . attention_weight ( alpha_sum_trans . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) \n alpha_score = torch . tanh ( query [ : , None , None , : ] + coverage_alpha + cnn_features_trans . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) \n energy = self . alpha_convert ( alpha_score ) \n energy = energy - energy . max ( ) \n energy_exp = torch . exp ( energy . squeeze ( - <NUM_LIT> ) ) \n if image_mask is not None : \n energy_exp = energy_exp * image_mask . squeeze ( <NUM_LIT> ) \n alpha = energy_exp / ( energy_exp . sum ( - <NUM_LIT> ) . sum ( - <NUM_LIT> ) [ : , None , None ] + <NUM_LIT> ) \n alpha_sum = alpha [ : , None , : , : ] + alpha_sum \n context_vector = ( alpha [ : , None , : , : ] * cnn_features ) . sum ( - <NUM_LIT> ) . sum ( - <NUM_LIT> ) \n return context_vector , alpha , alpha_sum"}, {"input": "import torch \n import torch . nn . functional as F \n import numpy as np \n from torch . autograd import Function \n import torch . nn as nn \n import functools \n from math import ceil \n import pywt \n from einops import rearrange , repeat \n from einops . layers . torch import Rearrange \n device = '<STR_LIT>' \n def sfb1d ( lo , hi , g0 , g1 , mode = '<STR_LIT>' , dim = - <NUM_LIT> ) : \n C = lo . shape [ <NUM_LIT> ] \n d = dim % <NUM_LIT> \n if not isinstance ( g0 , torch . Tensor ) : \n g0 = torch . tensor ( np . copy ( np . array ( g0 ) . ravel ( ) ) , \n dtype = torch . float , device = lo . device ) \n if not isinstance ( g1 , torch . Tensor ) : \n g1 = torch . tensor ( np . copy ( np . array ( g1 ) . ravel ( ) ) , \n dtype = torch . float , device = lo . device ) \n L = g0 . numel ( ) \n shape = [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n shape [ d ] = L \n N = <NUM_LIT> * lo . shape [ d ] \n if g0 . shape != tuple ( shape ) : \n g0 = g0 . reshape ( * shape ) \n if g1 . shape != tuple ( shape ) : \n g1 = g1 . reshape ( * shape ) \n s = ( <NUM_LIT> , <NUM_LIT> ) if d == <NUM_LIT> else ( <NUM_LIT> , <NUM_LIT> ) \n g0 = torch . cat ( [ g0 ] * C , dim = <NUM_LIT> ) \n g1 = torch . cat ( [ g1 ] * C , dim = <NUM_LIT> ) \n if mode == '<STR_LIT>' or mode == '<STR_LIT>' : \n y = F . conv_transpose2d ( lo , g0 , stride = s , groups = C ) + F . conv_transpose2d ( hi , g1 , stride = s , groups = C ) \n if d == <NUM_LIT> : \n y [ : , : , : L - <NUM_LIT> ] = y [ : , : , : L - <NUM_LIT> ] + y [ : , : , N : N + L - <NUM_LIT> ] \n y = y [ : , : , : N ] \n else : \n y [ : , : , : , : L - <NUM_LIT> ] = y [ : , : , : , : L - <NUM_LIT> ] + y [ : , : , : , N : N + L - <NUM_LIT> ] \n y = y [ : , : , : , : N ] \n y = roll ( y , <NUM_LIT> - L // <NUM_LIT> , dim = dim ) \n else : \n if mode == '<STR_LIT>' or mode == '<STR_LIT>' or mode == '<STR_LIT>' or mode == '<STR_LIT>' : \n pad = ( L - <NUM_LIT> , <NUM_LIT> ) if d == <NUM_LIT> else ( <NUM_LIT> , L - <NUM_LIT> ) \n y = F . conv_transpose2d ( lo , g0 , stride = s , padding = pad , groups = C ) + F . conv_transpose2d ( hi , g1 , stride = s , padding = pad , groups = C ) \n else : \n raise ValueError ( \"<STR_LIT>\" . format ( mode ) ) \n return y \n def reflect ( x , minx , maxx ) : \n x = np . asanyarray ( x ) \n rng = maxx - minx \n rng_by_2 = <NUM_LIT> * rng \n mod = np . fmod ( x - minx , rng_by_2 ) \n normed_mod = np . where ( mod < <NUM_LIT> , mod + rng_by_2 , mod ) \n out = np . where ( normed_mod >= rng , rng_by_2 - normed_mod , normed_mod ) + minx \n return np . array ( out , dtype = x . dtype ) \n def mode_to_int ( mode ) : \n if mode == '<STR_LIT>' : \n return <NUM_LIT> \n elif mode == '<STR_LIT>' : \n return <NUM_LIT> \n elif mode == '<STR_LIT>' or mode == '<STR_LIT>' : \n return <NUM_LIT> \n elif mode == '<STR_LIT>' : \n return <NUM_LIT> \n elif mode == '<STR_LIT>' : \n return <NUM_LIT> \n elif mode == '<STR_LIT>' : \n return <NUM_LIT> \n elif mode == '<STR_LIT>' : \n return <NUM_LIT> \n else : \n raise ValueError ( \"<STR_LIT>\" . format ( mode ) ) \n def int_to_mode ( mode ) : \n if mode == <NUM_LIT> : \n return '<STR_LIT>' \n elif mode == <NUM_LIT> : \n return '<STR_LIT>' \n elif mode == <NUM_LIT> : \n return '<STR_LIT>' \n elif mode == <NUM_LIT> : \n return '<STR_LIT>' \n elif mode == <NUM_LIT> : \n return '<STR_LIT>' \n elif mode == <NUM_LIT> : \n return '<STR_LIT>' \n elif mode == <NUM_LIT> : \n return '<STR_LIT>' \n else : \n raise ValueError ( \"<STR_LIT>\" . format ( mode ) ) \n def afb1d ( x , h0 , h1 , mode = '<STR_LIT>' , dim = - <NUM_LIT> ) : \n C = x . shape [ <NUM_LIT> ] \n d = dim % <NUM_LIT> \n s = ( <NUM_LIT> , <NUM_LIT> ) if d == <NUM_LIT> else ( <NUM_LIT> , <NUM_LIT> ) \n N = x . shape [ d ] \n if not isinstance ( h0 , torch . Tensor ) : \n h0 = torch . tensor ( np . copy ( np . array ( h0 ) . ravel ( ) [ : : - <NUM_LIT> ] ) , \n dtype = torch . float , device = x . device ) \n if not isinstance ( h1 , torch . Tensor ) : \n h1 = torch . tensor ( np . copy ( np . array ( h1 ) . ravel ( ) [ : : - <NUM_LIT> ] ) , \n dtype = torch . float , device = x . device ) \n L = h0 . numel ( ) \n L2 = L // <NUM_LIT> \n shape = [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n shape [ d ] = L \n if h0 . shape != tuple ( shape ) : \n h0 = h0 . reshape ( * shape ) \n if h1 . shape != tuple ( shape ) : \n h1 = h1 . reshape ( * shape ) \n h = torch . cat ( [ h0 , h1 ] * C , dim = <NUM_LIT> ) \n if mode == '<STR_LIT>' or mode == '<STR_LIT>' : \n if x . shape [ dim ] % <NUM_LIT> == <NUM_LIT> : \n if d == <NUM_LIT> : \n x = torch . cat ( ( x , x [ : , : , - <NUM_LIT> : ] ) , dim = <NUM_LIT> ) \n else : \n x = torch . cat ( ( x , x [ : , : , : , - <NUM_LIT> : ] ) , dim = <NUM_LIT> ) \n N += <NUM_LIT> \n x = roll ( x , - L2 , dim = d ) \n pad = ( L - <NUM_LIT> , <NUM_LIT> ) if d == <NUM_LIT> else ( <NUM_LIT> , L - <NUM_LIT> ) \n lohi = F . conv2d ( x , h , padding = pad , stride = s , groups = C ) \n N2 = N // <NUM_LIT> \n if d == <NUM_LIT> : \n lohi [ : , : , : L2 ] = lohi [ : , : , : L2 ] + lohi [ : , : , N2 : N2 + L2 ] \n lohi = lohi [ : , : , : N2 ] \n else : \n lohi [ : , : , : , : L2 ] = lohi [ : , : , : , : L2 ] + lohi [ : , : , : , N2 : N2 + L2 ] \n lohi = lohi [ : , : , : , : N2 ] \n else : \n outsize = pywt . dwt_coeff_len ( N , L , mode = mode ) \n p = <NUM_LIT> * ( outsize - <NUM_LIT> ) - N + L \n if mode == '<STR_LIT>' : \n if p % <NUM_LIT> == <NUM_LIT> : \n pad = ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) if d == <NUM_LIT> else ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n x = F . pad ( x , pad ) \n pad = ( p // <NUM_LIT> , <NUM_LIT> ) if d == <NUM_LIT> else ( <NUM_LIT> , p // <NUM_LIT> ) \n lohi = F . conv2d ( x , h , padding = pad , stride = s , groups = C ) \n elif mode == '<STR_LIT>' or mode == '<STR_LIT>' or mode == '<STR_LIT>' : \n pad = ( <NUM_LIT> , <NUM_LIT> , p // <NUM_LIT> , ( p + <NUM_LIT> ) // <NUM_LIT> ) if d == <NUM_LIT> else ( p // <NUM_LIT> , ( p + <NUM_LIT> ) // <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n x = mypad ( x , pad = pad , mode = mode ) \n lohi = F . conv2d ( x , h , stride = s , groups = C ) \n else : \n raise ValueError ( \"<STR_LIT>\" . format ( mode ) ) \n return lohi \n class AFB2D ( Function ) : \n @ staticmethod \n def forward ( ctx , x , h0_row , h1_row , h0_col , h1_col , mode ) : \n ctx . save_for_backward ( h0_row , h1_row , h0_col , h1_col ) \n ctx . shape = x . shape [ - <NUM_LIT> : ] \n mode = int_to_mode ( mode ) \n ctx . mode = mode \n lohi = afb1d ( x , h0_row , h1_row , mode = mode , dim = <NUM_LIT> ) \n y = afb1d ( lohi , h0_col , h1_col , mode = mode , dim = <NUM_LIT> ) \n s = y . shape \n y = y . reshape ( s [ <NUM_LIT> ] , - <NUM_LIT> , <NUM_LIT> , s [ - <NUM_LIT> ] , s [ - <NUM_LIT> ] ) \n low = y [ : , : , <NUM_LIT> ] . contiguous ( ) \n highs = y [ : , : , <NUM_LIT> : ] . contiguous ( ) \n return low , highs \n @ staticmethod \n def backward ( ctx , low , highs ) : \n dx = None \n if ctx . needs_input_grad [ <NUM_LIT> ] : \n mode = ctx . mode \n h0_row , h1_row , h0_col , h1_col = ctx . saved_tensors \n lh , hl , hh = torch . unbind ( highs , dim = <NUM_LIT> ) \n lo = sfb1d ( low , lh , h0_col , h1_col , mode = mode , dim = <NUM_LIT> ) \n hi = sfb1d ( hl , hh , h0_col , h1_col , mode = mode , dim = <NUM_LIT> ) \n dx = sfb1d ( lo , hi , h0_row , h1_row , mode = mode , dim = <NUM_LIT> ) \n if dx . shape [ - <NUM_LIT> ] > ctx . shape [ - <NUM_LIT> ] and dx . shape [ - <NUM_LIT> ] > ctx . shape [ - <NUM_LIT> ] : \n dx = dx [ : , : , : ctx . shape [ - <NUM_LIT> ] , : ctx . shape [ - <NUM_LIT> ] ] \n elif dx . shape [ - <NUM_LIT> ] > ctx . shape [ - <NUM_LIT> ] : \n dx = dx [ : , : , : ctx . shape [ - <NUM_LIT> ] ] \n elif dx . shape [ - <NUM_LIT> ] > ctx . shape [ - <NUM_LIT> ] : \n dx = dx [ : , : , : , : ctx . shape [ - <NUM_LIT> ] ] \n return dx , None , None , None , None , None \n def prep_filt_afb2d ( h0_col , h1_col , h0_row = None , h1_row = None , device = device ) : \n h0_col , h1_col = prep_filt_afb1d ( h0_col , h1_col , device ) \n if h0_row is None : \n h0_row , h1_col = h0_col , h1_col \n else : \n h0_row , h1_row = prep_filt_afb1d ( h0_row , h1_row , device ) \n h0_col = h0_col . reshape ( ( <NUM_LIT> , <NUM_LIT> , - <NUM_LIT> , <NUM_LIT> ) ) \n h1_col = h1_col . reshape ( ( <NUM_LIT> , <NUM_LIT> , - <NUM_LIT> , <NUM_LIT> ) ) \n h0_row = h0_row . reshape ( ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , - <NUM_LIT> ) ) \n h1_row = h1_row . reshape ( ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , - <NUM_LIT> ) ) \n return h0_col , h1_col , h0_row , h1_row \n def prep_filt_afb1d ( h0 , h1 , device = device ) : \n h0 = np . array ( h0 [ : : - <NUM_LIT> ] ) . ravel ( ) \n h1 = np . array ( h1 [ : : - <NUM_LIT> ] ) . ravel ( ) \n t = torch . get_default_dtype ( ) \n h0 = torch . tensor ( h0 , device = device , dtype = t ) . reshape ( ( <NUM_LIT> , <NUM_LIT> , - <NUM_LIT> ) ) \n h1 = torch . tensor ( h1 , device = device , dtype = t ) . reshape ( ( <NUM_LIT> , <NUM_LIT> , - <NUM_LIT> ) ) \n return h0 , h1 \n class DWTForward ( nn . Module ) : \n def __init__ ( self , J = <NUM_LIT> , wave = '<STR_LIT>' , mode = '<STR_LIT>' ) : \n super ( ) . __init__ ( ) \n if isinstance ( wave , str ) : \n wave = pywt . Wavelet ( wave ) \n if isinstance ( wave , pywt . Wavelet ) : \n h0_col , h1_col = wave . dec_lo , wave . dec_hi \n h0_row , h1_row = h0_col , h1_col \n else : \n if len ( wave ) == <NUM_LIT> : \n h0_col , h1_col = wave [ <NUM_LIT> ] , wave [ <NUM_LIT> ] \n h0_row , h1_row = h0_col , h1_col \n elif len ( wave ) == <NUM_LIT> : \n h0_col , h1_col = wave [ <NUM_LIT> ] , wave [ <NUM_LIT> ] \n h0_row , h1_row = wave [ <NUM_LIT> ] , wave [ <NUM_LIT> ] \n filts = prep_filt_afb2d ( h0_col , h1_col , h0_row , h1_row ) \n self . register_buffer ( '<STR_LIT>' , filts [ <NUM_LIT> ] ) \n self . register_buffer ( '<STR_LIT>' , filts [ <NUM_LIT> ] ) \n self . register_buffer ( '<STR_LIT>' , filts [ <NUM_LIT> ] ) \n self . register_buffer ( '<STR_LIT>' , filts [ <NUM_LIT> ] ) \n self . J = J \n self . mode = mode \n def forward ( self , x ) : \n yh = [ ] \n ll = x \n mode = mode_to_int ( self . mode ) \n for j in range ( self . J ) : \n ll , high = AFB2D . apply ( \n ll , self . h0_col , self . h1_col , self . h0_row , self . h1_row , mode ) \n yh . append ( high ) \n return ll , yh \n from numpy . lib . function_base import hamming \n class Waveblock ( nn . Module ) : \n def __init__ ( \n self , \n * , \n mult = <NUM_LIT> , \n ff_channel = <NUM_LIT> , \n final_dim = <NUM_LIT> , \n dropout = <NUM_LIT> , \n ) : \n super ( ) . __init__ ( ) \n self . feedforward = nn . Sequential ( \n nn . Conv2d ( final_dim , final_dim * mult , <NUM_LIT> ) , \n nn . GELU ( ) , \n nn . Dropout ( dropout ) , \n nn . Conv2d ( final_dim * mult , ff_channel , <NUM_LIT> ) , \n nn . ConvTranspose2d ( ff_channel , final_dim , <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( final_dim ) \n ) \n self . reduction = nn . Conv2d ( final_dim , int ( final_dim / <NUM_LIT> ) , <NUM_LIT> ) \n def forward ( self , x ) : \n b , c , h , w = x . shape \n x = self . reduction ( x ) \n xf1 = DWTForward ( J = <NUM_LIT> , mode = '<STR_LIT>' , wave = '<STR_LIT>' ) . cuda ( ) \n Y1 , Yh = xf1 ( x ) \n x = torch . reshape ( Yh [ <NUM_LIT> ] , ( b , int ( c * <NUM_LIT> / <NUM_LIT> ) , int ( h / <NUM_LIT> ) , int ( w / <NUM_LIT> ) ) ) \n x = torch . cat ( ( Y1 , x ) , dim = <NUM_LIT> ) \n x = self . feedforward ( x ) \n return x \n class WaveMix ( nn . Module ) : \n def __init__ ( \n self , \n * , \n num_classes , \n depth , \n mult = <NUM_LIT> , \n ff_channel = <NUM_LIT> , \n final_dim = <NUM_LIT> , \n dropout = <NUM_LIT> , \n ) : \n super ( ) . __init__ ( ) \n self . layers = nn . ModuleList ( [ ] ) \n for _ in range ( depth ) : \n self . layers . append ( Waveblock ( mult = mult , ff_channel = ff_channel , final_dim = final_dim , dropout = dropout ) ) \n self . pool = nn . Sequential ( \n nn . AdaptiveAvgPool2d ( <NUM_LIT> ) , \n Rearrange ( '<STR_LIT>' ) , \n nn . Linear ( final_dim , num_classes )", "output": ") \n self . conv = nn . Sequential ( \n nn . Conv2d ( <NUM_LIT> , int ( final_dim / <NUM_LIT> ) , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) , \n nn . Conv2d ( int ( final_dim / <NUM_LIT> ) , final_dim , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n ) \n def forward ( self , img ) : \n x = self . conv ( img ) \n for attn in self . layers : \n x = attn ( x ) + x \n out = self . pool ( x ) \n return out \n model = WaveMix ( \n num_classes = <NUM_LIT> , \n depth = <NUM_LIT> , \n mult = <NUM_LIT> , \n ff_channel = <NUM_LIT> , \n final_dim = <NUM_LIT> , \n dropout = <NUM_LIT> \n )"}, {"input": "import requests , datetime , os \n from bs4 import BeautifulSoup as bs \n from utils . general import headers \n def get_epgs_gdtv ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n try : \n url = '<STR_LIT>' % ( channel_id , dt . strftime ( '<STR_LIT>' ) ) \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n epgs_contents = soup . select ( '<STR_LIT>' ) \n epgs = [ ] \n for epga in epgs_contents : \n starttime = datetime . datetime . fromtimestamp ( int ( epga . attrs [ '<STR_LIT>' ] ) ) \n endtime = datetime . datetime . fromtimestamp ( int ( epga . attrs [ '<STR_LIT>' ] ) ) \n title = epga . get_text ( ) . strip ( ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : endtime , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_gdtv ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url , headers = headers )", "output": "res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n contents = soup . select ( '<STR_LIT>' ) \n channels = [ ] \n for content in contents : \n id = content . attrs [ '<STR_LIT>' ] \n name = content . ctitle . text \n cdate = content . cdate . text \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : cdate \n } \n channels . append ( channel ) \n return channels"}, {"input": "from django . contrib import admin \n from feeds . models import Entry , Location \n @ admin . register ( Entry ) \n class EntryAdmin ( admin . ModelAdmin ) : \n list_display = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n list_filter = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n search_fields = [ \"<STR_LIT>\" ] \n class Meta : \n model = Entry", "output": "@ admin . register ( Location ) \n class LocationAdmin ( admin . ModelAdmin ) : \n list_display = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n class Meta : \n model = Location"}, {"input": "from django . db import models \n class User ( models . Model ) : \n username = models . CharField ( max_length = <NUM_LIT> , unique = True ) \n email = models . CharField ( max_length = <NUM_LIT> , unique = True ) \n password = models . CharField ( max_length = <NUM_LIT> ) \n school = models . CharField ( max_length = <NUM_LIT> ) \n class Meta : \n abstract = True \n class Student ( User ) : \n pass \n class Teacher ( User ) : \n pass \n class Paper ( models . Model ) : \n teacher = models . ForeignKey ( to = Teacher , on_delete = models . CASCADE ) \n created_at = models . DateTimeField ( auto_now_add = True ) \n name = models . CharField ( max_length = <NUM_LIT> ) \n class Problem ( models . Model ) : \n paper = models . ForeignKey ( to = Paper , on_delete = models . CASCADE ) \n type = models . CharField ( max_length = <NUM_LIT> ) \n class Answer ( models . Model ) : \n problem = models . ForeignKey ( to = Problem , on_delete = models . CASCADE ) \n answer = models . TextField ( ) \n class Score ( models . Model ) : \n student = models . ForeignKey ( to = Problem , on_delete = models . CASCADE ) \n paper = models . ForeignKey ( to = Paper , on_delete = models . CASCADE ) \n class UploadPhoto ( models . Model ) : \n photoPath = models . CharField ( max_length = <NUM_LIT> )", "output": "paper = models . ForeignKey ( to = Paper , on_delete = models . CASCADE ) \n class Meta : \n abstract = True \n class PaperPhoto ( UploadPhoto ) : \n pass \n class StudentUploadAnswerPhoto ( UploadPhoto ) : \n student = models . ForeignKey ( to = Student , on_delete = models . CASCADE )"}, {"input": "from django . db . models import F \n from rest_framework . decorators import action \n from rest_framework . permissions import IsAuthenticated \n from dvadmin . system . models import MenuButton , RoleMenuButtonPermission \n from dvadmin . utils . json_response import DetailResponse , SuccessResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class MenuButtonSerializer ( CustomModelSerializer ) : \n class Meta :", "output": "model = MenuButton \n fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n read_only_fields = [ \"<STR_LIT>\" ] \n class MenuButtonCreateUpdateSerializer ( CustomModelSerializer ) : \n class Meta : \n model = MenuButton \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class MenuButtonViewSet ( CustomModelViewSet ) : \n queryset = MenuButton . objects . order_by ( '<STR_LIT>' ) \n serializer_class = MenuButtonSerializer \n create_serializer_class = MenuButtonCreateUpdateSerializer \n update_serializer_class = MenuButtonCreateUpdateSerializer \n extra_filter_class = [ ] \n def list ( self , request , * args , ** kwargs ) : \n queryset = self . filter_queryset ( self . get_queryset ( ) ) . order_by ( '<STR_LIT>' ) \n serializer = self . get_serializer ( queryset , many = True , request = request ) \n return SuccessResponse ( serializer . data , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def menu_button_all_permission ( self , request ) : \n is_superuser = request . user . is_superuser \n if is_superuser : \n queryset = MenuButton . objects . values_list ( '<STR_LIT>' , flat = True ) \n else : \n role_id = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n queryset = RoleMenuButtonPermission . objects . filter ( role__in = role_id ) . values_list ( '<STR_LIT>' , flat = True ) . distinct ( ) \n return DetailResponse ( data = queryset )"}, {"input": "import logging \n from django . core . management . base import BaseCommand \n from application import settings \n logger = logging . getLogger ( __name__ ) \n class Command ( BaseCommand ) : \n def add_arguments ( self , parser ) : \n parser . add_argument ( \n \"<STR_LIT>\" , \n nargs = \"<STR_LIT>\" ,", "output": "type = str , \n ) \n parser . add_argument ( \"<STR_LIT>\" , nargs = \"<STR_LIT>\" ) \n parser . add_argument ( \"<STR_LIT>\" , nargs = \"<STR_LIT>\" ) \n parser . add_argument ( \"<STR_LIT>\" , nargs = \"<STR_LIT>\" ) \n parser . add_argument ( \"<STR_LIT>\" , nargs = \"<STR_LIT>\" ) \n def handle ( self , * args , ** options ) : \n reset = False \n if isinstance ( options . get ( \"<STR_LIT>\" ) , list ) or isinstance ( options . get ( \"<STR_LIT>\" ) , list ) : \n reset = True \n if isinstance ( options . get ( \"<STR_LIT>\" ) , list ) or isinstance ( options . get ( \"<STR_LIT>\" ) , list ) : \n reset = False \n for app in settings . INSTALLED_APPS : \n try : \n exec ( \n ) \n except ModuleNotFoundError : \n try : \n exec ( \n ) \n except ModuleNotFoundError : \n pass \n print ( \"<STR_LIT>\" )"}, {"input": "from unittest . mock import patch \n from django . apps import apps \n from django . test import override_settings \n from admin_site_search . views import AdminSiteSearchView \n from dev . football . core . factories import GroupFactory \n from dev . football . players . factories import PlayerAttributesFactory , PlayerFactory \n from dev . football . stadiums . factories import StadiumFactory \n from dev . football . teams . factories import TeamFactory \n from tests import request_search \n def test_empty ( client_admin ) : \n response = request_search ( client_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert len ( data . keys ( ) ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : [ ] } \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ] \n def test_apps ( client_super_admin ) : \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert len ( data . keys ( ) ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ ] , \n } \n ] \n } \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ] \n def test_models ( client_super_admin ) : \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ ] , \n } \n ] , \n } \n ] \n } \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ] \n def test_model_class_none ( client_super_admin ) :", "output": "with patch . object ( AdminSiteSearchView , \"<STR_LIT>\" ) as get_model_class : \n get_model_class . return_value = None \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ ] , \n } \n ] \n } \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ] \n def test_objects ( client_super_admin ) : \n match = GroupFactory ( name = \"<STR_LIT>\" ) \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : str ( match . id ) , \n \"<STR_LIT>\" : str ( match ) , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n } \n ] , \n } \n ] , \n } \n ] \n } \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ] \n def test_objects_one_to_one_pk ( client_super_admin ) : \n match = PlayerAttributesFactory ( nationality = \"<STR_LIT>\" ) \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : str ( match . pk ) , \n \"<STR_LIT>\" : str ( match ) , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n } \n ] , \n } \n ] , \n } \n ] \n } \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ] \n def test_counts ( client_super_admin ) : \n TeamFactory ( name = \"<STR_LIT>\" ) \n TeamFactory ( name = \"<STR_LIT>\" ) \n PlayerFactory ( name = \"<STR_LIT>\" ) \n StadiumFactory ( name = \"<STR_LIT>\" ) \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ] \n def test_limit ( client_super_admin ) : \n for i in range ( <NUM_LIT> ) : \n GroupFactory ( name = f\"<STR_LIT>\" ) \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert len ( data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ] \n @ override_settings ( DEBUG = True ) \n def test_errors_on ( client_super_admin ) : \n team = TeamFactory ( name = \"<STR_LIT>\" ) \n StadiumFactory ( name = \"<STR_LIT>\" ) \n def error_if_stadium ( app_label , model_dict ) : \n if model_dict [ \"<STR_LIT>\" ] == \"<STR_LIT>\" : \n raise Exception ( \"<STR_LIT>\" ) \n else : \n return apps . get_model ( app_label , model_dict [ \"<STR_LIT>\" ] ) \n with patch . object ( AdminSiteSearchView , \"<STR_LIT>\" ) as get_model_class : \n get_model_class . side_effect = error_if_stadium \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert len ( data . keys ( ) ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : str ( team . pk ) , \n \"<STR_LIT>\" : str ( team ) , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n } \n ] , \n } \n ] , \n } \n ] \n } \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert len ( data [ \"<STR_LIT>\" ] ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] [ <NUM_LIT> ] == { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n @ override_settings ( DEBUG = False ) \n def test_errors_off ( client_super_admin ) : \n with patch . object ( AdminSiteSearchView , \"<STR_LIT>\" ) as get_model_class : \n get_model_class . side_effect = Exception \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : [ ] } \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n assert not data [ \"<STR_LIT>\" ]"}, {"input": "from django . db import migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ]", "output": "operations = [ \n migrations . RemoveField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n ) , \n ]"}, {"input": "import uuid \n import django . core . validators \n import django . db . models . deletion \n import django . utils . timezone \n import model_utils . fields \n from django . db import migrations , models \n import django_webhook . validators \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n model_utils . fields . AutoCreatedField ( \n default = django . utils . timezone . now , \n editable = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n model_utils . fields . AutoLastModifiedField ( \n default = django . utils . timezone . now , \n editable = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . URLField ( ) ) , \n ( \"<STR_LIT>\" , models . BooleanField ( default = True ) ) , \n ( \"<STR_LIT>\" , models . UUIDField ( default = uuid . uuid4 , editable = False ) ) , \n ] , \n options = { \n \"<STR_LIT>\" : False , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n max_length = <NUM_LIT> , \n unique = True , \n validators = [ \n django . core . validators . RegexValidator ( \n \"<STR_LIT>\" , \n message = \"<STR_LIT>\" , \n ) , \n django_webhook . validators . validate_topic_model , \n ] , \n ) , \n ) , \n ] , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . AutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" ,", "output": ") , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n max_length = <NUM_LIT> , \n validators = [ django . core . validators . MinLengthValidator ( <NUM_LIT> ) ] , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n model_utils . fields . AutoCreatedField ( \n default = django . utils . timezone . now , editable = False \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ForeignKey ( \n editable = False , \n on_delete = django . db . models . deletion . CASCADE , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . ManyToManyField ( \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ]"}, {"input": "from factory import SubFactory , django , fuzzy \n from dev . football . stadiums . factories import StadiumFactory \n from dev . football . teams . models import Squad , Team \n class FuzzyURL ( fuzzy . BaseFuzzyAttribute ) : \n def fuzz ( self ) : \n return f\"<STR_LIT>\" . lower ( ) \n class TeamFactory ( django . DjangoModelFactory ) : \n name = fuzzy . FuzzyText ( ) \n key = fuzzy . FuzzyText ( ) \n type = \"<STR_LIT>\" \n website = FuzzyURL ( ) \n motto = fuzzy . FuzzyText ( ) \n stadium = SubFactory ( StadiumFactory ) \n class Meta : \n model = Team \n class SquadFactory ( django . DjangoModelFactory ) : \n team = SubFactory ( TeamFactory ) \n type = \"<STR_LIT>\" \n class Meta :", "output": "model = Squad"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . BooleanField ( default = True ) , \n ) , \n migrations . AddField (", "output": "model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . CharField ( default = '<STR_LIT>' , max_length = <NUM_LIT> ) , \n ) , \n ]"}, {"input": "from collections . abc import Callable , Iterator \n from typing import Any , Protocol \n class AIResponse ( Protocol ) : \n def __iter__ ( self ) -> Iterator [ str ] : \n ... \n def text ( self ) -> str : \n ... \n class TextSplitterProtocol ( Protocol ) : \n def __init__ (", "output": "self , * , chunk_size : int , length_function : Callable [ [ str ] , int ] , ** kwargs : Any \n ) -> None : \n ... \n def split_text ( self , text : str ) -> list [ str ] : \n ... \n class TextSplitterLengthCalculatorProtocol ( Protocol ) : \n def get_splitter_length ( self , text : str ) -> int : \n ..."}, {"input": "import torch \n import cv2 \n import torchvision \n from torchvision import transforms \n import os \n from scoreblocks . CharacterRecognition . model import SpinalVGG \n from scoreblocks . CharacterRecognition . model_new import * \n class Model : \n def __init__ ( self , path , name ) : \n self . model_name = name \n if self . model_name == '<STR_LIT>' : \n self . model = WaveMix ( \n num_classes = <NUM_LIT> , \n depth = <NUM_LIT> , \n mult = <NUM_LIT> , \n ff_channel = <NUM_LIT> , \n final_dim = <NUM_LIT> , \n dropout = <NUM_LIT> \n ) \n elif self . model_name == '<STR_LIT>' : \n self . model = SpinalVGG ( <NUM_LIT> ) \n self . model . load_state_dict ( torch . load ( path ) ) \n self . transforms = transforms . Compose ( [ torchvision . transforms . ToTensor ( ) , \n torchvision . transforms . Normalize ( \n ( <NUM_LIT> , ) , ( <NUM_LIT> , ) ) ] ) \n def img_preprocessing ( self , img_path ) : \n img = cv2 . imread ( img_path ) \n gray = cv2 . cvtColor ( img , cv2 . COLOR_BGR2GRAY ) \n gray = cv2 . resize ( gray , ( <NUM_LIT> , <NUM_LIT> ) )", "output": "gray = cv2 . transpose ( gray ) \n _ , binary = cv2 . threshold ( gray , <NUM_LIT> , <NUM_LIT> , cv2 . THRESH_BINARY_INV ) \n binary = cv2 . dilate ( binary , ( <NUM_LIT> , <NUM_LIT> ) ) \n return binary \n def output ( self , img_path ) : \n binary = self . img_preprocessing ( img_path ) \n inp = self . transforms ( binary ) \n inp = torch . unsqueeze ( inp , <NUM_LIT> ) \n inp = inp . cuda ( ) \n self . model . eval ( ) \n with torch . no_grad ( ) : \n out = self . model ( inp ) \n return out \n if __name__ == '<STR_LIT>' : \n selection = { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' } \n m = Model ( selection [ '<STR_LIT>' ] , '<STR_LIT>' ) \n img_path = input ( \"<STR_LIT>\" ) \n acc = <NUM_LIT> \n sum_ = <NUM_LIT> \n lst = os . listdir ( img_path ) \n for i in lst : \n if i . endswith ( '<STR_LIT>' ) or i . endswith ( '<STR_LIT>' ) : \n sum_ += <NUM_LIT> \n path = os . path . join ( img_path , i ) \n out = m . output ( path ) \n res = chr ( out . argmax ( <NUM_LIT> ) + <NUM_LIT> ) \n print ( res )"}, {"input": "import logging \n from collections . abc import Callable \n from . . types import TextSplitterLengthCalculatorProtocol , TextSplitterProtocol \n logger = logging . getLogger ( __name__ ) \n class DummyTextSplitter ( TextSplitterProtocol ) : \n def __init__ ( \n self , * , chunk_size : int , length_function : Callable [ [ str ] , int ] \n ) -> None : \n pass \n def split_text ( self , text : str ) -> list [ str ] : \n return [ text ] \n class DummyLengthCalculator ( TextSplitterLengthCalculatorProtocol ) :", "output": "def get_splitter_length ( self , text : str ) -> int : \n return len ( text )"}, {"input": "from django . contrib . sitemaps import Sitemap \n from django . shortcuts import reverse \n class StaticViewSitemap ( Sitemap ) :", "output": "changefreq = \"<STR_LIT>\" \n priority = <NUM_LIT> \n protocol = '<STR_LIT>' \n def items ( self ) : \n return [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n def location ( self , item ) : \n return reverse ( item )"}, {"input": "from django . apps import AppConfig \n from django . utils . translation import gettext_lazy as _ \n class IndexesConfig ( AppConfig ) : \n default_auto_field = \"<STR_LIT>\" \n name = \"<STR_LIT>\" \n verbose_name = _ ( \"<STR_LIT>\" )", "output": "def ready ( self ) : \n try : \n import delphic . indexes . signals \n except ImportError : \n pass"}, {"input": "from ninja import Schema \n class CollectionStatusEnum ( str ) : \n COMPLETE = \"<STR_LIT>\" \n RUNNING = \"<STR_LIT>\" \n QUEUED = \"<STR_LIT>\" \n ERROR = \"<STR_LIT>\" \n class CollectionIn ( Schema ) :", "output": "title : str \n description : str | None \n class CollectionModelSchema ( Schema ) : \n id : int \n title : str \n description : str \n status : CollectionStatusEnum \n created : str \n modified : str \n processing : bool \n has_model : bool \n document_names : list [ str ] \n class CollectionQueryInput ( Schema ) : \n collection_id : int \n query_str : str \n class CollectionQueryOutput ( Schema ) : \n response : str"}, {"input": "import logging \n from urllib . parse import parse_qsl \n import jwt \n from channels . db import database_sync_to_async \n from channels . middleware import BaseMiddleware \n from django . conf import settings \n from django . contrib . auth import get_user_model \n logger = logging . getLogger ( __name__ ) \n @ database_sync_to_async \n def get_user_from_token ( token ) : \n from ninja_jwt . tokens import UntypedToken \n User = get_user_model ( ) \n print ( f\"<STR_LIT>\" ) \n try : \n UntypedToken ( token ) \n payload = jwt . decode ( token , settings . SECRET_KEY , algorithms = [ \"<STR_LIT>\" ] ) \n user_id = payload . get ( \"<STR_LIT>\" ) \n user = User . objects . get ( id = user_id ) \n return user \n except Exception as e : \n logger . error ( f\"<STR_LIT>\" ) \n raise ValueError ( \"<STR_LIT>\" ) from e \n class TokenAuthMiddleware ( BaseMiddleware ) : \n def __init__ ( self , app ) : \n self . app = app \n async def __call__ ( self , scope , receive , send ) : \n try : \n query_string = dict ( parse_qsl ( scope [ \"<STR_LIT>\" ] . decode ( \"<STR_LIT>\" ) ) ) \n token = query_string [ \"<STR_LIT>\" ] \n scope [ \"<STR_LIT>\" ] = await get_user_from_token ( token ) \n return await self . app ( scope , receive , send ) \n except ( KeyError , ValueError ) as e : \n if isinstance ( e , KeyError ) : \n error_msg = \"<STR_LIT>\" \n else : \n error_msg = \"<STR_LIT>\" \n scope [ \"<STR_LIT>\" ] = error_msg \n await send ( \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : \"<STR_LIT>\" } \n )", "output": "return await self . app ( scope , receive , send )"}, {"input": "from django . db import models \n from django . contrib . postgres . fields import ArrayField \n class Entry ( models . Model ) : \n CHANNEL_CHOICES = ( \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ) \n full_text = models . TextField ( ) \n location = ArrayField ( base_field = models . FloatField ( default = <NUM_LIT> ) , null = True ) \n is_resolved = models . BooleanField ( default = False ) \n is_geolocated = models . BooleanField ( default = False ) \n channel = models . CharField ( max_length = <NUM_LIT> , choices = CHANNEL_CHOICES ) \n extra_parameters = models . TextField ( null = True , blank = True ) \n timestamp = models . DateTimeField ( auto_now_add = True , auto_now = False ) \n class Meta : \n ordering = [ \"<STR_LIT>\" ] \n class Location ( models . Model ) : \n entry = models . ForeignKey ( \n \"<STR_LIT>\" , on_delete = models . CASCADE , related_query_name = \"<STR_LIT>\" , related_name = \"<STR_LIT>\"", "output": ") \n formatted_address = models . TextField ( null = True , blank = True ) \n latitude = models . FloatField ( default = <NUM_LIT> ) \n longitude = models . FloatField ( default = <NUM_LIT> ) \n northeast_lat = models . FloatField ( default = <NUM_LIT> ) \n northeast_lng = models . FloatField ( default = <NUM_LIT> ) \n southwest_lat = models . FloatField ( default = <NUM_LIT> ) \n southwest_lng = models . FloatField ( default = <NUM_LIT> ) \n @ property \n def loc ( self ) : \n return [ self . latitude , self . longitude ] \n @ property \n def viewport ( self ) : \n return { \n \"<STR_LIT>\" : { \"<STR_LIT>\" : self . northeast_lat , \"<STR_LIT>\" : self . northeast_lng } , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : self . southwest_lat , \"<STR_LIT>\" : self . southwest_lng } , \n } \n class Meta : \n ordering = [ \"<STR_LIT>\" ]"}, {"input": "from asgiref . sync import sync_to_async \n from django . conf import settings \n from django . core . files . base import ContentFile \n from django . http import HttpRequest \n from ninja import File , Form , Router \n from ninja . files import UploadedFile \n from ninja_extra import NinjaExtraAPI \n from ninja_jwt . controller import NinjaJWTDefaultController \n from delphic . indexes . models import Collection , Document \n from delphic . tasks import create_index \n from delphic . utils . collections import query_collection \n from . auth . api_key import NinjaApiKeyAuth \n from . ninja_types import ( \n CollectionModelSchema , \n CollectionQueryInput , \n CollectionQueryOutput , \n CollectionStatusEnum , \n ) \n collections_router = Router ( ) \n api = NinjaExtraAPI ( \n title = \"<STR_LIT>\" , \n description = \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" , \n version = \"<STR_LIT>\" , \n auth = None if settings . OPEN_ACCESS_MODE else NinjaApiKeyAuth ( ) , \n ) \n api . add_router ( \"<STR_LIT>\" , collections_router ) \n api . register_controllers ( NinjaJWTDefaultController ) \n @ api . get ( \n \"<STR_LIT>\" , \n auth = None , \n response = bool , \n tags = [ \"<STR_LIT>\" ] , \n summary = \"<STR_LIT>\" , \n ) \n def check_heartbeat ( request ) : \n return True \n @ collections_router . post ( \"<STR_LIT>\" ) \n async def create_collection ( \n request , \n title : str = Form ( ... ) , \n description : str = Form ( ... ) , \n files : list [ UploadedFile ] = File ( ... ) , \n ) : \n key = None if getattr ( request , \"<STR_LIT>\" , None ) is None else request . auth \n if key is not None : \n key = await key \n collection_instance = Collection ( \n api_key = key , \n title = title ,", "output": "description = description , \n status = CollectionStatusEnum . QUEUED , \n ) \n await sync_to_async ( collection_instance . save ) ( ) \n for uploaded_file in files : \n doc_data = uploaded_file . file . read ( ) \n doc_file = ContentFile ( doc_data , uploaded_file . name ) \n document = Document ( collection = collection_instance , file = doc_file ) \n await sync_to_async ( document . save ) ( ) \n create_index . si ( collection_instance . id ) . apply_async ( ) \n return await sync_to_async ( CollectionModelSchema ) ( \n id = collection_instance . id , \n title = collection_instance . title , \n description = collection_instance . description , \n status = collection_instance . status , \n created = collection_instance . created . isoformat ( ) , \n modified = collection_instance . modified . isoformat ( ) , \n processing = collection_instance . processing , \n has_model = bool ( collection_instance . model . name ) , \n document_names = await sync_to_async ( list ) ( \n await sync_to_async ( collection_instance . documents . values_list ) ( \n \"<STR_LIT>\" , flat = True \n ) \n ) \n ) \n @ collections_router . post ( \n \"<STR_LIT>\" , \n response = CollectionQueryOutput , \n summary = \"<STR_LIT>\" , \n ) \n def query_collection_view ( request : HttpRequest , query_input : CollectionQueryInput ) : \n collection_id = query_input . collection_id \n query_str = query_input . query_str \n response = query_collection ( collection_id , query_str ) \n return { \"<STR_LIT>\" : response } \n @ collections_router . get ( \n \"<STR_LIT>\" , \n response = list [ CollectionModelSchema ] , \n summary = \"<STR_LIT>\" \"<STR_LIT>\" , \n ) \n async def get_my_collections_view ( request : HttpRequest ) : \n key = None if getattr ( request , \"<STR_LIT>\" , None ) is None else request . auth \n if key is not None : \n key = await key \n print ( f\"<STR_LIT>\" ) \n collections = Collection . objects . filter ( api_key = key ) \n return [ \n { \n \"<STR_LIT>\" : collection . id , \n \"<STR_LIT>\" : collection . title , \n \"<STR_LIT>\" : collection . description , \n \"<STR_LIT>\" : collection . status , \n \"<STR_LIT>\" : collection . created . isoformat ( ) , \n \"<STR_LIT>\" : collection . modified . isoformat ( ) , \n \"<STR_LIT>\" : collection . processing , \n \"<STR_LIT>\" : bool ( collection . model . name ) , \n \"<STR_LIT>\" : await sync_to_async ( list ) ( \n await sync_to_async ( collection . documents . values_list ) ( \"<STR_LIT>\" , flat = True ) \n ) , \n } \n async for collection in collections \n ] \n @ collections_router . post ( \n \"<STR_LIT>\" , summary = \"<STR_LIT>\" \n ) \n async def add_file_to_collection ( \n request , \n collection_id : int , \n file : UploadedFile = File ( ... ) , \n description : str = Form ( ... ) , \n ) : \n collection = await sync_to_async ( Collection . objects . get ) ( id = collection_id ) \n doc_data = file . read ( ) \n doc_file = ContentFile ( doc_data , file . name ) \n document = Document ( collection = collection , file = doc_file , description = description ) \n await sync_to_async ( document . save ) ( ) \n return { \"<STR_LIT>\" : f\"<STR_LIT>\" }"}, {"input": "from django . conf import settings \n from django . db import migrations \n def _update_or_create_site_with_sequence ( site_model , connection , domain , name ) : \n site , created = site_model . objects . update_or_create ( \n id = settings . SITE_ID , \n defaults = { \n \"<STR_LIT>\" : domain , \n \"<STR_LIT>\" : name , \n } , \n ) \n if created : \n max_id = site_model . objects . order_by ( '<STR_LIT>' ) . first ( ) . id \n with connection . cursor ( ) as cursor : \n cursor . execute ( \"<STR_LIT>\" ) \n ( current_id , ) = cursor . fetchone ( ) \n if current_id <= max_id : \n cursor . execute ( \n \"<STR_LIT>\" , \n [ max_id + <NUM_LIT> ] , \n ) \n def update_site_forward ( apps , schema_editor ) : \n Site = apps . get_model ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n _update_or_create_site_with_sequence ( \n Site , \n schema_editor . connection , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) \n def update_site_backward ( apps , schema_editor ) : \n Site = apps . get_model ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n _update_or_create_site_with_sequence (", "output": "Site , \n schema_editor . connection , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) \n class Migration ( migrations . Migration ) : \n dependencies = [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] \n operations = [ migrations . RunPython ( update_site_forward , update_site_backward ) ]"}, {"input": "import http \n import uuid \n from typing import Any , Optional , Tuple , Union \n import django . core . exceptions \n import django . http \n import django . test \n import ninja \n from ninja_crud import views \n from tests . test_app . models import Item \n class TestAbstractModelView ( django . test . TestCase ) : \n def test_property_model_viewset_class ( self ) : \n class ModelView ( views . AbstractModelView ) : \n def handle_request ( \n self , \n request : django . http . HttpRequest , \n path_parameters : Optional [ ninja . Schema ] , \n query_parameters : Optional [ ninja . Schema ] , \n request_body : Optional [ ninja . Schema ] , \n ) -> Union [ Any , Tuple [ http . HTTPStatus , Any ] ] : \n pass \n class ItemViewSet : \n model = Item \n model_view = ModelView ( method = views . enums . HTTPMethod . GET , path = \"<STR_LIT>\" ) \n self . assertIsNone ( \n model_view . handle_request ( \n request = django . http . HttpRequest ( ) , \n path_parameters = None , \n query_parameters = None , \n request_body = None , \n ) \n ) \n with self . assertRaises ( ValueError ) : \n _ = model_view . model_viewset_class \n model_view . model_viewset_class = ItemViewSet \n with self . assertRaises ( ValueError ) : \n model_view . model_viewset_class = ItemViewSet \n def test_infer_field_type ( self ) : \n self . assertEqual ( \n views . AbstractModelView . _infer_field_type ( \n model_class = Item , field_name = \"<STR_LIT>\" \n ) , \n uuid . UUID , \n ) \n self . assertEqual ( \n views . AbstractModelView . _infer_field_type ( \n model_class = Item , field_name = \"<STR_LIT>\" \n ) , \n str , \n ) \n self . assertEqual ( \n views . AbstractModelView . _infer_field_type ( \n model_class = Item , field_name = \"<STR_LIT>\" \n ) , \n str , \n ) \n self . assertEqual ( \n views . AbstractModelView . _infer_field_type ( \n model_class = Item , field_name = \"<STR_LIT>\" \n ) , \n uuid . UUID , \n ) \n with self . assertRaises ( ValueError ) : \n views . AbstractModelView . _infer_field_type ( \n model_class = Item , field_name = \"<STR_LIT>\" \n )", "output": "with self . assertRaises ( django . core . exceptions . FieldDoesNotExist ) : \n views . AbstractModelView . _infer_field_type ( \n model_class = Item , field_name = \"<STR_LIT>\" \n )"}, {"input": "import torch \n from tqdm import tqdm \n from utils import update_lr , Meter , cal_score \n def train ( params , model , optimizer , epoch , train_loader , writer = None ) : \n model . train ( ) \n device = params [ '<STR_LIT>' ] \n loss_meter = Meter ( ) \n word_right , exp_right , length , cal_num = <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> \n with tqdm ( train_loader , total = len ( train_loader ) // params [ '<STR_LIT>' ] ) as pbar : \n for batch_idx , ( images , image_masks , labels , label_masks ) in enumerate ( pbar ) : \n images , image_masks , labels , label_masks = images . to ( device ) , image_masks . to ( \n device ) , labels . to ( device ) , label_masks . to ( device ) \n batch , time = labels . shape [ : <NUM_LIT> ] \n if not '<STR_LIT>' in params or params [ '<STR_LIT>' ] == '<STR_LIT>' : \n update_lr ( optimizer , epoch , batch_idx , len ( train_loader ) , params [ '<STR_LIT>' ] , params [ '<STR_LIT>' ] ) \n optimizer . zero_grad ( ) \n probs , counting_preds , word_loss , counting_loss = model ( images , image_masks , labels , label_masks ) \n loss = word_loss + counting_loss \n loss . backward ( ) \n if params [ '<STR_LIT>' ] : \n torch . nn . utils . clip_grad_norm_ ( model . parameters ( ) , params [ '<STR_LIT>' ] ) \n optimizer . step ( ) \n loss_meter . add ( loss . item ( ) ) \n wordRate , ExpRate = cal_score ( probs , labels , label_masks ) \n word_right = word_right + wordRate * time \n exp_right = exp_right + ExpRate * batch \n length = length + time \n cal_num = cal_num + batch \n if writer : \n current_step = epoch * len ( train_loader ) // params [ '<STR_LIT>' ] + batch_idx + <NUM_LIT> \n writer . add_scalar ( '<STR_LIT>' , word_loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , counting_loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , wordRate , current_step ) \n writer . add_scalar ( '<STR_LIT>' , ExpRate , current_step ) \n writer . add_scalar ( '<STR_LIT>' , optimizer . param_groups [ <NUM_LIT> ] [ '<STR_LIT>' ] , current_step ) \n pbar . set_description ( f'<STR_LIT>' \n f'<STR_LIT>' ) \n if batch_idx >= len ( train_loader ) // params [ '<STR_LIT>' ] : \n break \n if writer : \n writer . add_scalar ( '<STR_LIT>' , loss_meter . mean , epoch + <NUM_LIT> ) \n writer . add_scalar ( '<STR_LIT>' , word_right / length , epoch + <NUM_LIT> ) \n writer . add_scalar ( '<STR_LIT>' , exp_right / cal_num , epoch + <NUM_LIT> ) \n return loss_meter . mean , word_right / length , exp_right / cal_num \n def eval ( params , model , epoch , eval_loader , writer = None ) : \n model . eval ( ) \n device = params [ '<STR_LIT>' ] \n loss_meter = Meter ( ) \n word_right , exp_right , length , cal_num = <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> \n with tqdm ( eval_loader , total = len ( eval_loader ) // params [ '<STR_LIT>' ] ) as pbar , torch . no_grad ( ) : \n for batch_idx , ( images , image_masks , labels , label_masks ) in enumerate ( pbar ) : \n images , image_masks , labels , label_masks = images . to ( device ) , image_masks . to ( \n device ) , labels . to ( device ) , label_masks . to ( device ) \n batch , time = labels . shape [ : <NUM_LIT> ] \n probs , counting_preds , word_loss , counting_loss = model ( images , image_masks , labels , label_masks , is_train = False ) \n loss = word_loss + counting_loss \n loss_meter . add ( loss . item ( ) ) \n wordRate , ExpRate = cal_score ( probs , labels , label_masks ) \n word_right = word_right + wordRate * time \n exp_right = exp_right + ExpRate * batch \n length = length + time \n cal_num = cal_num + batch \n if writer : \n current_step = epoch * len ( eval_loader ) // params [ '<STR_LIT>' ] + batch_idx + <NUM_LIT> \n writer . add_scalar ( '<STR_LIT>' , word_loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , counting_loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , wordRate , current_step ) \n writer . add_scalar ( '<STR_LIT>' , ExpRate , current_step ) \n pbar . set_description ( f'<STR_LIT>' \n f'<STR_LIT>' ) \n if batch_idx >= len ( eval_loader ) // params [ '<STR_LIT>' ] : \n break \n if writer : \n writer . add_scalar ( '<STR_LIT>' , loss_meter . mean , epoch + <NUM_LIT> ) \n writer . add_scalar ( '<STR_LIT>' , word_right / length , epoch + <NUM_LIT> ) \n writer . add_scalar ( '<STR_LIT>' , exp_right / len ( eval_loader . dataset ) , epoch + <NUM_LIT> )", "output": "return loss_meter . mean , word_right / length , exp_right / cal_num"}, {"input": "import logging \n import traceback \n from django . db . models import ProtectedError \n from django . http import Http404 \n from rest_framework . exceptions import APIException as DRFAPIException , AuthenticationFailed , NotAuthenticated \n from rest_framework . status import HTTP_401_UNAUTHORIZED \n from rest_framework . views import set_rollback , exception_handler \n from dvadmin . utils . json_response import ErrorResponse \n logger = logging . getLogger ( __name__ ) \n class CustomAuthenticationFailed ( NotAuthenticated ) : \n status_code = <NUM_LIT> \n def CustomExceptionHandler ( ex , context ) : \n msg = '<STR_LIT>' \n code = <NUM_LIT> \n response = exception_handler ( ex , context ) \n if isinstance ( ex , AuthenticationFailed ) : \n if response and response . data . get ( '<STR_LIT>' ) == \"<STR_LIT>\" :", "output": "code = <NUM_LIT> \n msg = ex . detail \n elif response and response . data . get ( '<STR_LIT>' ) == \"<STR_LIT>\" : \n return ErrorResponse ( status = HTTP_401_UNAUTHORIZED ) \n else : \n code = <NUM_LIT> \n msg = ex . detail \n elif isinstance ( ex , Http404 ) : \n code = <NUM_LIT> \n msg = \"<STR_LIT>\" \n elif isinstance ( ex , DRFAPIException ) : \n set_rollback ( ) \n msg = ex . detail \n if isinstance ( msg , dict ) : \n for k , v in msg . items ( ) : \n for i in v : \n msg = \"<STR_LIT>\" % ( k , i ) \n elif isinstance ( ex , ProtectedError ) : \n set_rollback ( ) \n msg = \"<STR_LIT>\" \n elif isinstance ( ex , Exception ) : \n logger . exception ( traceback . format_exc ( ) ) \n msg = str ( ex ) \n return ErrorResponse ( msg = msg , code = code )"}, {"input": "from ninja import Router \n from examples . models import Employee \n from examples . schemas import EmployeeIn , EmployeeOut \n from ninja_crud import views , viewsets", "output": "router = Router ( ) \n class EmployeeViewSet ( viewsets . ModelViewSet ) : \n model = Employee \n read_employee = views . ReadModelView ( response_body = EmployeeOut ) \n update_employee = views . UpdateModelView ( \n request_body = EmployeeIn , response_body = EmployeeOut \n ) \n delete_employee = views . DeleteModelView ( ) \n EmployeeViewSet . register_routes ( router )"}, {"input": "from django . utils . translation import gettext as _ \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' )", "output": "_ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' ) \n _ ( '<STR_LIT>' )"}, {"input": "import os \n import sys \n def main ( ) : \n os . environ . setdefault ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n try : \n from django . core . management import execute_from_command_line \n except ImportError as exc : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\"", "output": "\"<STR_LIT>\" \n ) from exc \n execute_from_command_line ( sys . argv ) \n if __name__ == \"<STR_LIT>\" : \n main ( )"}, {"input": "from rest_framework . response import Response \n class SuccessResponse ( Response ) : \n def __init__ ( self , data = None , msg = '<STR_LIT>' , status = None , template_name = None , headers = None , exception = False , \n content_type = None , page = <NUM_LIT> , limit = <NUM_LIT> , total = <NUM_LIT> ) : \n std_data = { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : page , \n \"<STR_LIT>\" : limit , \n \"<STR_LIT>\" : total , \n \"<STR_LIT>\" : data , \n \"<STR_LIT>\" : msg \n } \n super ( ) . __init__ ( std_data , status , template_name , headers , exception , content_type ) \n class DetailResponse ( Response ) : \n def __init__ ( self , data = None , msg = '<STR_LIT>' , status = None , template_name = None , headers = None , exception = False , \n content_type = None , ) : \n std_data = { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : data , \n \"<STR_LIT>\" : msg \n } \n super ( ) . __init__ ( std_data , status , template_name , headers , exception , content_type ) \n class ErrorResponse ( Response ) : \n def __init__ ( self , data = None , msg = '<STR_LIT>' , code = <NUM_LIT> , status = None , template_name = None , headers = None , \n exception = False , content_type = None ) : \n std_data = {", "output": "\"<STR_LIT>\" : code , \n \"<STR_LIT>\" : data , \n \"<STR_LIT>\" : msg \n } \n super ( ) . __init__ ( std_data , status , template_name , headers , exception , content_type )"}, {"input": "import io \n import os \n from pathlib import Path \n from unittest . mock import patch \n import tomlkit \n from cappa . testing import CommandRunner \n def test_sync_dotenv ( runner : CommandRunner , pyproject_toml ) : \n runner . invoke ( \"<STR_LIT>\" ) \n env_file = Path ( \"<STR_LIT>\" ) \n env_template_file = Path ( \"<STR_LIT>\" ) \n assert env_file . exists ( ) \n assert env_template_file . exists ( ) \n assert \"<STR_LIT>\" in env_file . read_text ( ) \n assert \"<STR_LIT>\" in env_template_file . read_text ( ) \n def test_sync_dotenv_update_files ( runner : CommandRunner , pyproject_toml ) : \n env_file = Path ( \"<STR_LIT>\" ) \n env_template_file = Path ( \"<STR_LIT>\" ) \n env_file . write_text ( \"<STR_LIT>\" ) \n env_template_file . write_text ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" ) \n assert \"<STR_LIT>\" in env_file . read_text ( ) \n assert \"<STR_LIT>\" in env_template_file . read_text ( ) \n def test_sync_dotenv_priority ( runner : CommandRunner , pyproject_toml ) : \n env_file = Path ( \"<STR_LIT>\" ) \n env_template_file = Path ( \"<STR_LIT>\" ) \n env_file . write_text ( \"<STR_LIT>\" ) \n env_template_file . write_text ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" ) \n assert \"<STR_LIT>\" in env_file . read_text ( ) \n def test_print_value ( runner : CommandRunner , pyproject_toml ) : \n env_template_file = Path ( \"<STR_LIT>\" )", "output": "env_template_file . write_text ( \"<STR_LIT>\" ) \n with patch ( \"<STR_LIT>\" , new = io . StringIO ( ) ) as fake_stdout : \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n stdout = fake_stdout . getvalue ( ) \n assert not Path ( \"<STR_LIT>\" ) . exists ( ) \n assert \"<STR_LIT>\" in stdout \n def test_prod_config ( runner : CommandRunner , pyproject_toml ) : \n os . environ [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n pyproject = tomlkit . parse ( pyproject_toml . read_text ( ) ) \n pyproject [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } ] \n pyproject_toml . write_text ( tomlkit . dumps ( pyproject ) ) \n runner . invoke ( \"<STR_LIT>\" ) \n assert \"<STR_LIT>\" in Path ( \"<STR_LIT>\" ) . read_text ( ) \n assert \"<STR_LIT>\" in Path ( \"<STR_LIT>\" ) . read_text ( ) \n assert \"<STR_LIT>\" in Path ( \"<STR_LIT>\" ) . read_text ( )"}, {"input": "from pathlib import Path \n import environ \n BASE_DIR = Path ( __file__ ) . resolve ( strict = True ) . parent . parent . parent \n APPS_DIR = BASE_DIR / \"<STR_LIT>\" \n env = environ . Env ( ) \n READ_DOT_ENV_FILE = env . bool ( \"<STR_LIT>\" , default = False ) \n if READ_DOT_ENV_FILE : \n env . read_env ( str ( BASE_DIR / \"<STR_LIT>\" ) ) \n USE_AWS = env . bool ( \"<STR_LIT>\" , False ) \n DEBUG = env . bool ( \"<STR_LIT>\" , False ) \n TIME_ZONE = \"<STR_LIT>\" \n LANGUAGE_CODE = \"<STR_LIT>\" \n SITE_ID = <NUM_LIT> \n USE_I18N = True \n USE_TZ = True \n LOCALE_PATHS = [ str ( BASE_DIR / \"<STR_LIT>\" ) ] \n DATABASES = { \"<STR_LIT>\" : env . db ( \"<STR_LIT>\" ) } \n DEFAULT_AUTO_FIELD = \"<STR_LIT>\" \n ROOT_URLCONF = \"<STR_LIT>\" \n WSGI_APPLICATION = \"<STR_LIT>\" \n DJANGO_APPS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ,", "output": "] \n THIRD_PARTY_APPS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n LOCAL_APPS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n INSTALLED_APPS = DJANGO_APPS + THIRD_PARTY_APPS + LOCAL_APPS \n MIGRATION_MODULES = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n AUTHENTICATION_BACKENDS = [ \n \"<STR_LIT>\" , \n ] \n AUTH_USER_MODEL = \"<STR_LIT>\" \n LOGIN_REDIRECT_URL = \"<STR_LIT>\" \n LOGIN_URL = \"<STR_LIT>\" \n PASSWORD_HASHERS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n AUTH_PASSWORD_VALIDATORS = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ] \n MIDDLEWARE = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n STATIC_ROOT = str ( BASE_DIR / \"<STR_LIT>\" ) \n STATICFILES_DIRS = [ str ( APPS_DIR / \"<STR_LIT>\" ) ] \n STATICFILES_FINDERS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n if not USE_AWS : \n STATIC_URL = \"<STR_LIT>\" \n print ( f\"<STR_LIT>\" ) \n MEDIA_ROOT = str ( APPS_DIR / \"<STR_LIT>\" ) \n MEDIA_URL = \"<STR_LIT>\" \n else : \n INSTALLED_APPS += [ \"<STR_LIT>\" ] \n AWS_ACCESS_KEY_ID = env ( \"<STR_LIT>\" ) \n AWS_SECRET_ACCESS_KEY = env ( \"<STR_LIT>\" ) \n AWS_STORAGE_BUCKET_NAME = env ( \"<STR_LIT>\" ) \n AWS_QUERYSTRING_AUTH = True \n _AWS_EXPIRY = <NUM_LIT> * <NUM_LIT> * <NUM_LIT> * <NUM_LIT> \n AWS_S3_OBJECT_PARAMETERS = { \n \"<STR_LIT>\" : f\"<STR_LIT>\" \n } \n AWS_S3_REGION_NAME = env ( \"<STR_LIT>\" , default = None ) \n AWS_S3_CUSTOM_DOMAIN = env ( \"<STR_LIT>\" , default = None ) \n aws_s3_domain = ( \n AWS_S3_CUSTOM_DOMAIN or f\"<STR_LIT>\" \n ) \n S3_ACCESS_KEY = AWS_ACCESS_KEY_ID \n S3_SECRET_KEY = AWS_SECRET_ACCESS_KEY \n S3_BUCKET = AWS_STORAGE_BUCKET_NAME \n S3_PREFIX = env ( \"<STR_LIT>\" , default = \"<STR_LIT>\" ) \n S3_COMPRESSION_LEVEL = int ( env ( \"<STR_LIT>\" , default = <NUM_LIT> ) ) \n STATICFILES_STORAGE = \"<STR_LIT>\" \n STATIC_URL = f\"<STR_LIT>\" \n DEFAULT_FILE_STORAGE = \"<STR_LIT>\" \n MEDIA_URL = f\"<STR_LIT>\" \n MEDIA_ROOT = str ( APPS_DIR / \"<STR_LIT>\" ) \n INSTALLED_APPS += [ \"<STR_LIT>\" ] \n COLLECTFAST_STRATEGY = \"<STR_LIT>\" \n TEMPLATES = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ str ( APPS_DIR / \"<STR_LIT>\" ) ] , \n \"<STR_LIT>\" : True , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n } , \n } \n ] \n FORM_RENDERER = \"<STR_LIT>\" \n CRISPY_TEMPLATE_PACK = \"<STR_LIT>\" \n CRISPY_ALLOWED_TEMPLATE_PACKS = \"<STR_LIT>\" \n FIXTURE_DIRS = ( str ( APPS_DIR / \"<STR_LIT>\" ) , ) \n SESSION_COOKIE_HTTPONLY = True \n CSRF_COOKIE_HTTPONLY = True \n X_FRAME_OPTIONS = \"<STR_LIT>\" \n EMAIL_BACKEND = env ( \n \"<STR_LIT>\" , \n default = \"<STR_LIT>\" , \n ) \n EMAIL_TIMEOUT = <NUM_LIT> \n ADMIN_URL = \"<STR_LIT>\" \n ADMINS = [ ( , \"<STR_LIT>\" ) ] \n MANAGERS = ADMINS \n LOGGING = { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n \"<STR_LIT>\" \n } \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n } , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : [ \"<STR_LIT>\" ] } , \n } \n if USE_TZ : \n CELERY_TIMEZONE = TIME_ZONE \n CELERY_BROKER_URL = env ( \"<STR_LIT>\" ) \n CELERY_RESULT_BACKEND = CELERY_BROKER_URL \n CELERY_RESULT_EXTENDED = True \n CELERY_RESULT_BACKEND_ALWAYS_RETRY = True \n CELERY_RESULT_BACKEND_MAX_RETRIES = <NUM_LIT> \n CELERY_ACCEPT_CONTENT = [ \"<STR_LIT>\" ] \n CELERY_TASK_SERIALIZER = \"<STR_LIT>\" \n CELERY_RESULT_SERIALIZER = \"<STR_LIT>\" \n CELERY_TASK_TIME_LIMIT = <NUM_LIT> * <NUM_LIT> \n CELERY_TASK_SOFT_TIME_LIMIT = <NUM_LIT> \n CELERY_BEAT_SCHEDULER = \"<STR_LIT>\" \n CELERY_WORKER_SEND_TASK_EVENTS = True \n CELERY_TASK_SEND_SENT_EVENT = True \n ACCOUNT_ALLOW_REGISTRATION = env . bool ( \"<STR_LIT>\" , True ) \n ACCOUNT_AUTHENTICATION_METHOD = \"<STR_LIT>\" \n ACCOUNT_EMAIL_REQUIRED = True \n ACCOUNT_EMAIL_VERIFICATION = \"<STR_LIT>\" \n ACCOUNT_ADAPTER = \"<STR_LIT>\" \n ACCOUNT_FORMS = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n SOCIALACCOUNT_ADAPTER = \"<STR_LIT>\" \n SOCIALACCOUNT_FORMS = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n OPEN_ACCESS_MODE = env . bool ( \"<STR_LIT>\" , False ) \n ASGI_APPLICATION = \"<STR_LIT>\" \n CHANNEL_LAYERS = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ ( \"<STR_LIT>\" , <NUM_LIT> ) ] , \n } , \n } , \n } \n MODEL_NAME = env ( \"<STR_LIT>\" ) \n MAX_TOKENS = env . int ( \"<STR_LIT>\" , <NUM_LIT> )"}, {"input": "from typing import List , Optional \n from uuid import UUID \n from django . db . models import Q , QuerySet \n from ninja import FilterSchema , Schema \n class Identifiable ( Schema ) : \n id : UUID \n class Representable ( Schema ) : \n name : str \n description : Optional [ str ] = None \n class OrderByFilterSchema ( FilterSchema ) : \n order_by : Optional [ List [ str ] ] = None \n def filter_order_by ( self , value ) -> Q : \n return Q ( ) \n def filter ( self , queryset : QuerySet ) -> QuerySet : \n queryset = super ( ) . filter ( queryset )", "output": "if self . order_by : \n queryset = queryset . order_by ( * self . order_by ) \n return queryset \n class CollectionFilter ( OrderByFilterSchema ) : \n name : Optional [ str ] = None \n class CollectionIn ( Representable ) : \n pass \n class CollectionOut ( Identifiable , Representable ) : \n pass \n class ItemIn ( Representable ) : \n pass \n class ItemOut ( Identifiable , Representable ) : \n collection_id : UUID \n class TagOut ( Identifiable , Representable ) : \n pass \n class UserRequestBody ( Schema ) : \n username : str \n email : str \n password : str \n groups : Optional [ List [ int ] ] = None \n class UserResponseBody ( Schema ) : \n id : int \n username : str \n email : str \n class UserQueryParameters ( Schema ) : \n username__contains : Optional [ str ] = None"}, {"input": "import multiprocessing \n workers = multiprocessing . cpu_count ( ) * <NUM_LIT> + <NUM_LIT> \n threads = <NUM_LIT> \n bind = '<STR_LIT>' \n daemon = '<STR_LIT>' \n worker_class = '<STR_LIT>' \n worker_connections = <NUM_LIT> \n max_requests = <NUM_LIT> \n max_requests_jitter = <NUM_LIT> \n pidfile = '<STR_LIT>' \n loglevel = '<STR_LIT>' \n access_log_format = '<STR_LIT>' \n backlog = <NUM_LIT> \n proc_name = '<STR_LIT>' \n timeout = <NUM_LIT> \n graceful_timeout = <NUM_LIT> \n keepalive = <NUM_LIT> \n limit_request_line = <NUM_LIT>", "output": "limit_request_fields = <NUM_LIT> \n limit_request_field_size = <NUM_LIT> \n accesslog = '<STR_LIT>'"}, {"input": "import django . db . models . deletion \n from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . ForeignKey ( \n help_text = \"<STR_LIT>\" , \n on_delete = django . db . models . deletion . CASCADE ,", "output": "to = \"<STR_LIT>\" , \n ) , \n ) , \n ]"}, {"input": "from django . contrib import admin \n from . models import ArxivPaper , Author , Vote , SummaryPaper , PaperHistory , PDFHistory , PaperScore , PaperAuthor , PickledData , AIassistant , Search \n from django import forms \n from django . db import models \n admin . site . register ( ArxivPaper ) \n admin . site . register ( Author ) \n admin . site . register ( Vote )", "output": "admin . site . register ( PaperAuthor ) \n admin . site . register ( SummaryPaper ) \n admin . site . register ( AIassistant ) \n admin . site . register ( Search ) \n admin . site . register ( PaperScore ) \n class MyModelAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n admin . site . register ( PaperHistory , MyModelAdmin ) \n admin . site . register ( PDFHistory , MyModelAdmin ) \n from django . utils . translation import gettext_lazy as _ \n from django . forms . widgets import ClearableFileInput \n class MyModelAdmin2 ( admin . ModelAdmin ) : \n formfield_overrides = { \n models . BinaryField : { '<STR_LIT>' : forms . Textarea ( attrs = dict ( readonly = True ) ) } , \n } \n admin . site . register ( PickledData , MyModelAdmin2 )"}, {"input": "import django \n from django . contrib import admin \n from django . urls import path \n from api . views import index \n if django . __version__ . split ( '<STR_LIT>' ) [ <NUM_LIT> ] >= '<STR_LIT>' : \n from django . urls import re_path as url \n from django . conf . urls import include \n else : \n from django . conf . urls import url , include", "output": "from django . views import static \n from django . conf import settings \n urlpatterns = [ \n path ( '<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n path ( '<STR_LIT>' , admin . site . urls ) , \n url ( r'<STR_LIT>' , index ) , \n url ( r'<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n url ( r'<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n url ( r'<STR_LIT>' , static . serve , { '<STR_LIT>' : settings . STATIC_ROOT } , name = '<STR_LIT>' ) , \n url ( r'<STR_LIT>' , static . serve , { '<STR_LIT>' : '<STR_LIT>' } , name = '<STR_LIT>' ) , \n ] \n from django . conf . urls import static as sc \n if not settings . DEBUG : \n urlpatterns += sc . static ( settings . STATIC_URL , document_root = settings . STATIC_ROOT )"}, {"input": "from django . db . models import Q \n from rest_framework import serializers \n from dvadmin . system . models import Area \n from dvadmin . utils . json_response import SuccessResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class AreaSerializer ( CustomModelSerializer ) : \n pcode_count = serializers . SerializerMethodField ( read_only = True ) \n hasChild = serializers . SerializerMethodField ( ) \n def get_pcode_count ( self , instance : Area ) : \n return Area . objects . filter ( pcode = instance ) . count ( ) \n def get_hasChild ( self , instance ) : \n hasChild = Area . objects . filter ( pcode = instance . code ) \n if hasChild : \n return True \n return False \n class Meta : \n model = Area \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class AreaCreateUpdateSerializer ( CustomModelSerializer ) :", "output": "class Meta : \n model = Area \n fields = '<STR_LIT>' \n class AreaViewSet ( CustomModelViewSet ) : \n queryset = Area . objects . all ( ) \n serializer_class = AreaSerializer \n extra_filter_class = [ ] \n def get_queryset ( self ) : \n self . request . query_params . _mutable = True \n params = self . request . query_params \n pcode = params . get ( '<STR_LIT>' , None ) \n page = params . get ( '<STR_LIT>' , None ) \n limit = params . get ( '<STR_LIT>' , None ) \n if page : \n del params [ '<STR_LIT>' ] \n if limit : \n del params [ '<STR_LIT>' ] \n if params and pcode : \n queryset = self . queryset . filter ( enable = True , pcode = pcode ) \n else : \n queryset = self . queryset . filter ( enable = True ) \n return queryset"}, {"input": "from django . core . management . base import BaseCommand \n from django_webhook . models import Webhook , WebhookSecret , WebhookTopic \n class Command ( BaseCommand ) : \n help = \"<STR_LIT>\" \n def handle ( self , * args , ** options ) : \n wh , _ = Webhook . objects . update_or_create ( \n url = \"<STR_LIT>\" \n ) \n wh . topics . set ( \n [ \n WebhookTopic . objects . get ( name = \"<STR_LIT>\" ) ,", "output": "WebhookTopic . objects . get ( name = \"<STR_LIT>\" ) , \n ] \n ) \n WebhookSecret . objects . update_or_create ( webhook = wh , token = \"<STR_LIT>\" ) \n wh , _ = Webhook . objects . update_or_create ( \n url = \"<STR_LIT>\" \n ) \n wh . topics . set ( \n [ \n WebhookTopic . objects . get ( name = \"<STR_LIT>\" ) , \n WebhookTopic . objects . get ( name = \"<STR_LIT>\" ) , \n ] \n ) \n WebhookSecret . objects . update_or_create ( webhook = wh , token = \"<STR_LIT>\" )"}, {"input": "from pathlib import Path \n from cappa . testing import CommandRunner \n from falco . config import write_falco_config \n def test_htmx_ext_download ( runner : CommandRunner ) : \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert Path ( \"<STR_LIT>\" ) . exists ( ) \n def test_htmx_ext_download_to_output_dir ( runner : CommandRunner ) : \n output = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , str ( output . resolve ( ) ) ) \n assert ( output / \"<STR_LIT>\" ) . exists ( ) \n def test_htmx_ext_download_to_output_file ( runner : CommandRunner ) :", "output": "output = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , str ( output . resolve ( ) ) ) \n assert output . exists ( ) \n def test_htmx_ext_file_existing_config ( runner : CommandRunner ) : \n pyproject_toml = Path ( \"<STR_LIT>\" ) \n pyproject_toml . touch ( ) \n write_falco_config ( pyproject_path = pyproject_toml , htmx = \"<STR_LIT>\" ) \n output = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert output . exists ( ) \n def test_htmx_ext_download_to_output_file_existing_config ( runner : CommandRunner ) : \n pyproject_toml = Path ( \"<STR_LIT>\" ) \n pyproject_toml . touch ( ) \n write_falco_config ( pyproject_path = pyproject_toml , htmx = \"<STR_LIT>\" ) \n output = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert not output . exists ( ) \n assert Path ( \"<STR_LIT>\" ) . exists ( )"}, {"input": "from django . shortcuts import render \n from django . http import HttpResponseRedirect \n from django . contrib . auth . hashers import make_password \n from django . http import JsonResponse \n from django . db . models import Q \n from django . contrib . auth . decorators import login_required \n from django . contrib import auth \n from api . models import RustDeskPeer , RustDesDevice , UserProfile , ShareLink \n from django . forms . models import model_to_dict \n from django . core . paginator import Paginator \n from django . http import HttpResponse \n from django . conf import settings \n from itertools import chain \n from django . db . models . fields import DateTimeField , DateField , CharField , TextField \n import datetime \n from django . db . models import Model \n import json \n import time \n import hashlib \n import sys \n from io import BytesIO \n import xlwt \n from django . utils . translation import gettext as _ \n salt = '<STR_LIT>' \n EFFECTIVE_SECONDS = <NUM_LIT> \n def getStrMd5 ( s ) : \n if not isinstance ( s , ( str , ) ) : \n s = str ( s ) \n myHash = hashlib . md5 ( ) \n myHash . update ( s . encode ( ) ) \n return myHash . hexdigest ( ) \n def model_to_dict2 ( instance , fields = None , exclude = None , replace = None , default = None ) : \n if not isinstance ( instance , Model ) : \n raise Exception ( _ ( '<STR_LIT>' ) ) \n if replace and type ( replace ) == dict : \n for replace_field in replace . values ( ) : \n if hasattr ( instance , replace_field ) : \n raise Exception ( _ ( f'<STR_LIT>' ) ) \n if default and type ( default ) == dict : \n for default_key in default . keys ( ) : \n if hasattr ( instance , default_key ) : \n raise Exception ( _ ( f'<STR_LIT>' ) ) \n opts = instance . _meta \n data = { } \n for f in chain ( opts . concrete_fields , opts . private_fields , opts . many_to_many ) : \n if not getattr ( f , '<STR_LIT>' , False ) : \n if type ( f ) == DateField or type ( f ) == DateTimeField : \n pass \n else : \n continue \n if fields is not None and f . name not in fields : \n continue \n if exclude and f . name in exclude : \n continue \n key = f . name \n if type ( f ) == DateTimeField : \n value = getattr ( instance , key ) \n value = datetime . datetime . strftime ( value , '<STR_LIT>' ) \n elif type ( f ) == DateField : \n value = getattr ( instance , key ) \n value = datetime . datetime . strftime ( value , '<STR_LIT>' ) \n elif type ( f ) == CharField or type ( f ) == TextField : \n value = getattr ( instance , key ) \n try : \n value = json . loads ( value ) \n except Exception as _ : \n value = value \n else : \n key = f . name \n value = f . value_from_object ( instance ) \n if replace and key in replace . keys ( ) : \n key = replace . get ( key ) \n data [ key ] = value \n if default : \n data . update ( default ) \n return data \n def index ( request ) : \n print ( '<STR_LIT>' , sys . argv ) \n if request . user and request . user . username != '<STR_LIT>' : \n return HttpResponseRedirect ( '<STR_LIT>' )", "output": "return HttpResponseRedirect ( '<STR_LIT>' ) \n def user_action ( request ) : \n action = request . GET . get ( '<STR_LIT>' , '<STR_LIT>' ) \n if action == '<STR_LIT>' : \n return user_login ( request ) \n elif action == '<STR_LIT>' : \n return user_register ( request ) \n elif action == '<STR_LIT>' : \n return user_logout ( request ) \n else : \n return \n def user_login ( request ) : \n if request . method == '<STR_LIT>' : \n return render ( request , '<STR_LIT>' ) \n username = request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) \n password = request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) \n if not username or not password : \n return JsonResponse ( { '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : _ ( '<STR_LIT>' ) } ) \n user = auth . authenticate ( username = username , password = password ) \n if user : \n auth . login ( request , user ) \n return JsonResponse ( { '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : '<STR_LIT>' } ) \n else : \n return JsonResponse ( { '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : _ ( '<STR_LIT>' ) } ) \n def user_register ( request ) : \n info = '<STR_LIT>' \n if request . method == '<STR_LIT>' : \n return render ( request , '<STR_LIT>' ) \n ALLOW_REGISTRATION = settings . ALLOW_REGISTRATION \n result = { \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : '<STR_LIT>' \n } \n if not ALLOW_REGISTRATION : \n result [ '<STR_LIT>' ] = _ ( '<STR_LIT>' ) \n return JsonResponse ( result ) \n username = request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) \n password1 = request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) \n if len ( username ) <= <NUM_LIT> : \n info = _ ( '<STR_LIT>' ) \n result [ '<STR_LIT>' ] = info \n return JsonResponse ( result ) \n if len ( password1 ) < <NUM_LIT> or len ( password1 ) > <NUM_LIT> : \n info = _ ( '<STR_LIT>' ) \n result [ '<STR_LIT>' ] = info \n return JsonResponse ( result ) \n user = UserProfile . objects . filter ( Q ( username = username ) ) . first ( ) \n if user : \n info = _ ( '<STR_LIT>' ) \n result [ '<STR_LIT>' ] = info \n return JsonResponse ( result ) \n user = UserProfile ( \n username = username , \n password = make_password ( password1 ) , \n is_admin = True if UserProfile . objects . count ( ) == <NUM_LIT> else False , \n is_superuser = True if UserProfile . objects . count ( ) == <NUM_LIT> else False , \n is_active = True \n ) \n user . save ( ) \n result [ '<STR_LIT>' ] = info \n result [ '<STR_LIT>' ] = <NUM_LIT> \n return JsonResponse ( result ) \n @ login_required ( login_url = '<STR_LIT>' ) \n def user_logout ( request ) : \n info = '<STR_LIT>' \n auth . logout ( request ) \n return HttpResponseRedirect ( '<STR_LIT>' ) \n def get_single_info ( uid ) : \n peers = RustDeskPeer . objects . filter ( Q ( uid = uid ) ) \n rids = [ x . rid for x in peers ] \n peers = { x . rid : model_to_dict ( x ) for x in peers } \n devices = RustDesDevice . objects . filter ( rid__in = rids ) \n devices = { x . rid : x for x in devices } \n now = datetime . datetime . now ( ) \n for rid , device in devices . items ( ) : \n peers [ rid ] [ '<STR_LIT>' ] = device . create_time . strftime ( '<STR_LIT>' ) \n peers [ rid ] [ '<STR_LIT>' ] = device . update_time . strftime ( '<STR_LIT>' ) \n peers [ rid ] [ '<STR_LIT>' ] = device . version \n peers [ rid ] [ '<STR_LIT>' ] = device . memory \n peers [ rid ] [ '<STR_LIT>' ] = device . cpu \n peers [ rid ] [ '<STR_LIT>' ] = device . os \n peers [ rid ] [ '<STR_LIT>' ] = _ ( '<STR_LIT>' ) if ( now - device . update_time ) . seconds <= <NUM_LIT> else _ ( '<STR_LIT>' ) \n for rid in peers . keys ( ) : \n peers [ rid ] [ '<STR_LIT>' ] = _ ( '<STR_LIT>' ) if len ( peers [ rid ] [ '<STR_LIT>' ] ) > <NUM_LIT> else _ ( '<STR_LIT>' ) \n return [ v for k , v in peers . items ( ) ] \n def get_all_info ( ) : \n devices = RustDesDevice . objects . all ( ) \n peers = RustDeskPeer . objects . all ( ) \n devices = { x . rid : model_to_dict2 ( x ) for x in devices } \n now = datetime . datetime . now ( ) \n for peer in peers : \n user = UserProfile . objects . filter ( Q ( id = peer . uid ) ) . first ( ) \n device = devices . get ( peer . rid , None ) \n if device : \n devices [ peer . rid ] [ '<STR_LIT>' ] = user . username \n for k , v in devices . items ( ) : \n devices [ k ] [ '<STR_LIT>' ] = _ ( '<STR_LIT>' ) if ( now - datetime . datetime . strptime ( v [ '<STR_LIT>' ] , '<STR_LIT>' ) ) . seconds <= <NUM_LIT> else _ ( '<STR_LIT>' ) \n return [ v for k , v in devices . items ( ) ] \n @ login_required ( login_url = '<STR_LIT>' ) \n def work ( request ) : \n username = request . user \n u = UserProfile . objects . get ( username = username ) \n show_type = request . GET . get ( '<STR_LIT>' , '<STR_LIT>' ) \n show_all = True if show_type == '<STR_LIT>' and u . is_admin else False \n paginator = Paginator ( get_all_info ( ) , <NUM_LIT> ) if show_type == '<STR_LIT>' and u . is_admin else Paginator ( get_single_info ( u . id ) , <NUM_LIT> ) \n page_number = request . GET . get ( '<STR_LIT>' ) \n page_obj = paginator . get_page ( page_number ) \n return render ( request , '<STR_LIT>' , { '<STR_LIT>' : u , '<STR_LIT>' : show_all , '<STR_LIT>' : page_obj } ) \n @ login_required ( login_url = '<STR_LIT>' ) \n def down_peers ( request ) : \n username = request . user \n u = UserProfile . objects . get ( username = username ) \n if not u . is_admin : \n print ( u . is_admin ) \n return HttpResponseRedirect ( '<STR_LIT>' ) \n all_info = get_all_info ( ) \n f = xlwt . Workbook ( encoding = '<STR_LIT>' ) \n sheet1 = f . add_sheet ( _ ( u'<STR_LIT>' ) , cell_overwrite_ok = True ) \n all_fields = [ x . name for x in RustDesDevice . _meta . get_fields ( ) ] \n all_fields . append ( '<STR_LIT>' ) \n for i , one in enumerate ( all_info ) : \n for j , name in enumerate ( all_fields ) : \n if i == <NUM_LIT> : \n sheet1 . write ( i , j , name ) \n sheet1 . write ( i + <NUM_LIT> , j , one . get ( name , '<STR_LIT>' ) ) \n sio = BytesIO ( ) \n f . save ( sio ) \n sio . seek ( <NUM_LIT> ) \n response = HttpResponse ( sio . getvalue ( ) , content_type = '<STR_LIT>' ) \n response [ '<STR_LIT>' ] = '<STR_LIT>' \n response . write ( sio . getvalue ( ) ) \n return response \n def check_sharelink_expired ( sharelink ) : \n now = datetime . datetime . now ( ) \n if sharelink . create_time > now : \n return False \n if ( now - sharelink . create_time ) . seconds < <NUM_LIT> * <NUM_LIT> : \n return False \n else : \n sharelink . is_expired = True \n sharelink . save ( ) \n return True \n @ login_required ( login_url = '<STR_LIT>' ) \n def share ( request ) : \n peers = RustDeskPeer . objects . filter ( Q ( uid = request . user . id ) ) \n sharelinks = ShareLink . objects . filter ( Q ( uid = request . user . id ) & Q ( is_used = False ) & Q ( is_expired = False ) ) \n now = datetime . datetime . now ( ) \n for sl in sharelinks : \n check_sharelink_expired ( sl ) \n sharelinks = ShareLink . objects . filter ( Q ( uid = request . user . id ) & Q ( is_used = False ) & Q ( is_expired = False ) ) \n peers = [ { '<STR_LIT>' : ix + <NUM_LIT> , '<STR_LIT>' : f'<STR_LIT>' } for ix , p in enumerate ( peers ) ] \n sharelinks = [ { '<STR_LIT>' : s . shash , '<STR_LIT>' : s . is_used , '<STR_LIT>' : s . is_expired , '<STR_LIT>' : s . create_time , '<STR_LIT>' : s . peers } for ix , s in enumerate ( sharelinks ) ] \n if request . method == '<STR_LIT>' : \n url = request . build_absolute_uri ( ) \n if url . endswith ( '<STR_LIT>' ) : \n return render ( request , '<STR_LIT>' , { '<STR_LIT>' : peers , '<STR_LIT>' : sharelinks } ) \n else : \n shash = url . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] \n sharelink = ShareLink . objects . filter ( Q ( shash = shash ) ) \n msg = '<STR_LIT>' \n title = '<STR_LIT>' \n if not sharelink : \n title = '<STR_LIT>' \n msg = f'<STR_LIT>' \n else : \n sharelink = sharelink [ <NUM_LIT> ] \n if str ( request . user . id ) == str ( sharelink . uid ) : \n title = '<STR_LIT>' \n msg = f'<STR_LIT>' \n else : \n sharelink . is_used = True \n sharelink . save ( ) \n peers = sharelink . peers \n peers = peers . split ( '<STR_LIT>' ) \n peers_self_ids = [ x . rid for x in RustDeskPeer . objects . filter ( Q ( uid = request . user . id ) ) ] \n peers_share = RustDeskPeer . objects . filter ( Q ( rid__in = peers ) & Q ( uid = sharelink . uid ) ) \n peers_share_ids = [ x . rid for x in peers_share ] \n for peer in peers_share : \n if peer . rid in peers_self_ids : \n continue \n peer_f = RustDeskPeer . objects . filter ( Q ( rid = peer . rid ) & Q ( uid = sharelink . uid ) ) \n if not peer_f : \n msg += f\"<STR_LIT>\" \n continue \n if len ( peer_f ) > <NUM_LIT> : \n msg += f'<STR_LIT>' \n continue \n peer = peer_f [ <NUM_LIT> ] \n peer . id = None \n peer . uid = request . user . id \n peer . save ( ) \n msg += f\"<STR_LIT>\" \n msg += '<STR_LIT>' \n title = _ ( title ) \n msg = _ ( msg ) \n return render ( request , '<STR_LIT>' , { '<STR_LIT>' : msg , '<STR_LIT>' : msg } ) \n else : \n data = request . POST . get ( '<STR_LIT>' , '<STR_LIT>' ) \n data = json . loads ( data ) \n if not data : \n return JsonResponse ( { '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : _ ( '<STR_LIT>' ) } ) \n rustdesk_ids = [ x [ '<STR_LIT>' ] . split ( '<STR_LIT>' ) [ <NUM_LIT> ] for x in data ] \n rustdesk_ids = '<STR_LIT>' . join ( rustdesk_ids ) \n sharelink = ShareLink ( \n uid = request . user . id , \n shash = getStrMd5 ( str ( time . time ( ) ) + salt ) , \n peers = rustdesk_ids , \n ) \n sharelink . save ( ) \n return JsonResponse ( { '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : sharelink . shash } )"}, {"input": "from . abstract_model_view import AbstractModelView \n from . abstract_view import AbstractView \n from . create_model_view import CreateModelView \n from . delete_model_view import DeleteModelView \n from . list_model_view import ListModelView \n from . read_model_view import ReadModelView \n from . update_model_view import UpdateModelView \n __all__ = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" , \n ]"}, {"input": "from pathlib import Path \n from cappa . testing import CommandRunner \n from falco . config import write_falco_config \n def test_install_crud_utils ( runner : CommandRunner , pyproject_toml ) : \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert Path ( \"<STR_LIT>\" ) . exists ( ) \n assert Path ( \"<STR_LIT>\" ) . exists ( ) \n assert Path ( \"<STR_LIT>\" ) . exists ( )", "output": "def test_install_crud_utils_to_output_dir ( runner : CommandRunner , pyproject_toml ) : \n output = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" , str ( output . resolve ( ) ) ) \n assert ( output / \"<STR_LIT>\" ) . exists ( ) \n assert ( output / \"<STR_LIT>\" ) . exists ( ) \n assert ( output / \"<STR_LIT>\" ) . exists ( ) \n def test_install_crud_utils_to_existing_config ( runner : CommandRunner , pyproject_toml ) : \n pyproject_toml = Path ( \"<STR_LIT>\" ) \n write_falco_config ( pyproject_path = pyproject_toml , crud = { \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n output = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" ) \n assert ( output / \"<STR_LIT>\" ) . exists ( ) \n assert ( output / \"<STR_LIT>\" ) . exists ( ) \n assert ( output / \"<STR_LIT>\" ) . exists ( )"}, {"input": "from django . db import migrations , models", "output": "class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . BinaryField ( ) ) , \n ( '<STR_LIT>' , models . BinaryField ( ) ) , \n ( '<STR_LIT>' , models . BinaryField ( ) ) , \n ] , \n ) , \n ]"}, {"input": "from pathlib import Path \n import pytest \n from merge_production_dotenvs_in_dotenv import merge \n @ pytest . mark . parametrize ( \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n [ \n ( [ ] , \"<STR_LIT>\" ) , \n ( [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) , \n ( [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) , \n ( [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , \"<STR_LIT>\" ) , \n ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \"<STR_LIT>\" ) , \n ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \"<STR_LIT>\" ) , \n ] ,", "output": ") \n def test_merge ( \n tmp_path : Path , \n input_contents : list [ str ] , \n expected_output : str , \n ) : \n output_file = tmp_path / \"<STR_LIT>\" \n files_to_merge = [ ] \n for num , input_content in enumerate ( input_contents , start = <NUM_LIT> ) : \n merge_file = tmp_path / f\"<STR_LIT>\" \n merge_file . write_text ( input_content ) \n files_to_merge . append ( merge_file ) \n merge ( output_file , files_to_merge ) \n assert output_file . read_text ( ) == expected_output"}, {"input": "from django . contrib import admin \n from django . urls import path , include \n from chat . views import conversation , gen_title , upload_conversations \n urlpatterns = [ \n path ( '<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n path ( '<STR_LIT>' , conversation , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , upload_conversations , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , gen_title , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , include ( '<STR_LIT>' ) ) ,", "output": "path ( '<STR_LIT>' , admin . site . urls ) , \n ]"}, {"input": "from django . db import models \n class Order ( models . Model ) :", "output": "name = models . CharField ( max_length = <NUM_LIT> ) \n email = models . EmailField ( ) \n address = models . CharField ( max_length = <NUM_LIT> ) \n postal_code = models . CharField ( max_length = <NUM_LIT> ) \n city = models . CharField ( max_length = <NUM_LIT> ) \n products = models . ManyToManyField ( \"<STR_LIT>\" ) \n created = models . DateTimeField ( auto_now_add = True ) \n completed = models . BooleanField ( default = False ) \n receipt = models . FileField ( null = True , blank = True ) \n image = models . ImageField ( null = True , blank = True )"}, {"input": "import os \n import sys \n def main ( ) : \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n try : \n from django . core . management import execute_from_command_line \n except ImportError as exc : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) from exc \n execute_from_command_line ( sys . argv )", "output": "if __name__ == '<STR_LIT>' : \n main ( )"}, {"input": "import django_filters \n from django . db . models import Q \n from django_filters . rest_framework import BooleanFilter \n from rest_framework import serializers \n from rest_framework . views import APIView \n from application import dispatch \n from dvadmin . system . models import SystemConfig \n from dvadmin . utils . json_response import DetailResponse , SuccessResponse , ErrorResponse \n from dvadmin . utils . models import get_all_models_objects \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . validator import CustomValidationError \n from dvadmin . utils . viewset import CustomModelViewSet \n class SystemConfigCreateSerializer ( CustomModelSerializer ) : \n form_item_type_label = serializers . CharField ( source = '<STR_LIT>' , read_only = True ) \n class Meta : \n model = SystemConfig \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n def validate_key ( self , value ) : \n instance = SystemConfig . objects . filter ( key = value , parent__isnull = True ) . exists ( ) \n if instance : \n raise CustomValidationError ( '<STR_LIT>' ) \n return value \n class SystemConfigSerializer ( CustomModelSerializer ) : \n form_item_type_label = serializers . CharField ( source = '<STR_LIT>' , read_only = True ) \n class Meta : \n model = SystemConfig \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class SystemConfigChinldernSerializer ( CustomModelSerializer ) : \n children = serializers . SerializerMethodField ( ) \n form_item_type_label = serializers . CharField ( source = '<STR_LIT>' , read_only = True ) \n def get_children ( self , instance ) : \n queryset = SystemConfig . objects . filter ( parent = instance ) \n serializer = SystemConfigSerializer ( queryset , many = True ) \n return serializer . data \n class Meta : \n model = SystemConfig \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class SystemConfigListSerializer ( CustomModelSerializer ) : \n def update ( self , instance , validated_data ) : \n instance_mapping = { obj . id : obj for obj in instance } \n data_mapping = { item [ '<STR_LIT>' ] : item for item in validated_data } \n for obj_id , data in data_mapping . items ( ) : \n instance_obj = instance_mapping . get ( obj_id , None ) \n if instance_obj is None : \n return SystemConfig . objects . create ( ** data ) \n else : \n return instance_obj . objects . update ( ** data ) \n class Meta : \n model = SystemConfig \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class SystemConfigSaveSerializer ( serializers . Serializer ) : \n class Meta : \n read_only_fields = [ \"<STR_LIT>\" ] \n list_serializer_class = SystemConfigListSerializer \n class SystemConfigFilter ( django_filters . rest_framework . FilterSet ) : \n parent__isnull = BooleanFilter ( field_name = '<STR_LIT>' , lookup_expr = \"<STR_LIT>\" ) \n class Meta : \n model = SystemConfig \n fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n class SystemConfigViewSet ( CustomModelViewSet ) : \n queryset = SystemConfig . objects . order_by ( '<STR_LIT>' , '<STR_LIT>' ) \n serializer_class = SystemConfigChinldernSerializer \n create_serializer_class = SystemConfigCreateSerializer \n retrieve_serializer_class = SystemConfigChinldernSerializer \n filter_class = SystemConfigFilter \n def save_content ( self , request ) : \n body = request . data \n data_mapping = { item [ '<STR_LIT>' ] : item for item in body } \n for obj_id , data in data_mapping . items ( ) : \n instance_obj = SystemConfig . objects . filter ( id = obj_id ) . first ( ) \n if instance_obj is None : \n serializer = SystemConfigCreateSerializer ( data = data ) \n else : \n serializer = SystemConfigCreateSerializer ( instance_obj , data = data ) \n if serializer . is_valid ( raise_exception = True ) : \n serializer . save ( ) \n return DetailResponse ( msg = \"<STR_LIT>\" ) \n def get_association_table ( self , request ) : \n res = [ ele . get ( '<STR_LIT>' ) for ele in get_all_models_objects ( ) . values ( ) ] \n return DetailResponse ( msg = \"<STR_LIT>\" , data = res ) \n def get_table_data ( self , request , pk ) : \n instance = SystemConfig . objects . filter ( id = pk ) . first ( ) \n if instance is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n setting = instance . setting \n if setting is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n table = setting . get ( '<STR_LIT>' ) \n model = get_all_models_objects ( table ) . get ( \"<STR_LIT>\" , { } ) \n queryset = model . objects . values ( ) \n body = request . query_params \n search_value = body . get ( '<STR_LIT>' , None ) \n if search_value : \n search_fields = setting . get ( '<STR_LIT>' ) \n filters = Q ( ) \n filters . connector = '<STR_LIT>' \n for item in search_fields : \n filed = '<STR_LIT>' . format ( item . get ( '<STR_LIT>' ) ) \n filters . children . append ( ( filed , search_value ) ) \n queryset = model . objects . filter ( filters ) . values ( ) \n page = self . paginate_queryset ( queryset ) \n if page is not None : \n return self . get_paginated_response ( queryset ) \n return SuccessResponse ( msg = \"<STR_LIT>\" , data = queryset , total = len ( queryset ) ) \n def get_relation_info ( self , request ) : \n body = request . query_params \n var_name = body . get ( '<STR_LIT>' , None ) \n table = body . get ( '<STR_LIT>' , None ) \n instance = SystemConfig . objects . filter ( key = var_name , setting__table = table ) . first ( ) \n if instance is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n relation_id = body . get ( '<STR_LIT>' , None ) \n relationIds = [ ] \n if relation_id is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n if instance . form_item_type in [ <NUM_LIT> ] : \n relationIds = [ relation_id ] \n elif instance . form_item_type in [ <NUM_LIT> ] : \n relationIds = relation_id . split ( '<STR_LIT>' ) \n queryset = SystemConfig . objects . filter ( value__in = relationIds ) . first ( ) \n if queryset is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n serializer = SystemConfigChinldernSerializer ( queryset . parent ) \n return DetailResponse ( msg = \"<STR_LIT>\" , data = serializer . data ) \n class InitSettingsViewSet ( APIView ) : \n authentication_classes = [ ] \n permission_classes = [ ] \n def filter_system_config_values ( self , data : dict ) : \n if not self . request . query_params . get ( '<STR_LIT>' , '<STR_LIT>' ) : \n return data \n new_data = { } \n for key in self . request . query_params . get ( '<STR_LIT>' , '<STR_LIT>' ) . split ( '<STR_LIT>' ) : \n if key : \n new_data . update ( ** dict ( filter ( lambda x : x [ <NUM_LIT> ] . startswith ( key ) , data . items ( ) ) ) ) \n return new_data \n def get ( self , request ) :", "output": "data = dispatch . get_system_config ( ) \n if not data : \n dispatch . refresh_system_config ( ) \n data = dispatch . get_system_config ( ) \n backend_config = [ f\"<STR_LIT>\" for ele in \n SystemConfig . objects . filter ( status = False , parent_id__isnull = False ) . values ( '<STR_LIT>' , \n '<STR_LIT>' ) ] \n data = dict ( filter ( lambda x : x [ <NUM_LIT> ] not in backend_config , data . items ( ) ) ) \n data = self . filter_system_config_values ( data = data ) \n return DetailResponse ( data = data )"}, {"input": "import argparse \n import os \n import shutil \n import sys \n import warnings \n from django . core . management import execute_from_command_line \n os . environ [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n sys . path . append ( \"<STR_LIT>\" ) \n def make_parser ( ) : \n parser = argparse . ArgumentParser ( ) \n parser . add_argument ( \n \"<STR_LIT>\" , \n choices = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n default = \"<STR_LIT>\" , \n ) \n return parser \n def parse_args ( args = None ) : \n return make_parser ( ) . parse_known_args ( args ) \n def runtests ( ) : \n args , rest = parse_args ( ) \n only_wagtail = r\"<STR_LIT>\" \n if args . deprecation == \"<STR_LIT>\" : \n warnings . simplefilter ( \"<STR_LIT>\" , DeprecationWarning ) \n warnings . simplefilter ( \"<STR_LIT>\" , PendingDeprecationWarning )", "output": "elif args . deprecation == \"<STR_LIT>\" : \n warnings . filterwarnings ( \n \"<STR_LIT>\" , category = DeprecationWarning , module = only_wagtail \n ) \n warnings . filterwarnings ( \n \"<STR_LIT>\" , category = PendingDeprecationWarning , module = only_wagtail \n ) \n elif args . deprecation == \"<STR_LIT>\" : \n warnings . filterwarnings ( \n \"<STR_LIT>\" , category = DeprecationWarning , module = only_wagtail \n ) \n elif args . deprecation == \"<STR_LIT>\" : \n pass \n argv = [ sys . argv [ <NUM_LIT> ] , * rest ] \n try : \n execute_from_command_line ( argv ) \n finally : \n from wagtail . test . settings import MEDIA_ROOT , STATIC_ROOT \n shutil . rmtree ( STATIC_ROOT , ignore_errors = True ) \n shutil . rmtree ( MEDIA_ROOT , ignore_errors = True ) \n if __name__ == \"<STR_LIT>\" : \n runtests ( )"}, {"input": "import requests , re , datetime , json , os \n from utils . general import headers \n requests . packages . urllib3 . util . ssl_ . DEFAULT_CIPHERS += '<STR_LIT>' \n headers = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' ,", "output": "} \n def get_epgs_nowtv ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n url = '<STR_LIT>' % ( dt . strftime ( \"<STR_LIT>\" ) , channel_id [ : <NUM_LIT> ] ) \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n j = res . json ( ) \n chs = j [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n for ch in chs : \n if \"<STR_LIT>\" == ch or ch != channel_id [ <NUM_LIT> : ] : \n continue \n nowtvid = '<STR_LIT>' % ( channel_id [ : <NUM_LIT> ] , ch . strip ( ) ) \n for channelepg in chs [ ch ] : \n starttime = datetime . datetime . fromtimestamp ( channelepg [ '<STR_LIT>' ] / <NUM_LIT> ) \n endtime = datetime . datetime . fromtimestamp ( channelepg [ '<STR_LIT>' ] / <NUM_LIT> ) \n title = channelepg [ '<STR_LIT>' ] \n desc = channelepg [ '<STR_LIT>' ] \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : endtime , \n '<STR_LIT>' : title , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : starttime . date ( ) , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_nowtv ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n reinfo = re . search ( '<STR_LIT>' , res . text , re . DOTALL ) \n cs = reinfo . group ( <NUM_LIT> ) [ : - <NUM_LIT> ] \n cs = json . loads ( cs ) \n channels = [ ] \n for c in cs : \n if '<STR_LIT>' not in cs [ c ] : \n continue \n id1 = cs [ c ] [ '<STR_LIT>' ] [ <NUM_LIT> ] \n id2 = c \n channel_id = '<STR_LIT>' % ( id1 , id2 ) \n print ( cs [ c ] ) \n name = cs [ c ] [ '<STR_LIT>' ] \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ channel_id ] , \n '<STR_LIT>' : url , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n channels . append ( channel ) \n return channels"}, {"input": "from typing import Dict , List , Union \n from rest_framework import serializers \n from rest_framework . exceptions import ValidationError \n from feeds . models import Entry , Location \n class BaseEntrySerializer ( serializers . ModelSerializer ) : \n def validate ( self , attrs : Dict [ str , Union [ str , float , bool ] ] ) : \n if attrs . get ( \"<STR_LIT>\" ) : \n location = attrs . get ( \"<STR_LIT>\" , None ) \n if not location : \n raise ValidationError ( { \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n if len ( location ) != <NUM_LIT> : \n raise ValidationError ( { \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n for loc in location : \n if type ( loc ) != float : \n raise ValidationError ( { \"<STR_LIT>\" : \"<STR_LIT>\" } ) \n return attrs \n class BulkEntrySerializer ( BaseEntrySerializer ) : \n class Meta : \n model = Entry \n fields = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n class EntrySerializer ( BaseEntrySerializer ) : \n def create ( self , validated_data : Dict [ str , Union [ str , bool ] ] ) :", "output": "from feeds . tasks import process_entry \n instance : Entry = super ( ) . create ( validated_data = validated_data ) \n process_entry . apply_async ( kwargs = { \"<STR_LIT>\" : instance . id } ) \n return instance \n class Meta : \n model = Entry \n fields = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n class LocationLiteSerializer ( serializers . ModelSerializer ) : \n class Meta : \n model = Location \n fields = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n class LocationSerializer ( serializers . ModelSerializer ) : \n raw = EntrySerializer ( source = \"<STR_LIT>\" ) \n class Meta : \n model = Location \n fields = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n class LocationFilterParamSerializer ( serializers . Serializer ) : \n timestamp__gte = serializers . DateTimeField ( required = False ) \n timestamp__lte = serializers . DateTimeField ( required = False )"}, {"input": "from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ]", "output": "operations = [ \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) , \n ) , \n ]"}, {"input": "from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ,", "output": "] \n operations = [ \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) , \n ) , \n ]"}, {"input": "from django . contrib . auth import forms as admin_forms \n from django . contrib . auth import get_user_model \n from django . utils . translation import gettext_lazy as _ \n User = get_user_model ( ) \n class UserAdminChangeForm ( admin_forms . UserChangeForm ) : \n class Meta ( admin_forms . UserChangeForm . Meta ) : \n model = User \n class UserAdminCreationForm ( admin_forms . UserCreationForm ) : \n class Meta ( admin_forms . UserCreationForm . Meta ) :", "output": "model = User \n error_messages = { \n \"<STR_LIT>\" : { \"<STR_LIT>\" : _ ( \"<STR_LIT>\" ) } \n }"}, {"input": "import pytest \n from django . test import Client \n from django . urls import reverse \n ELEMENTS_CUSTOM = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n \"<STR_LIT>\" , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n ELEMENT_HEADER = '<STR_LIT>' \n ELEMENT_FOOTER = '<STR_LIT>' \n ELEMENT_USER_TOOL = '<STR_LIT>' \n def request_admin_content ( \n client : Client , \n view_name : str = \"<STR_LIT>\" , \n query_str : str = \"<STR_LIT>\" , \n method : str = \"<STR_LIT>\" , \n follow : bool = True , \n ) -> str : \n path = reverse ( f\"<STR_LIT>\" ) \n response = getattr ( client , method ) ( f\"<STR_LIT>\" , follow = follow ) \n return str ( response . content ) \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n ) \n def test_authenticated ( client_super_admin , view_name ) : \n content = request_admin_content ( client_super_admin , view_name ) \n for element in ELEMENTS_CUSTOM : \n assert element in content \n assert ELEMENT_HEADER in content \n assert ELEMENT_FOOTER in content \n assert ELEMENT_USER_TOOL in content \n def test_popup ( client_super_admin ) : \n content = request_admin_content ( client_super_admin , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n for element in ELEMENTS_CUSTOM : \n assert element not in content \n assert ELEMENT_HEADER not in content \n assert ELEMENT_FOOTER in content \n assert ELEMENT_USER_TOOL not in content \n def test_login ( client_super_admin ) : \n client_super_admin . logout ( ) \n content = request_admin_content ( client_super_admin ) \n for element in ELEMENTS_CUSTOM : \n assert element not in content \n assert ELEMENT_HEADER in content \n assert ELEMENT_FOOTER in content \n assert ELEMENT_USER_TOOL not in content \n def test_logout ( client_super_admin ) : \n content = request_admin_content ( \n client_super_admin , \"<STR_LIT>\" , method = \"<STR_LIT>\" , follow = False", "output": ") \n for element in ELEMENTS_CUSTOM : \n assert element not in content \n assert ELEMENT_HEADER in content \n assert ELEMENT_FOOTER in content \n assert ELEMENT_USER_TOOL not in content"}, {"input": "from rest_framework import serializers \n from rest_framework . decorators import action \n from rest_framework . permissions import IsAuthenticated \n from dvadmin . system . models import Role , Menu , MenuButton , Dept \n from dvadmin . system . views . dept import DeptSerializer \n from dvadmin . system . views . menu import MenuSerializer \n from dvadmin . system . views . menu_button import MenuButtonSerializer \n from dvadmin . utils . crud_mixin import FastCrudMixin \n from dvadmin . utils . field_permission import FieldPermissionMixin \n from dvadmin . utils . json_response import SuccessResponse , DetailResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . validator import CustomUniqueValidator \n from dvadmin . utils . viewset import CustomModelViewSet \n class RoleSerializer ( CustomModelSerializer ) : \n class Meta : \n model = Role \n fields = \"<STR_LIT>\"", "output": "read_only_fields = [ \"<STR_LIT>\" ] \n class RoleCreateUpdateSerializer ( CustomModelSerializer ) : \n menu = MenuSerializer ( many = True , read_only = True ) \n dept = DeptSerializer ( many = True , read_only = True ) \n permission = MenuButtonSerializer ( many = True , read_only = True ) \n key = serializers . CharField ( max_length = <NUM_LIT> , \n validators = [ CustomUniqueValidator ( queryset = Role . objects . all ( ) , message = \"<STR_LIT>\" ) ] ) \n name = serializers . CharField ( max_length = <NUM_LIT> , validators = [ CustomUniqueValidator ( queryset = Role . objects . all ( ) ) ] ) \n def validate ( self , attrs : dict ) : \n return super ( ) . validate ( attrs ) \n class Meta : \n model = Role \n fields = '<STR_LIT>' \n class MenuPermissionSerializer ( CustomModelSerializer ) : \n menuPermission = serializers . SerializerMethodField ( ) \n def get_menuPermission ( self , instance ) : \n is_superuser = self . request . user . is_superuser \n if is_superuser : \n queryset = MenuButton . objects . filter ( menu__id = instance . id ) \n else : \n menu_permission_id_list = self . request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n queryset = MenuButton . objects . filter ( id__in = menu_permission_id_list , menu__id = instance . id ) \n serializer = MenuButtonSerializer ( queryset , many = True , read_only = True ) \n return serializer . data \n class Meta : \n model = Menu \n fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n class MenuButtonPermissionSerializer ( CustomModelSerializer ) : \n isCheck = serializers . SerializerMethodField ( ) \n def get_isCheck ( self , instance ) : \n is_superuser = self . request . user . is_superuser \n if is_superuser : \n return True \n else : \n return MenuButton . objects . filter ( \n menu__id = instance . id , \n role__id__in = self . request . user . role . values_list ( '<STR_LIT>' , flat = True ) , \n ) . exists ( ) \n class Meta : \n model = Menu \n fields = '<STR_LIT>' \n class RoleViewSet ( CustomModelViewSet , FastCrudMixin , FieldPermissionMixin ) : \n queryset = Role . objects . all ( ) \n serializer_class = RoleSerializer \n create_serializer_class = RoleCreateUpdateSerializer \n update_serializer_class = RoleCreateUpdateSerializer \n search_fields = [ '<STR_LIT>' , '<STR_LIT>' ]"}, {"input": "import ast \n import inspect \n import subprocess \n from collections . abc import Callable \n from contextlib import contextmanager \n from pathlib import Path \n from typing import TypeVar \n import cappa \n import httpx \n import tomlkit \n from falco import falco_version \n from rich . progress import Progress \n from rich . progress import SpinnerColumn \n from rich . progress import TextColumn \n ReturnType = TypeVar ( \"<STR_LIT>\" ) \n RICH_SUCCESS_MARKER = \"<STR_LIT>\" \n RICH_ERROR_MARKER = \"<STR_LIT>\" \n RICH_INFO_MARKER = \"<STR_LIT>\" \n def clean_project_name ( val : str ) -> str : \n return val . strip ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def get_pyproject_file ( ) -> Path : \n pyproject_path = Path ( \"<STR_LIT>\" ) \n if pyproject_path . exists ( ) : \n return pyproject_path \n raise cappa . Exit ( \"<STR_LIT>\" , code = <NUM_LIT> ) \n def get_project_name ( ) -> str : \n pyproject = tomlkit . parse ( get_pyproject_file ( ) . read_text ( ) ) \n return pyproject [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n @ contextmanager \n def simple_progress ( description : str , display_text = \"<STR_LIT>\" ) : \n progress = Progress ( SpinnerColumn ( ) , TextColumn ( display_text ) , transient = True ) \n progress . add_task ( description = description , total = None ) \n try : \n yield progress . start ( ) \n finally : \n progress . stop ( ) \n @ contextmanager \n def network_request_with_progress ( url : str , description : str ) : \n try : \n with simple_progress ( description ) : \n yield httpx . get ( url ) \n except httpx . ConnectError as e : \n msg = f\"<STR_LIT>\" \n raise cappa . Exit ( msg , code = <NUM_LIT> ) from e \n class ShellCodeError ( Exception ) : \n pass \n def run_in_shell ( func : Callable [ ... , ReturnType ] , * , eval_result : bool = True , ** kwargs ) -> ReturnType : \n source = inspect . getsource ( func ) \n arguments_list = [ ] \n for k , v in kwargs . items ( ) : \n if isinstance ( v , str ) : \n arguments_list . append ( f\"<STR_LIT>\" ) \n else :", "output": "arguments_list . append ( f\"<STR_LIT>\" ) \n arguments = \"<STR_LIT>\" . join ( arguments_list ) \n func_call = f\"<STR_LIT>\" \n code = f\"<STR_LIT>\" \n result = subprocess . run ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , code ] , \n capture_output = True , \n text = True , \n check = False , \n ) \n if result . returncode != <NUM_LIT> : \n raise ShellCodeError ( result . stderr ) \n return ast . literal_eval ( result . stdout ) if eval_result else result . stdout . strip ( ) \n def is_new_falco_cli_available ( ) -> bool : \n try : \n with network_request_with_progress ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) as response : \n latest_version = response . json ( ) [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n current_version = falco_version \n return latest_version != current_version \n except cappa . Exit : \n return False"}, {"input": "import uuid \n from pathlib import Path \n from unittest import mock \n from channels . testing import WebsocketCommunicator \n from django . contrib . auth import get_user_model \n from django . core . files . base import ContentFile \n from django . test import TransactionTestCase \n from ninja_jwt . tokens import AccessToken \n from config . api . websockets . queries import CollectionQueryConsumer \n from config . asgi import application \n from delphic . indexes . models import Collection , CollectionStatus \n User = get_user_model ( ) \n async def mocked_receive ( self , * args , ** kwargs ) : \n await self . send ( text_data = '<STR_LIT>' ) \n async def mocked_accept ( self , * args , ** kwargs ) : \n await self . accept ( ) \n class TokenAuthMiddlewareTestCase ( TransactionTestCase ) : \n def setUp ( self ) : \n self . user = User . objects . create_user ( \n username = uuid . uuid4 ( ) . __str__ ( ) , password = \"<STR_LIT>\" \n ) \n current_dir = Path . cwd ( ) \n index_file = current_dir / \"<STR_LIT>\" / \"<STR_LIT>\" / \"<STR_LIT>\" \n with index_file . open ( \"<STR_LIT>\" ) as model_file : \n self . collection = Collection . objects . create ( \n title = \"<STR_LIT>\" , \n description = \"<STR_LIT>\" , \n model = ContentFile ( model_file . read ( ) , name = \"<STR_LIT>\" ) , \n status = CollectionStatus . COMPLETE , \n ) \n async def test_middleware_with_valid_token ( self ) : \n token = AccessToken . for_user ( self . user ) \n print ( f\"<STR_LIT>\" ) \n communicator = WebsocketCommunicator ( \n CollectionQueryConsumer . as_asgi ( ) , \n f\"<STR_LIT>\" , \n )", "output": "mock_index = mock . MagicMock ( ) \n with mock . patch ( \n \"<STR_LIT>\" , \n return_value = mock_index , \n ) : \n connected , _ = await communicator . connect ( ) \n self . assertTrue ( connected ) \n await communicator . disconnect ( ) \n async def test_middleware_with_invalid_token ( self ) : \n communicator = WebsocketCommunicator ( \n application , \n f\"<STR_LIT>\" , \n ) \n connected , _ = await communicator . connect ( ) \n self . assertFalse ( connected ) \n self . assertEqual ( communicator . scope [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n await communicator . disconnect ( ) \n async def test_middleware_without_token ( self ) : \n communicator = WebsocketCommunicator ( \n application , \n f\"<STR_LIT>\" , \n ) \n connected , _ = await communicator . connect ( ) \n self . assertFalse ( connected ) \n self . assertEqual ( communicator . scope [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n await communicator . disconnect ( )"}, {"input": "import pytest \n from dev . football . teams . factories import TeamFactory \n from tests import request_search \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , \n [ \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ ] ) , \n ] , \n ) \n def test_apps ( client_super_admin , query , results_expected ) : \n response = request_search ( client_super_admin , query = query ) \n data = response . json ( ) \n results_actual = [ r [ \"<STR_LIT>\" ] for r in data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ] \n assert response . status_code == <NUM_LIT> \n assert len ( results_actual ) == len ( results_expected ) \n assert not set ( results_actual ) . difference ( set ( results_expected ) ) \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , \n [ \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ ] ) ,", "output": "( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) , \n ] , \n ) \n def test_models ( client_super_admin , query , results_expected ) : \n response = request_search ( client_super_admin , query = query ) \n data = response . json ( ) \n results_actual = [ ] \n for app in data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] : \n for model in app [ \"<STR_LIT>\" ] : \n results_actual . append ( model [ \"<STR_LIT>\" ] ) \n assert response . status_code == <NUM_LIT> \n assert len ( results_actual ) == len ( results_expected ) \n assert not set ( results_actual ) . difference ( set ( results_expected ) ) \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , \n [ \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) , \n ( \"<STR_LIT>\" , [ ] ) , \n ] , \n ) \n def test_objects ( client_super_admin , query , results_expected ) : \n for i , n in enumerate ( [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , start = <NUM_LIT> ) : \n TeamFactory ( \n id = i , \n name = f\"<STR_LIT>\" , \n key = f\"<STR_LIT>\" , \n website = f\"<STR_LIT>\" , \n description = f\"<STR_LIT>\" , \n ) \n response = request_search ( client_super_admin , query = query ) \n data = response . json ( ) \n results_actual = [ ] \n for app in data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] : \n for model in app [ \"<STR_LIT>\" ] : \n for obj in model [ \"<STR_LIT>\" ] : \n results_actual . append ( obj [ \"<STR_LIT>\" ] ) \n assert response . status_code == <NUM_LIT> \n assert len ( results_actual ) == len ( results_expected ) \n assert not set ( results_actual ) . difference ( set ( results_expected ) )"}, {"input": "from . abstract_model_view_test import AbstractModelViewTest \n from . create_model_view_test import CreateModelViewTest \n from . delete_model_view_test import DeleteModelViewTest \n from . list_model_view_test import ListModelViewTest \n from . read_model_view_test import ReadModelViewTest \n from . update_model_view_test import UpdateModelViewTest \n __all__ = [", "output": "\"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ]"}, {"input": "from django . core . validators import MaxValueValidator , MinValueValidator \n from django . db import models \n from django . utils . translation import gettext_lazy as _ \n from dev . football . core . models import BaseModel \n from dev . football . players . enums import PlayerPosition \n class Player ( BaseModel ) : \n name = models . CharField ( max_length = <NUM_LIT> , help_text = _ ( \"<STR_LIT>\" ) ) \n key = models . SlugField ( \n max_length = <NUM_LIT> , \n help_text = _ ( \"<STR_LIT>\" ) , \n unique = True , \n ) \n def __str__ ( self ) : \n return self . name \n class PlayerAttributes ( BaseModel ) : \n player = models . OneToOneField ( \n Player , \n primary_key = True , \n on_delete = models . CASCADE , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n position = models . CharField ( \n max_length = <NUM_LIT> ,", "output": "choices = [ ( p . name , p . value ) for p in PlayerPosition ] , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n nationality = models . CharField ( \n max_length = <NUM_LIT> , help_text = _ ( \"<STR_LIT>\" ) \n ) \n age = models . PositiveSmallIntegerField ( help_text = _ ( \"<STR_LIT>\" ) ) \n score_defence = models . PositiveSmallIntegerField ( \n help_text = _ ( \"<STR_LIT>\" ) , \n default = <NUM_LIT> , \n validators = [ MaxValueValidator ( <NUM_LIT> ) , MinValueValidator ( <NUM_LIT> ) ] , \n ) \n score_midfield = models . PositiveSmallIntegerField ( \n help_text = _ ( \"<STR_LIT>\" ) , \n default = <NUM_LIT> , \n validators = [ MaxValueValidator ( <NUM_LIT> ) , MinValueValidator ( <NUM_LIT> ) ] , \n ) \n score_offence = models . PositiveSmallIntegerField ( \n help_text = _ ( \"<STR_LIT>\" ) , \n default = <NUM_LIT> , \n validators = [ MaxValueValidator ( <NUM_LIT> ) , MinValueValidator ( <NUM_LIT> ) ] , \n ) \n class PlayerContract ( BaseModel ) : \n player = models . ForeignKey ( \n Player , on_delete = models . CASCADE , help_text = _ ( \"<STR_LIT>\" ) \n ) \n team = models . ForeignKey ( \n \"<STR_LIT>\" , \n on_delete = models . CASCADE , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n valid_from = models . DateField ( \n help_text = _ ( \"<STR_LIT>\" ) \n ) \n duration = models . PositiveSmallIntegerField ( \n help_text = _ ( \"<STR_LIT>\" ) \n ) \n terms = models . TextField ( help_text = _ ( \"<STR_LIT>\" ) )"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( primary_key = True , serialize = False ) ) , \n ( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> ) ) ,", "output": "( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . CharField ( default = '<STR_LIT>' , max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( blank = True , null = True , on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) ) , \n ] , \n ) , \n ]"}, {"input": "from django . db import migrations", "output": "class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . RemoveField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n ) , \n ]"}, {"input": "import pytest \n from wagtail_ai . models import Prompt \n TEST_PROMPT_LABEL = \"<STR_LIT>\" \n TEST_PROMPT_VALUE = \"<STR_LIT>\" \n TEST_PROMPT_DESCRIPTION = \"<STR_LIT>\" \n @ pytest . fixture \n def test_prompt_values ( ) : \n return { \n \"<STR_LIT>\" : TEST_PROMPT_LABEL , \n \"<STR_LIT>\" : TEST_PROMPT_DESCRIPTION , \n \"<STR_LIT>\" : TEST_PROMPT_VALUE , \n \"<STR_LIT>\" : Prompt . Method . REPLACE . value , \n } \n @ pytest . fixture \n def setup_prompt_object ( test_prompt_values ) : \n prompt = Prompt . objects . create ( ** test_prompt_values ) \n yield prompt \n prompt . delete ( )", "output": "@ pytest . fixture ( autouse = True ) \n def temporary_media ( settings , tmp_path ) : \n settings . MEDIA_ROOT = tmp_path / \"<STR_LIT>\""}, {"input": "import http \n import json \n from typing import Optional , Type , cast \n import django . http \n import django . test \n from ninja import Schema \n from ninja_crud . testing . core import ArgOrCallable , TestCaseType , ViewTestManager \n from ninja_crud . testing . core . components import Headers , PathParameters , Payloads \n from ninja_crud . testing . views import AbstractModelViewTest \n from ninja_crud . views import CreateModelView \n class CreateModelViewTest ( AbstractModelViewTest ) : \n model_view : CreateModelView \n def __init__ ( \n self , \n payloads : ArgOrCallable [ Payloads , TestCaseType ] , \n path_parameters : Optional [ ArgOrCallable [ PathParameters , TestCaseType ] ] = None , \n headers : Optional [ ArgOrCallable [ Headers , TestCaseType ] ] = None , \n ) -> None : \n super ( ) . __init__ ( model_view_class = CreateModelView ) \n self . view_test_manager = ViewTestManager ( \n simulate_request = self . simulate_request , \n path_parameters = path_parameters , \n headers = headers , \n payloads = payloads , \n ) \n def on_successful_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) : \n actual_output = json . loads ( response . content ) \n expected_output = self . _get_expected_output ( \n response = response , \n path_parameters = path_parameters , \n ) \n self . model_viewset_test_case . assertDictEqual ( actual_output , expected_output ) \n def _get_expected_output ( \n self , response : django . http . HttpResponse , path_parameters : dict \n ) -> dict : \n content = json . loads ( response . content ) \n path_parameters_schema = ( \n self . model_view . path_parameters ( ** path_parameters ) \n if self . model_view . path_parameters \n else None \n ) \n model_class = self . model_view . init_model ( \n getattr ( response , \"<STR_LIT>\" , None ) , \n path_parameters_schema , \n ) . __class__ \n model = model_class . objects . get ( id = content [ \"<STR_LIT>\" ] ) \n schema = cast ( Type [ Schema ] , self . model_view . response_body ) . from_orm ( model ) \n return json . loads ( schema . json ( ) ) \n def on_failed_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) : \n pass \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_create_model_ok ( self ) : \n self . view_test_manager . test_view_ok ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_successful_request , \n status = http . HTTPStatus . CREATED , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_create_model_payloads_bad_request ( self ) : \n self . view_test_manager . test_view_payloads_bad_request ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_create_model_payloads_conflict ( self ) : \n self . view_test_manager . test_view_payloads_conflict ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_create_model_headers_unauthorized ( self ) : \n self . view_test_manager . test_view_headers_unauthorized ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_create_model_headers_forbidden ( self ) :", "output": "self . view_test_manager . test_view_headers_forbidden ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_create_model_path_parameters_not_found ( self ) : \n self . view_test_manager . test_view_path_parameters_not_found ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n )"}, {"input": "from rest_framework import filters \n from feeds . serializers import LocationFilterParamSerializer \n class LocationFilterBackend ( filters . BaseFilterBackend ) : \n def filter_queryset ( self , request , queryset , view ) : \n params = LocationFilterParamSerializer ( data = request . query_params ) \n params . is_valid ( raise_exception = True ) \n filter_list = params . validated_data \n timestamp__gte = filter_list . get ( \"<STR_LIT>\" , None ) \n timestamp__lte = filter_list . get ( \"<STR_LIT>\" , None )", "output": "if timestamp__gte : \n queryset = queryset . filter ( raw__timestamp__gte = timestamp__gte ) \n if timestamp__lte : \n queryset = queryset . filter ( raw__timestamp__lte = timestamp__lte ) \n return queryset"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) ,", "output": "] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( primary_key = True , serialize = False ) ) , \n ( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) ) , \n ] , \n ) , \n ]"}, {"input": "from core . helpers . trendyol_bff import TY_BFF \n from core . helpers . regex_api import ExtractInfo \n class AddressAPI : \n def __init__ ( self ) : \n self . ty_geolocation_url = \"<STR_LIT>\" \n self . ty_api = TY_BFF ( self . ty_geolocation_url ) \n self . regex_api = ExtractInfo ( ) \n def trendyol_bff_api_request ( self , address_text : str ) : \n return self . ty_api . request ( address_text ) \n def regex_api_request ( self , address_text : str ) :", "output": "return self . regex_api . extract ( address_text )"}, {"input": "from django . conf import settings \n import django . contrib . auth . models \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( primary_key = True , serialize = False ) ) , \n ( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> , unique = True ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now = True ) ) , \n ( '<STR_LIT>' , models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . URLField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . URLField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . DateField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) ) , \n ( '<STR_LIT>' , models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) ) , \n ( '<STR_LIT>' , models . DateField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . IntegerField ( default = <NUM_LIT> ) ) , \n ] , \n ) , \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . CharField ( blank = True , max_length = <NUM_LIT> , null = True ) ) , \n ] , \n ) , \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . OneToOneField ( auto_created = True , on_delete = django . db . models . deletion . CASCADE , parent_link = True , primary_key = True , serialize = False , to = settings . AUTH_USER_MODEL ) ) , \n ] , \n options = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : False , \n } , \n bases = ( '<STR_LIT>' , ) , \n managers = [ \n ( '<STR_LIT>' , django . contrib . auth . models . UserManager ( ) ) , \n ] , \n ) , \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . SmallIntegerField ( choices = [ ( <NUM_LIT> , '<STR_LIT>' ) , ( - <NUM_LIT> , '<STR_LIT>' ) ] ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . BooleanField ( default = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = '<STR_LIT>' ) ) , \n ] , \n ) , \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) ,", "output": "( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) ) , \n ] , \n ) , \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . PositiveSmallIntegerField ( ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = '<STR_LIT>' ) ) , \n ] , \n options = { \n '<STR_LIT>' : [ '<STR_LIT>' ] , \n '<STR_LIT>' : { ( '<STR_LIT>' , '<STR_LIT>' ) } , \n } , \n ) , \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . ManyToManyField ( blank = True , through = '<STR_LIT>' , to = '<STR_LIT>' ) , \n ) , \n ]"}, {"input": "from . headers import Headers \n from . path_parameters import PathParameters \n from . payloads import Payloads \n from . query_parameters import QueryParameters \n __all__ = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" , \n ]"}, {"input": "from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [", "output": "( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . TextField ( blank = True , null = True ) , \n ) , \n ]"}, {"input": "import subprocess \n from pathlib import Path \n import cappa \n import pytest \n from cappa . testing import CommandRunner \n def makemigaration ( ) : \n subprocess . run ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , check = False ) \n def test_rm_migrations ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n apps_dir = Path ( ) \n makemigaration ( ) \n first_migration = apps_dir / \"<STR_LIT>\" \n assert first_migration . exists ( ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert not first_migration . exists ( ) \n def test_rm_migrations_fake_apps_dir ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n apps_dir = Path ( ) \n makemigaration ( ) \n first_migration = apps_dir / \"<STR_LIT>\" \n assert first_migration . exists ( ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert first_migration . exists ( ) \n def test_rm_migrations_not_clean_repo ( django_project , runner : CommandRunner ) : \n with pytest . raises ( cappa . Exit ) :", "output": "runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" )"}, {"input": "import django , os \n from web . models import Channel_list \n from crawl . spiders import epg_source \n from utils . aboutdb import log \n from utils . general import cht_to_chs \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n django . setup ( ) \n def crawl ( ) : \n for source in epg_source : \n if True == True : \n channels = [ ] \n n = <NUM_LIT> \n try : \n channels = epg_source [ source ] ( )", "output": "for channel in channels : \n channel [ '<STR_LIT>' ] = cht_to_chs ( channel [ '<STR_LIT>' ] ) \n save_ret = Channel_list . save_to_db ( Channel_list , channels ) \n msg = '<STR_LIT>' % ( source , len ( channels ) , save_ret [ '<STR_LIT>' ] ) \n except Exception as e : \n msg = '<STR_LIT>' % ( source , e ) \n log ( msg ) \n for r in channels : \n n += <NUM_LIT> \n print ( n , r [ '<STR_LIT>' ] , '<STR_LIT>' . join ( r [ '<STR_LIT>' ] ) , r [ '<STR_LIT>' ] , r [ '<STR_LIT>' ] , r [ '<STR_LIT>' ] , r [ '<STR_LIT>' ] , r [ '<STR_LIT>' ] )"}, {"input": "from django . contrib . auth . backends import ModelBackend \n from django . contrib . auth import get_user_model \n from django . core . exceptions import PermissionDenied \n User = get_user_model ( ) \n class CustomModelBackend ( ModelBackend ) : \n def authenticate ( self , request , username = None , password = None , ** kwargs ) : \n print ( '<STR_LIT>' ) \n try : \n user = User . objects . get ( username = username ) \n if user . check_password ( password ) : \n return user \n else : \n return None \n except User . DoesNotExist : \n print ( '<STR_LIT>' )", "output": "return None"}, {"input": "import torch \n from transformers import AutoTokenizer \n from plms import mainplm , chunkplm \n from evaluate import evaluation \n from encoder import encode_documents \n from data import asap_essay_lengths , fix_score \n from lossfunctions import multi_loss \n import pandas as pd \n import matplotlib . pyplot as plt \n import math \n from torch . cuda . amp import autocast , GradScaler \n class AESmodel ( ) : \n def __init__ ( self , traindata , valdata , testdata , foldname , args = None ) : \n if args is not None : \n self . args = vars ( args ) \n self . tokenizer = AutoTokenizer . from_pretrained ( self . args [ '<STR_LIT>' ] ) \n self . prompt = int ( args . prompt [ <NUM_LIT> ] ) \n chunk_sizes_str = self . args [ '<STR_LIT>' ] \n self . chunk_sizes = [ ] \n self . bert_batch_sizes = [ ] \n if \"<STR_LIT>\" != chunk_sizes_str : \n for chunk_size_str in chunk_sizes_str . split ( \"<STR_LIT>\" ) : \n chunk_size = int ( chunk_size_str ) \n self . chunk_sizes . append ( chunk_size ) \n bert_batch_size = int ( asap_essay_lengths [ self . prompt ] / chunk_size ) + <NUM_LIT> \n self . bert_batch_sizes . append ( bert_batch_size ) \n plm_batch_size_str = \"<STR_LIT>\" . join ( [ str ( item ) for item in self . bert_batch_sizes ] ) \n print ( \"<STR_LIT>\" % ( self . prompt , asap_essay_lengths [ self . prompt ] ) ) \n print ( \"<STR_LIT>\" % ( chunk_sizes_str , plm_batch_size_str ) ) \n self . bert_regression_by_word_document = mainplm ( self . args ) \n self . bert_regression_by_chunk = chunkplm ( self . args ) \n self . multi_loss = multi_loss ( self . args ) \n self . lr = [ self . args [ '<STR_LIT>' ] , self . args [ '<STR_LIT>' ] ] \n self . optim = torch . optim . Adam ( [ \n { '<STR_LIT>' : self . bert_regression_by_word_document . parameters ( ) , '<STR_LIT>' : self . lr [ <NUM_LIT> ] } , \n { '<STR_LIT>' : self . bert_regression_by_chunk . parameters ( ) , '<STR_LIT>' : self . lr [ <NUM_LIT> ] } \n ] ) \n self . traindata = traindata \n self . valdata = valdata \n self . testdata = testdata \n self . foldname = foldname \n self . plt_x = [ ] \n self . plt_train_qwk = [ ] \n self . plt_val_qwk = [ ] \n self . plt_test_qwk = [ ] \n self . best_val_qwk = <NUM_LIT> \n def adjust_learning_rate ( self , epoch , start_lr , min_lr = <NUM_LIT> ) : \n optimizer = self . optim \n lr_0 = max ( start_lr [ <NUM_LIT> ] * ( <NUM_LIT> ** epoch ) , min_lr ) \n lr_1 = max ( start_lr [ <NUM_LIT> ] * ( <NUM_LIT> ** epoch ) , min_lr ) \n optimizer . param_groups [ <NUM_LIT> ] [ '<STR_LIT>' ] = lr_0 \n optimizer . param_groups [ <NUM_LIT> ] [ '<STR_LIT>' ] = lr_1 \n print ( f'<STR_LIT>' ) \n def adjust_loss_weight ( self , e ) : \n cosvalue = max ( ( math . cos ( ( e / ( self . args [ '<STR_LIT>' ] * <NUM_LIT> ) ) * math . pi ) + <NUM_LIT> ) / <NUM_LIT> , <NUM_LIT> ) \n self . multi_loss . weight = [ self . args [ '<STR_LIT>' ] , \n self . args [ '<STR_LIT>' ] , \n self . args [ '<STR_LIT>' ] * cosvalue ] \n def validate ( self , valdata , e = - <NUM_LIT> , mode = '<STR_LIT>' ) : \n self . bert_regression_by_word_document . eval ( ) \n self . bert_regression_by_chunk . eval ( ) \n scaler = GradScaler ( ) \n with torch . no_grad ( ) : \n target_scores = None \n if isinstance ( valdata , tuple ) and len ( valdata ) == <NUM_LIT> : \n doctok_token_indexes , doctok_token_indexes_slicenum = encode_documents ( \n valdata [ <NUM_LIT> ] , self . tokenizer , max_input_length = <NUM_LIT> ) \n chunk_token_indexes_list , chunk_token_indexes_length_list = [ ] , [ ] \n for i in range ( len ( self . chunk_sizes ) ) : \n document_representations_chunk , document_sequence_lengths_chunk = encode_documents ( \n valdata [ <NUM_LIT> ] , \n self . tokenizer , \n max_input_length = self . chunk_sizes [ i ] ) \n chunk_token_indexes_list . append ( document_representations_chunk ) \n chunk_token_indexes_length_list . append ( document_sequence_lengths_chunk ) \n target_scores = torch . FloatTensor ( valdata [ <NUM_LIT> ] ) \n predictions = torch . empty ( ( doctok_token_indexes . shape [ <NUM_LIT> ] ) ) \n acculation_loss = <NUM_LIT> \n for i in range ( <NUM_LIT> , doctok_token_indexes . shape [ <NUM_LIT> ] , self . args [ '<STR_LIT>' ] ) : \n batch_doctok_token_indexes = doctok_token_indexes [ i : i + self . args [ '<STR_LIT>' ] ] . to ( \n device = self . args [ '<STR_LIT>' ] ) \n batch_target_scores = target_scores [ i : i + self . args [ '<STR_LIT>' ] ] . to ( device = self . args [ '<STR_LIT>' ] ) \n with autocast ( ) : \n batch_doctok_predictions = self . bert_regression_by_word_document ( batch_doctok_token_indexes , \n device = self . args [ '<STR_LIT>' ] ) \n batch_doctok_predictions = torch . squeeze ( batch_doctok_predictions ) \n batch_predictions = batch_doctok_predictions \n if len ( batch_predictions . shape ) == <NUM_LIT> : \n batch_predictions = torch . tensor ( [ batch_predictions ] , device = self . args [ '<STR_LIT>' ] ) \n with autocast ( ) : \n loss = self . multi_loss ( batch_target_scores . unsqueeze ( <NUM_LIT> ) , batch_predictions . unsqueeze ( <NUM_LIT> ) ) \n acculation_loss += loss . item ( ) \n predictions [ i : i + self . args [ '<STR_LIT>' ] ] = batch_predictions \n assert target_scores . shape == predictions . shape \n print ( f'<STR_LIT>' ) \n prediction_scores = [ ] \n label_scores = [ ] \n predictions = predictions . detach ( ) . numpy ( ) \n target_scores = target_scores . detach ( ) . numpy ( ) \n for index , item in enumerate ( predictions ) : \n prediction_scores . append ( fix_score ( item , self . prompt ) ) \n label_scores . append ( target_scores [ index ] ) \n train_eva_res = evaluation ( label_scores , prediction_scores ) \n df = pd . DataFrame ( dict ( zip ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , \n [ predictions . tolist ( ) , prediction_scores , label_scores ] ) ) ) \n df . to_csv ( f'<STR_LIT>' , index = False ) \n print ( '<STR_LIT>' * <NUM_LIT> + f'<STR_LIT>' + '<STR_LIT>' * <NUM_LIT> ) \n print ( \"<STR_LIT>\" , float ( train_eva_res [ <NUM_LIT> ] ) ) \n print ( \"<STR_LIT>\" , float ( train_eva_res [ <NUM_LIT> ] ) ) \n if mode == '<STR_LIT>' : \n self . plt_val_qwk . append ( float ( train_eva_res [ <NUM_LIT> ] ) ) \n if self . best_val_qwk < float ( train_eva_res [ <NUM_LIT> ] ) : \n self . best_val_qwk = float ( train_eva_res [ <NUM_LIT> ] ) \n elif mode == '<STR_LIT>' : \n self . plt_test_qwk . append ( float ( train_eva_res [ <NUM_LIT> ] ) ) \n if self . best_val_qwk == self . plt_val_qwk [ - <NUM_LIT> ] : \n torch . save ( self . bert_regression_by_word_document . state_dict ( ) , f'<STR_LIT>' ) \n torch . save ( self . bert_regression_by_chunk . state_dict ( ) , f'<STR_LIT>' ) \n with open ( f'<STR_LIT>' , '<STR_LIT>' ) as f : \n f . write ( f'<STR_LIT>' ) \n def train ( self ) : \n epoch = self . args [ '<STR_LIT>' ] \n traindata = self . traindata \n self . bert_regression_by_word_document . to ( device = self . args [ '<STR_LIT>' ] ) \n self . bert_regression_by_chunk . to ( device = self . args [ '<STR_LIT>' ] ) \n self . multi_loss . to ( device = self . args [ '<STR_LIT>' ] ) \n scaler = GradScaler ( ) \n for e in range ( epoch ) : \n print ( '<STR_LIT>' * <NUM_LIT> + f'<STR_LIT>' + '<STR_LIT>' * <NUM_LIT> ) \n self . adjust_learning_rate ( e , self . lr ) \n self . adjust_loss_weight ( e ) \n self . bert_regression_by_word_document . train ( ) \n self . bert_regression_by_chunk . train ( ) \n target_scores = None \n if isinstance ( traindata , tuple ) and len ( traindata ) == <NUM_LIT> : \n doctok_token_indexes , doctok_token_indexes_slicenum = encode_documents ( \n traindata [ <NUM_LIT> ] , self . tokenizer , max_input_length = <NUM_LIT> ) \n chunk_token_indexes_list , chunk_token_indexes_length_list = [ ] , [ ] \n for i in range ( len ( self . chunk_sizes ) ) : \n document_representations_chunk , document_sequence_lengths_chunk = encode_documents ( \n traindata [ <NUM_LIT> ] , \n self . tokenizer , \n max_input_length = self . chunk_sizes [ i ] ) \n chunk_token_indexes_list . append ( document_representations_chunk ) \n chunk_token_indexes_length_list . append ( document_sequence_lengths_chunk ) \n target_scores = torch . FloatTensor ( traindata [ <NUM_LIT> ] )", "output": "predictions = torch . empty ( ( doctok_token_indexes . shape [ <NUM_LIT> ] ) ) \n acculation_loss = <NUM_LIT> \n for i in range ( <NUM_LIT> , doctok_token_indexes . shape [ <NUM_LIT> ] , self . args [ '<STR_LIT>' ] ) : \n self . optim . zero_grad ( ) \n batch_doctok_token_indexes = doctok_token_indexes [ i : i + self . args [ '<STR_LIT>' ] ] . to ( device = self . args [ '<STR_LIT>' ] ) \n batch_target_scores = target_scores [ i : i + self . args [ '<STR_LIT>' ] ] . to ( device = self . args [ '<STR_LIT>' ] ) \n with autocast ( ) : \n batch_doctok_predictions = self . bert_regression_by_word_document ( batch_doctok_token_indexes , device = self . args [ '<STR_LIT>' ] ) \n batch_doctok_predictions = torch . squeeze ( batch_doctok_predictions ) \n batch_predictions = batch_doctok_predictions \n if len ( batch_predictions . shape ) == <NUM_LIT> : \n batch_predictions = torch . tensor ( [ batch_predictions ] , device = self . args [ '<STR_LIT>' ] ) \n with autocast ( ) : \n loss = self . multi_loss ( batch_target_scores . unsqueeze ( <NUM_LIT> ) , batch_predictions . unsqueeze ( <NUM_LIT> ) ) \n loss . requires_grad_ ( True ) \n scaler . scale ( loss ) . backward ( ) \n scaler . step ( self . optim ) \n scaler . update ( ) \n acculation_loss += loss . item ( ) \n predictions [ i : i + self . args [ '<STR_LIT>' ] ] = batch_predictions \n assert target_scores . shape == predictions . shape \n print ( f'<STR_LIT>' ) \n prediction_scores = [ ] \n label_scores = [ ] \n predictions = predictions . detach ( ) . numpy ( ) \n target_scores = target_scores . detach ( ) . numpy ( ) \n for index , item in enumerate ( predictions ) : \n prediction_scores . append ( fix_score ( item , self . prompt ) ) \n label_scores . append ( target_scores [ index ] ) \n train_eva_res = evaluation ( label_scores , prediction_scores ) \n df = pd . DataFrame ( dict ( zip ( [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , [ predictions . tolist ( ) , prediction_scores , label_scores ] ) ) ) \n df . to_csv ( f'<STR_LIT>' , index = False ) \n print ( '<STR_LIT>' * <NUM_LIT> + '<STR_LIT>' + '<STR_LIT>' * <NUM_LIT> ) \n print ( \"<STR_LIT>\" , float ( train_eva_res [ <NUM_LIT> ] ) ) \n print ( \"<STR_LIT>\" , float ( train_eva_res [ <NUM_LIT> ] ) ) \n self . plt_x . append ( e + <NUM_LIT> ) \n self . plt_train_qwk . append ( float ( train_eva_res [ <NUM_LIT> ] ) ) \n self . validate ( self . valdata , e , mode = '<STR_LIT>' ) \n self . validate ( self . testdata , e , mode = '<STR_LIT>' ) \n plt . plot ( self . plt_x , self . plt_train_qwk , '<STR_LIT>' , color = '<STR_LIT>' , alpha = <NUM_LIT> , linewidth = <NUM_LIT> , label = '<STR_LIT>' ) \n plt . plot ( self . plt_x , self . plt_val_qwk , '<STR_LIT>' , color = '<STR_LIT>' , alpha = <NUM_LIT> , linewidth = <NUM_LIT> , label = '<STR_LIT>' ) \n plt . plot ( self . plt_x , self . plt_test_qwk , '<STR_LIT>' , color = '<STR_LIT>' , alpha = <NUM_LIT> , linewidth = <NUM_LIT> , label = '<STR_LIT>' ) \n plt . title ( self . foldname ) \n plt . xlabel ( '<STR_LIT>' ) \n plt . ylabel ( '<STR_LIT>' ) \n plt . legend ( loc = '<STR_LIT>' ) \n plt . savefig ( f'<STR_LIT>' ) \n plt . close ( )"}, {"input": "import os \n import sys \n def main ( ) : \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n try :", "output": "from django . core . management import execute_from_command_line \n except ImportError as exc : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) from exc \n execute_from_command_line ( sys . argv ) \n if __name__ == '<STR_LIT>' : \n main ( )"}, {"input": "import os \n import sys \n if __name__ == '<STR_LIT>' : \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n try :", "output": "from django . core . management import execute_from_command_line \n except ImportError as exc : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) from exc \n execute_from_command_line ( sys . argv )"}, {"input": "import subprocess \n from pathlib import Path \n import cappa \n import pytest \n from cappa . testing import CommandRunner \n from falco . config import write_falco_config \n views_functions = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n html_templates = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n views_functions_entry_point = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n html_templates_point = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n forms_attributes = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n admin_attributes = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n def create_pyproject_crud_config ( ** kwargs ) :", "output": "pyproject_toml = Path ( \"<STR_LIT>\" ) \n pyproject_toml . touch ( ) \n write_falco_config ( pyproject_path = pyproject_toml , crud = kwargs ) \n def healthy_django_project ( ) -> bool : \n result = subprocess . run ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n check = False , \n capture_output = True , \n text = True , \n ) \n return result . returncode == <NUM_LIT> \n def fix_users_import ( ) : \n types = Path ( \"<STR_LIT>\" ) \n types . write_text ( types . read_text ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n def install_crud_utils ( runner ) : \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n fix_users_import ( ) \n def test_crud ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n app_dir = Path ( \"<STR_LIT>\" ) \n assert ( app_dir / \"<STR_LIT>\" ) . exists ( ) \n for a in forms_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for a in admin_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for f in views_functions : \n assert f in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for t in html_templates : \n assert ( app_dir / \"<STR_LIT>\" / \"<STR_LIT>\" / f\"<STR_LIT>\" ) . exists ( ) \n def test_crud_all_models ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n app_dir = Path ( \"<STR_LIT>\" ) \n assert ( app_dir / \"<STR_LIT>\" ) . exists ( ) \n for a in forms_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for a in admin_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for f in views_functions : \n assert f in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for t in html_templates : \n assert ( app_dir / \"<STR_LIT>\" / \"<STR_LIT>\" / f\"<STR_LIT>\" ) . exists ( ) \n def test_crud_login ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n app_dir = Path ( \"<STR_LIT>\" ) \n assert ( app_dir / \"<STR_LIT>\" ) . exists ( ) \n for a in forms_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for a in admin_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for f in views_functions : \n assert f in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for t in html_templates : \n assert ( app_dir / \"<STR_LIT>\" / \"<STR_LIT>\" / f\"<STR_LIT>\" ) . exists ( ) \n def test_crud_entry_point ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n app_dir = Path ( \"<STR_LIT>\" ) \n assert ( app_dir / \"<STR_LIT>\" ) . exists ( ) \n for a in forms_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for a in admin_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for f in views_functions_entry_point : \n assert f in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for t in html_templates_point : \n assert ( app_dir / \"<STR_LIT>\" / \"<STR_LIT>\" / f\"<STR_LIT>\" ) . exists ( ) \n def test_crud_entry_point_login ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n app_dir = Path ( \"<STR_LIT>\" ) \n assert ( app_dir / \"<STR_LIT>\" ) . exists ( ) \n for a in forms_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for a in admin_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for f in views_functions_entry_point : \n assert f in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for t in html_templates_point : \n assert ( app_dir / \"<STR_LIT>\" / \"<STR_LIT>\" / f\"<STR_LIT>\" ) . exists ( ) \n def test_crud_only_html ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n app_dir = Path ( \"<STR_LIT>\" ) \n assert not ( app_dir / \"<STR_LIT>\" ) . exists ( ) \n assert not ( app_dir / \"<STR_LIT>\" ) . exists ( ) \n for f in views_functions : \n assert f not in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for t in html_templates : \n assert ( app_dir / \"<STR_LIT>\" / \"<STR_LIT>\" / f\"<STR_LIT>\" ) . exists ( ) \n def test_crud_only_python ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n app_dir = Path ( \"<STR_LIT>\" ) \n assert ( app_dir / \"<STR_LIT>\" ) . exists ( ) \n for a in forms_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for a in admin_attributes : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for f in views_functions : \n assert f in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n for t in html_templates : \n assert not ( app_dir / \"<STR_LIT>\" / \"<STR_LIT>\" / f\"<STR_LIT>\" ) . exists ( ) \n def test_crud_repo_not_clean ( django_project , runner : CommandRunner ) : \n with pytest . raises ( cappa . Exit ) : \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def test_crud_exclude_field ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n app_dir = Path ( \"<STR_LIT>\" ) \n assert \"<STR_LIT>\" not in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n assert \"<STR_LIT>\" not in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n assert \"<STR_LIT>\" not in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n forms_attributes_ = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n for a in forms_attributes_ : \n assert a in ( app_dir / \"<STR_LIT>\" ) . read_text ( ) \n def test_crud_login_required ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n views = ( Path ( \"<STR_LIT>\" ) / \"<STR_LIT>\" ) . read_text ( ) \n assert \"<STR_LIT>\" in views \n assert \"<STR_LIT>\" in views \n def test_crud_config_pyproject_skip_git_check_set ( django_project , runner : CommandRunner ) : \n create_pyproject_crud_config ( skip_git_check = True ) \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n views = ( Path ( \"<STR_LIT>\" ) / \"<STR_LIT>\" ) . read_text ( ) \n assert \"<STR_LIT>\" in views \n def test_crud_config_pyproject_login_required ( django_project , runner : CommandRunner ) : \n create_pyproject_crud_config ( skip_git_check = True , login_required = True ) \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n views = ( Path ( \"<STR_LIT>\" ) / \"<STR_LIT>\" ) . read_text ( ) \n assert \"<STR_LIT>\" in views \n assert \"<STR_LIT>\" in views \n def test_crud_config_pyproject_blueprints ( django_project , runner : CommandRunner ) : \n bp = django_project / \"<STR_LIT>\" \n bp . mkdir ( ) \n html_file = bp / \"<STR_LIT>\" \n html_file . touch ( ) \n html_file . write_text ( \"<STR_LIT>\" ) \n create_pyproject_crud_config ( blueprints = str ( Path ( \"<STR_LIT>\" ) ) , skip_git_check = True ) \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n views = ( Path ( \"<STR_LIT>\" ) / \"<STR_LIT>\" ) . read_text ( ) \n rendered_file = Path ( \"<STR_LIT>\" ) / \"<STR_LIT>\" / \"<STR_LIT>\" / \"<STR_LIT>\" \n assert rendered_file . exists ( ) \n assert \"<STR_LIT>\" in rendered_file . read_text ( ) \n assert \"<STR_LIT>\" in views \n def test_crud_always_migrate ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n create_pyproject_crud_config ( always_migrate = True ) \n settings = django_project / \"<STR_LIT>\" / \"<STR_LIT>\" \n settings . write_text ( settings . read_text ( ) + \"<STR_LIT>\" + \"<STR_LIT>\" ) \n install_crud_utils ( runner ) \n with pytest . raises ( cappa . Exit ) : \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert \"<STR_LIT>\" not in Path ( \"<STR_LIT>\" ) . read_text ( ) \n assert not healthy_django_project ( ) \n def test_forms_dates_widgets ( django_project , runner : CommandRunner , set_git_repo_to_clean ) : \n install_crud_utils ( runner ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n models = django_project / \"<STR_LIT>\" / \"<STR_LIT>\" / \"<STR_LIT>\" \n models . write_text ( \n models . read_text ( ) \n + \"<STR_LIT>\" \n + \"<STR_LIT>\" \n + \"<STR_LIT>\" \n ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert healthy_django_project ( ) \n assert \"<STR_LIT>\" not in ( django_project / \"<STR_LIT>\" / \"<STR_LIT>\" ) . read_text ( ) \n forms = django_project / \"<STR_LIT>\" / \"<STR_LIT>\" / \"<STR_LIT>\" \n assert \"<STR_LIT>\" in forms . read_text ( ) \n assert \"<STR_LIT>\" in forms . read_text ( ) \n assert \"<STR_LIT>\" in forms . read_text ( ) \n assert \"<STR_LIT>\" in forms . read_text ( )"}, {"input": "from django . db import models \n from django . utils . translation import gettext_lazy as _ \n from dev . football . core . models import BaseModel \n from dev . football . stadiums . enums import PitchSurfaceType \n class Stadium ( BaseModel ) : \n name = models . CharField ( max_length = <NUM_LIT> , help_text = _ ( \"<STR_LIT>\" ) ) \n key = models . SlugField ( \n max_length = <NUM_LIT> , \n help_text = _ ( \"<STR_LIT>\" ) , \n unique = True , \n ) \n capacity = models . IntegerField ( help_text = _ ( \"<STR_LIT>\" ) ) \n def __str__ ( self ) : \n return self . name \n class Pitch ( BaseModel ) : \n stadium = models . OneToOneField ( \n Stadium , \n on_delete = models . CASCADE , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n surface_type = models . CharField ( \n max_length = <NUM_LIT> , \n choices = [ ( t . name , t . value ) for t in PitchSurfaceType ] , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n width = models . PositiveSmallIntegerField (", "output": "help_text = _ ( \"<STR_LIT>\" ) \n ) \n length = models . PositiveSmallIntegerField ( \n help_text = _ ( \"<STR_LIT>\" ) \n )"}, {"input": "import inspect \n from typing import Optional , Type \n from django . db . models import Model \n from ninja import Router , Schema \n from ninja_crud . views import AbstractModelView \n class ModelViewSet : \n model : Type [ Model ] \n default_request_body : Optional [ Type [ Schema ] ] \n default_response_body : Optional [ Type [ Schema ] ] \n def __init_subclass__ ( cls , * args , ** kwargs ) -> None : \n super ( ) . __init_subclass__ ( * args , ** kwargs ) \n if hasattr ( cls , \"<STR_LIT>\" ) : \n cls . _bind_model_views ( ) \n @ classmethod \n def _bind_model_views ( cls ) -> None : \n for _ , model_view in inspect . getmembers ( \n cls , lambda member : isinstance ( member , AbstractModelView ) \n ) : \n model_view . model_viewset_class = cls \n @ classmethod \n def register_routes ( cls , router : Router ) -> None : \n view_attributes = { \n name : view \n for name , view in inspect . getmembers ( cls )", "output": "if isinstance ( view , AbstractModelView ) \n } \n attribute_order = list ( cls . __dict__ ) \n ordered_view_attributes = sorted ( \n view_attributes . items ( ) , key = lambda item : attribute_order . index ( item [ <NUM_LIT> ] ) \n ) \n for name , view in ordered_view_attributes : \n view . register_route ( router , route_name = name )"}, {"input": "import os \n import sys \n def main ( ) : \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' )", "output": "try : \n from django . core . management import execute_from_command_line \n except ImportError as exc : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) from exc \n execute_from_command_line ( sys . argv ) \n if __name__ == '<STR_LIT>' : \n main ( )"}, {"input": "import falco \n project = \"<STR_LIT>\" \n copyright = \"<STR_LIT>\" \n author = \"<STR_LIT>\" \n version = falco . falco_version \n release = version \n extensions = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n todo_include_todos = True \n extlinks = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n } \n templates_path = [ \"<STR_LIT>\" ] \n exclude_patterns = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n html_theme = \"<STR_LIT>\" \n html_static_path = [ \"<STR_LIT>\" ] \n html_baseurl = \"<STR_LIT>\" \n html_title = \"<STR_LIT>\" \n html_context = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n html_theme_options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n } \n html_logo = \"<STR_LIT>\" \n html_favicon = \"<STR_LIT>\" \n html_css_files = [ \n \"<STR_LIT>\" , \n ] \n html_js_files = [ \n ( \n \"<STR_LIT>\" , \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) , \n \"<STR_LIT>\" , \n ] \n mermaid_version = \"<STR_LIT>\" \n mermaid_output_format = \"<STR_LIT>\""}, {"input": "import requests , datetime , time , re , os \n from utils . general import headers \n from bs4 import BeautifulSoup as bs \n def get_epgs_tbc ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n channel_id = channel_id . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n url = '<STR_LIT>' % channel_id \n try : \n res = requests . get ( url , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n uls = soup . select ( '<STR_LIT>' ) \n for ul in uls : \n n1 = <NUM_LIT> \n lis = ul . select ( '<STR_LIT>' ) \n for li in lis : \n title = li . p . text \n desc = li . attrs [ '<STR_LIT>' ] \n date_ = li . attrs [ '<STR_LIT>' ]", "output": "time_delay = li . attrs [ '<STR_LIT>' ] . strip ( ) \n time_delay_re = re . search ( '<STR_LIT>' , time_delay ) \n if time_delay_re : \n start_str , end_str = time_delay_re . group ( <NUM_LIT> ) , time_delay_re . group ( <NUM_LIT> ) \n starttime = datetime . datetime . strptime ( date_ + start_str , '<STR_LIT>' ) \n endtime = datetime . datetime . strptime ( date_ + end_str , '<STR_LIT>' ) \n if starttime > endtime : \n endtime = endtime + datetime . timedelta ( days = <NUM_LIT> ) \n if starttime . date ( ) < dt : \n continue \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : endtime , \n '<STR_LIT>' : title , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : starttime . date ( ) , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : starttime . date ( ) if '<STR_LIT>' in dir ( ) else dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n today_int = int ( time . strftime ( '<STR_LIT>' , time . localtime ( ) ) ) \n def get_channels_tbc ( ) : \n channels = [ ] \n cookies = { \n '<STR_LIT>' : '<STR_LIT>' \n } \n url = '<STR_LIT>' \n res = requests . get ( url , headers = headers , cookies = cookies , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n lis = soup . select ( '<STR_LIT>' ) \n for li in lis : \n name = li [ '<STR_LIT>' ] \n id = li [ '<STR_LIT>' ] \n img = li . select ( '<STR_LIT>' ) [ <NUM_LIT> ] [ '<STR_LIT>' ] \n url = li . a [ '<STR_LIT>' ] \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : url , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : img , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n channels . append ( channel ) \n return channels"}, {"input": "from django . urls import include , path \n from rest_framework import routers \n from . views import ConversationViewSet , MessageViewSet , PromptViewSet , EmbeddingDocumentViewSet , SettingViewSet \n router = routers . SimpleRouter ( ) \n router . register ( r'<STR_LIT>' , ConversationViewSet , basename = '<STR_LIT>' ) \n router . register ( r'<STR_LIT>' , MessageViewSet , basename = '<STR_LIT>' ) \n router . register ( r'<STR_LIT>' , PromptViewSet , basename = '<STR_LIT>' ) \n router . register ( r'<STR_LIT>' , EmbeddingDocumentViewSet , basename = '<STR_LIT>' ) \n router . register ( r'<STR_LIT>' , SettingViewSet , basename = '<STR_LIT>' ) \n urlpatterns = [", "output": "path ( '<STR_LIT>' , include ( router . urls ) ) , \n ]"}, {"input": "from . base import * \n from . base import env \n DEBUG = True \n SECRET_KEY = env (", "output": "\"<STR_LIT>\" , \n default = \"<STR_LIT>\" , \n ) \n ALLOWED_HOSTS = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n CACHES = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n } \n EMAIL_BACKEND = env ( \n \"<STR_LIT>\" , default = \"<STR_LIT>\" \n ) \n INSTALLED_APPS += [ \"<STR_LIT>\" ] \n MIDDLEWARE += [ \"<STR_LIT>\" ] \n DEBUG_TOOLBAR_CONFIG = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : True , \n } \n INTERNAL_IPS = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n if env ( \"<STR_LIT>\" ) == \"<STR_LIT>\" : \n import socket \n hostname , _ , ips = socket . gethostbyname_ex ( socket . gethostname ( ) ) \n INTERNAL_IPS += [ \"<STR_LIT>\" . join ( ip . split ( \"<STR_LIT>\" ) [ : - <NUM_LIT> ] + [ \"<STR_LIT>\" ] ) for ip in ips ] \n INSTALLED_APPS += [ \"<STR_LIT>\" ] \n CELERY_TASK_EAGER_PROPAGATES = True \n CORS_ALLOW_ALL_ORIGINS = True"}, {"input": "import factory \n from django_webhook . models import ( \n Webhook , \n WebhookEvent , \n WebhookSecret , \n WebhookTopic , \n states , \n ) \n class WebhookSecretFactory ( factory . django . DjangoModelFactory ) : \n class Meta : \n model = WebhookSecret \n token = factory . Faker ( \"<STR_LIT>\" ) \n class WebhookFactory ( factory . django . DjangoModelFactory ) : \n class Meta :", "output": "model = Webhook \n url = factory . Faker ( \"<STR_LIT>\" , schemes = [ \"<STR_LIT>\" ] ) \n active = True \n secrets = factory . RelatedFactory ( \n WebhookSecretFactory , factory_related_name = \"<STR_LIT>\" \n ) \n @ factory . post_generation \n def topics ( self , create , extracted , ** kwargs ) : \n self . refresh_from_db ( ) \n if not create : \n return \n if extracted : \n for topic in extracted : \n self . topics . add ( topic ) \n class WebhookTopicFactory ( factory . django . DjangoModelFactory ) : \n class Meta : \n model = WebhookTopic \n class WebhookEventFactory ( factory . django . DjangoModelFactory ) : \n class Meta : \n model = WebhookEvent \n webhook = factory . SubFactory ( WebhookFactory ) \n object = factory . Faker ( \"<STR_LIT>\" ) \n object_type = factory . Faker ( \"<STR_LIT>\" ) \n status = factory . Faker ( \"<STR_LIT>\" , elements = states . ALL_STATES ) \n url = factory . Faker ( \"<STR_LIT>\" ) \n topic = factory . Faker ( \"<STR_LIT>\" )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( \n auto_now_add = True , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" ,", "output": "field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( \n blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( \n max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( \n blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . TextField ( blank = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , unique = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ]"}, {"input": "import json \n import logging \n from django . conf import settings \n from django . contrib . auth . models import AnonymousUser \n from django . http import HttpResponse , HttpResponseServerError \n from django . utils . deprecation import MiddlewareMixin \n from dvadmin . system . models import OperationLog \n from dvadmin . utils . request_util import get_request_user , get_request_ip , get_request_data , get_request_path , get_os , get_browser , get_verbose_name \n class ApiLoggingMiddleware ( MiddlewareMixin ) : \n def __init__ ( self , get_response = None ) : \n super ( ) . __init__ ( get_response )", "output": "self . enable = getattr ( settings , '<STR_LIT>' , None ) or False \n self . methods = getattr ( settings , '<STR_LIT>' , None ) or set ( ) \n self . operation_log_id = None \n @ classmethod \n def __handle_request ( cls , request ) : \n request . request_ip = get_request_ip ( request ) \n request . request_data = get_request_data ( request ) \n request . request_path = get_request_path ( request ) \n def __handle_response ( self , request , response ) : \n body = getattr ( request , '<STR_LIT>' , { } ) \n if isinstance ( body , dict ) and body . get ( '<STR_LIT>' , '<STR_LIT>' ) : \n body [ '<STR_LIT>' ] = '<STR_LIT>' * len ( body [ '<STR_LIT>' ] ) \n if not hasattr ( response , '<STR_LIT>' ) or not isinstance ( response . data , dict ) : \n response . data = { } \n try : \n if not response . data and response . content : \n content = json . loads ( response . content . decode ( ) ) \n response . data = content if isinstance ( content , dict ) else { } \n except Exception : \n return \n user = get_request_user ( request ) \n info = { \n '<STR_LIT>' : getattr ( request , '<STR_LIT>' , '<STR_LIT>' ) , \n '<STR_LIT>' : user if not isinstance ( user , AnonymousUser ) else None , \n '<STR_LIT>' : getattr ( request . user , '<STR_LIT>' , None ) , \n '<STR_LIT>' : request . method , \n '<STR_LIT>' : request . request_path , \n '<STR_LIT>' : body , \n '<STR_LIT>' : response . data . get ( '<STR_LIT>' ) , \n '<STR_LIT>' : get_os ( request ) , \n '<STR_LIT>' : get_browser ( request ) , \n '<STR_LIT>' : request . session . get ( '<STR_LIT>' ) , \n '<STR_LIT>' : True if response . data . get ( '<STR_LIT>' ) in [ <NUM_LIT> , ] else False , \n '<STR_LIT>' : { \"<STR_LIT>\" : response . data . get ( '<STR_LIT>' ) , \"<STR_LIT>\" : response . data . get ( '<STR_LIT>' ) } , \n } \n operation_log , creat = OperationLog . objects . update_or_create ( defaults = info , id = self . operation_log_id ) \n if not operation_log . request_modular and settings . API_MODEL_MAP . get ( request . request_path , None ) : \n operation_log . request_modular = settings . API_MODEL_MAP [ request . request_path ] \n operation_log . save ( ) \n def process_view ( self , request , view_func , view_args , view_kwargs ) : \n if hasattr ( view_func , '<STR_LIT>' ) and hasattr ( view_func . cls , '<STR_LIT>' ) : \n if self . enable : \n if self . methods == '<STR_LIT>' or request . method in self . methods : \n log = OperationLog ( request_modular = get_verbose_name ( view_func . cls . queryset ) ) \n log . save ( ) \n self . operation_log_id = log . id \n return \n def process_request ( self , request ) : \n self . __handle_request ( request ) \n def process_response ( self , request , response ) : \n if self . enable : \n if self . methods == '<STR_LIT>' or request . method in self . methods : \n self . __handle_response ( request , response ) \n return response \n logger = logging . getLogger ( \"<STR_LIT>\" ) \n class HealthCheckMiddleware ( object ) : \n def __init__ ( self , get_response ) : \n self . get_response = get_response \n def __call__ ( self , request ) : \n if request . method == \"<STR_LIT>\" : \n if request . path == \"<STR_LIT>\" : \n return self . readiness ( request ) \n elif request . path == \"<STR_LIT>\" : \n return self . healthz ( request ) \n return self . get_response ( request ) \n def healthz ( self , request ) : \n return HttpResponse ( \"<STR_LIT>\" ) \n def readiness ( self , request ) : \n try : \n from django . db import connections \n for name in connections : \n cursor = connections [ name ] . cursor ( ) \n cursor . execute ( \"<STR_LIT>\" ) \n row = cursor . fetchone ( ) \n if row is None : \n return HttpResponseServerError ( \"<STR_LIT>\" ) \n except Exception as e : \n logger . exception ( e ) \n return HttpResponseServerError ( \"<STR_LIT>\" ) \n try : \n from django . core . cache import caches \n from django . core . cache . backends . memcached import BaseMemcachedCache \n for cache in caches . all ( ) : \n if isinstance ( cache , BaseMemcachedCache ) : \n stats = cache . _cache . get_stats ( ) \n if len ( stats ) != len ( cache . _servers ) : \n return HttpResponseServerError ( \"<STR_LIT>\" ) \n except Exception as e : \n logger . exception ( e ) \n return HttpResponseServerError ( \"<STR_LIT>\" ) \n return HttpResponse ( \"<STR_LIT>\" )"}, {"input": "import django . utils . timezone \n from django . db import migrations \n from django . db import models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ,", "output": "] \n operations = [ \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True , default = django . utils . timezone . now ) , \n preserve_default = False , \n ) , \n ]"}, {"input": "import http \n from typing import Optional \n import django . http \n import django . test \n from django . core . exceptions import ObjectDoesNotExist \n from ninja import Schema \n from ninja_crud . testing . core import ArgOrCallable , TestCaseType , ViewTestManager \n from ninja_crud . testing . core . components import Headers , PathParameters \n from ninja_crud . testing . views import AbstractModelViewTest \n from ninja_crud . views import DeleteModelView \n class DeleteModelViewTest ( AbstractModelViewTest ) : \n model_view : DeleteModelView \n def __init__ ( \n self , \n path_parameters : ArgOrCallable [ PathParameters , TestCaseType ] , \n headers : Optional [ ArgOrCallable [ Headers , TestCaseType ] ] = None , \n ) -> None : \n super ( ) . __init__ ( model_view_class = DeleteModelView ) \n self . view_test_manager = ViewTestManager ( \n simulate_request = self . simulate_request , \n path_parameters = path_parameters , \n headers = headers , \n ) \n def on_successful_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) : \n self . model_viewset_test_case . assertEqual ( response . content , b\"<STR_LIT>\" ) \n path_parameters_schema : Optional [ Schema ] = ( \n self . model_view . path_parameters ( ** path_parameters ) \n if self . model_view . path_parameters \n else None \n ) \n with self . model_viewset_test_case . assertRaises ( ObjectDoesNotExist ) : \n self . model_view . get_model ( \n getattr ( response , \"<STR_LIT>\" , None ) , \n path_parameters_schema , \n ) \n def on_failed_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict ,", "output": ") : \n pass \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_delete_model_ok ( self ) : \n self . view_test_manager . test_view_ok ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_successful_request , \n status = http . HTTPStatus . NO_CONTENT , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_delete_model_headers_unauthorized ( self ) : \n self . view_test_manager . test_view_headers_unauthorized ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_delete_model_headers_forbidden ( self ) : \n self . view_test_manager . test_view_headers_forbidden ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_delete_model_path_parameters_not_found ( self ) : \n self . view_test_manager . test_view_path_parameters_not_found ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n )"}, {"input": "from django . db import migrations \n from wagtail_ai . prompts import DEFAULT_PROMPTS \n def set_default_ai_prompts ( apps , schema_editor ) : \n Prompt = apps . get_model ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n for default_prompt in DEFAULT_PROMPTS : \n Prompt . objects . update_or_create ( \n default_prompt_id = default_prompt [ \"<STR_LIT>\" ] ,", "output": "prompt = None , \n defaults = { \n \"<STR_LIT>\" : default_prompt [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : default_prompt . get ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : default_prompt . get ( \"<STR_LIT>\" , None ) , \n } , \n ) \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . RunPython ( set_default_ai_prompts , migrations . RunPython . noop ) , \n ]"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : ( \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( \n blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . TextField ( blank = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" ,", "output": "field = models . BooleanField ( default = False , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , unique = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ]"}, {"input": "from rest_framework import serializers \n from rest_framework . views import APIView \n from application import dispatch \n from dvadmin . system . models import Dictionary \n from dvadmin . utils . json_response import SuccessResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class DictionarySerializer ( CustomModelSerializer ) : \n class Meta : \n model = Dictionary \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class DictionaryCreateUpdateSerializer ( CustomModelSerializer ) : \n value = serializers . CharField ( max_length = <NUM_LIT> ) \n def validate_value ( self , value ) : \n initial_data = self . initial_data \n parent = initial_data . get ( '<STR_LIT>' , None ) \n if parent is None : \n unique = Dictionary . objects . filter ( value = value ) . exists ( ) \n if unique : \n raise serializers . ValidationError ( \"<STR_LIT>\" ) \n return value \n class Meta : \n model = Dictionary \n fields = '<STR_LIT>' \n class DictionaryViewSet ( CustomModelViewSet ) : \n queryset = Dictionary . objects . all ( ) \n serializer_class = DictionarySerializer \n create_serializer_class = DictionaryCreateUpdateSerializer \n extra_filter_class = [ ] \n search_fields = [ '<STR_LIT>' ] \n def get_queryset ( self ) : \n if self . action == '<STR_LIT>' : \n params = self . request . query_params \n parent = params . get ( '<STR_LIT>' , None ) \n if params : \n if parent :", "output": "queryset = self . queryset . filter ( parent = parent ) \n else : \n queryset = self . queryset . filter ( parent__isnull = True ) \n else : \n queryset = self . queryset . filter ( parent__isnull = True ) \n return queryset \n else : \n return self . queryset \n class InitDictionaryViewSet ( APIView ) : \n authentication_classes = [ ] \n permission_classes = [ ] \n queryset = Dictionary . objects . all ( ) \n def get ( self , request ) : \n dictionary_key = self . request . query_params . get ( '<STR_LIT>' ) \n if dictionary_key : \n if dictionary_key == '<STR_LIT>' : \n data = [ ele for ele in dispatch . get_dictionary_config ( ) . values ( ) ] \n if not data : \n dispatch . refresh_dictionary ( ) \n data = [ ele for ele in dispatch . get_dictionary_config ( ) . values ( ) ] \n else : \n data = self . queryset . filter ( parent__value = dictionary_key , status = True ) . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' ) \n return SuccessResponse ( data = data , msg = \"<STR_LIT>\" ) \n return SuccessResponse ( data = [ ] , msg = \"<STR_LIT>\" )"}, {"input": "from django . contrib import admin \n from dev . football . core . admin import BaseAdmin \n from dev . football . players . models import Player , PlayerAttributes , PlayerContract \n @ admin . register ( Player ) \n class PlayerAdmin ( BaseAdmin ) : \n pass", "output": "@ admin . register ( PlayerAttributes ) \n class PlayerAttributes ( BaseAdmin ) : \n pass \n @ admin . register ( PlayerContract ) \n class PlayerContractAdmin ( BaseAdmin ) : \n pass"}, {"input": "import requests , datetime , os , re , time , json \n from utils . general import headers \n def get_epgs_sdtv ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n t = time . time ( ) \n try : \n url = '<STR_LIT>' % ( \n t , channel_id , dt , t ) \n res = requests . get ( url , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n re_j = re . search ( '<STR_LIT>' , res . text , re . DOTALL ) . group ( <NUM_LIT> ) \n re_json = json . loads ( re_j ) \n contents = re_json [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n time_delta_days = ( dt - datetime . datetime . now ( ) . date ( ) ) . days \n for content in contents : \n starttime = datetime . datetime . fromtimestamp ( int ( content [ '<STR_LIT>' ] ) ) + datetime . timedelta ( days = time_delta_days ) \n endtime = datetime . datetime . fromtimestamp ( int ( content [ '<STR_LIT>' ] ) ) + datetime . timedelta ( days = time_delta_days ) \n title = content [ '<STR_LIT>' ] \n epg = { '<STR_LIT>' : channel_id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : endtime , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : dt ,", "output": "} \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_sdtv ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url ) \n res . encoding = '<STR_LIT>' \n re_l = re . search ( '<STR_LIT>' , res . text , re . DOTALL ) . group ( <NUM_LIT> ) \n contents = re . findall ( \n '<STR_LIT>' , re_l , \n re . DOTALL ) \n channels = [ ] \n for content in contents : \n id = content [ <NUM_LIT> ] \n name = content [ <NUM_LIT> ] \n curl = '<STR_LIT>' % content [ <NUM_LIT> ] \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : curl , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' if name != '<STR_LIT>' else '<STR_LIT>' \n } \n channels . append ( channel ) \n return channels"}, {"input": "import os \n from collections . abc import Sequence \n from pathlib import Path \n BASE_DIR = Path ( __file__ ) . parent . resolve ( ) \n PRODUCTION_DOTENVS_DIR = BASE_DIR / \"<STR_LIT>\" / \"<STR_LIT>\" \n PRODUCTION_DOTENV_FILES = [ \n PRODUCTION_DOTENVS_DIR / \"<STR_LIT>\" , \n PRODUCTION_DOTENVS_DIR / \"<STR_LIT>\" , \n ] \n DOTENV_FILE = BASE_DIR / \"<STR_LIT>\" \n def merge ( \n output_file : Path , \n files_to_merge : Sequence [ Path ] ,", "output": ") -> None : \n merged_content = \"<STR_LIT>\" \n for merge_file in files_to_merge : \n merged_content += merge_file . read_text ( ) \n merged_content += os . linesep \n output_file . write_text ( merged_content ) \n if __name__ == \"<STR_LIT>\" : \n merge ( DOTENV_FILE , PRODUCTION_DOTENV_FILES )"}, {"input": "from rest_framework . views import APIView \n from rest_framework . request import Request \n from rest_framework . response import Response \n from rest_framework . viewsets import ModelViewSet \n from rest_framework . permissions import IsAuthenticated \n from rest_framework . authentication import BasicAuthentication , SessionAuthentication \n from feeds . models import Entry \n from feeds . tasks import write_bulk_entries \n from feeds . serializers import EntrySerializer \n from core . authentication import AfetHaritaAuthentication \n class EntryViewSet ( ModelViewSet ) : \n authentication_classes = [", "output": "AfetHaritaAuthentication , \n BasicAuthentication , \n SessionAuthentication , \n ] \n permission_classes = [ IsAuthenticated ] \n queryset = Entry . objects . all ( ) \n serializer_class = EntrySerializer \n http_method_names = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n class BulkEntryView ( APIView ) : \n write_task = write_bulk_entries \n permission_classes = [ IsAuthenticated ] \n authentication_classes = [ \n AfetHaritaAuthentication , \n BasicAuthentication , \n SessionAuthentication , \n ] \n def post ( self , request : Request ) -> Response : \n self . write_task . apply_async ( kwargs = { \"<STR_LIT>\" : request . data } ) \n return Response ( { \"<STR_LIT>\" : \"<STR_LIT>\" } )"}, {"input": "from django . urls import path \n from rest_framework . routers import DefaultRouter \n from feeds . views . locations import LocationViewSet \n from feeds . views . entries import EntryViewSet , BulkEntryView \n from feeds . views . areas import AreaViewSet , AreaLiteViewSet , AreasCountViewSet , CityByCityCountView \n router = DefaultRouter ( trailing_slash = False ) \n router . register ( \"<STR_LIT>\" , LocationViewSet , basename = \"<STR_LIT>\" ) \n router . register ( \"<STR_LIT>\" , EntryViewSet , basename = \"<STR_LIT>\" ) \n router . register ( \"<STR_LIT>\" , AreaViewSet , basename = \"<STR_LIT>\" ) \n router . register ( \"<STR_LIT>\" , AreasCountViewSet , basename = \"<STR_LIT>\" ) \n router . register ( \"<STR_LIT>\" , AreaLiteViewSet , basename = \"<STR_LIT>\" )", "output": "urlpatterns = [ \n path ( \"<STR_LIT>\" , BulkEntryView . as_view ( ) ) , \n path ( \"<STR_LIT>\" , CityByCityCountView . as_view ( ) ) , \n ] + router . urls"}, {"input": "import os \n import re \n from pathlib import Path \n from setuptools import find_packages , setup \n def get_version ( * file_paths ) : \n filename = os . path . join ( os . path . dirname ( __file__ ) , * file_paths ) \n version_file = Path ( filename ) . read_text ( \"<STR_LIT>\" ) \n version_match = re . search ( r\"<STR_LIT>\" , version_file , re . M ) \n if version_match : \n return version_match . group ( <NUM_LIT> ) \n raise RuntimeError ( \"<STR_LIT>\" ) \n version = get_version ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n readme = Path ( \"<STR_LIT>\" ) . read_text ( \"<STR_LIT>\" ) \n setup ( \n name = \"<STR_LIT>\" , \n version = version , \n description = , \n long_description = readme , \n author = \"<STR_LIT>\" , \n author_email = \"<STR_LIT>\" , \n url = \"<STR_LIT>\" , \n packages = find_packages ( ) , \n include_package_data = True , \n install_requires = [ ] , \n license = \"<STR_LIT>\" , \n keywords = \"<STR_LIT>\" , \n classifiers = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" , \n ] , \n )"}, {"input": "import subprocess \n from pathlib import Path \n from typing import Annotated \n from typing import TypedDict \n import cappa \n import parso \n from falco import checks \n from falco . config import CRUDConfig \n from falco . config import read_falco_config \n from falco . utils import get_project_name \n from falco . utils import RICH_ERROR_MARKER \n from falco . utils import RICH_INFO_MARKER \n from falco . utils import RICH_SUCCESS_MARKER \n from falco . utils import run_in_shell \n from falco . utils import simple_progress \n from rich import print as rich_print \n from . install_crud_utils import InstallCrudUtils \n from . utils import extract_python_file_templates \n from . utils import get_crud_blueprints_path \n from . utils import render_to_string \n from . utils import run_html_formatters \n from . utils import run_python_formatters \n class DjangoField ( TypedDict ) : \n verbose_name : str \n editable : bool \n class_name : str \n accessor : str \n class DjangoModel ( TypedDict ) : \n name : str \n name_plural : str \n verbose_name : str \n verbose_name_plural : str \n fields : dict [ str , DjangoField ] \n has_file_field : bool \n has_editable_date_field : bool \n class PythonBlueprintContext ( TypedDict ) : \n project_name : str \n login_required : bool \n app_label : str \n model_name : str \n model_name_plural : str \n model_verbose_name_plural : str \n model_has_file_fields : bool \n model_has_editable_date_fields : bool \n model_fields : dict [ str , DjangoField ] \n crud_utils_import : str \n entry_point : bool \n class UrlsForContext ( TypedDict ) : \n list_view_url : str \n create_view_url : str \n detail_view_url : str \n update_view_url : str \n delete_view_url : str \n class HtmlBlueprintContext ( UrlsForContext ) : \n app_label : str \n model_name : str \n model_name_plural : str \n model_verbose_name : str \n model_verbose_name_plural : str \n model_has_file_fields : bool \n model_fields : dict [ str , DjangoField ] \n @ cappa . command ( help = \"<STR_LIT>\" , name = \"<STR_LIT>\" ) \n class ModelCRUD : \n model_path : Annotated [ \n str , \n cappa . Arg ( \n help = \"<STR_LIT>\" \n ) , \n ] \n blueprints : Annotated [ \n str , \n cappa . Arg ( \n default = \"<STR_LIT>\" , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] \n excluded_fields : Annotated [ \n list [ str ] , \n cappa . Arg ( \n short = True , \n default = [ ] , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] \n only_python : Annotated [ \n bool , \n cappa . Arg ( default = False , long = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) , \n ] \n only_html : Annotated [ \n bool , \n cappa . Arg ( default = False , long = \"<STR_LIT>\" , help = \"<STR_LIT>\" ) , \n ] \n entry_point : Annotated [ \n bool , \n cappa . Arg ( \n default = False , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] \n login_required : Annotated [ \n bool , \n cappa . Arg ( \n default = False , \n short = \"<STR_LIT>\" , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] \n skip_git_check : Annotated [ \n bool , \n cappa . Arg ( \n default = False , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] \n def __call__ ( self , project_name : Annotated [ str , cappa . Dep ( get_project_name ) ] ) : \n pyproject_path = Path ( \"<STR_LIT>\" ) \n falco_config = read_falco_config ( pyproject_path = pyproject_path ) if pyproject_path . exists ( ) else { } \n crud_config : CRUDConfig = falco_config . get ( \"<STR_LIT>\" , { } ) \n self . blueprints = crud_config . get ( \"<STR_LIT>\" , self . blueprints ) \n self . login_required = crud_config . get ( \"<STR_LIT>\" , self . login_required ) \n self . skip_git_check = crud_config . get ( \"<STR_LIT>\" , self . skip_git_check ) \n checks . clean_git_repo ( ignore_dirty = self . skip_git_check ) \n v = self . model_path . split ( \"<STR_LIT>\" ) \n if len ( v ) == <NUM_LIT> : \n name = None \n app_label = v [ <NUM_LIT> ] \n else : \n name = v . pop ( ) \n app_label = \"<STR_LIT>\" . join ( v ) \n if crud_config . get ( \"<STR_LIT>\" , False ) : \n commands = [ \n f\"<STR_LIT>\" , \n f\"<STR_LIT>\" , \n ] \n with simple_progress ( \"<STR_LIT>\" ) : \n for cmd in commands : \n result = subprocess . run ( cmd . split ( ) , capture_output = True , check = False , text = True ) \n if result . returncode != <NUM_LIT> : \n msg = result . stderr \n raise cappa . Exit ( \"<STR_LIT>\" + msg , code = <NUM_LIT> ) \n if self . entry_point and not name : \n raise cappa . Exit ( \"<STR_LIT>\" , code = <NUM_LIT> ) \n with simple_progress ( \"<STR_LIT>\" ) : \n all_django_models = run_in_shell ( \n get_models_data , \n app_label = app_label , \n excluded_fields = self . excluded_fields , \n entry_point = self . entry_point , \n ) \n app_folder_path_str , app_name , templates_dir_str = run_in_shell ( \n get_app_path_name_and_templates_dir , app_label = app_label \n ) \n app_folder_path = Path ( app_folder_path_str ) \n templates_dir = Path ( templates_dir_str ) \n django_models = ( \n [ m for m in all_django_models if m [ \"<STR_LIT>\" ] . lower ( ) == name . lower ( ) ] if name else all_django_models \n ) \n if name and not django_models : \n msg = f\"<STR_LIT>\" \n raise cappa . Exit ( msg , code = <NUM_LIT> ) \n python_blueprint_context : list [ PythonBlueprintContext ] = [ ] \n html_blueprint_context : list [ HtmlBlueprintContext ] = [ ] \n install_path , crud_utils_installed = InstallCrudUtils . get_install_path ( \n project_name = project_name , \n falco_config = falco_config , \n ) \n crud_utils_import = str ( install_path ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n for django_model in django_models : \n python_blueprint_context . append ( \n get_python_blueprint_context ( \n project_name = project_name , \n app_label = app_label , \n django_model = django_model , \n crud_utils_import = crud_utils_import , \n login_required = self . login_required , \n entry_point = self . entry_point , \n ) \n ) \n html_blueprint_context . append ( get_html_blueprint_context ( app_label = app_label , django_model = django_model ) ) \n updated_python_files = set ( ) \n if not self . only_html : \n python_blueprints = list ( ( get_crud_blueprints_path ( ) / \"<STR_LIT>\" ) . iterdir ( ) ) \n updated_python_files . update ( \n self . generate_python_code ( \n app_label = app_label , \n blueprints = python_blueprints , \n app_folder_path = app_folder_path , \n contexts = python_blueprint_context , \n entry_point = self . entry_point , \n ) \n ) \n updated_python_files . update ( \n self . generating_urls ( \n app_name = app_name , \n app_folder_path = app_folder_path , \n app_label = app_label , \n django_models = django_models , \n entry_point = self . entry_point , \n ) \n ) \n updated_html_files = set ( ) \n if not self . only_python : \n html_blueprints = ( \n list ( Path ( self . blueprints ) . glob ( \"<STR_LIT>\" ) ) \n if self . blueprints \n else list ( ( get_crud_blueprints_path ( ) / \"<STR_LIT>\" ) . iterdir ( ) ) \n ) \n updated_html_files . update ( \n self . generate_html_templates ( \n contexts = html_blueprint_context , \n entry_point = self . entry_point , \n blueprints = html_blueprints , \n templates_dir = templates_dir , \n ) \n ) \n for file in updated_python_files : \n run_python_formatters ( str ( file ) ) \n for file in updated_html_files : \n run_html_formatters ( str ( file ) ) \n display_names = \"<STR_LIT>\" . join ( m . get ( \"<STR_LIT>\" ) for m in django_models ) \n rich_print ( f\"<STR_LIT>\" ) \n if not crud_utils_installed : \n rich_print ( \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n ) \n @ simple_progress ( \"<STR_LIT>\" ) \n def generate_python_code ( \n self , \n app_label : str , \n app_folder_path : Path , \n blueprints : list [ Path ] , \n contexts : list [ \"<STR_LIT>\" ] , \n * , \n entry_point : bool , \n ) -> list [ Path ] : \n updated_files = [ ] \n for blueprint in blueprints : \n imports_template , code_template = extract_python_file_templates ( blueprint . read_text ( ) ) \n file_name_without_jinja = \"<STR_LIT>\" . join ( blueprint . name . split ( \"<STR_LIT>\" ) [ : - <NUM_LIT> ] ) \n file_to_write_to = app_folder_path / file_name_without_jinja \n file_to_write_to . touch ( exist_ok = True ) \n imports_content , code_content = \"<STR_LIT>\" , \"<STR_LIT>\" \n for context in contexts : \n model_name_lower = context [ \"<STR_LIT>\" ] . lower ( ) \n imports_content += render_to_string ( imports_template , context ) \n code_content += render_to_string ( code_template , context ) \n if entry_point : \n code_content = code_content . replace ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) \n code_content = code_content . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n file_to_write_to . write_text ( imports_content + file_to_write_to . read_text ( ) + code_content ) \n updated_files . append ( file_to_write_to ) \n model_name = contexts [ <NUM_LIT> ] [ \"<STR_LIT>\" ] if len ( contexts ) == <NUM_LIT> else None \n updated_files . append ( \n register_models_in_admin ( \n app_folder_path = app_folder_path , \n app_label = app_label , \n model_name = model_name , \n ) \n ) \n return updated_files \n @ simple_progress ( \"<STR_LIT>\" ) \n def generating_urls ( \n self , \n app_folder_path : Path , \n app_label : str , \n app_name : str , \n django_models : list [ \"<STR_LIT>\" ] , \n * , \n entry_point : bool , \n ) -> list [ Path ] : \n urls_content = \"<STR_LIT>\" \n for django_model in django_models : \n model_name_lower = django_model [ \"<STR_LIT>\" ] . lower ( ) \n urlsafe_model_verbose_name_plural = django_model [ \"<STR_LIT>\" ] . lower ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n urls_content += get_urls ( \n model_name_lower = model_name_lower , \n urlsafe_model_verbose_name_plural = urlsafe_model_verbose_name_plural , \n ) \n if entry_point : \n urls_content = urls_content . replace ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) \n urls_content = urls_content . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n urls_content = urls_content . replace ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) \n app_urls = app_folder_path / \"<STR_LIT>\" \n updated_files = [ app_urls ] \n if app_urls . exists ( ) : \n urlpatterns = f\"<STR_LIT>\" \n app_urls . write_text ( app_urls . read_text ( ) + urlpatterns ) \n else : \n app_urls . touch ( ) \n app_urls . write_text ( initial_urls_content ( app_label , urls_content ) ) \n updated_files . append ( register_app_urls ( app_label = app_label , app_name = app_name ) ) \n return updated_files \n @ simple_progress ( \"<STR_LIT>\" ) \n def generate_html_templates ( \n self , \n templates_dir : Path , \n blueprints : list [ Path ] , \n contexts : list [ \"<STR_LIT>\" ] , \n * , \n entry_point : bool , \n ) -> list [ Path ] : \n updated_files = [ ] \n templates_dir . mkdir ( exist_ok = True , parents = True ) \n for blueprint in blueprints : \n filecontent = blueprint . read_text ( ) \n for context in contexts : \n model_name_lower = context [ \"<STR_LIT>\" ] . lower ( ) \n new_filename = f\"<STR_LIT>\" \n if entry_point : \n new_filename = blueprint . name . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if new_filename . startswith ( \"<STR_LIT>\" ) : \n new_filename = new_filename . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n file_to_write_to = templates_dir / new_filename \n file_to_write_to . touch ( exist_ok = True ) \n views_content = render_to_string ( filecontent , context = context ) \n if entry_point : \n views_content = views_content . replace ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) \n views_content = views_content . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n file_to_write_to . write_text ( views_content ) \n updated_files . append ( file_to_write_to ) \n return updated_files \n def get_urls ( model_name_lower : str , urlsafe_model_verbose_name_plural : str ) -> str : \n prefix = urlsafe_model_verbose_name_plural \n return \n def get_urls_template_string ( app_label : str , model_name_lower : str ) -> UrlsForContext : \n return { \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n } \n def initial_urls_content ( app_label : str , urls_content : str ) -> str : \n return \n def register_app_urls ( app_label : str , app_name : str ) -> Path : \n root_url = run_in_shell ( get_root_url_config_path , eval_result = False ) \n root_url = root_url . strip ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n rool_url_path = Path ( f\"<STR_LIT>\" ) \n module = parso . parse ( rool_url_path . read_text ( ) ) \n new_path = parso . parse ( f\"<STR_LIT>\" ) \n for node in module . children : \n try : \n if ( \n node . children [ <NUM_LIT> ] . type == parso . python . tree . ExprStmt . type \n and node . children [ <NUM_LIT> ] . children [ <NUM_LIT> ] . value == \"<STR_LIT>\" \n ) : \n patterns = node . children [ <NUM_LIT> ] . children [ <NUM_LIT> ] \n elements = patterns . children [ <NUM_LIT> ] \n elements . children . append ( new_path ) \n new_content = module . get_code ( ) \n new_content = \"<STR_LIT>\" + new_content \n rool_url_path . write_text ( new_content ) \n break \n except AttributeError : \n continue \n return rool_url_path \n def register_models_in_admin ( app_folder_path : Path , app_label : str , model_name : str | None = None ) -> Path : \n admin_file = app_folder_path / \"<STR_LIT>\" \n admin_file . touch ( exist_ok = True ) \n cmd_args = [ app_label ] \n if model_name : \n cmd_args . append ( model_name ) \n result = subprocess . run ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , * cmd_args ] ,", "output": "capture_output = True , \n text = True , \n check = False , \n ) \n if result . returncode != <NUM_LIT> : \n msg = result . stderr . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] \n rich_print ( f\"<STR_LIT>\" ) \n return admin_file \n admin_code = result . stdout . split ( \"<STR_LIT>\" , <NUM_LIT> ) [ <NUM_LIT> ] \n admin_file . write_text ( admin_file . read_text ( ) + admin_code ) \n if not model_name : \n return admin_file \n admin_lines = admin_file . read_text ( ) . split ( \"<STR_LIT>\" ) \n _imports = [ ] \n _code = [ ] \n for line in admin_lines : \n if line . startswith ( \"<STR_LIT>\" ) : \n _imports . append ( line ) \n else : \n _code . append ( line ) \n admin_file . write_text ( \"<STR_LIT>\" + \"<STR_LIT>\" . join ( _imports ) + \"<STR_LIT>\" + \"<STR_LIT>\" . join ( _code ) ) \n return admin_file \n def get_python_blueprint_context ( \n project_name : str , \n app_label : str , \n django_model : DjangoModel , \n crud_utils_import : str , \n * , \n login_required : bool , \n entry_point : bool , \n ) -> PythonBlueprintContext : \n model_fields = django_model [ \"<STR_LIT>\" ] \n model_name = django_model [ \"<STR_LIT>\" ] \n return { \n \"<STR_LIT>\" : project_name , \n \"<STR_LIT>\" : app_label , \n \"<STR_LIT>\" : login_required , \n \"<STR_LIT>\" : model_name , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : model_fields , \n \"<STR_LIT>\" : crud_utils_import , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : entry_point , \n } \n def get_html_blueprint_context ( app_label : str , django_model : DjangoModel ) -> HtmlBlueprintContext : \n return { \n \"<STR_LIT>\" : app_label , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : django_model [ \"<STR_LIT>\" ] , \n ** get_urls_template_string ( \n app_label = app_label , \n model_name_lower = django_model [ \"<STR_LIT>\" ] . lower ( ) , \n ) , \n } \n def get_models_data ( app_label : str , excluded_fields : list [ str ] , * , entry_point : bool ) -> \"<STR_LIT>\" : \n from django . apps import apps \n models = apps . get_app_config ( app_label ) . get_models ( ) \n file_fields = ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n dates_fields = ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def get_model_dict ( model ) -> \"<STR_LIT>\" : \n name = model . __name__ \n name_lower = name . lower ( ) \n if entry_point : \n name_plural = app_label . lower ( ) \n else : \n name_plural = f\"<STR_LIT>\" if name . endswith ( \"<STR_LIT>\" ) else f\"<STR_LIT>\" \n verbose_name = model . _meta . verbose_name \n verbose_name_plural = model . _meta . verbose_name_plural \n fields : dict [ str , \"<STR_LIT>\" ] = { \n field . name : { \n \"<STR_LIT>\" : field . verbose_name , \n \"<STR_LIT>\" : field . editable , \n \"<STR_LIT>\" : field . __class__ . __name__ , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n f\"<STR_LIT>\" + ( \"<STR_LIT>\" if field . __class__ . __name__ in file_fields else \"<STR_LIT>\" ) , \n } \n for field in model . _meta . fields \n if field . name not in excluded_fields \n } \n return { \n \"<STR_LIT>\" : name , \n \"<STR_LIT>\" : name_plural , \n \"<STR_LIT>\" : fields , \n \"<STR_LIT>\" : verbose_name , \n \"<STR_LIT>\" : verbose_name_plural , \n \"<STR_LIT>\" : any ( f [ \"<STR_LIT>\" ] in file_fields for f in fields . values ( ) ) , \n \"<STR_LIT>\" : any ( f [ \"<STR_LIT>\" ] in dates_fields and f [ \"<STR_LIT>\" ] for f in fields . values ( ) ) , \n } \n return [ get_model_dict ( model ) for model in models ] \n def get_app_path_name_and_templates_dir ( app_label : str ) -> tuple [ str , str , str ] : \n from django . apps import apps \n from django . conf import settings \n from pathlib import Path \n app = apps . get_app_config ( app_label ) \n dirs = settings . TEMPLATES [ <NUM_LIT> ] . get ( \"<STR_LIT>\" , [ ] ) \n templates_dir = Path ( dirs [ <NUM_LIT> ] ) if dirs else Path ( app . path ) / \"<STR_LIT>\" \n app_templates_dir = templates_dir / app_label \n return str ( app . path ) , str ( app . name ) , str ( app_templates_dir ) \n def get_root_url_config_path ( ) -> str : \n from django . conf import settings \n return settings . ROOT_URLCONF"}, {"input": "import http \n from typing import Callable , Dict , List , Optional , Type \n from django . db . models import ManyToManyField , Model \n from django . http import HttpRequest \n from ninja import Schema \n from ninja_crud . views . abstract_model_view import AbstractModelView \n from ninja_crud . views . enums import HTTPMethod \n class UpdateModelView ( AbstractModelView ) : \n def __init__ ( \n self , \n method : HTTPMethod = HTTPMethod . PUT , \n path : str = \"<STR_LIT>\" , \n path_parameters : Optional [ Schema ] = None , \n request_body : Optional [ Type [ Schema ] ] = None , \n response_body : Optional [ Type [ Schema ] ] = None , \n decorators : Optional [ List [ Callable ] ] = None , \n router_kwargs : Optional [ Dict ] = None , \n get_model : Optional [ Callable [ [ HttpRequest , Optional [ Schema ] ] , Model ] ] = None , \n pre_save : Optional [ Callable [ [ HttpRequest , Model ] , None ] ] = None , \n post_save : Optional [ Callable [ [ HttpRequest , Model ] , None ] ] = None , \n update_model : Optional [ \n Callable [ [ HttpRequest , Optional [ Schema ] , Optional [ Schema ] ] , Model ] \n ] = None , \n ) -> None : \n super ( ) . __init__ ( \n method = method , \n path = path , \n path_parameters = path_parameters , \n query_parameters = None , \n request_body = request_body , \n response_body = response_body , \n response_status = http . HTTPStatus . OK , \n decorators = decorators , \n router_kwargs = router_kwargs , \n ) \n self . get_model = get_model or self . _default_get_model \n self . pre_save = pre_save or self . _default_pre_save \n self . post_save = post_save or self . _default_post_save \n self . update_model = update_model or self . _default_update_model", "output": "def _default_get_model ( \n self , request : HttpRequest , path_parameters : Optional [ Schema ] \n ) -> Model : \n return self . model_viewset_class . model . objects . get ( \n ** ( path_parameters . dict ( ) if path_parameters else { } ) \n ) \n @ staticmethod \n def _default_pre_save ( request : HttpRequest , instance : Model ) -> None : \n instance . full_clean ( ) \n @ staticmethod \n def _default_post_save ( request : HttpRequest , instance : Model ) -> None : \n pass \n def _default_update_model ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] , \n request_body : Optional [ Schema ] , \n ) -> Model : \n instance = self . get_model ( request , path_parameters ) \n if request_body : \n for field , value in request_body . dict ( exclude_unset = True ) . items ( ) : \n if isinstance ( instance . _meta . get_field ( field ) , ManyToManyField ) : \n getattr ( instance , field ) . set ( value ) \n else : \n setattr ( instance , field , value ) \n self . pre_save ( request , instance ) \n instance . save ( ) \n self . post_save ( request , instance ) \n return instance \n def handle_request ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] , \n query_parameters : Optional [ Schema ] , \n request_body : Optional [ Schema ] , \n ) -> Model : \n return self . update_model ( request , path_parameters , request_body ) \n def _inherit_model_viewset_class_attributes ( self ) -> None : \n if self . request_body is None : \n self . request_body = self . model_viewset_class . default_request_body \n if self . response_body is None : \n self . response_body = self . model_viewset_class . default_response_body"}, {"input": "from rest_framework . viewsets import ModelViewSet \n from feeds . models import Location \n from core . pagination import LocationPagination \n from feeds . filters import LocationFilterBackend \n from feeds . serializers import LocationSerializer \n class LocationViewSet ( ModelViewSet ) :", "output": "queryset = Location . objects . select_related ( \"<STR_LIT>\" ) . all ( ) \n serializer_class = LocationSerializer \n http_method_names = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n pagination_class = LocationPagination \n filter_backends = [ LocationFilterBackend ]"}, {"input": "import os \n from collections . abc import Mapping \n from typing import Any , NotRequired , Self \n import llm \n from llm . models import dataclass \n from . . types import AIResponse \n from . base import AIBackend , BaseAIBackendConfig , BaseAIBackendConfigSettings \n class LLMBackendConfigSettingsDict ( BaseAIBackendConfigSettings ) : \n PROMPT_KWARGS : NotRequired [ Mapping [ str , Any ] | None ] \n INIT_KWARGS : NotRequired [ Mapping [ str , Any ] | None ] \n @ dataclass ( kw_only = True ) \n class LLMBackendConfig ( BaseAIBackendConfig [ LLMBackendConfigSettingsDict ] ) : \n prompt_kwargs : Mapping [ str , Any ] \n init_kwargs : Mapping [ str , Any ] \n @ classmethod \n def from_settings ( cls , config : LLMBackendConfigSettingsDict , ** kwargs : Any ) -> Self : \n init_kwargs = config . get ( \"<STR_LIT>\" ) \n if init_kwargs is None : \n init_kwargs = { } \n kwargs . setdefault ( \"<STR_LIT>\" , init_kwargs ) \n prompt_kwargs = config . get ( \"<STR_LIT>\" ) \n if prompt_kwargs is None : \n prompt_kwargs = { } \n kwargs . setdefault ( \"<STR_LIT>\" , prompt_kwargs ) \n return super ( ) . from_settings ( config , ** kwargs ) \n class LLMBackend ( AIBackend [ LLMBackendConfig ] ) : \n config_cls = LLMBackendConfig \n def prompt_with_context ( \n self , * , pre_prompt : str , context : str , post_prompt : str | None = None \n ) -> AIResponse :", "output": "model = self . get_llm_model ( ) \n parts = [ pre_prompt , context ] \n if post_prompt is not None : \n parts . append ( post_prompt ) \n full_prompt = os . linesep . join ( parts ) \n prompt_kwargs = { } \n if self . config . prompt_kwargs is not None : \n prompt_kwargs . update ( self . config . prompt_kwargs ) \n return model . prompt ( full_prompt , ** prompt_kwargs ) \n def get_llm_model ( self ) -> llm . Model : \n model = llm . get_model ( self . config . model_id ) \n if self . config . init_kwargs is not None : \n for config_key , config_val in self . config . init_kwargs . items ( ) : \n setattr ( model , config_key , config_val ) \n return model"}, {"input": "import os \n import sys", "output": "def main ( ) : \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n try : \n from django . core . management import execute_from_command_line \n except ImportError as exc : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) from exc \n execute_from_command_line ( sys . argv ) \n if __name__ == '<STR_LIT>' : \n main ( )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AddField (", "output": "model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . TextField ( blank = True , null = True ) , \n ) , \n ]"}, {"input": "import subprocess \n from contextlib import suppress \n import cappa", "output": "def clean_git_repo ( * , ignore_dirty : bool = False ) -> None : \n if ignore_dirty : \n return \n with suppress ( subprocess . CalledProcessError ) : \n result = subprocess . run ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , capture_output = True , text = True , check = True ) \n if result . stdout . strip ( ) == \"<STR_LIT>\" : \n return \n raise cappa . Exit ( \n \"<STR_LIT>\" , \n code = <NUM_LIT> , \n )"}, {"input": "from unittest . mock import MagicMock \n from django . test import TestCase \n from ninja_crud import views , viewsets \n from tests . test_app . models import Item \n from tests . test_app . schemas import ItemIn , ItemOut \n class TestUpdateModelView ( TestCase ) : \n def test_register_route_router_kwargs ( self ) :", "output": "router_mock = MagicMock ( ) \n class ItemViewSet ( viewsets . ModelViewSet ) : \n model = Item \n update_item = views . UpdateModelView ( \n request_body = ItemIn , \n response_body = ItemOut , \n router_kwargs = { \"<STR_LIT>\" : True } , \n ) \n ItemViewSet . update_item . register_route ( router_mock , \"<STR_LIT>\" ) \n router_mock . api_operation . assert_called_once ( ) \n self . assertTrue ( router_mock . api_operation . call_args [ <NUM_LIT> ] [ \"<STR_LIT>\" ] )"}, {"input": "from __future__ import annotations \n from pathlib import Path \n from typing import Annotated \n import cappa \n from falco . config import read_falco_config \n from falco . config import write_falco_config \n from falco . utils import get_pyproject_file \n from falco . utils import network_request_with_progress \n from httpx import codes \n from rich import print as rich_print \n from rich . panel import Panel \n HTMX_DOWNLOAD_URL = \"<STR_LIT>\" \n HTMX_GH_RELEASE_LATEST_URL = \"<STR_LIT>\" \n HtmxConfig = tuple [ Path , str | None ] \n def get_latest_tag ( ) -> str : \n with network_request_with_progress ( HTMX_GH_RELEASE_LATEST_URL , \"<STR_LIT>\" ) as response : \n try : \n return response . json ( ) [ \"<STR_LIT>\" ] [ <NUM_LIT> : ] \n except KeyError as e : \n msg = ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) \n raise cappa . Exit ( msg , code = <NUM_LIT> ) from e \n @ cappa . command ( help = \"<STR_LIT>\" ) \n class Htmx : \n version : Annotated [ str , cappa . Arg ( default = \"<STR_LIT>\" ) ] = \"<STR_LIT>\" \n output : Annotated [ Path | None , cappa . Arg ( default = None , short = \"<STR_LIT>\" , long = \"<STR_LIT>\" ) ] = None \n def __call__ ( self ) : \n latest_version = get_latest_tag ( ) \n version = self . version if self . version != \"<STR_LIT>\" else latest_version \n try : \n pyproject_path = get_pyproject_file ( ) \n falco_config = read_falco_config ( pyproject_path ) \n except cappa . Exit : \n falco_config = { } \n pyproject_path = None \n filepath = self . download ( version , falco_config = falco_config ) \n if pyproject_path : \n write_falco_config ( \n pyproject_path = pyproject_path , \n htmx = self . format_for_config ( filepath , version ) , \n ) \n subtitle = ( \n \"<STR_LIT>\" \n if version == latest_version \n else f\"<STR_LIT>\" \n ) \n rich_print ( \n Panel ( \n f\"<STR_LIT>\" , \n subtitle = subtitle , \n )", "output": ") \n @ classmethod \n def format_for_config ( cls , filepath : Path , version : str | None ) -> str : \n return str ( filepath ) if version is None else f\"<STR_LIT>\" \n def download ( self , version : str , falco_config : dict ) -> Path : \n url = HTMX_DOWNLOAD_URL . format ( version = version ) \n with network_request_with_progress ( url , f\"<STR_LIT>\" ) as response : \n content = response . content . decode ( \"<STR_LIT>\" ) \n if response . status_code == codes . NOT_FOUND : \n msg = f\"<STR_LIT>\" \n raise cappa . Exit ( msg , code = <NUM_LIT> ) \n filepath = self . resolve_filepath ( falco_config = falco_config ) \n filepath . parent . mkdir ( parents = True , exist_ok = True ) \n filepath . write_text ( content ) \n return filepath \n def resolve_filepath ( self , falco_config : dict ) -> Path : \n if self . output : \n filepath = self . output if str ( self . output ) . endswith ( \"<STR_LIT>\" ) else self . output / \"<STR_LIT>\" \n elif self . output is None and \"<STR_LIT>\" in falco_config : \n htmx_config = self . read_from_config ( falco_config ) \n filepath , _ = htmx_config \n else : \n filepath = Path ( \"<STR_LIT>\" ) \n return filepath \n @ classmethod \n def read_from_config ( cls , falco_config : dict ) -> HtmxConfig : \n htmx = falco_config . get ( \"<STR_LIT>\" ) \n if not htmx : \n return Path ( \"<STR_LIT>\" ) , None \n try : \n filepath , version = htmx . split ( \"<STR_LIT>\" ) \n except ValueError : \n return Path ( htmx ) , None \n return Path ( filepath ) , version"}, {"input": "from factory import SubFactory , django , fuzzy \n from dev . football . stadiums . models import Pitch , Stadium \n class StadiumFactory ( django . DjangoModelFactory ) : \n name = fuzzy . FuzzyText ( ) \n key = fuzzy . FuzzyText ( )", "output": "capacity = fuzzy . FuzzyInteger ( low = <NUM_LIT> , high = <NUM_LIT> ) \n class Meta : \n model = Stadium \n class PitchFactory ( django . DjangoModelFactory ) : \n stadium = SubFactory ( StadiumFactory ) \n surface_type = \"<STR_LIT>\" \n width = fuzzy . FuzzyInteger ( low = <NUM_LIT> , high = <NUM_LIT> ) \n length = fuzzy . FuzzyInteger ( low = <NUM_LIT> , high = <NUM_LIT> ) \n class Meta : \n model = Pitch"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . TextField ( blank = True , null = True ) , \n ) , \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' ,", "output": "field = models . CharField ( default = '<STR_LIT>' , max_length = <NUM_LIT> ) , \n ) , \n ]"}, {"input": "import http \n import json \n from typing import Optional , Type , cast \n import django . http \n import django . test \n from ninja import Schema \n from ninja_crud . testing . core import ArgOrCallable , TestCaseType , ViewTestManager \n from ninja_crud . testing . core . components import Headers , PathParameters , Payloads \n from ninja_crud . testing . views import AbstractModelViewTest \n from ninja_crud . views import UpdateModelView \n class UpdateModelViewTest ( AbstractModelViewTest ) :", "output": "model_view : UpdateModelView \n def __init__ ( \n self , \n path_parameters : ArgOrCallable [ PathParameters , TestCaseType ] , \n payloads : ArgOrCallable [ Payloads , TestCaseType ] , \n headers : Optional [ ArgOrCallable [ Headers , TestCaseType ] ] = None , \n ) -> None : \n super ( ) . __init__ ( model_view_class = UpdateModelView ) \n self . view_test_manager = ViewTestManager ( \n simulate_request = self . simulate_request , \n path_parameters = path_parameters , \n headers = headers , \n payloads = payloads , \n ) \n def on_successful_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) -> None : \n actual_output = json . loads ( response . content ) \n expected_output = self . _get_expected_output ( \n response = response , path_parameters = path_parameters \n ) \n self . model_viewset_test_case . assertDictEqual ( actual_output , expected_output ) \n def _get_expected_output ( \n self , response : django . http . HttpResponse , path_parameters : dict \n ) -> dict : \n path_parameters_schema : Optional [ Schema ] = ( \n self . model_view . path_parameters ( ** path_parameters ) \n if self . model_view . path_parameters \n else None \n ) \n instance = self . model_view . get_model ( \n getattr ( response , \"<STR_LIT>\" , None ) , \n path_parameters_schema , \n ) \n schema = cast ( Type [ Schema ] , self . model_view . response_body ) . from_orm ( instance ) \n return json . loads ( schema . json ( ) ) \n def on_failed_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) -> None : \n pass \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_update_model_ok ( self ) : \n self . view_test_manager . test_view_ok ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_successful_request , \n status = http . HTTPStatus . OK , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_update_model_payloads_bad_request ( self ) : \n self . view_test_manager . test_view_payloads_bad_request ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_update_model_payloads_conflict ( self ) : \n self . view_test_manager . test_view_payloads_conflict ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_update_model_headers_unauthorized ( self ) : \n self . view_test_manager . test_view_headers_unauthorized ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_update_model_headers_forbidden ( self ) : \n self . view_test_manager . test_view_headers_forbidden ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_update_model_path_parameters_not_found ( self ) : \n self . view_test_manager . test_view_path_parameters_not_found ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n )"}, {"input": "", "output": "class PrimaryReplicaRouter : \n def db_for_read ( self , model , ** hints ) : \n return \"<STR_LIT>\" \n def db_for_write ( self , model , ** hints ) : \n return \"<STR_LIT>\" \n def allow_relation ( self , obj1 , obj2 , ** hints ) : \n db_set = { \"<STR_LIT>\" , \"<STR_LIT>\" } \n if obj1 . _state . db in db_set and obj2 . _state . db in db_set : \n return True \n return None \n def allow_migrate ( self , db , app_label , model_name = None , ** hints ) : \n return True"}, {"input": "from unittest . mock import MagicMock \n from django . test import TestCase \n from ninja_crud import views , viewsets \n from ninja_crud . viewsets import ModelViewSet \n from tests . test_app . models import Item \n from tests . test_app . schemas import ItemOut \n class TestReadModelView ( TestCase ) : \n def test_register_route_router_kwargs ( self ) : \n router_mock = MagicMock ( )", "output": "class ItemViewSet ( viewsets . ModelViewSet ) : \n model = Item \n read_item = views . ReadModelView ( \n response_body = ItemOut , \n router_kwargs = { \"<STR_LIT>\" : True } , \n ) \n ItemViewSet . read_item . register_route ( router_mock , \"<STR_LIT>\" ) \n router_mock . api_operation . assert_called_once ( ) \n self . assertTrue ( router_mock . api_operation . call_args [ <NUM_LIT> ] [ \"<STR_LIT>\" ] ) \n def test_bind_to_viewset_with_response_body ( self ) : \n model_view = views . ReadModelView ( response_body = ItemOut ) \n class ItemModelViewSet ( ModelViewSet ) : \n model = Item \n default_request_body = None \n default_response_body = None \n model_view . model_viewset_class = ItemModelViewSet \n def test_bind_to_viewset_without_response_body ( self ) : \n model_view = views . ReadModelView ( ) \n class ItemModelViewSet ( ModelViewSet ) : \n model = Item \n default_request_body = None \n default_response_body = ItemOut \n model_view . model_viewset_class = ItemModelViewSet \n def test_bind_to_viewset_without_response_body_error ( self ) : \n model_view = views . ReadModelView ( ) \n class ItemModelViewSet ( ModelViewSet ) : \n model = Item \n with self . assertRaises ( AttributeError ) : \n model_view . model_viewset_class = ItemModelViewSet"}, {"input": "from drf_yasg . generators import OpenAPISchemaGenerator \n from drf_yasg . inspectors import SwaggerAutoSchema \n from application . settings import SWAGGER_SETTINGS \n def get_summary ( string ) : \n if string is not None : \n result = string . strip ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . split ( \"<STR_LIT>\" ) \n return result [ <NUM_LIT> ] \n class CustomSwaggerAutoSchema ( SwaggerAutoSchema ) : \n def get_tags ( self , operation_keys = None ) : \n tags = super ( ) . get_tags ( operation_keys )", "output": "if \"<STR_LIT>\" in tags and operation_keys : \n tags [ <NUM_LIT> ] = operation_keys [ SWAGGER_SETTINGS . get ( '<STR_LIT>' , <NUM_LIT> ) ] \n return tags \n def get_summary_and_description ( self ) : \n summary_and_description = super ( ) . get_summary_and_description ( ) \n summary = get_summary ( self . __dict__ . get ( '<STR_LIT>' ) . __doc__ ) \n description = summary_and_description [ <NUM_LIT> ] \n return summary , description \n class CustomOpenAPISchemaGenerator ( OpenAPISchemaGenerator ) : \n def get_schema ( self , request = None , public = False ) : \n swagger = super ( ) . get_schema ( request , public ) \n swagger . tags = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } , \n ] \n return swagger"}, {"input": "import os . path \n try : \n chr = unichr \n except NameError : \n pass \n VERSION = '<STR_LIT>' \n class Pinyin ( object ) : \n data_path = os . path . join ( os . path . dirname ( os . path . abspath ( __file__ ) ) , '<STR_LIT>' ) \n def __init__ ( self ) : \n self . dict = { } \n self . revdict = { } \n for line in open ( self . data_path ) : \n k , v = line . strip ( ) . split ( '<STR_LIT>' ) \n v = v . lower ( ) . split ( '<STR_LIT>' ) \n hz = chr ( int ( '<STR_LIT>' % k , <NUM_LIT> ) ) \n self . dict [ hz ] = v \n for vkey in v : \n self . revdict . setdefault ( vkey , [ ] ) \n self . revdict [ vkey ] . append ( hz ) \n def py2hz ( self , pinyin ) : \n if pinyin == '<STR_LIT>' : \n return [ ] \n pinyin = pinyin . lower ( ) \n if pinyin [ - <NUM_LIT> ] . isdigit ( ) : \n return self . revdict . get ( pinyin , [ ] ) \n ret = [ ] \n for i in range ( <NUM_LIT> , <NUM_LIT> ) : \n key = '<STR_LIT>' % ( pinyin , i ) \n ret += self . revdict . get ( key , [ ] ) \n return ret \n def get_pinyin ( self , chars = '<STR_LIT>' , splitter = '<STR_LIT>' , tone = False ) : \n result = [ ]", "output": "for char in chars : \n v = self . dict . get ( char , None ) \n if v : \n v = v [ <NUM_LIT> ] \n if not tone and v [ - <NUM_LIT> ] . isdigit ( ) : \n v = v [ : - <NUM_LIT> ] \n else : \n v = char \n result . append ( v ) \n return splitter . join ( result ) \n def get_initials ( self , char = '<STR_LIT>' ) : \n if char == '<STR_LIT>' : \n return '<STR_LIT>' \n return self . dict . get ( char , [ char ] ) [ <NUM_LIT> ] [ <NUM_LIT> ] . upper ( ) \n if __name__ == '<STR_LIT>' : \n import unittest \n class PinyinTestCase ( unittest . TestCase ) : \n def setUp ( self ) : \n import sys \n py = sys . version_info \n self . py3k = py >= ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . py = Pinyin ( ) \n def to_unicode ( self , s ) : \n if self . py3k : \n return s \n return s . decode ( '<STR_LIT>' ) \n def test_get_pinyin ( self ) : \n s = self . to_unicode ( '<STR_LIT>' ) \n a = self . to_unicode ( '<STR_LIT>' ) \n aa = self . to_unicode ( '<STR_LIT>' ) \n aaa = self . to_unicode ( '<STR_LIT>' ) \n self . assertEqual ( self . py . get_pinyin ( s ) , a ) \n self . assertEqual ( self . py . get_pinyin ( s , tone = True ) , aa ) \n self . assertEqual ( self . py . get_pinyin ( s , splitter = '<STR_LIT>' ) , aaa ) \n def test_get_initials ( self ) : \n s = self . to_unicode ( '<STR_LIT>' ) \n a = self . to_unicode ( '<STR_LIT>' ) \n self . assertEqual ( self . py . get_initials ( s ) , a ) \n def test_py2hz ( self ) : \n s1 = self . to_unicode ( '<STR_LIT>' ) \n s2 = self . to_unicode ( '<STR_LIT>' ) \n a1 = self . to_unicode ( '<STR_LIT>' ) \n a2 = self . to_unicode ( '<STR_LIT>' ) \n self . assertEqual ( '<STR_LIT>' . join ( self . py . py2hz ( s1 ) ) , a1 ) \n self . assertEqual ( '<STR_LIT>' . join ( self . py . py2hz ( s2 ) ) , a2 ) \n unittest . main ( )"}, {"input": "from pathlib import Path \n from unittest . mock import patch \n import pytest \n from cappa . testing import CommandRunner \n from falco . commands . htmx import Htmx \n from falco . config import read_falco_config \n from falco . config import write_falco_config \n @ pytest . fixture ( autouse = True ) \n def mock_latest_tag_getter ( ) : \n def _get_latest_tag ( ) : \n return \"<STR_LIT>\" \n with patch ( \"<STR_LIT>\" , new = _get_latest_tag ) : \n yield \n def test_htmx_download ( runner : CommandRunner ) : \n runner . invoke ( \"<STR_LIT>\" ) \n assert Path ( \"<STR_LIT>\" ) . exists ( ) \n def test_htmx_download_with_version ( runner : CommandRunner ) : \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert Path ( \"<STR_LIT>\" ) . exists ( ) \n def test_htmx_download_with_specific_version ( runner : CommandRunner ) : \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n assert Path ( \"<STR_LIT>\" ) . exists ( ) \n def test_htmx_download_to_output_dir ( runner : CommandRunner ) : \n output = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , str ( output . resolve ( ) ) ) \n assert ( output / \"<STR_LIT>\" ) . exists ( ) \n def test_htmx_download_to_output_file ( runner : CommandRunner ) : \n output = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , str ( output . resolve ( ) ) ) \n assert output . exists ( ) \n def test_htmx_with_pyproject_toml ( runner : CommandRunner ) : \n pyproject_toml = Path ( \"<STR_LIT>\" ) \n pyproject_toml . touch ( ) \n write_falco_config ( pyproject_path = pyproject_toml ) \n runner . invoke ( \"<STR_LIT>\" ) \n assert Path ( \"<STR_LIT>\" ) . exists ( ) \n filepath , version = Htmx . read_from_config ( read_falco_config ( pyproject_toml ) ) \n assert filepath == Path ( \"<STR_LIT>\" ) \n def test_htmx_with_pyproject_toml_custom_folder ( runner : CommandRunner ) : \n pyproject_toml = Path ( \"<STR_LIT>\" ) \n pyproject_toml . touch ( ) \n write_falco_config ( pyproject_path = pyproject_toml ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n output = Path ( \"<STR_LIT>\" ) \n assert output . exists ( ) \n filepath , version = Htmx . read_from_config ( read_falco_config ( pyproject_toml ) ) \n assert filepath == output \n def test_htmx_with_pyproject_toml_custom_file ( runner : CommandRunner ) : \n pyproject_toml = Path ( \"<STR_LIT>\" )", "output": "pyproject_toml . touch ( ) \n write_falco_config ( pyproject_path = pyproject_toml ) \n runner . invoke ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n output = Path ( \"<STR_LIT>\" ) \n assert output . exists ( ) \n filepath , version = Htmx . read_from_config ( read_falco_config ( pyproject_toml ) ) \n assert filepath == output \n def test_htmx_with_pyproject_toml_custom_file_existing_config ( runner : CommandRunner ) : \n pyproject_toml = Path ( \"<STR_LIT>\" ) \n pyproject_toml . touch ( ) \n write_falco_config ( pyproject_path = pyproject_toml , htmx = \"<STR_LIT>\" ) \n existing_path = Path ( \"<STR_LIT>\" ) \n runner . invoke ( \"<STR_LIT>\" ) \n filepath , _ = Htmx . read_from_config ( read_falco_config ( pyproject_toml ) ) \n assert filepath == existing_path \n assert existing_path . exists ( )"}, {"input": "from rest_framework import serializers \n from rest_framework . decorators import action \n from dvadmin . system . models import Menu , RoleMenuPermission \n from dvadmin . system . views . menu_button import MenuButtonSerializer \n from dvadmin . utils . json_response import SuccessResponse , ErrorResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class MenuSerializer ( CustomModelSerializer ) : \n menuPermission = serializers . SerializerMethodField ( read_only = True ) \n hasChild = serializers . SerializerMethodField ( ) \n def get_menuPermission ( self , instance ) : \n queryset = instance . menuPermission . order_by ( '<STR_LIT>' ) . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n if queryset : \n return queryset \n else : \n return None \n def get_hasChild ( self , instance ) : \n hasChild = Menu . objects . filter ( parent = instance . id ) \n if hasChild : \n return True \n return False \n class Meta : \n model = Menu \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class MenuCreateSerializer ( CustomModelSerializer ) :", "output": "name = serializers . CharField ( required = False ) \n def create ( self , validated_data ) : \n menu_obj = Menu . objects . filter ( parent_id = validated_data . get ( '<STR_LIT>' , None ) ) . order_by ( '<STR_LIT>' ) . first ( ) \n last_sort = menu_obj . sort if menu_obj else <NUM_LIT> \n validated_data [ '<STR_LIT>' ] = last_sort + <NUM_LIT> \n return super ( ) . create ( validated_data ) \n class Meta : \n model = Menu \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class WebRouterSerializer ( CustomModelSerializer ) : \n path = serializers . CharField ( source = \"<STR_LIT>\" ) \n title = serializers . CharField ( source = \"<STR_LIT>\" ) \n class Meta : \n model = Menu \n fields = ( \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n read_only_fields = [ \"<STR_LIT>\" ] \n class MenuViewSet ( CustomModelViewSet ) : \n queryset = Menu . objects . all ( ) \n serializer_class = MenuSerializer \n create_serializer_class = MenuCreateSerializer \n update_serializer_class = MenuCreateSerializer \n search_fields = [ '<STR_LIT>' , '<STR_LIT>' ] \n filter_fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n def list ( self , request ) : \n request . query_params . _mutable = True \n params = request . query_params \n parent = params . get ( '<STR_LIT>' , None ) \n page = params . get ( '<STR_LIT>' , None ) \n limit = params . get ( '<STR_LIT>' , None ) \n if page : \n del params [ '<STR_LIT>' ] \n if limit : \n del params [ '<STR_LIT>' ] \n if params : \n if parent : \n queryset = self . queryset . filter ( parent = parent ) \n else : \n queryset = self . queryset . filter ( ) \n else : \n queryset = self . queryset . filter ( parent__isnull = True ) \n queryset = self . filter_queryset ( queryset ) \n serializer = MenuSerializer ( queryset , many = True , request = request ) \n data = serializer . data \n return SuccessResponse ( data = data ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ ] ) \n def web_router ( self , request ) : \n user = request . user \n if user . is_superuser : \n queryset = self . queryset . filter ( status = <NUM_LIT> ) \n else : \n role_list = user . role . values_list ( '<STR_LIT>' , flat = True ) \n menu_list = RoleMenuPermission . objects . filter ( role__in = role_list ) . values_list ( '<STR_LIT>' , flat = True ) \n queryset = Menu . objects . filter ( id__in = menu_list ) \n serializer = WebRouterSerializer ( queryset , many = True , request = request ) \n data = serializer . data \n return SuccessResponse ( data = data , total = len ( data ) , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ ] ) \n def get_all_menu ( self , request ) : \n user = request . user \n queryset = self . queryset . all ( ) \n if not user . is_superuser : \n role_list = user . role . values_list ( '<STR_LIT>' , flat = True ) \n menu_list = RoleMenuPermission . objects . filter ( role__in = role_list ) . values_list ( '<STR_LIT>' ) \n queryset = Menu . objects . filter ( id__in = menu_list ) \n serializer = WebRouterSerializer ( queryset , many = True , request = request ) \n data = serializer . data \n return SuccessResponse ( data = data , total = len ( data ) , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ ] ) \n def move_up ( self , request ) : \n menu_id = request . data . get ( '<STR_LIT>' ) \n try : \n menu = Menu . objects . get ( id = menu_id ) \n except Menu . DoesNotExist : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n previous_menu = Menu . objects . filter ( sort__lt = menu . sort , parent = menu . parent ) . order_by ( '<STR_LIT>' ) . first ( ) \n if previous_menu : \n previous_menu . sort , menu . sort = menu . sort , previous_menu . sort \n previous_menu . save ( ) \n menu . save ( ) \n return SuccessResponse ( data = [ ] , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ ] ) \n def move_down ( self , request ) : \n menu_id = request . data [ '<STR_LIT>' ] \n try : \n menu = Menu . objects . get ( id = menu_id ) \n except Menu . DoesNotExist : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n next_menu = Menu . objects . filter ( sort__gt = menu . sort , parent = menu . parent ) . order_by ( '<STR_LIT>' ) . first ( ) \n if next_menu : \n next_menu . sort , menu . sort = menu . sort , next_menu . sort \n next_menu . save ( ) \n menu . save ( ) \n return SuccessResponse ( data = [ ] , msg = \"<STR_LIT>\" )"}, {"input": "import abc \n import functools \n import http \n import logging \n from typing import Any , Callable , Dict , List , Optional , Tuple , Type , Union \n import django . http \n import ninja \n from ninja_crud . views . enums import HTTPMethod \n logger = logging . getLogger ( __name__ ) \n class AbstractView ( abc . ABC ) : \n def __init__ ( \n self , \n method : HTTPMethod , \n path : str , \n path_parameters : Optional [ Type [ ninja . Schema ] ] = None , \n query_parameters : Optional [ Type [ ninja . Schema ] ] = None , \n request_body : Optional [ Type [ ninja . Schema ] ] = None , \n response_body : Union [ Type [ ninja . Schema ] , Type [ List [ ninja . Schema ] ] , None ] = None , \n response_status : http . HTTPStatus = http . HTTPStatus . OK , \n decorators : Optional [ List [ Callable ] ] = None , \n router_kwargs : Optional [ Dict ] = None , \n ) -> None : \n self . method = method \n self . path = path \n self . path_parameters = path_parameters \n self . query_parameters = query_parameters \n self . request_body = request_body \n self . response_body = response_body \n self . response_status = response_status \n self . decorators = decorators or [ ] \n self . router_kwargs = router_kwargs or { } \n @ abc . abstractmethod \n def handle_request ( \n self , \n request : django . http . HttpRequest , \n path_parameters : Optional [ ninja . Schema ] , \n query_parameters : Optional [ ninja . Schema ] , \n request_body : Optional [ ninja . Schema ] , \n ) -> Union [ Any , Tuple [ http . HTTPStatus , Any ] ] : \n pass \n def create_view_handler ( self ) -> Callable : \n path_parameters_schema_class = self . path_parameters \n query_parameters_schema_class = self . query_parameters \n request_body_schema_class = self . request_body \n def view_handler ( \n request : django . http . HttpRequest , \n path_parameters : path_parameters_schema_class = ninja . Path ( \n default = None , include_in_schema = False \n ) , \n query_parameters : query_parameters_schema_class = ninja . Query ( \n default = None , include_in_schema = False \n ) , \n request_body : request_body_schema_class = ninja . Body ( \n default = None , include_in_schema = False \n ) , \n ) : \n return self . handle_request ( \n request = request , \n path_parameters = path_parameters , \n query_parameters = query_parameters , \n request_body = request_body , \n ) \n return view_handler \n def register_route ( self , router : ninja . Router , route_name : str ) -> None : \n view = self . create_view_handler ( ) \n view . __name__ = route_name \n self . _configure_view_routing ( router = router ) ( view ) \n def _configure_view_routing ( self , router : ninja . Router ) -> Callable : \n def route_decorator ( view : Callable ) : \n for decorator in reversed ( self . decorators ) : \n view = decorator ( view ) \n @ router . api_operation ( ** self . _get_router_kwargs ( view . __name__ ) ) \n @ functools . wraps ( view ) \n def wrapped_view ( request : django . http . HttpRequest , * args , ** kwargs ) : \n return view ( request , * args , ** kwargs ) \n return wrapped_view \n return route_decorator \n def _get_router_kwargs ( self , operation_id : str ) -> Dict [ str , Any ] : \n return { \n \"<STR_LIT>\" : [ self . method . value ] , \n \"<STR_LIT>\" : self . path , \n \"<STR_LIT>\" : { self . response_status . value : self . response_body } , \n \"<STR_LIT>\" : operation_id , \n ** self . _clean_router_kwargs ( self . router_kwargs ) , \n } \n @ staticmethod \n def _clean_router_kwargs ( router_kwargs : dict ) -> dict : \n locked_keys = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n cleaned_kwargs = router_kwargs . copy ( ) \n for locked_key in locked_keys : \n if locked_key in cleaned_kwargs : \n logger . warning ( f\"<STR_LIT>\" )", "output": "cleaned_kwargs . pop ( locked_key ) \n return cleaned_kwargs"}, {"input": "import django . contrib . auth . models \n import django . contrib . auth . validators \n import django . utils . timezone \n from django . db import migrations \n from django . db import models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . DateTimeField ( blank = True , null = True , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . BooleanField ( \n default = False , \n help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n error_messages = { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n unique = True , \n validators = [ django . contrib . auth . validators . UnicodeUsernameValidator ( ) ] , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ,", "output": ") , \n ( \n \"<STR_LIT>\" , \n models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . EmailField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . BooleanField ( \n default = False , \n help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . BooleanField ( \n default = True , \n help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . DateTimeField ( default = django . utils . timezone . now , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ManyToManyField ( \n blank = True , \n help_text = \"<STR_LIT>\" , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ManyToManyField ( \n blank = True , \n help_text = \"<STR_LIT>\" , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : False , \n } , \n managers = [ \n ( \"<STR_LIT>\" , django . contrib . auth . models . UserManager ( ) ) , \n ] , \n ) , \n ]"}, {"input": "import os , django , sys , datetime , platform \n from django . utils import timezone \n from utils . general import argvs_get , channel_ids_to_dict , in_exclude_channel \n from utils . aboutdb import log \n from . spiders import epg_func \n from dateutil import tz \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n django . setup ( ) \n from web . models import Channel , Epg \n from utils . general import crawl_info , xmlinfo , dirs , add_info_title , add_info_desc , noepg \n recrawl , cname , crawl_dt , save_to_db = argvs_get ( sys . argv ) \n tz_sh = tz . gettz ( '<STR_LIT>' ) \n def main ( ) : \n log_start = '<STR_LIT>' \n max_crawl_days = crawl_info [ '<STR_LIT>' ] \n recrawl_days = crawl_info [ '<STR_LIT>' ] \n epgs_no = <NUM_LIT> \n for d in range ( max_crawl_days ) : \n ban_channels = [ ] \n dt = datetime . datetime . now ( ) . date ( ) + datetime . timedelta ( days = d ) if not cname else crawl_dt \n if cname : \n channels = Channel . get_spec_channel ( Channel , name = cname ) \n max_crawl_days = <NUM_LIT> \n else : \n if recrawl and d < recrawl_days : \n recrawl1 = <NUM_LIT> \n else : \n recrawl1 = <NUM_LIT> \n channels = Channel . get_crawl_channels ( Channel , dt , recrawl = recrawl1 ) \n channel_num = <NUM_LIT> \n failed_channels = [ ] \n success_num = <NUM_LIT> \n channel_queryset_no = <NUM_LIT> \n channel_no = channels . count ( ) \n log ( '<STR_LIT>' % ( dt . strftime ( '<STR_LIT>' ) , d + <NUM_LIT> , channel_no ) ) \n while True : \n if channel_queryset_no >= channel_no : \n if len ( ban_channels ) == <NUM_LIT> : \n break \n else : \n channel = ban_channels [ <NUM_LIT> ] \n else : \n channel = channels [ <NUM_LIT> ] \n channel_queryset_no += <NUM_LIT> \n channel_num += <NUM_LIT> \n msg1 = '<STR_LIT>' % ( \n channel_num , channel_no , channel . id , channel . name ) \n ret = get_epg ( channel , dt ) \n if '<STR_LIT>' not in ret : \n ret . update ( { '<STR_LIT>' : <NUM_LIT> } ) \n if ret [ '<STR_LIT>' ] == <NUM_LIT> : \n msg2 = '<STR_LIT>' % ret [ '<STR_LIT>' ] \n msg5 = '<STR_LIT>' \n if channel not in ban_channels : \n ban_channels . append ( channel ) \n msg5 = '<STR_LIT>' \n log ( '<STR_LIT>' % ( log_start , msg1 , msg2 , msg5 ) ) \n continue \n elif ret [ '<STR_LIT>' ] == <NUM_LIT> and channel in ban_channels : \n ban_channels . pop ( channel ) \n msg2 = '<STR_LIT>' % ( len ( ret [ '<STR_LIT>' ] ) , ret [ '<STR_LIT>' ] ) \n if cname : \n msg1 = '<STR_LIT>' % ( msg1 , channel . source ) \n for ep in ret [ '<STR_LIT>' ] : \n print ( '<STR_LIT>' % ( ep [ '<STR_LIT>' ] , ep [ '<STR_LIT>' ] , ep [ '<STR_LIT>' ] ) ) \n if len ( ret [ '<STR_LIT>' ] ) > <NUM_LIT> : \n msg1 = '<STR_LIT>' % ( msg1 , ret [ '<STR_LIT>' ] ) \n success_num += <NUM_LIT> \n msgx = '<STR_LIT>' \n if recrawl and channel . recrawl and d < recrawl_days : \n del_ret = Epg . del_channel_epgs ( Epg , channel . id , dt , ret [ '<STR_LIT>' ] ) \n msgx = '<STR_LIT>' % del_ret [ <NUM_LIT> ] \n recrawl_today = <NUM_LIT> \n else : \n recrawl_today = <NUM_LIT> \n if save_to_db : \n save_ret = Epg . save_to_dbs ( Epg , ret ) \n if save_ret [ '<STR_LIT>' ] : \n msg3 = '<STR_LIT>' \n else : \n msg3 = '<STR_LIT>' % save_ret [ '<STR_LIT>' ] \n else : \n msg3 = '<STR_LIT>' \n msgall = '<STR_LIT>' . join ( [ msg1 , msgx , msg2 , msg3 ] ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n log ( msgall ) \n if not recrawl_today : \n channel . last_program_date = ret [ '<STR_LIT>' ] \n else : \n channel . last_crawl_dt = timezone . now ( ) \n channel . save ( ) \n else : \n failed_channels . append ( '<STR_LIT>' % ( channel . id , channel . name ) ) \n if not cname : \n channels = channels . exclude ( id = channel . id ) \n if cname : \n return \n msgn1 = '<STR_LIT>' % ( '<STR_LIT>' . join ( failed_channels ) ) if len ( failed_channels ) > <NUM_LIT> else '<STR_LIT>' \n msg_failed = '<STR_LIT>' % ( channel_no - success_num ) if channel_no - success_num > <NUM_LIT> else '<STR_LIT>' \n msgn = '<STR_LIT>' % ( d + <NUM_LIT> , success_num , channel_no , msg_failed , msgn1 ) \n log ( msgn ) \n for s in xmlinfo : \n xmlgen_ret = gen_xml ( s ) \n epgs_no1 , epgsdir = xmlgen_ret [ <NUM_LIT> ] , xmlgen_ret [ <NUM_LIT> ] \n epgs_no = epgs_no1 if epgs_no1 > epgs_no else epgs_no \n if platform . system ( ) . lower ( ) == '<STR_LIT>' : \n new_epgsdir = epgsdir + '<STR_LIT>' \n cmd = '<STR_LIT>' % ( epgsdir , new_epgsdir ) \n os . system ( cmd ) \n log ( '<STR_LIT>' % new_epgsdir ) \n channels = Channel . get_need_channels ( Channel , '<STR_LIT>' ) [ <NUM_LIT> ] \n gen_test_m3u_ret = gen_test_m3u ( channels , dirs [ '<STR_LIT>' ] ) \n if gen_test_m3u_ret [ <NUM_LIT> ] : \n log ( gen_test_m3u_ret [ <NUM_LIT> ] ) \n def get_epg ( channel , dt , func_arg = <NUM_LIT> ) : \n log_start = '<STR_LIT>' \n n = <NUM_LIT> \n msg = '<STR_LIT>' \n channel_ids = channel_ids_to_dict ( channel . channel_id ) \n channel_id = channel_ids [ channel . source ] \n while n <= crawl_info [ '<STR_LIT>' ] : \n ret = epg_func ( channel , channel_id , dt , func_arg = func_arg ) \n if '<STR_LIT>' in ret and ret [ '<STR_LIT>' ] == <NUM_LIT> : \n return ret \n ret . update ( { '<STR_LIT>' : channel . source } )", "output": "if len ( ret [ '<STR_LIT>' ] ) > <NUM_LIT> : \n break \n else : \n log ( '<STR_LIT>' % ( channel . id , channel . name , channel . source , n , ret [ '<STR_LIT>' ] ) ) \n n += <NUM_LIT> \n if n > crawl_info [ '<STR_LIT>' ] : \n msg = '<STR_LIT>' % ( n - <NUM_LIT> , channel . source , '<STR_LIT>' % ( channel . id , channel . name ) , '<STR_LIT>' if crawl_info [ '<STR_LIT>' ] else '<STR_LIT>' , ret [ '<STR_LIT>' ] ) \n log ( msg ) \n if crawl_info [ '<STR_LIT>' ] : \n channel_ids . pop ( channel . source ) \n sources = [ channel . source ] \n for source in channel_ids : \n channel_id = channel_ids [ source ] \n ret = epg_func ( channel , channel_id , dt , func_arg = func_arg , source = source ) \n ret . update ( { '<STR_LIT>' : source } ) \n if ret [ '<STR_LIT>' ] == <NUM_LIT> : \n break \n else : \n log ( '<STR_LIT>' % ( channel . id , channel . name , source , ret [ '<STR_LIT>' ] ) , \n level = <NUM_LIT> ) \n sources . append ( source ) \n if not ret [ '<STR_LIT>' ] : \n log ( '<STR_LIT>' % ( '<STR_LIT>' . join ( sources ) ) , level = <NUM_LIT> ) \n else : \n log ( '<STR_LIT>' % ( '<STR_LIT>' . join ( sources ) + '<STR_LIT>' , ret [ '<STR_LIT>' ] ) , level = <NUM_LIT> ) \n return ret \n def gen_xml ( sort ) : \n if cname : \n return <NUM_LIT> \n xmlhead = '<STR_LIT>' \n xmlbottom = '<STR_LIT>' \n get_days = crawl_info [ '<STR_LIT>' ] \n xmldir = '<STR_LIT>' % ( dirs [ '<STR_LIT>' ] , xmlinfo [ sort ] [ '<STR_LIT>' ] ) \n tz = '<STR_LIT>' \n need_date = datetime . datetime . now ( ) . date ( ) + datetime . timedelta ( days = get_days ) \n channels = Channel . get_need_channels ( Channel , xmlinfo [ sort ] [ '<STR_LIT>' ] ) \n epgs = Epg . get_epgs ( Epg , channels [ <NUM_LIT> ] , need_date ) \n log ( '<STR_LIT>' % ( channels [ <NUM_LIT> ] . count ( ) , epgs . count ( ) ) ) \n f = open ( xmldir , '<STR_LIT>' , encoding = '<STR_LIT>' ) \n f . write ( xmlhead ) \n for channel in channels [ <NUM_LIT> ] : \n if channel . sort in in_exclude_channel [ '<STR_LIT>' ] and channel . name not in in_exclude_channel [ '<STR_LIT>' ] and channel . tvg_name not in in_exclude_channel [ '<STR_LIT>' ] : \n continue \n c = '<STR_LIT>' % ( channel . id , channel . tvg_name ) \n f . write ( c ) \n noepg_channel = '<STR_LIT>' \n f . write ( noepg_channel ) \n for epg in epgs : \n start = epg . starttime . astimezone ( tz = tz_sh ) . strftime ( '<STR_LIT>' ) + tz \n end = epg . endtime . astimezone ( tz = tz_sh ) . strftime ( '<STR_LIT>' ) + tz \n id = epg . channel_id \n title = epg . title + add_info_title \n title = title . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( \"<STR_LIT>\" , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n desc = epg . descr + add_info_desc \n desc = desc . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( \"<STR_LIT>\" , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n programinfo = % ( start , end , id , title , desc ) \n f . write ( programinfo ) \n for x in range ( <NUM_LIT> ) : \n noepg_program_day = noepg ( '<STR_LIT>' , '<STR_LIT>' , ( datetime . datetime . now ( ) . date ( ) + datetime . timedelta ( days = x - <NUM_LIT> ) ) ) \n f . write ( noepg_program_day ) \n f . write ( xmlbottom ) \n f . close ( ) \n log ( '<STR_LIT>' % ( xmlinfo [ sort ] [ '<STR_LIT>' ] , xmldir ) ) \n return [ epgs . count ( ) , xmldir ] \n def gen_test_m3u ( channels , test_dir ) : \n with open ( test_dir , '<STR_LIT>' , encoding = '<STR_LIT>' , errors = '<STR_LIT>' ) as f : \n f . write ( '<STR_LIT>' ) \n n = <NUM_LIT> \n for channel in channels : \n n += <NUM_LIT> \n logo = channel . logo \n tvgname = channel . tvg_name \n name = channel . name \n grouptitle = channel . sort \n channel_id = channel . id \n if grouptitle in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : \n grouptitle = '<STR_LIT>' \n if grouptitle not in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : \n grouptitle = '<STR_LIT>' \n line = '<STR_LIT>' % ( logo , channel_id , tvgname , grouptitle , name ) \n line1 = '<STR_LIT>' % ( n ) \n f . write ( line ) \n f . write ( line1 ) \n msg = '<STR_LIT>' % ( channels . count ( ) , dirs [ '<STR_LIT>' ] ) \n return [ <NUM_LIT> , msg ]"}, {"input": "from enum import Enum \n class HTTPMethod ( str , Enum ) : \n def __init__ ( self , value , description ) : \n self . _value_ = value \n self . description = description \n def __new__ ( cls , value , description ) : \n obj = str . __new__ ( cls , value ) \n obj . _value_ = value \n obj . description = description \n return obj \n CONNECT = \"<STR_LIT>\" , \"<STR_LIT>\" \n DELETE = \"<STR_LIT>\" , \"<STR_LIT>\" \n GET = \"<STR_LIT>\" , \"<STR_LIT>\" \n HEAD = \"<STR_LIT>\" , \"<STR_LIT>\"", "output": "OPTIONS = \"<STR_LIT>\" , \"<STR_LIT>\" \n PATCH = \"<STR_LIT>\" , \"<STR_LIT>\" \n POST = \"<STR_LIT>\" , \"<STR_LIT>\" \n PUT = \"<STR_LIT>\" , \"<STR_LIT>\" \n TRACE = \"<STR_LIT>\" , \"<STR_LIT>\""}, {"input": "", "output": "class SearchRequest : \n def __init__ ( self , query : str , timerange : str = None , region : str = None , ua : str = None ) : \n self . query = query \n self . timerange = timerange \n self . region = region \n self . ua = ua \n class SearchResponse : \n def __init__ ( self , status : int , html : str , url : str ) : \n self . status = status \n self . html = html \n self . url = url \n class SearchResult : \n def __init__ ( self , title : str , body : str , url : str ) : \n self . title = title \n self . body = body \n self . url = url"}, {"input": "from enum import Enum \n from django . utils . translation import gettext_lazy as _", "output": "class PlayerPosition ( Enum ) : \n GK = _ ( \"<STR_LIT>\" ) \n LB = _ ( \"<STR_LIT>\" ) \n CB = _ ( \"<STR_LIT>\" ) \n RB = _ ( \"<STR_LIT>\" ) \n DM = _ ( \"<STR_LIT>\" ) \n CM = _ ( \"<STR_LIT>\" ) \n AM = _ ( \"<STR_LIT>\" ) \n LW = _ ( \"<STR_LIT>\" ) \n RW = _ ( \"<STR_LIT>\" ) \n ST = _ ( \"<STR_LIT>\" )"}, {"input": "from django . conf import settings \n from django . contrib import admin \n from django . urls import path , include \n from django . conf . urls . static import static \n urlpatterns = [", "output": "path ( \"<STR_LIT>\" , admin . site . urls ) , \n path ( \"<STR_LIT>\" , include ( \"<STR_LIT>\" ) ) , \n path ( \"<STR_LIT>\" , include ( \"<STR_LIT>\" ) ) , \n ] + static ( settings . STATIC_URL , document_root = settings . STATIC_ROOT ) \n if settings . DEBUG : \n urlpatterns += [ path ( \"<STR_LIT>\" , include ( \"<STR_LIT>\" ) ) ]"}, {"input": "import django . utils . timezone \n from django . db import migrations \n from django . db import models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , unique = True ) ) , \n ( \"<STR_LIT>\" , models . TextField ( ) ) , \n ( \"<STR_LIT>\" , models . DecimalField ( decimal_places = <NUM_LIT> , max_digits = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , unique = True ) ) ,", "output": "( \"<STR_LIT>\" , models . DateTimeField ( default = django . utils . timezone . now ) ) , \n ] , \n ) , \n ]"}, {"input": "import django . db . models . deletion \n import django . contrib . postgres . fields \n from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \"<STR_LIT>\" : [ \"<STR_LIT>\" ] } , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = django . contrib . postgres . fields . ArrayField ( \n base_field = models . CharField ( max_length = <NUM_LIT> ) , null = True , size = None \n ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" ,", "output": "field = models . CharField ( \n choices = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] , \n max_length = <NUM_LIT> , \n ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . ForeignKey ( \n on_delete = django . db . models . deletion . CASCADE , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ]"}, {"input": "from django . urls import path \n from . import views \n app_name = \"<STR_LIT>\" \n urlpatterns = [ \n path ( \"<STR_LIT>\" , views . product_list , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . product_create , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . product_detail , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , views . product_update , name = \"<STR_LIT>\" ) ,", "output": "path ( \"<STR_LIT>\" , views . product_delete , name = \"<STR_LIT>\" ) , \n ]"}, {"input": "import os \n import requests \n if \"<STR_LIT>\" in os . environ : \n print ( \"<STR_LIT>\" ) \n response = requests . post ( \n os . environ [ \"<STR_LIT>\" ] , \n json = { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n + os . environ [ \"<STR_LIT>\" ] , \n } , \n ) \n print ( \"<STR_LIT>\" , response ) \n else : \n print (", "output": "\"<STR_LIT>\" \n )"}, {"input": "import re \n from typing import List \n from datetime import datetime \n from . search_abc import SearchResult \n def remove_commands ( query : str ) -> str : \n query = re . sub ( r'<STR_LIT>' , '<STR_LIT>' , query ) \n query = re . sub ( r'<STR_LIT>' , '<STR_LIT>' , query ) \n return query \n def compile_prompt ( results : List [ SearchResult ] , query : str , default_prompt : str ) -> str : \n formatted_results = format_web_results ( results ) \n current_date = datetime . now ( ) . strftime ( \"<STR_LIT>\" ) \n print ( default_prompt ) \n prompt = replace_variables ( default_prompt , { \n '<STR_LIT>' : formatted_results , \n '<STR_LIT>' : remove_commands ( query ) , \n '<STR_LIT>' : current_date", "output": "} ) \n return prompt \n def format_web_results ( results : List [ SearchResult ] ) -> str : \n if len ( results ) == <NUM_LIT> : \n return \"<STR_LIT>\" \n formatted_results = \"<STR_LIT>\" \n counter = <NUM_LIT> \n for result in results : \n formatted_results += f\"<STR_LIT>\" \n counter += <NUM_LIT> \n return formatted_results \n def replace_variables ( prompt : str , variables : dict ) -> str : \n new_prompt = prompt \n for key , value in variables . items ( ) : \n try : \n new_prompt = new_prompt . replace ( key , value ) \n except Exception as error : \n print ( \"<STR_LIT>\" , error ) \n return new_prompt"}, {"input": "import pickle \n from asap . makedataset import Dataset \n import torch \n import configargparse \n from model import AESmodel \n from fivefold import fivefold \n import os \n def _initialize_arguments ( p : configargparse . ArgParser ) : \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' ) \n p . add ( '<STR_LIT>' , action = '<STR_LIT>' , help = '<STR_LIT>' ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = float ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = int ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = int ) \n p . add ( '<STR_LIT>' , action = '<STR_LIT>' , help = '<STR_LIT>' ) \n p . add ( '<STR_LIT>' ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = float ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = str ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = int ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = float ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = float ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = float ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = float ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = float ) \n p . add ( '<STR_LIT>' , help = '<STR_LIT>' , type = str ) \n args = p . parse_args ( ) \n if torch . cuda . is_available ( ) and args . cuda : \n args . device = '<STR_LIT>' \n else : \n args . device = '<STR_LIT>' \n return args \n if __name__ == \"<STR_LIT>\" : \n p = configargparse . ArgParser ( default_config_files = [ \"<STR_LIT>\" ] ) \n args = _initialize_arguments ( p ) \n print ( f'<STR_LIT>' ) \n with open ( f'<STR_LIT>' , '<STR_LIT>' ) as f : \n dataset = pickle . load ( f ) \n folds = fivefold ( dataset ) \n for val_index in range ( len ( folds . essay_folds ) ) : \n for test_index in range ( len ( folds . essay_folds ) ) : \n valessays = [ ] \n valscores = [ ] \n testessays = [ ] \n testscores = [ ] \n trainessays = [ ] \n trainscores = [ ]", "output": "if val_index == test_index : \n continue \n foldname = f'<STR_LIT>' \n for i , ( essays , scores ) in enumerate ( zip ( folds . essay_folds , folds . score_folds ) ) : \n if i == val_index : \n valessays = folds . essay_folds [ i ] \n valscores = folds . score_folds [ i ] \n elif i == test_index : \n testessays = folds . essay_folds [ i ] \n testscores = folds . score_folds [ i ] \n else : \n trainessays = trainessays + folds . essay_folds [ i ] \n trainscores = trainscores + folds . score_folds [ i ] \n model = AESmodel ( traindata = ( trainessays , trainscores ) , valdata = ( valessays , valscores ) , \n testdata = ( testessays , testscores ) , foldname = foldname , args = args ) \n filepath = f'<STR_LIT>' \n if not os . path . isdir ( filepath ) : \n os . mkdir ( filepath ) \n if not os . path . isdir ( filepath + f'<STR_LIT>' ) : \n os . mkdir ( filepath + f'<STR_LIT>' ) \n os . mkdir ( filepath + f'<STR_LIT>' ) \n os . mkdir ( filepath + f'<STR_LIT>' ) \n os . mkdir ( filepath + f'<STR_LIT>' ) \n model . train ( ) \n pass"}, {"input": "import pytest \n from test_utils . settings import custom_text_splitting \n from wagtail_ai . ai import ( \n get_ai_backend , \n ) \n from wagtail_ai . text_splitters . dummy import DummyLengthCalculator , DummyTextSplitter \n from wagtail_ai . text_splitters . langchain import LangchainRecursiveCharacterTextSplitter \n from wagtail_ai . text_splitters . length import NaiveTextSplitterCalculator \n @ custom_text_splitting ( { } ) \n def test_default_text_splitter ( ) : \n ai_backend = get_ai_backend ( \"<STR_LIT>\" ) \n text_splitter = ai_backend . get_text_splitter ( ) \n assert isinstance ( text_splitter , LangchainRecursiveCharacterTextSplitter ) \n @ custom_text_splitting ( { } ) \n def test_default_length_calculator ( ) : \n ai_backend = get_ai_backend ( \"<STR_LIT>\" ) \n length_calculator = ai_backend . get_splitter_length_calculator ( ) \n assert isinstance ( length_calculator , NaiveTextSplitterCalculator ) \n @ custom_text_splitting ( \n { \"<STR_LIT>\" : \"<STR_LIT>\" } \n ) \n def test_custom_text_splitter ( ) : \n ai_backend = get_ai_backend ( \"<STR_LIT>\" ) \n text_splitter = ai_backend . get_text_splitter ( ) \n assert isinstance ( text_splitter , DummyTextSplitter ) \n @ custom_text_splitting ( \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n ) \n def test_custom_length_calculator ( ) : \n ai_backend = get_ai_backend ( \"<STR_LIT>\" ) \n length_calculator = ai_backend . get_splitter_length_calculator ( ) \n assert isinstance ( length_calculator , DummyLengthCalculator ) \n LENGTH_CALCULATOR_SAMPLE_TEXTS = [ \n , \n , \n ]", "output": "NAIVE_LENGTH_CALCULATOR_TESTS_TABLE = [ \n ( LENGTH_CALCULATOR_SAMPLE_TEXTS [ <NUM_LIT> ] , <NUM_LIT> ) , \n ( LENGTH_CALCULATOR_SAMPLE_TEXTS [ <NUM_LIT> ] , <NUM_LIT> ) , \n ] \n @ pytest . mark . parametrize ( \"<STR_LIT>\" , NAIVE_LENGTH_CALCULATOR_TESTS_TABLE ) \n def test_naive_text_splitter_length_calculator ( test_input , expected ) : \n length_calculator = NaiveTextSplitterCalculator ( ) \n assert length_calculator . get_splitter_length ( test_input ) == expected \n DUMMY_LENGTH_CALCULATOR_TESTS_TABLE = [ \n ( val , len ( val ) ) for val in LENGTH_CALCULATOR_SAMPLE_TEXTS \n ] \n @ pytest . mark . parametrize ( \"<STR_LIT>\" , DUMMY_LENGTH_CALCULATOR_TESTS_TABLE ) \n def test_dummy_text_splitter_length_calculator ( test_input , expected ) : \n length_calculator = DummyLengthCalculator ( ) \n assert length_calculator . get_splitter_length ( test_input ) == expected"}, {"input": "import logging \n import os \n from typing import Type , cast \n from django import forms \n from django . conf import settings \n from django . http import JsonResponse \n from django . shortcuts import get_object_or_404 \n from django . utils . translation import gettext as _ \n from django . views . decorators . csrf import csrf_exempt \n from wagtail . admin . ui . tables import UpdatedAtColumn \n from wagtail . admin . viewsets . model import ModelViewSet \n from wagtail . images . models import AbstractImage \n from wagtail . images . permissions import get_image_model \n from . import ai , types \n from . ai . base import BackendFeature \n from . forms import DescribeImageApiForm , PromptForm \n from . models import Prompt \n logger = logging . getLogger ( __name__ ) \n class AIHandlerException ( Exception ) : \n pass \n def _process_backend_request ( \n ai_backend : ai . AIBackend , pre_prompt : str , context : str \n ) -> types . AIResponse : \n try : \n response = ai_backend . prompt_with_context ( \n pre_prompt = pre_prompt , context = context \n ) \n except Exception as e : \n raise AIHandlerException ( \n \"<STR_LIT>\" \n ) from e \n return response \n def _replace_handler ( * , prompt : Prompt , text : str ) -> str : \n ai_backend = ai . get_backend ( ) \n splitter = ai_backend . get_text_splitter ( ) \n texts = splitter . split_text ( text ) \n for split in texts : \n response = _process_backend_request ( \n ai_backend , pre_prompt = prompt . prompt_value , context = split \n ) \n message = os . linesep . join ( [ s for s in response . text ( ) . splitlines ( ) if s ] ) \n text = text . replace ( split , message ) \n return text \n def _append_handler ( * , prompt : Prompt , text : str ) -> str : \n ai_backend = ai . get_backend ( ) \n length_calculator = ai_backend . get_splitter_length_calculator ( ) \n if length_calculator . get_splitter_length ( text ) > ai_backend . config . token_limit : \n raise AIHandlerException ( \"<STR_LIT>\" ) \n response = _process_backend_request ( \n ai_backend , pre_prompt = prompt . prompt_value , context = text \n ) \n message = os . linesep . join ( [ s for s in response . text ( ) . splitlines ( ) if s ] ) \n return message \n def ErrorJsonResponse ( error_message , status = <NUM_LIT> ) : \n return JsonResponse ( { \"<STR_LIT>\" : error_message } , status = status ) \n @ csrf_exempt \n def text_completion ( request ) -> JsonResponse : \n prompt_form = PromptForm ( request . POST ) \n if not prompt_form . is_valid ( ) : \n return ErrorJsonResponse ( prompt_form . errors_for_json_response ( ) , status = <NUM_LIT> ) \n try : \n prompt = Prompt . objects . get ( uuid = prompt_form . cleaned_data [ \"<STR_LIT>\" ] ) \n except Prompt . DoesNotExist : \n return ErrorJsonResponse ( _ ( \"<STR_LIT>\" ) , status = <NUM_LIT> ) \n handlers = { \n Prompt . Method . REPLACE : _replace_handler , \n Prompt . Method . APPEND : _append_handler , \n } \n handler = handlers [ Prompt . Method ( prompt . method ) ] \n try : \n response = handler ( prompt = prompt , text = prompt_form . cleaned_data [ \"<STR_LIT>\" ] ) \n except AIHandlerException as e : \n return ErrorJsonResponse ( str ( e ) , status = <NUM_LIT> ) \n except Exception : \n logger . exception ( \"<STR_LIT>\" ) \n return ErrorJsonResponse ( _ ( \"<STR_LIT>\" ) ) \n return JsonResponse ( { \"<STR_LIT>\" : response } ) \n def user_has_permission_for_image ( user , image ) : \n from wagtail . images . permissions import permission_policy \n return permission_policy . user_has_permission_for_instance ( user , \"<STR_LIT>\" , image ) \n def describe_image ( request ) -> JsonResponse : \n form = DescribeImageApiForm ( request . POST ) \n if not form . is_valid ( ) : \n return ErrorJsonResponse ( form . errors_for_json_response ( ) , status = <NUM_LIT> ) \n model = cast ( Type [ AbstractImage ] , get_image_model ( ) ) \n image = get_object_or_404 ( model , pk = form . cleaned_data [ \"<STR_LIT>\" ] ) \n if not user_has_permission_for_image ( request . user , image ) : \n return ErrorJsonResponse ( \"<STR_LIT>\" , status = <NUM_LIT> ) \n try : \n backend = ai . get_backend ( BackendFeature . IMAGE_DESCRIPTION ) \n except ai . BackendNotFound : \n return ErrorJsonResponse ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" , \n status = <NUM_LIT> , \n ) \n wagtail_ai_settings = getattr ( settings , \"<STR_LIT>\" , { } ) \n rendition_filter = wagtail_ai_settings . get ( \n \"<STR_LIT>\" , \"<STR_LIT>\" \n ) \n rendition = image . get_rendition ( rendition_filter ) \n maxlength = form . cleaned_data [ \"<STR_LIT>\" ]", "output": "prompt = wagtail_ai_settings . get ( \"<STR_LIT>\" ) \n if prompt is None : \n prompt = ( \n \"<STR_LIT>\" \n ) \n if maxlength is not None : \n prompt += f\"<STR_LIT>\" \n try : \n ai_response = backend . describe_image ( image_file = rendition . file , prompt = prompt ) \n description = ai_response . text ( ) \n except Exception : \n logger . exception ( \"<STR_LIT>\" ) \n return ErrorJsonResponse ( \"<STR_LIT>\" ) \n if not description : \n return ErrorJsonResponse ( \"<STR_LIT>\" ) \n if maxlength is not None : \n description = description [ : maxlength ] \n return JsonResponse ( { \"<STR_LIT>\" : description } ) \n class PromptEditForm ( forms . ModelForm ) : \n class Meta : \n model = Prompt \n fields = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n def __init__ ( self , * args , ** kwargs ) : \n super ( ) . __init__ ( * args , ** kwargs ) \n if self . instance . is_default : \n self . fields [ \"<STR_LIT>\" ] . required = False \n self . fields [ \"<STR_LIT>\" ] . widget . attrs [ \n \"<STR_LIT>\" \n ] = self . instance . get_default_prompt_value ( ) \n class PromptViewSet ( ModelViewSet ) : \n model = Prompt \n form_fields = PromptEditForm . Meta . fields \n list_display = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , UpdatedAtColumn ( ) ] \n icon = \"<STR_LIT>\" \n add_to_settings_menu = True \n menu_order = <NUM_LIT> \n def get_form_class ( self , for_update = False ) : \n if for_update : \n return PromptEditForm \n return super ( ) . get_form_class ( for_update ) \n prompt_viewset = PromptViewSet ( \"<STR_LIT>\" )"}, {"input": "from django . contrib . auth . models import AbstractUser \n from django . db . models import CharField \n from django . urls import reverse \n from django . utils . translation import gettext_lazy as _ \n class User ( AbstractUser ) : \n name = CharField ( _ ( \"<STR_LIT>\" ) , blank = True , max_length = <NUM_LIT> ) \n first_name = None \n last_name = None \n def get_absolute_url ( self ) :", "output": "return reverse ( \"<STR_LIT>\" , kwargs = { \"<STR_LIT>\" : self . username } )"}, {"input": "from pathlib import Path \n from typing import Annotated \n import cappa \n from falco import checks \n from falco . utils import get_project_name \n from falco . utils import run_in_shell \n from falco . utils import simple_progress \n from rich import print as rich_print \n def get_django_debug_value ( ) -> bool : \n from django . conf import settings \n return settings . DEBUG \n @ cappa . command ( help = \"<STR_LIT>\" ) \n class RmMigrations : \n apps_dir : Annotated [ \n Path | None , \n cappa . Arg ( default = None , help = \"<STR_LIT>\" ) , \n ] \n skip_git_check : Annotated [ \n bool ,", "output": "cappa . Arg ( \n default = False , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] \n def __call__ ( self , project_name : Annotated [ str , cappa . Dep ( get_project_name ) ] ) : \n checks . clean_git_repo ( ignore_dirty = self . skip_git_check ) \n django_debug_value = run_in_shell ( get_django_debug_value , eval_result = True ) \n if not django_debug_value : \n raise cappa . Exit ( \n \"<STR_LIT>\" , \n code = <NUM_LIT> , \n ) \n if not self . apps_dir : \n self . apps_dir = Path ( ) / project_name \n apps = set ( ) \n with simple_progress ( \"<STR_LIT>\" ) : \n for folder in self . apps_dir . iterdir ( ) : \n migration_dir = folder / \"<STR_LIT>\" \n if not migration_dir . exists ( ) : \n continue \n apps . add ( folder . stem ) \n for file in migration_dir . iterdir ( ) : \n if file . suffix == \"<STR_LIT>\" and file . name not in [ \"<STR_LIT>\" ] : \n file . unlink ( ) \n apps_ = \"<STR_LIT>\" . join ( apps ) \n rich_print ( f\"<STR_LIT>\" )"}, {"input": "from collections . abc import Sequence \n from typing import NotRequired , Required , TypedDict \n class PromptDict ( TypedDict ) : \n default_prompt_id : Required [ int ] \n label : Required [ str ] \n description : NotRequired [ str ] \n prompt : Required [ str ] \n method : Required [ str ] \n DEFAULT_PROMPTS : Sequence [ PromptDict ] = [ \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : (", "output": "\"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ]"}, {"input": "import requests , os , datetime \n from utils . general import cht_to_chs , headers \n def get_epgs_icable ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n url = '<STR_LIT>' % ( channel_id , dt . strftime ( '<STR_LIT>' ) ) \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n js = res . json ( ) \n epg_list = js [ '<STR_LIT>' ] \n for g in epg_list : \n title = cht_to_chs ( g [ '<STR_LIT>' ] ) \n ampm = g [ '<STR_LIT>' ] \n t = g [ '<STR_LIT>' ] \n starttime = datetime . datetime . strptime ( dt . strftime ( '<STR_LIT>' ) + t , '<STR_LIT>' ) \n if ampm . upper ( ) == '<STR_LIT>' : \n starttime = starttime + datetime . timedelta ( hours = <NUM_LIT> ) \n elif ampm . upper ( ) == '<STR_LIT>' : \n starttime = starttime + datetime . timedelta ( days = <NUM_LIT> ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : starttime . date ( ) , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs ,", "output": "'<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_icable ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url ) \n res_json = res . json ( ) \n channels_json = res_json [ '<STR_LIT>' ] \n channels = [ ] \n for c in channels_json : \n name = c [ '<STR_LIT>' ] \n id = c [ '<STR_LIT>' ] \n url = '<STR_LIT>' % c [ '<STR_LIT>' ] \n logo = '<STR_LIT>' % c [ '<STR_LIT>' ] \n name_eng = c [ '<STR_LIT>' ] \n catelog = c [ '<STR_LIT>' ] \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : url , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : logo , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : name_eng , \n '<STR_LIT>' : catelog , \n } \n channels . append ( channel ) \n return channels"}, {"input": "from django . conf . urls . static import static \n from django . urls import path , include , re_path \n from drf_yasg import openapi \n from drf_yasg . views import get_schema_view \n from rest_framework import permissions \n from rest_framework_simplejwt . views import ( \n TokenRefreshView , \n ) \n from application import dispatch \n from application import settings \n from dvadmin . system . views . dictionary import InitDictionaryViewSet \n from dvadmin . system . views . login import ( \n LoginView , \n CaptchaView , \n ApiLogin , \n LogoutView , \n LoginTokenView \n ) \n from dvadmin . system . views . system_config import InitSettingsViewSet \n from dvadmin . utils . swagger import CustomOpenAPISchemaGenerator \n dispatch . init_system_config ( ) \n dispatch . init_dictionary ( ) \n schema_view = get_schema_view ( \n openapi . Info ( \n title = \"<STR_LIT>\" , \n default_version = \"<STR_LIT>\" , \n description = \"<STR_LIT>\" , \n terms_of_service = \"<STR_LIT>\" , \n contact = openapi . Contact ( email = \"<STR_LIT>\" ) , \n license = openapi . License ( name = \"<STR_LIT>\" ) , \n ) , \n public = True , \n permission_classes = ( permissions . AllowAny , ) , \n generator_class = CustomOpenAPISchemaGenerator , \n ) \n urlpatterns = ( \n [ \n re_path ( \n r\"<STR_LIT>\" , \n schema_view . without_ui ( cache_timeout = <NUM_LIT> ) , \n name = \"<STR_LIT>\" , \n ) , \n path ( \n \"<STR_LIT>\" , \n schema_view . with_ui ( \"<STR_LIT>\" , cache_timeout = <NUM_LIT> ) , \n name = \"<STR_LIT>\" , \n ) , \n path (", "output": "r\"<STR_LIT>\" , \n schema_view . with_ui ( \"<STR_LIT>\" , cache_timeout = <NUM_LIT> ) , \n name = \"<STR_LIT>\" , \n ) , \n path ( \"<STR_LIT>\" , include ( \"<STR_LIT>\" ) ) , \n path ( \"<STR_LIT>\" , LoginView . as_view ( ) , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , LogoutView . as_view ( ) , name = \"<STR_LIT>\" ) , \n path ( \"<STR_LIT>\" , TokenRefreshView . as_view ( ) , name = \"<STR_LIT>\" ) , \n re_path ( \n r\"<STR_LIT>\" , include ( \"<STR_LIT>\" , namespace = \"<STR_LIT>\" ) \n ) , \n path ( \"<STR_LIT>\" , CaptchaView . as_view ( ) ) , \n path ( \"<STR_LIT>\" , InitDictionaryViewSet . as_view ( ) ) , \n path ( \"<STR_LIT>\" , InitSettingsViewSet . as_view ( ) ) , \n path ( \"<STR_LIT>\" , ApiLogin . as_view ( ) ) , \n path ( \"<STR_LIT>\" , LoginTokenView . as_view ( ) ) , \n ] \n + static ( settings . MEDIA_URL , document_root = settings . MEDIA_ROOT ) \n + static ( settings . STATIC_URL , document_root = settings . STATIC_URL ) \n + [ re_path ( ele . get ( '<STR_LIT>' ) , include ( ele . get ( '<STR_LIT>' ) ) ) for ele in settings . PLUGINS_URL_PATTERNS ] \n )"}, {"input": "import torch \n import torch . nn as nn \n import torch . nn . functional as F \n import numpy as np \n import matplotlib . pyplot as plt \n import os \n def gen_counting_label ( labels , channel , tag ) : \n b , t = labels . size ( ) \n device = labels . device \n counting_labels = torch . zeros ( ( b , channel ) ) \n if tag : \n ignore = [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n else : \n ignore = [ ] \n for i in range ( b ) : \n for j in range ( t ) : \n k = labels [ i ] [ j ] \n if k in ignore : \n continue \n else :", "output": "counting_labels [ i ] [ k ] += <NUM_LIT> \n return counting_labels . to ( device )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [", "output": "( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . BinaryField ( editable = True ) , \n ) , \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . BinaryField ( editable = True ) , \n ) , \n ]"}, {"input": "import functools \n import os \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n from django . conf import settings \n from celery import platforms \n if \"<STR_LIT>\" in settings . INSTALLED_APPS : \n from tenant_schemas_celery . app import CeleryApp as TenantAwareCeleryApp \n app = TenantAwareCeleryApp ( ) \n else : \n from celery import Celery \n app = Celery ( f\"<STR_LIT>\" ) \n app . config_from_object ( '<STR_LIT>' ) \n app . autodiscover_tasks ( lambda : settings . INSTALLED_APPS ) \n platforms . C_FORCE_ROOT = True \n def retry_base_task_error ( ) : \n def wraps ( func ) : \n @ app . task ( bind = True , retry_delay = <NUM_LIT> , max_retries = <NUM_LIT> ) \n @ functools . wraps ( func ) \n def wrapper ( self , * args , ** kwargs ) : \n try : \n return func ( * args , ** kwargs )", "output": "except Exception as exc : \n raise self . retry ( exc = exc ) \n return wrapper \n return wraps"}, {"input": "from django . db import models \n from django . contrib import admin \n from django . utils . translation import gettext as _ \n class RustDeskToken ( models . Model ) : \n username = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n rid = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n uid = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n uuid = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n access_token = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> , blank = True ) \n create_time = models . DateTimeField ( verbose_name = _ ( '<STR_LIT>' ) , auto_now_add = True ) \n class Meta : \n ordering = ( '<STR_LIT>' , ) \n verbose_name = \"<STR_LIT>\" \n verbose_name_plural = _ ( \"<STR_LIT>\" ) \n class RustDeskTokenAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' ) \n search_fields = ( '<STR_LIT>' , '<STR_LIT>' ) \n list_filter = ( '<STR_LIT>' , ) \n class RustDeskTag ( models . Model ) : \n uid = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n tag_name = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n tag_color = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> , blank = True ) \n class Meta : \n ordering = ( '<STR_LIT>' , ) \n verbose_name = \"<STR_LIT>\" \n verbose_name_plural = _ ( \"<STR_LIT>\" )", "output": "class RustDeskTagAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n search_fields = ( '<STR_LIT>' , '<STR_LIT>' ) \n list_filter = ( '<STR_LIT>' , ) \n class RustDeskPeer ( models . Model ) : \n uid = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n rid = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n username = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n hostname = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n alias = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n platform = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n tags = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n rhash = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n class Meta : \n ordering = ( '<STR_LIT>' , ) \n verbose_name = \"<STR_LIT>\" \n verbose_name_plural = _ ( \"<STR_LIT>\" ) \n class RustDeskPeerAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n search_fields = ( '<STR_LIT>' , '<STR_LIT>' ) \n list_filter = ( '<STR_LIT>' , '<STR_LIT>' , ) \n class RustDesDevice ( models . Model ) : \n rid = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> , blank = True ) \n cpu = models . CharField ( verbose_name = '<STR_LIT>' , max_length = <NUM_LIT> ) \n hostname = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n memory = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n os = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n uuid = models . CharField ( verbose_name = '<STR_LIT>' , max_length = <NUM_LIT> ) \n username = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> , blank = True ) \n version = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n create_time = models . DateTimeField ( verbose_name = _ ( '<STR_LIT>' ) , auto_now_add = True ) \n update_time = models . DateTimeField ( verbose_name = ( '<STR_LIT>' ) , auto_now = True , blank = True ) \n class Meta : \n ordering = ( '<STR_LIT>' , ) \n verbose_name = _ ( \"<STR_LIT>\" ) \n verbose_name_plural = _ ( \"<STR_LIT>\" ) \n class RustDesDeviceAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n search_fields = ( '<STR_LIT>' , '<STR_LIT>' ) \n list_filter = ( '<STR_LIT>' , ) \n class ShareLink ( models . Model ) : \n uid = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n shash = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n peers = models . CharField ( verbose_name = _ ( '<STR_LIT>' ) , max_length = <NUM_LIT> ) \n is_used = models . BooleanField ( verbose_name = _ ( '<STR_LIT>' ) , default = False ) \n is_expired = models . BooleanField ( verbose_name = _ ( '<STR_LIT>' ) , default = False ) \n create_time = models . DateTimeField ( verbose_name = _ ( '<STR_LIT>' ) , auto_now_add = True ) \n class Meta : \n ordering = ( '<STR_LIT>' , ) \n verbose_name = _ ( \"<STR_LIT>\" ) \n verbose_name_plural = _ ( \"<STR_LIT>\" ) \n class ShareLinkAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n search_fields = ( '<STR_LIT>' , ) \n list_filter = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "from functools import wraps \n from django . core . paginator import InvalidPage \n from django . core . paginator import Paginator \n from django . db . models import QuerySet \n from django . http import Http404 \n from django . http import HttpResponse \n from django . template . loader import render_to_string \n from django . utils . translation import gettext_lazy as _ \n from . types import HttpRequest \n def paginate_queryset ( request : HttpRequest , queryset : QuerySet , page_size : int = <NUM_LIT> ) : \n paginator = Paginator ( queryset , page_size ) \n page_number = request . GET . get ( \"<STR_LIT>\" ) or <NUM_LIT> \n try : \n page_number = int ( page_number ) \n except ValueError as e : \n if page_number == \"<STR_LIT>\" : \n page_number = paginator . num_pages \n else : \n msg = \"<STR_LIT>\" \n raise Http404 ( _ ( msg ) ) from e \n try : \n return paginator . page ( page_number ) \n except InvalidPage as exc : \n msg = \"<STR_LIT>\" \n raise Http404 ( _ ( msg ) % ( page_number , str ( exc ) ) ) from exc \n def for_htmx ( \n * , \n if_hx_target : str | None = None , \n use_template : str | None = None , \n use_partial : str | list [ str ] | None = None , \n use_partial_from_params : bool = False , \n ) : \n if len ( [ p for p in [ use_partial , use_template , use_partial_from_params ] if p ] ) != <NUM_LIT> : \n raise ValueError ( \"<STR_LIT>\" ) \n def decorator ( view ) :", "output": "@ wraps ( view ) \n def _view ( request : HttpRequest , * args , ** kwargs ) : \n resp = view ( request , * args , ** kwargs ) \n if not request . htmx : \n return resp \n apply_decorator = if_hx_target is None or request . headers . get ( \"<STR_LIT>\" , None ) == if_hx_target \n if not apply_decorator : \n return resp \n partials_to_use = use_partial \n if not hasattr ( resp , \"<STR_LIT>\" ) : \n if not resp . content and any ( \n h in resp . headers \n for h in ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) \n ) : \n return resp \n raise ValueError ( \"<STR_LIT>\" ) \n if resp . is_rendered : \n raise ValueError ( \"<STR_LIT>\" ) \n if use_partial_from_params : \n use_partial_from_params_val = _get_param_from_request ( request , \"<STR_LIT>\" ) \n if use_partial_from_params_val is not None : \n partials_to_use = use_partial_from_params_val \n if use_template is not None : \n resp . template_name = use_template \n elif partials_to_use is not None : \n if not isinstance ( partials_to_use , list ) : \n partials_to_use = [ partials_to_use ] \n rendered_partials = [ \n render_to_string ( f\"<STR_LIT>\" , context = resp . context_data , request = request ) \n for b in partials_to_use \n ] \n resp = HttpResponse ( \n content = \"<STR_LIT>\" . join ( rendered_partials ) , \n status = resp . status_code , \n headers = resp . headers , \n ) \n return resp \n return _view \n return decorator \n def _get_param_from_request ( request , param ) : \n if param in request . GET : \n return request . GET . getlist ( param ) \n if request . method == \"<STR_LIT>\" and param in request . POST : \n return request . POST . getlist ( param ) \n return None"}, {"input": "import datetime \n from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [", "output": "( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateField ( default = datetime . date ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) , \n preserve_default = False , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( default = datetime . datetime ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) ) , \n preserve_default = False , \n ) , \n ]"}, {"input": "from . base import * \n from . base import env \n SECRET_KEY = env ( \"<STR_LIT>\" ) \n ALLOWED_HOSTS = env . list ( \"<STR_LIT>\" , default = [ \"<STR_LIT>\" ] ) \n DATABASES [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = env . int ( \"<STR_LIT>\" , default = <NUM_LIT> ) \n CACHES = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : env ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : True , \n } , \n } \n } \n SECURE_PROXY_SSL_HEADER = ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n SECURE_SSL_REDIRECT = env . bool ( \"<STR_LIT>\" , default = True ) \n SESSION_COOKIE_SECURE = True \n CSRF_COOKIE_SECURE = True \n SECURE_HSTS_SECONDS = <NUM_LIT> \n SECURE_HSTS_INCLUDE_SUBDOMAINS = env . bool ( \n \"<STR_LIT>\" , default = True \n ) \n SECURE_HSTS_PRELOAD = env . bool ( \"<STR_LIT>\" , default = True ) \n SECURE_CONTENT_TYPE_NOSNIFF = env . bool ( \n \"<STR_LIT>\" , default = True \n ) \n CORS_ALLOWED_ORIGINS = [ \n \"<STR_LIT>\" ,", "output": "] \n CORS_ORIGIN_ALLOW_ALL = False \n DEFAULT_FROM_EMAIL = env ( \n \"<STR_LIT>\" , \n default = \"<STR_LIT>\" , \n ) \n SERVER_EMAIL = env ( \"<STR_LIT>\" , default = DEFAULT_FROM_EMAIL ) \n EMAIL_SUBJECT_PREFIX = env ( \n \"<STR_LIT>\" , \n default = \"<STR_LIT>\" , \n ) \n ADMIN_URL = env ( \"<STR_LIT>\" ) \n INSTALLED_APPS += [ \"<STR_LIT>\" ] \n EMAIL_BACKEND = \"<STR_LIT>\" \n ANYMAIL = { \n \"<STR_LIT>\" : env ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : env ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : env ( \"<STR_LIT>\" , default = \"<STR_LIT>\" ) , \n } \n LOGGING = { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : { \"<STR_LIT>\" : \"<STR_LIT>\" } } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n \"<STR_LIT>\" \n } \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : [ \"<STR_LIT>\" ] } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : True , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : True , \n } , \n } , \n }"}, {"input": "import json \n import requests \n from django . conf import settings \n from django . contrib . auth . models import AbstractBaseUser \n from django . contrib . auth . models import AnonymousUser \n from django . urls . resolvers import ResolverMatch \n from rest_framework_simplejwt . authentication import JWTAuthentication \n from user_agents import parse \n from dvadmin . system . models import LoginLog", "output": "def get_request_user ( request ) : \n user : AbstractBaseUser = getattr ( request , '<STR_LIT>' , None ) \n if user and user . is_authenticated : \n return user \n try : \n user , tokrn = JWTAuthentication ( ) . authenticate ( request ) \n except Exception as e : \n pass \n return user or AnonymousUser ( ) \n def get_request_ip ( request ) : \n x_forwarded_for = request . META . get ( '<STR_LIT>' , '<STR_LIT>' ) \n if x_forwarded_for : \n ip = x_forwarded_for . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] . strip ( ) \n return ip \n ip = request . META . get ( '<STR_LIT>' , '<STR_LIT>' ) or getattr ( request , '<STR_LIT>' , None ) \n return ip or '<STR_LIT>' \n def get_request_data ( request ) : \n request_data = getattr ( request , '<STR_LIT>' , None ) \n if request_data : \n return request_data \n data : dict = { ** request . GET . dict ( ) , ** request . POST . dict ( ) } \n if not data : \n try : \n body = request . body \n if body : \n data = json . loads ( body ) \n except Exception as e : \n pass \n if not isinstance ( data , dict ) : \n data = { '<STR_LIT>' : data } \n return data \n def get_request_path ( request , * args , ** kwargs ) : \n request_path = getattr ( request , '<STR_LIT>' , None ) \n if request_path : \n return request_path \n values = [ ] \n for arg in args : \n if len ( arg ) == <NUM_LIT> : \n continue \n if isinstance ( arg , str ) : \n values . append ( arg ) \n elif isinstance ( arg , ( tuple , set , list ) ) : \n values . extend ( arg ) \n elif isinstance ( arg , dict ) : \n values . extend ( arg . values ( ) ) \n if len ( values ) == <NUM_LIT> : \n return request . path \n path : str = request . path \n for value in values : \n path = path . replace ( '<STR_LIT>' + value , '<STR_LIT>' + '<STR_LIT>' ) \n return path \n def get_request_canonical_path ( request , ) : \n request_path = getattr ( request , '<STR_LIT>' , None ) \n if request_path : \n return request_path \n path : str = request . path \n resolver_match : ResolverMatch = request . resolver_match \n for value in resolver_match . args : \n path = path . replace ( f\"<STR_LIT>\" , \"<STR_LIT>\" ) \n for key , value in resolver_match . kwargs . items ( ) : \n if key == '<STR_LIT>' : \n path = path . replace ( f\"<STR_LIT>\" , f\"<STR_LIT>\" ) \n continue \n path = path . replace ( f\"<STR_LIT>\" , f\"<STR_LIT>\" ) \n return path \n def get_browser ( request , ) : \n ua_string = request . META [ '<STR_LIT>' ] \n user_agent = parse ( ua_string ) \n return user_agent . get_browser ( ) \n def get_os ( request , ) : \n ua_string = request . META [ '<STR_LIT>' ] \n user_agent = parse ( ua_string ) \n return user_agent . get_os ( ) \n def get_verbose_name ( queryset = None , view = None , model = None ) : \n try : \n if queryset is not None and hasattr ( queryset , '<STR_LIT>' ) : \n model = queryset . model \n elif view and hasattr ( view . get_queryset ( ) , '<STR_LIT>' ) : \n model = view . get_queryset ( ) . model \n elif view and hasattr ( view . get_serializer ( ) , '<STR_LIT>' ) and hasattr ( view . get_serializer ( ) . Meta , '<STR_LIT>' ) : \n model = view . get_serializer ( ) . Meta . model \n if model : \n return getattr ( model , '<STR_LIT>' ) . verbose_name \n else : \n model = queryset . model . _meta . verbose_name \n except Exception as e : \n pass \n return model if model else \"<STR_LIT>\" \n def get_ip_analysis ( ip ) : \n data = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n if ip != '<STR_LIT>' and ip : \n if getattr ( settings , '<STR_LIT>' , True ) : \n try : \n res = requests . get ( url = '<STR_LIT>' , params = { \"<STR_LIT>\" : ip } , timeout = <NUM_LIT> ) \n if res . status_code == <NUM_LIT> : \n res_data = res . json ( ) \n if res_data . get ( '<STR_LIT>' ) == <NUM_LIT> : \n data = res_data . get ( '<STR_LIT>' ) \n return data \n except Exception as e : \n print ( e ) \n return data \n def save_login_log ( request ) : \n ip = get_request_ip ( request = request ) \n analysis_data = get_ip_analysis ( ip ) \n analysis_data [ '<STR_LIT>' ] = request . user . username \n analysis_data [ '<STR_LIT>' ] = ip \n analysis_data [ '<STR_LIT>' ] = str ( parse ( request . META [ '<STR_LIT>' ] ) ) \n analysis_data [ '<STR_LIT>' ] = get_browser ( request ) \n analysis_data [ '<STR_LIT>' ] = get_os ( request ) \n analysis_data [ '<STR_LIT>' ] = request . user . id \n analysis_data [ '<STR_LIT>' ] = getattr ( request . user , '<STR_LIT>' , '<STR_LIT>' ) \n LoginLog . objects . create ( ** analysis_data )"}, {"input": "from django . db import migrations \n from django . db import models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [", "output": "migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( blank = True , null = True ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . ImageField ( blank = True , null = True , upload_to = \"<STR_LIT>\" ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . FileField ( blank = True , null = True , upload_to = \"<STR_LIT>\" ) , \n ) , \n ]"}, {"input": "import segmentation . Layout4Card . api as OuterSegmentation \n import segmentation . blankSegmentation . blank_segmentation as BlankSegmentation \n import scoreblocks . singleCharacterRecognition as SingleCharacterRecognition \n import scoreblocks . fillblankmodel as FillBlankModel \n import scoreblocks . candemo as CanDemo \n import scoreblocks . essayscoremodel as EssayScoreModel \n import PIL . Image \n import cv2 \n import os \n class scoresystem : \n def __init__ ( self ) : \n self . outer_segmentation = OuterSegmentation . OuterSegmentation ( ) \n self . blank_segmentation = BlankSegmentation . Model ( ) \n self . single_character_recognition = SingleCharacterRecognition . Model ( '<STR_LIT>' , '<STR_LIT>' ) \n self . fill_blank_model = FillBlankModel . model ( ) \n self . candemo = CanDemo . model ( ) \n self . essay_score_model = EssayScoreModel . model ( ) \n self . answer = None \n def set_answer ( self , answer ) : \n self . answer = answer \n def tkt_score ( self , section_img , section_answer ) : \n blank_segmentation_result = self . blank_segmentation . process_img ( section_img ) \n score_result = { '<STR_LIT>' : '<STR_LIT>' } \n right_array = [ ] \n for i in range ( len ( blank_segmentation_result ) ) : \n recognition_result = self . fill_blank_model . recognize_text ( blank_segmentation_result [ i ] ) \n if recognition_result is not None : \n if recognition_result [ <NUM_LIT> ] == section_answer [ i ] : \n right_array . append ( <NUM_LIT> ) \n else : \n judge_index = self . fill_blank_model . judge_with_clip ( section_answer [ i ] , recognition_result [ <NUM_LIT> ] , blank_segmentation_result [ i ] ) \n if judge_index == <NUM_LIT> : \n right_array . append ( <NUM_LIT> ) \n else : \n right_array . append ( <NUM_LIT> ) \n else : \n right_array . append ( <NUM_LIT> ) \n score_result [ '<STR_LIT>' ] = right_array \n return score_result \n def tkt_math_score ( self , section_img , section_answer ) : \n blank_segmentation_result = self . blank_segmentation . process_img ( \n section_img ) \n score_result = { '<STR_LIT>' : '<STR_LIT>' } \n right_array = [ ] \n for i in range ( len ( blank_segmentation_result ) ) : \n recognition_result = self . candemo . output_img ( blank_segmentation_result [ i ] ) \n if recognition_result is not None : \n if recognition_result [ <NUM_LIT> ] == section_answer [ i ] : \n right_array . append ( <NUM_LIT> ) \n else : \n judge_index = self . fill_blank_model . judge_with_clip ( section_answer [ i ] , recognition_result [ <NUM_LIT> ] , blank_segmentation_result [ i ] ) \n if judge_index == <NUM_LIT> : \n right_array . append ( <NUM_LIT> ) \n else : \n right_array . append ( <NUM_LIT> ) \n else : \n right_array . append ( <NUM_LIT> ) \n score_result [ '<STR_LIT>' ] = right_array \n return score_result \n def zwt_score ( self , section_img ) : \n score_result = { '<STR_LIT>' : '<STR_LIT>' } \n right_array = [ ] \n essay = '<STR_LIT>' \n str_set = self . fill_blank_model . ocr . ocr ( section_img ) [ <NUM_LIT> ] \n if str_set is not None : \n for str_item in str_set : \n essay += str_item [ <NUM_LIT> ] [ <NUM_LIT> ] \n result = self . essay_score_model . getscore ( [ essay ] ) \n if result != None : \n result = result / <NUM_LIT> * <NUM_LIT> \n right_array . append ( result ) \n else : \n right_array . append ( <NUM_LIT> ) \n else : \n right_array . append ( <NUM_LIT> ) \n score_result [ '<STR_LIT>' ] = right_array \n return score_result \n def get_score ( self , img : PIL . Image . Image ) : \n total_result = [ ] \n answer_set_index = <NUM_LIT> \n outer_segmentation_results = self . outer_segmentation . get_segmentation ( img )", "output": "CLS_ID_NAME_MAP = { \n <NUM_LIT> : '<STR_LIT>' , \n <NUM_LIT> : '<STR_LIT>' , \n <NUM_LIT> : '<STR_LIT>' , \n <NUM_LIT> : '<STR_LIT>' \n } \n for outer_segmentation_result in outer_segmentation_results : \n for box in outer_segmentation_result . boxes : \n cls_id = box . cls . cpu ( ) . numpy ( ) [ <NUM_LIT> ] \n x1 , y1 , x2 , y2 = box . xyxy . cpu ( ) . numpy ( ) [ <NUM_LIT> ] \n cls_name = CLS_ID_NAME_MAP [ cls_id ] \n if cls_name == '<STR_LIT>' : \n continue \n if cls_name == '<STR_LIT>' : \n for answer in self . answer [ answer_set_index : ] : \n if answer [ '<STR_LIT>' ] == '<STR_LIT>' : \n answer_set_index = self . answer . index ( answer ) \n section_answer = answer [ '<STR_LIT>' ] \n section_img = outer_segmentation_result . orig_img \n section_img = section_img [ int ( y1 ) : int ( y2 ) , int ( x1 ) : int ( x2 ) ] \n score_result = self . tkt_score ( section_img , section_answer ) \n total_result . append ( score_result ) \n elif answer [ '<STR_LIT>' ] == '<STR_LIT>' : \n answer_set_index = self . answer . index ( answer ) \n section_answer = answer [ '<STR_LIT>' ] \n section_img = outer_segmentation_result . orig_img \n section_img = section_img [ int ( y1 ) : int ( y2 ) , int ( x1 ) : int ( x2 ) ] \n score_result = self . tkt_math_score ( section_img , section_answer ) \n total_result . append ( score_result ) \n elif cls_name == '<STR_LIT>' : \n for answer in self . answer [ answer_set_index : ] : \n if answer [ '<STR_LIT>' ] == '<STR_LIT>' : \n answer_set_index = self . answer . index ( answer ) \n section_img = outer_segmentation_result . orig_img \n section_img = section_img [ int ( y1 ) : int ( y2 ) , int ( x1 ) : int ( x2 ) ] \n score_result = self . zwt_score ( section_img ) \n total_result . append ( score_result ) \n elif cls_name == '<STR_LIT>' : \n for answer in self . answer [ answer_set_index : ] : \n if answer [ '<STR_LIT>' ] == '<STR_LIT>' : \n answer_set_index = self . answer . index ( answer ) \n section_answer = answer [ '<STR_LIT>' ] \n section_img = outer_segmentation_result . orig_img \n section_img = section_img [ int ( y1 ) : int ( y2 ) , int ( x1 ) : int ( x2 ) ] \n pass \n return total_result \n if __name__ == '<STR_LIT>' : \n test_dir = '<STR_LIT>' \n lst = os . listdir ( test_dir ) \n s = scoresystem ( ) \n s . set_answer ( [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] } , { '<STR_LIT>' : '<STR_LIT>' } ] ) \n for i in lst : \n if i . endswith ( '<STR_LIT>' ) or i . endswith ( '<STR_LIT>' ) : \n path = os . path . join ( test_dir , i ) \n img = PIL . Image . open ( path ) \n total_result = s . get_score ( img ) \n print ( total_result ) \n break"}, {"input": "import os \n import sys \n from pathlib import Path \n from typing import Annotated \n import cappa \n from falco . config import read_falco_config \n from honcho . manager import Manager \n from . sync_dotenv import parse as parse_dotenv \n default_server_cmd = \"<STR_LIT>\" \n default_address = \"<STR_LIT>\" \n @ cappa . command ( help = \"<STR_LIT>\" ) \n class Work : \n address : Annotated [ str , cappa . Arg ( default = default_address , help = \"<STR_LIT>\" ) ] = default_address \n def __call__ ( self ) -> None : \n commands = self . get_commands ( ) \n manager = Manager ( ) \n django_env = self . resolve_django_env ( ) \n for name , cmd in commands . items ( ) : \n manager . add_process ( name , cmd , env = django_env ) \n try : \n manager . loop ( ) \n finally : \n manager . terminate ( ) \n sys . exit ( manager . returncode ) \n def resolve_django_env ( self ) -> dict : \n current_dir = Path ( ) . resolve ( )", "output": "env_file = current_dir / \"<STR_LIT>\" \n env_vars = parse_dotenv ( env_file . read_text ( ) ) if env_file . exists ( ) else { } \n return { \n ** os . environ , \n \"<STR_LIT>\" : str ( current_dir ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n ** env_vars , \n } \n def get_commands ( self ) -> dict : \n commands = { \"<STR_LIT>\" : default_server_cmd } \n pyproject_file = Path ( \"<STR_LIT>\" ) \n if pyproject_file . exists ( ) : \n user_commands = read_falco_config ( pyproject_path = pyproject_file ) . get ( \"<STR_LIT>\" , { } ) \n else : \n user_commands = { } \n commands |= user_commands \n commands [ \"<STR_LIT>\" ] = commands [ \"<STR_LIT>\" ] . format ( address = self . address ) \n return commands"}, {"input": "import re \n import pytest \n from test_utils . settings import ( \n custom_ai_backend_class , \n custom_ai_backend_settings , \n ) \n from wagtail_ai . ai import ( \n BackendNotFound , \n InvalidAIBackendError , \n get_ai_backend , \n get_backend ,", "output": ") \n from wagtail_ai . ai . base import BackendFeature \n from wagtail_ai . ai . echo import EchoBackend \n @ custom_ai_backend_class ( \"<STR_LIT>\" ) \n def test_get_configured_backend_instance ( ) : \n backend = get_ai_backend ( \"<STR_LIT>\" ) \n assert isinstance ( backend , EchoBackend ) \n @ custom_ai_backend_class ( \"<STR_LIT>\" ) \n def test_get_invalid_backend_class_instance ( ) : \n with pytest . raises ( \n InvalidAIBackendError , \n match = re . escape ( \n '<STR_LIT>' \n '<STR_LIT>' \n ) , \n ) : \n get_ai_backend ( \"<STR_LIT>\" ) \n @ custom_ai_backend_settings ( \n new_value = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } \n ) \n def test_get_backend_instance_with_custom_setting ( ) : \n backend = get_ai_backend ( \"<STR_LIT>\" ) \n assert isinstance ( backend , EchoBackend ) \n assert backend . config . model_id == \"<STR_LIT>\" \n assert backend . config . max_word_sleep_seconds == <NUM_LIT> \n assert backend . config . token_limit == <NUM_LIT> \n @ custom_ai_backend_settings ( \n new_value = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } \n ) \n def test_prompt_with_context ( ) : \n backend = get_ai_backend ( \"<STR_LIT>\" ) \n response = backend . prompt_with_context ( \n pre_prompt = \"<STR_LIT>\" , \n context = \"<STR_LIT>\" , \n ) \n assert response . text ( ) == \"<STR_LIT>\" \n @ custom_ai_backend_settings ( \n new_value = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } \n ) \n def test_prompt_with_context_iterator ( ) : \n backend = get_ai_backend ( \"<STR_LIT>\" ) \n response = backend . prompt_with_context ( \n pre_prompt = \"<STR_LIT>\" , \n context = \"<STR_LIT>\" , \n ) \n assert list ( response ) == [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n def test_get_backend_with_feature ( settings ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : <NUM_LIT> } , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : <NUM_LIT> } , \n } , \n } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n assert get_backend ( ) . config . model_id == \"<STR_LIT>\" \n assert get_backend ( BackendFeature . TEXT_COMPLETION ) . config . model_id == \"<STR_LIT>\" \n assert get_backend ( BackendFeature . IMAGE_DESCRIPTION ) . config . model_id == \"<STR_LIT>\" \n def test_get_backend_not_found ( settings ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : <NUM_LIT> } , \n } , \n } , \n } \n with pytest . raises ( BackendNotFound ) as exception : \n get_backend ( BackendFeature . IMAGE_DESCRIPTION ) \n assert exception . match ( r\"<STR_LIT>\" )"}, {"input": "import re \n import copy \n from typing import Dict , Union , Optional \n import unidecode \n import pandas as pd \n from django . conf import settings \n DATA_PATH = settings . APPLICATIONS_DIR / \"<STR_LIT>\" / \"<STR_LIT>\" / \"<STR_LIT>\" \n neighbourhood_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n street_list = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n site_list = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n block_list = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n df = pd . read_csv ( str ( DATA_PATH / \"<STR_LIT>\" ) ) \n city_pattern = re . compile ( r\"<STR_LIT>\" + \"<STR_LIT>\" . join ( df [ \"<STR_LIT>\" ] . tolist ( ) ) + \"<STR_LIT>\" , re . IGNORECASE ) \n distinct_pattern = re . compile ( r\"<STR_LIT>\" + \"<STR_LIT>\" . join ( df [ \"<STR_LIT>\" ] . tolist ( ) ) + \"<STR_LIT>\" , re . IGNORECASE ) \n neighbourhood_pattern = re . compile ( r\"<STR_LIT>\" + \"<STR_LIT>\" . join ( df [ \"<STR_LIT>\" ] . tolist ( ) ) + \"<STR_LIT>\" , re . IGNORECASE ) \n neighbourhood_pattern_v2 = re . compile ( \n r\"<STR_LIT>\" + \"<STR_LIT>\" . join ( neighbourhood_list ) + r\"<STR_LIT>\" , \n re . IGNORECASE , \n ) \n street_road_boulevard_pattern = re . compile ( r\"<STR_LIT>\" + \"<STR_LIT>\" . join ( street_list ) + \"<STR_LIT>\" , re . IGNORECASE ) \n site_apartment_pattern = re . compile ( r\"<STR_LIT>\" + \"<STR_LIT>\" . join ( site_list ) + \"<STR_LIT>\" , re . IGNORECASE ) \n block_pattern = re . compile ( r\"<STR_LIT>\" + \"<STR_LIT>\" . join ( block_list ) + \"<STR_LIT>\" , re . IGNORECASE ) \n floor_pattern = re . compile ( r\"<STR_LIT>\" , re . IGNORECASE ) \n apartment_no_pattern = re . compile ( \n r\"<STR_LIT>\" , \n re . IGNORECASE , \n ) \n phone_number_pattern = re . compile ( r\"<STR_LIT>\" , re . IGNORECASE ) \n city_dict = dict ( zip ( df [ \"<STR_LIT>\" ] . tolist ( ) , df [ \"<STR_LIT>\" ] . tolist ( ) ) ) \n distinct_dict = dict ( zip ( df [ \"<STR_LIT>\" ] . tolist ( ) , df [ \"<STR_LIT>\" ] . tolist ( ) ) ) \n neighbourhood_dict = dict ( zip ( df [ \"<STR_LIT>\" ] . tolist ( ) , df [ \"<STR_LIT>\" ] . tolist ( ) ) ) \n remove_punct_pattern = re . compile ( r\"<STR_LIT>\" , re . IGNORECASE ) \n number_regex = re . compile ( r\"<STR_LIT>\" , re . IGNORECASE ) \n class ExtractInfo : \n result : Dict [ str , Optional [ Union [ str , int ] ] ] \n text : str \n def __init__ ( self ) : \n self . stopword_list = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n @ staticmethod \n def process_text ( text , is_unidecode = True ) : \n text = text . translate ( str . maketrans ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) . lower ( ) \n if is_unidecode : \n text = unidecode . unidecode ( text ) \n return text \n @ staticmethod \n def number_exact_match ( text1 , text2 ) : \n return True if set ( number_regex . findall ( text1 ) ) == set ( number_regex . findall ( text2 ) ) else False \n def get_sim_based_city_distinct_neighbourhood ( self ) : \n for token in self . text . split ( ) : \n token_lower = token . translate ( str . maketrans ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) . lower ( ) \n for city in city_dict . values ( ) : \n city_lower = city . translate ( str . maketrans ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) . lower ( ) \n if textdistance . levenshtein . normalized_similarity ( token_lower , city_lower ) >= <NUM_LIT> : \n self . result [ \"<STR_LIT>\" ] = city \n break \n for distinct in distinct_dict . values ( ) : \n distinct_lower = distinct . translate ( str . maketrans ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) . lower ( ) \n if textdistance . levenshtein . normalized_similarity ( token_lower , distinct_lower ) >= <NUM_LIT> : \n self . result [ \"<STR_LIT>\" ] = distinct \n break \n for neighbourhood in neighbourhood_dict . values ( ) : \n neighbourhood_lower = neighbourhood . translate ( str . maketrans ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) . lower ( ) \n if textdistance . levenshtein . normalized_similarity ( token_lower , neighbourhood_lower ) >= <NUM_LIT> : \n self . result [ \"<STR_LIT>\" ] = neighbourhood \n break \n def get_until_stopword ( self , text , key ) : \n index = text . find ( key ) \n current_text = text [ : index ] + f\"<STR_LIT>\" \n stopword_index = - <NUM_LIT> \n for stopword in self . stopword_list : \n index = [ el . end ( ) for el in re . finditer ( stopword , current_text ) ] \n if index : \n st_index = index [ - <NUM_LIT> ] \n else : \n continue \n if st_index > stopword_index : \n stopword_index = st_index \n if stopword_index != - <NUM_LIT> : \n current_text = current_text [ stopword_index : ] \n current_text = \"<STR_LIT>\" . join ( current_text . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> : ] ) \n return re . sub ( \"<STR_LIT>\" , \"<STR_LIT>\" , current_text ) . strip ( ) \n def extract ( self , text ) : \n self . text = \"<STR_LIT>\" . join ( text . strip ( ) . split ( ) ) \n self . result = { \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : { } , \n \"<STR_LIT>\" : copy . deepcopy ( text ) , \n } \n self . text = self . text . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] \n self . text = remove_punct_pattern . sub ( \"<STR_LIT>\" , self . text ) \n unidecoded_text = self . process_text ( self . text ) \n try : \n extracted_il = city_pattern . findall ( unidecoded_text ) [ <NUM_LIT> ] \n unidecoded_text = unidecoded_text . replace ( extracted_il , \"<STR_LIT>\" ) \n self . result [ \"<STR_LIT>\" ] = city_dict [ extracted_il ] . title ( ) \n except Exception as e :", "output": "print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n try : \n extracted_distinct = distinct_pattern . findall ( unidecoded_text ) [ <NUM_LIT> ] \n unidecoded_text = unidecoded_text . replace ( extracted_distinct , \"<STR_LIT>\" ) \n self . result [ \"<STR_LIT>\" ] = distinct_dict [ extracted_distinct ] . title ( ) \n except Exception as e : \n print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n try : \n self . result [ \"<STR_LIT>\" ] = neighbourhood_pattern_v2 . findall ( self . text ) [ <NUM_LIT> ] [ <NUM_LIT> ] . strip ( ) \n self . text = self . text . replace ( self . result [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n except Exception as e : \n print ( str ( e ) ) \n try : \n extracted_neighbourhood = neighbourhood_pattern . findall ( unidecoded_text ) [ <NUM_LIT> ] \n self . result [ \"<STR_LIT>\" ] = neighbourhood_dict [ extracted_neighbourhood ] \n except Exception as e : \n print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n try : \n self . result [ \"<STR_LIT>\" ] = street_road_boulevard_pattern . findall ( self . text ) [ <NUM_LIT> ] [ <NUM_LIT> ] . strip ( ) \n self . text = self . text . replace ( self . result [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n except Exception as e : \n print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n try : \n self . result [ \"<STR_LIT>\" ] = site_apartment_pattern . findall ( self . text ) [ <NUM_LIT> ] [ <NUM_LIT> ] . strip ( ) \n self . text = self . text . replace ( self . result [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n except Exception as e : \n print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n try : \n self . result [ \"<STR_LIT>\" ] = block_pattern . findall ( self . text ) [ <NUM_LIT> ] [ <NUM_LIT> ] . strip ( ) \n self . text = self . text . replace ( self . result [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n self . result [ \"<STR_LIT>\" ] = self . result [ \"<STR_LIT>\" ] . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . strip ( ) \n except Exception as e : \n print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n try : \n self . result [ \"<STR_LIT>\" ] = floor_pattern . findall ( self . text ) [ <NUM_LIT> ] [ <NUM_LIT> ] . strip ( ) \n self . text = self . text . replace ( self . result [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n self . result [ \"<STR_LIT>\" ] = int ( self . result [ \"<STR_LIT>\" ] . lower ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . strip ( ) ) \n except Exception as e : \n print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n try : \n self . result [ \"<STR_LIT>\" ] = apartment_no_pattern . findall ( self . text ) [ <NUM_LIT> ] [ <NUM_LIT> ] . strip ( ) \n self . text = self . text . replace ( self . result [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n self . result [ \"<STR_LIT>\" ] = int ( \n self . result [ \"<STR_LIT>\" ] . lower ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . strip ( ) \n ) \n except Exception as e : \n print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n try : \n phone_number = [ \n phone_number \n for phone_number in sorted ( \n re . findall ( \n r\"<STR_LIT>\" , \n self . text , \n ) , \n key = len , \n reverse = True , \n ) \n if <NUM_LIT> <= len ( phone_number ) <= <NUM_LIT> \n ] [ <NUM_LIT> ] \n self . result [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = phone_number if <NUM_LIT> <= len ( phone_number ) <= <NUM_LIT> else \"<STR_LIT>\" \n self . text = self . text . replace ( self . result [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n except Exception as e : \n print ( str ( e ) ) \n self . result [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n self . concat_address ( ) \n self . calculate_score ( ) \n return self . result \n def concat_address ( self ) : \n address_str = \"<STR_LIT>\" \n for key , value in self . result . items ( ) : \n if value != \"<STR_LIT>\" : \n if key == \"<STR_LIT>\" : \n address_str = address_str + value + \"<STR_LIT>\" \n if key == \"<STR_LIT>\" : \n address_str = address_str + value + \"<STR_LIT>\" \n if key == \"<STR_LIT>\" : \n address_str = address_str + value + \"<STR_LIT>\" \n if key == \"<STR_LIT>\" : \n address_str = address_str + value + \"<STR_LIT>\" \n if key == \"<STR_LIT>\" : \n address_str = address_str + value + \"<STR_LIT>\" \n self . result [ \"<STR_LIT>\" ] = address_str \n def calculate_score ( self ) : \n weighted_score = <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n if self . result [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] != \"<STR_LIT>\" : \n weighted_score += <NUM_LIT> \n self . result [ \"<STR_LIT>\" ] = weighted_score / ( <NUM_LIT> + <NUM_LIT> + <NUM_LIT> + <NUM_LIT> + <NUM_LIT> + <NUM_LIT> + <NUM_LIT> + <NUM_LIT> + <NUM_LIT> ) \n return self . result"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ]", "output": "operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( primary_key = True , serialize = False ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . CharField ( default = '<STR_LIT>' , max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( blank = True , null = True , on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) ) , \n ] , \n ) , \n ]"}, {"input": "import uuid \n from django . db import models \n from django . utils . translation import gettext_lazy as _ \n from wagtail . search import index \n from wagtail_ai . prompts import DEFAULT_PROMPTS \n class Prompt ( models . Model , index . Indexed ) : \n class Method ( models . TextChoices ) : \n REPLACE = \"<STR_LIT>\" , _ ( \"<STR_LIT>\" ) \n APPEND = \"<STR_LIT>\" , _ ( \"<STR_LIT>\" ) \n uuid = models . UUIDField ( default = uuid . uuid4 , unique = True , editable = False ) \n default_prompt_id = models . SmallIntegerField ( unique = True , editable = False , null = True ) \n label = models . CharField ( max_length = <NUM_LIT> ) \n description = models . CharField ( \n max_length = <NUM_LIT> , \n blank = True , \n help_text = _ ( \n \"<STR_LIT>\" \n ) , \n ) \n prompt = models . TextField ( \n null = True , \n blank = False , \n help_text = _ ( \n \"<STR_LIT>\" \n ) , \n ) \n method = models . CharField ( \n max_length = <NUM_LIT> , \n choices = Method . choices , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n search_fields = [ \n index . AutocompleteField ( \"<STR_LIT>\" ) , \n index . SearchField ( \"<STR_LIT>\" ) , \n index . SearchField ( \"<STR_LIT>\" ) , \n ] \n def __str__ ( self ) : \n return self . label \n def get_default_prompt_value ( self ) -> str : \n return next ( \n ( \n prompt [ \"<STR_LIT>\" ] \n for prompt in DEFAULT_PROMPTS \n if prompt [ \"<STR_LIT>\" ] == self . default_prompt_id \n ) , \n \"<STR_LIT>\" , \n ) \n @ property \n def is_default ( self ) -> bool : \n return self . default_prompt_id is not None \n @ property \n def prompt_value ( self ) -> str : \n if self . prompt is None : \n if self . is_default : \n return self . get_default_prompt_value ( ) \n else : \n raise ValueError ( \"<STR_LIT>\" )", "output": "return self . prompt"}, {"input": "from . zhtools . langconv import * \n import datetime \n from pathlib import Path \n import re , os \n add_info_desc = '<STR_LIT>' \n add_info_title = '<STR_LIT>' \n BASE_DIR = Path ( __file__ ) . resolve ( ) . parent . parent \n root_dir = os . path . join ( BASE_DIR , '<STR_LIT>' ) \n crawl_info = { \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : <NUM_LIT> , \n } \n dirs = { \n '<STR_LIT>' : \"<STR_LIT>\" % root_dir , \n '<STR_LIT>' : '<STR_LIT>' % root_dir \n } \n chuanliu_Authorization = '<STR_LIT>' \n headers = { \n '<STR_LIT>' : '<STR_LIT>' \n '<STR_LIT>' \n '<STR_LIT>' \n } \n in_exclude_channel = { \n '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] , \n '<STR_LIT>' : [ ] , \n '<STR_LIT>' : [ ] , \n '<STR_LIT>' : [ ] , \n } \n xmlinfo = { \n '<STR_LIT>' : { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' \n } , \n '<STR_LIT>' : { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' ] \n } , \n '<STR_LIT>' : { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n } , \n '<STR_LIT>' : { \n '<STR_LIT>' : '<STR_LIT>' ,", "output": "'<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n } , \n } \n def cht_to_chs ( line ) : \n line = Converter ( '<STR_LIT>' ) . convert ( line ) \n line . encode ( '<STR_LIT>' ) \n return line \n def channel_ids_to_dict ( channel_id ) : \n channel_list = { } \n rs = re . findall ( '<STR_LIT>' , channel_id ) \n for r in rs : \n c = { r [ <NUM_LIT> ] : r [ <NUM_LIT> ] } \n channel_list . update ( c ) \n return channel_list \n def argvs_get ( argv ) : \n recrawl = <NUM_LIT> \n cname = <NUM_LIT> \n dt = <NUM_LIT> \n save_to_db = <NUM_LIT> \n if '<STR_LIT>' in argv : \n recrawl = <NUM_LIT> \n if '<STR_LIT>' in argv and len ( argv ) >= argv . index ( '<STR_LIT>' ) + <NUM_LIT> and '<STR_LIT>' not in argv [ argv . index ( '<STR_LIT>' ) + <NUM_LIT> ] : \n cname = argv [ argv . index ( '<STR_LIT>' ) + <NUM_LIT> ] \n if '<STR_LIT>' in argv and len ( argv ) >= argv . index ( '<STR_LIT>' ) + <NUM_LIT> and '<STR_LIT>' not in argv [ argv . index ( '<STR_LIT>' ) + <NUM_LIT> ] : \n dt = argv [ argv . index ( '<STR_LIT>' ) + <NUM_LIT> ] \n dt = datetime . datetime . strptime ( dt , '<STR_LIT>' ) . date ( ) \n else : \n dt = datetime . datetime . now ( ) . date ( ) \n if '<STR_LIT>' in argv and len ( argv ) >= argv . index ( '<STR_LIT>' ) + <NUM_LIT> and '<STR_LIT>' not in argv [ argv . index ( '<STR_LIT>' ) + <NUM_LIT> ] : \n save_to_db = int ( argv [ argv . index ( '<STR_LIT>' ) + <NUM_LIT> ] ) \n if '<STR_LIT>' in argv and '<STR_LIT>' not in argv : \n save_to_db = <NUM_LIT> \n return [ recrawl , cname , dt , save_to_db ] \n def noepgjson ( name , id , need_date ) : \n title = '<STR_LIT>' \n epgjsons = [ ] \n for x in range ( <NUM_LIT> ) : \n start = datetime . datetime . combine ( need_date , datetime . time ( x , <NUM_LIT> , <NUM_LIT> ) ) . strftime ( '<STR_LIT>' ) \n end = datetime . datetime . combine ( need_date , datetime . time ( x , <NUM_LIT> , <NUM_LIT> ) ) . strftime ( '<STR_LIT>' ) \n epgjsons . append ( { \n '<STR_LIT>' : start , \n '<STR_LIT>' : end , \n '<STR_LIT>' : '<STR_LIT>' % ( title , add_info_title ) , \n '<STR_LIT>' : add_info_desc , \n } ) \n return epgjsons \n def noepg ( name , id , need_date ) : \n hours_epg = [ ] \n tz = '<STR_LIT>' \n for x in range ( <NUM_LIT> ) : \n start = datetime . datetime . combine ( need_date , datetime . time ( x , <NUM_LIT> , <NUM_LIT> ) ) \n end = datetime . datetime . combine ( need_date , datetime . time ( x , <NUM_LIT> , <NUM_LIT> ) ) \n starttime_str = start . strftime ( '<STR_LIT>' ) + tz \n endtime_str = end . strftime ( '<STR_LIT>' ) + tz \n hour_epg = % ( starttime_str , endtime_str ) \n hours_epg . append ( hour_epg ) \n xmlepg = '<STR_LIT>' . join ( hours_epg ) \n return xmlepg"}, {"input": "import logging \n from asgiref . sync import sync_to_async \n from ninja . security import APIKeyHeader \n from rest_framework_api_key . models import APIKey \n logger = logging . getLogger ( __name__ ) \n class NinjaApiKeyAuth ( APIKeyHeader ) : \n param_name = \"<STR_LIT>\"", "output": "async def authenticate ( self , request , key ) : \n print ( f\"<STR_LIT>\" ) \n try : \n api_key = await sync_to_async ( APIKey . objects . get_from_key ) ( key ) \n print ( f\"<STR_LIT>\" ) \n return api_key \n except Exception as e : \n logger . warning ( f\"<STR_LIT>\" )"}, {"input": "from django . db . models import F , Subquery , OuterRef , Exists \n from rest_framework import serializers \n from rest_framework . decorators import action \n from rest_framework . permissions import IsAuthenticated \n from dvadmin . system . models import RoleMenuButtonPermission , Menu , MenuButton , Dept , RoleMenuPermission , FieldPermission , MenuField \n from dvadmin . system . views . menu import MenuSerializer \n from dvadmin . utils . json_response import DetailResponse , ErrorResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class RoleMenuButtonPermissionSerializer ( CustomModelSerializer ) : \n class Meta : \n model = RoleMenuButtonPermission \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class RoleMenuButtonPermissionCreateUpdateSerializer ( CustomModelSerializer ) : \n menu_button__name = serializers . CharField ( source = '<STR_LIT>' , read_only = True ) \n menu_button__value = serializers . CharField ( source = '<STR_LIT>' , read_only = True ) \n class Meta : \n model = RoleMenuButtonPermission \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class RoleButtonPermissionSerializer ( CustomModelSerializer ) : \n isCheck = serializers . SerializerMethodField ( ) \n data_range = serializers . SerializerMethodField ( ) \n def get_isCheck ( self , instance ) : \n params = self . request . query_params \n return RoleMenuButtonPermission . objects . filter ( \n menu_button__id = instance [ '<STR_LIT>' ] , \n role__id = params . get ( '<STR_LIT>' ) , \n ) . exists ( ) \n def get_data_range ( self , instance ) : \n params = self . request . query_params \n obj = RoleMenuButtonPermission . objects . filter ( \n menu_button__id = instance [ '<STR_LIT>' ] , \n role__id = params . get ( '<STR_LIT>' ) , \n ) . first ( ) \n if obj is None : \n return None \n return obj . data_range \n class Meta : \n model = MenuButton \n fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n class RoleFieldPermissionSerializer ( CustomModelSerializer ) : \n class Meta : \n model = FieldPermission \n fields = \"<STR_LIT>\" \n class RoleMenuFieldSerializer ( CustomModelSerializer ) : \n is_query = serializers . SerializerMethodField ( ) \n is_create = serializers . SerializerMethodField ( ) \n is_update = serializers . SerializerMethodField ( ) \n def get_is_query ( self , instance ) : \n params = self . request . query_params \n queryset = instance . menu_field . filter ( role = params . get ( '<STR_LIT>' ) ) . first ( ) \n if queryset : \n return queryset . is_query \n return False \n def get_is_create ( self , instance ) : \n params = self . request . query_params \n queryset = instance . menu_field . filter ( role = params . get ( '<STR_LIT>' ) ) . first ( ) \n if queryset : \n return queryset . is_create \n return False \n def get_is_update ( self , instance ) : \n params = self . request . query_params \n queryset = instance . menu_field . filter ( role = params . get ( '<STR_LIT>' ) ) . first ( ) \n if queryset : \n return queryset . is_update \n return False \n class Meta : \n model = MenuField \n fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n class RoleMenuPermissionSerializer ( CustomModelSerializer ) : \n name = serializers . SerializerMethodField ( ) \n isCheck = serializers . SerializerMethodField ( ) \n btns = serializers . SerializerMethodField ( ) \n columns = serializers . SerializerMethodField ( ) \n def get_name ( self , instance ) : \n parent_list = Menu . get_all_parent ( instance [ '<STR_LIT>' ] ) \n names = [ d [ \"<STR_LIT>\" ] for d in parent_list ] \n return \"<STR_LIT>\" . join ( names ) \n def get_isCheck ( self , instance ) : \n params = self . request . query_params \n return RoleMenuPermission . objects . filter ( \n menu__id = instance [ '<STR_LIT>' ] , \n role__id = params . get ( '<STR_LIT>' ) , \n ) . exists ( ) \n def get_btns ( self , instance ) : \n btn_list = MenuButton . objects . filter ( menu__id = instance [ '<STR_LIT>' ] ) . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n serializer = RoleButtonPermissionSerializer ( btn_list , many = True , request = self . request ) \n return serializer . data \n def get_columns ( self , instance ) : \n col_list = MenuField . objects . filter ( menu = instance [ '<STR_LIT>' ] ) \n serializer = RoleMenuFieldSerializer ( col_list , many = True , request = self . request ) \n return serializer . data \n class Meta : \n model = Menu \n fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n class RoleMenuButtonPermissionViewSet ( CustomModelViewSet ) : \n queryset = RoleMenuButtonPermission . objects . all ( ) \n serializer_class = RoleMenuButtonPermissionSerializer \n create_serializer_class = RoleMenuButtonPermissionCreateUpdateSerializer \n update_serializer_class = RoleMenuButtonPermissionCreateUpdateSerializer \n extra_filter_class = [ ] \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def get_role_premission ( self , request ) : \n params = request . query_params \n role = params . get ( '<STR_LIT>' , None ) \n if role is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n is_superuser = request . user . is_superuser \n data = [ ] \n if is_superuser : \n queryset = Menu . objects . filter ( status = <NUM_LIT> , is_catalog = False ) . values ( '<STR_LIT>' , '<STR_LIT>' ) . all ( ) \n else : \n role_id = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n menu_list = RoleMenuPermission . objects . filter ( role__in = role_id ) . values_list ( '<STR_LIT>' , flat = True ) \n queryset = Menu . objects . filter ( status = <NUM_LIT> , is_catalog = False , id__in = menu_list ) . values ( '<STR_LIT>' , '<STR_LIT>' ) \n for item in queryset : \n parent_list = Menu . get_all_parent ( item [ '<STR_LIT>' ] ) \n names = [ d [ \"<STR_LIT>\" ] for d in parent_list ] \n completeName = \"<STR_LIT>\" . join ( names ) \n isCheck = RoleMenuPermission . objects . filter ( \n menu__id = item [ '<STR_LIT>' ] , \n role__id = role , \n ) . exists ( ) \n mbCheck = RoleMenuButtonPermission . objects . filter ( \n menu_button = OuterRef ( \"<STR_LIT>\" ) , \n role__id = role , \n ) \n btns = MenuButton . objects . filter ( \n menu__id = item [ '<STR_LIT>' ] , \n ) . annotate ( isCheck = Exists ( mbCheck ) ) . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n data_range = F ( '<STR_LIT>' ) ) \n dicts = { \n '<STR_LIT>' : completeName , \n '<STR_LIT>' : item [ '<STR_LIT>' ] , \n '<STR_LIT>' : isCheck , \n '<STR_LIT>' : btns , \n } \n data . append ( dicts ) \n return DetailResponse ( data = data ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = True , permission_classes = [ IsAuthenticated ] ) \n def set_role_premission ( self , request , pk ) : \n body = request . data \n RoleMenuPermission . objects . filter ( role = pk ) . delete ( ) \n RoleMenuButtonPermission . objects . filter ( role = pk ) . delete ( ) \n for menu in body : \n if menu . get ( '<STR_LIT>' ) : \n menu_parent = Menu . get_all_parent ( menu . get ( '<STR_LIT>' ) ) \n role_menu_permission_list = [ ] \n for d in menu_parent : \n role_menu_permission_list . append ( RoleMenuPermission ( role_id = pk , menu_id = d [ \"<STR_LIT>\" ] ) ) \n RoleMenuPermission . objects . bulk_create ( role_menu_permission_list ) \n for btn in menu . get ( '<STR_LIT>' ) : \n if btn . get ( '<STR_LIT>' ) : \n data_range = btn . get ( '<STR_LIT>' , <NUM_LIT> ) or <NUM_LIT> \n instance = RoleMenuButtonPermission . objects . create ( role_id = pk , menu_button_id = btn . get ( '<STR_LIT>' ) , data_range = data_range ) \n instance . dept . set ( btn . get ( '<STR_LIT>' , [ ] ) ) \n for col in menu . get ( '<STR_LIT>' ) : \n FieldPermission . objects . update_or_create ( role_id = pk , field_id = col . get ( '<STR_LIT>' ) , is_query = col . get ( '<STR_LIT>' ) , is_create = col . get ( '<STR_LIT>' ) , is_update = col . get ( '<STR_LIT>' ) ) \n return DetailResponse ( msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def role_menu_get_button ( self , request ) : \n if params := request . query_params : \n if menu_id := params . get ( '<STR_LIT>' , None ) : \n is_superuser = request . user . is_superuser \n if is_superuser : \n queryset = MenuButton . objects . filter ( menu = menu_id ) . values ( '<STR_LIT>' , '<STR_LIT>' ) \n else : \n role_list = request . user . role . values_list ( '<STR_LIT>' , flat = True )", "output": "queryset = RoleMenuButtonPermission . objects . filter ( \n role__in = role_list , menu_button__menu = menu_id \n ) . values ( btn_id = F ( '<STR_LIT>' ) , name = F ( '<STR_LIT>' ) ) \n return DetailResponse ( data = queryset ) \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def data_scope ( self , request ) : \n is_superuser = request . user . is_superuser \n if is_superuser : \n data = [ \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } \n ] \n return DetailResponse ( data = data ) \n else : \n data = [ ] \n role_list = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n if params := request . query_params : \n if menu_button_id := params . get ( '<STR_LIT>' , None ) : \n role_queryset = RoleMenuButtonPermission . objects . filter ( \n role__in = role_list , menu_button__id = menu_button_id \n ) . values_list ( '<STR_LIT>' , flat = True ) \n data_range_list = list ( set ( role_queryset ) ) \n for item in data_range_list : \n if item == <NUM_LIT> : \n data = [ { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } ] \n elif item == <NUM_LIT> : \n data = [ { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } ] \n elif item == <NUM_LIT> : \n data = [ { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } ] \n elif item == <NUM_LIT> : \n data = [ { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , ] \n elif item == <NUM_LIT> : \n data = [ { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } , \n { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : '<STR_LIT>' \n } ] \n else : \n data = [ ] \n return DetailResponse ( data = data ) \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def role_to_dept_all ( self , request ) : \n params = request . query_params \n is_superuser = request . user . is_superuser \n if is_superuser : \n queryset = Dept . objects . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n else : \n if not params : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n menu_button = params . get ( '<STR_LIT>' ) \n if menu_button is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n role_list = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n queryset = RoleMenuButtonPermission . objects . filter ( role__in = role_list , menu_button = None ) . values ( \n dept_id = F ( '<STR_LIT>' ) , \n name = F ( '<STR_LIT>' ) , \n parent = F ( '<STR_LIT>' ) \n ) \n return DetailResponse ( data = queryset ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def menu_to_button ( self , request ) : \n params = request . query_params \n menu_id = params . get ( '<STR_LIT>' , None ) \n if menu_id is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n is_superuser = request . user . is_superuser \n if is_superuser : \n queryset = RoleMenuButtonPermission . objects . filter ( menu_button__menu = menu_id ) . values ( \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' \n ) \n return DetailResponse ( data = queryset ) \n else : \n if params : \n role_id = params . get ( '<STR_LIT>' , None ) \n if role_id is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n queryset = RoleMenuButtonPermission . objects . filter ( role = role_id , menu_button__menu = menu_id ) . values ( \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' \n ) \n return DetailResponse ( data = queryset ) \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def role_to_menu ( self , request ) : \n params = request . query_params \n role_id = params . get ( '<STR_LIT>' , None ) \n if role_id is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n queryset = RoleMenuPermission . objects . filter ( role_id = role_id ) . values_list ( '<STR_LIT>' , flat = True ) . distinct ( ) \n return DetailResponse ( data = queryset )"}, {"input": "from django . db import migrations \n class Migration ( migrations . Migration ) :", "output": "dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterModelOptions ( \n name = \"<STR_LIT>\" , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ) , \n ]"}, {"input": "import functools \n import sys \n import cv2 \n import os \n import numpy as np \n import math \n class Model : \n def __init__ ( self , debug = False ) : \n self . rects = [ ] \n self . crop_img = [ ] \n self . img = None \n self . debug = debug \n self . name = '<STR_LIT>' \n def process ( self , img_path , name ) : \n binary = self . __preProcessing ( img_path , name ) \n horizon = self . __detectLines ( binary ) \n self . __contourExtraction ( horizon ) \n result = self . __segmentation ( ) \n self . rects . clear ( ) \n self . img = None \n self . name = '<STR_LIT>' \n return result \n def __preProcessing ( self , img_path , name ) : \n img = cv2 . imread ( img_path ) \n self . img = img \n self . name = name \n gray = cv2 . cvtColor ( img , cv2 . COLOR_BGR2GRAY ) \n blur = cv2 . GaussianBlur ( gray , ( <NUM_LIT> , <NUM_LIT> ) , <NUM_LIT> ) \n _ , binary = cv2 . threshold ( blur , <NUM_LIT> , <NUM_LIT> , cv2 . THRESH_BINARY + cv2 . THRESH_OTSU ) \n thresh , binary = cv2 . threshold ( blur , int ( _ * <NUM_LIT> ) , <NUM_LIT> , cv2 . THRESH_BINARY ) \n return binary \n def process_img ( self , img ) : \n self . __preProcessing_img ( img ) \n binary = self . __preProcessing_img ( img ) \n horizon = self . __detectLines ( binary ) \n self . __contourExtraction ( horizon ) \n result = self . __segmentation ( ) \n self . rects . clear ( ) \n self . img = None \n return result \n def __preProcessing_img ( self , img ) : \n self . img = img \n gray = cv2 . cvtColor ( img , cv2 . COLOR_BGR2GRAY ) \n blur = cv2 . GaussianBlur ( gray , ( <NUM_LIT> , <NUM_LIT> ) , <NUM_LIT> ) \n _ , binary = cv2 . threshold ( blur , <NUM_LIT> , <NUM_LIT> , cv2 . THRESH_BINARY + cv2 . THRESH_OTSU ) \n thresh , binary = cv2 . threshold ( blur , int ( _ * <NUM_LIT> ) , <NUM_LIT> , cv2 . THRESH_BINARY ) \n return binary \n @ staticmethod \n def __detectLines ( img ) : \n horizon_k = int ( math . sqrt ( img . shape [ <NUM_LIT> ] ) * <NUM_LIT> ) \n kernel = cv2 . getStructuringElement ( cv2 . MORPH_RECT , ( horizon_k , <NUM_LIT> ) ) \n horizon = ~ cv2 . dilate ( img , kernel , iterations = <NUM_LIT> ) \n kernel = cv2 . getStructuringElement ( cv2 . MORPH_RECT , ( int ( horizon_k / <NUM_LIT> ) , <NUM_LIT> ) ) \n horizon = cv2 . dilate ( horizon , kernel , iterations = <NUM_LIT> ) \n return horizon \n def __contourExtraction ( self , img , debug = False ) : \n cnts = cv2 . findContours ( img , cv2 . RETR_EXTERNAL , cv2 . CHAIN_APPROX_SIMPLE ) \n border_y , border_x = img . shape \n for cnt in cnts [ <NUM_LIT> ] : \n x , y , w , h = cv2 . boundingRect ( cnt ) \n if y < <NUM_LIT> or y > border_y - <NUM_LIT> : \n continue \n if self . debug and debug : \n cv2 . rectangle ( self . img , ( x , y ) , ( w + x , h + y ) , ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) , <NUM_LIT> ) \n self . rects . append ( [ x , y , w , h ] ) \n self . rects = sorted ( self . rects , key = functools . cmp_to_key ( self . __cmp_rect_r ) ) \n pre = None \n idx_lst = [ ] \n for idx , cnt in enumerate ( self . rects ) : \n x , y , w , h = cnt \n if w < <NUM_LIT> : \n continue \n if pre is None : \n pre = [ x , y , w ] \n elif <NUM_LIT> < abs ( pre [ <NUM_LIT> ] - ( y + h / <NUM_LIT> ) ) < <NUM_LIT> : \n continue \n pre [ <NUM_LIT> ] = y + h / <NUM_LIT> \n pre [ <NUM_LIT> ] = x \n pre [ <NUM_LIT> ] = w \n idx_lst . append ( idx ) \n self . rects = [ self . rects [ x ] for x in idx_lst ] \n self . rects = sorted ( self . rects , key = functools . cmp_to_key ( self . __cmp_rect ) ) \n pre_y , pre_h = - <NUM_LIT> , - <NUM_LIT> \n for idx , cnt in enumerate ( self . rects ) : \n x , y , w , h = cnt \n if pre_h == - <NUM_LIT> : \n pre_y = y \n h = y - <NUM_LIT> \n y = <NUM_LIT> \n pre_h = h \n else : \n if abs ( pre_y - y ) < <NUM_LIT> : \n h = pre_h \n y = max ( y - h , <NUM_LIT> ) \n else : \n pre_h = abs ( y - pre_y ) - <NUM_LIT> \n pre_y = y \n h = pre_h \n y = pre_y - h \n self . rects [ idx ] = [ x , y , w , h + <NUM_LIT> ] \n def __segmentation ( self ) : \n if self . debug : \n if not os . path . exists ( '<STR_LIT>' ) : \n os . mkdir ( '<STR_LIT>' ) \n for idx , rect in enumerate ( self . rects ) : \n x , y , w , h = rect \n cv2 . rectangle ( self . img , ( x , y ) , ( w + x , h + y ) , ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) , <NUM_LIT> ) \n cv2 . putText ( self . img , str ( idx + <NUM_LIT> ) , ( x , y + <NUM_LIT> ) , cv2 . FONT_HERSHEY_SIMPLEX , <NUM_LIT> , ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) , <NUM_LIT> ) \n cv2 . imwrite ( '<STR_LIT>' . format ( self . name ) , self . img ) \n else : \n for idx , rect in enumerate ( self . rects ) : \n x , y , w , h = rect \n crop_img = self . img [ y : y + h , x : x + w ] \n crop_img = crop_img . copy ( ) \n self . crop_img . append ( crop_img ) \n return self . crop_img \n @ staticmethod \n def __cmp_rect ( a , b ) : \n if ( abs ( a [ <NUM_LIT> ] - b [ <NUM_LIT> ] ) < <NUM_LIT> and a [ <NUM_LIT> ] > b [ <NUM_LIT> ] ) or a [ <NUM_LIT> ] > b [ <NUM_LIT> ] : \n return <NUM_LIT> \n elif abs ( a [ <NUM_LIT> ] - b [ <NUM_LIT> ] ) < <NUM_LIT> and abs ( a [ <NUM_LIT> ] - b [ <NUM_LIT> ] ) < <NUM_LIT> : \n return <NUM_LIT> \n else : \n return - <NUM_LIT> \n @ staticmethod \n def __cmp_rect_r ( a , b ) :", "output": "if ( abs ( a [ <NUM_LIT> ] - b [ <NUM_LIT> ] ) < <NUM_LIT> and a [ <NUM_LIT> ] < b [ <NUM_LIT> ] ) or a [ <NUM_LIT> ] > b [ <NUM_LIT> ] : \n return - <NUM_LIT> \n elif abs ( a [ <NUM_LIT> ] - b [ <NUM_LIT> ] ) < <NUM_LIT> and abs ( a [ <NUM_LIT> ] - b [ <NUM_LIT> ] ) < <NUM_LIT> : \n return <NUM_LIT> \n else : \n return <NUM_LIT> \n if __name__ == '<STR_LIT>' : \n path = input ( '<STR_LIT>' ) \n debug = input ( '<STR_LIT>' ) \n if debug == '<STR_LIT>' : \n debug = True \n elif debug == '<STR_LIT>' : \n debug = False \n else : \n print ( '<STR_LIT>' ) \n sys . exit ( ) \n folder = os . listdir ( path ) \n count = <NUM_LIT> \n model = Model ( debug = debug ) \n for i in folder : \n pic_path = os . path . join ( path , i ) \n name_ = i [ : - <NUM_LIT> ] \n res = model . process ( pic_path , name_ )"}, {"input": "from django . contrib import admin \n from django . contrib . admin import TabularInline \n from django_webhook . models import Webhook , WebhookEvent , WebhookSecret \n from . forms import WebhookForm \n class WebhookSecretInline ( TabularInline ) : \n model = WebhookSecret \n fields = ( \"<STR_LIT>\" , ) \n extra = <NUM_LIT> \n @ admin . register ( Webhook )", "output": "class WebhookAdmin ( admin . ModelAdmin ) : \n form = WebhookForm \n list_display = ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) \n list_filter = ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n search_fields = ( \"<STR_LIT>\" , ) \n filter_horizontal = ( \"<STR_LIT>\" , ) \n inlines = [ WebhookSecretInline ] \n @ admin . register ( WebhookEvent ) \n class WebhookEventAdmin ( admin . ModelAdmin ) : \n list_display = ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n list_filter = ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n search_fields = ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n readonly_fields = ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) \n def has_add_permission ( self , request ) : \n return False \n def has_change_permission ( self , request , obj = None ) : \n return False"}, {"input": "from django . apps import AppConfig \n from django . utils . translation import gettext_lazy as _ \n class UsersConfig ( AppConfig ) : \n name = \"<STR_LIT>\" \n verbose_name = _ ( \"<STR_LIT>\" ) \n def ready ( self ) : \n try : \n import delphic . users . signals", "output": "except ImportError : \n pass"}, {"input": "from rest_framework . decorators import action \n from rest_framework . permissions import AllowAny \n from dvadmin . utils . json_response import DetailResponse \n class FastCrudMixin : \n crud_fields = None \n exclude_fields = None \n custom_crud_json = None \n crud_update_key_value = None \n def __handle_type ( self , type ) : \n if type in [ '<STR_LIT>' , '<STR_LIT>' ] : \n return \"<STR_LIT>\" \n if type == '<STR_LIT>' : \n return \"<STR_LIT>\" \n if type == '<STR_LIT>' : \n return \"<STR_LIT>\" \n if type == '<STR_LIT>' : \n return \"<STR_LIT>\" \n if type == '<STR_LIT>' : \n return \"<STR_LIT>\" \n def __get_field_attribute ( self ) : \n result = [ ] \n queryset = self . get_queryset ( ) \n __name = \"<STR_LIT>\" \n __verbose_name = \"<STR_LIT>\" \n __type = \"<STR_LIT>\" \n if self . crud_fields and type ( self . crud_fields == list ) : \n for item in self . crud_fields : \n try : \n field = queryset . model . _meta . get_field ( item ) \n field_type = field . get_internal_type ( ) \n __name = field . name \n if field_type in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : \n continue \n else : \n __verbose_name = field . verbose_name \n __type = self . __handle_type ( field_type ) \n except : \n continue \n result . append ( { \"<STR_LIT>\" : __name , \"<STR_LIT>\" : __verbose_name , \"<STR_LIT>\" : __type } ) \n else : \n model_fields = queryset . model . _meta . get_fields ( ) \n for field in model_fields : \n field_type = field . get_internal_type ( ) \n __name = field . name \n if self . exclude_fields and type ( self . exclude_fields == list ) : \n if __name in self . exclude_fields : \n continue \n if field_type in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : \n continue \n else : \n __verbose_name = field . verbose_name \n __type = self . __handle_type ( field_type ) \n result . append ( { \"<STR_LIT>\" : __name , \"<STR_LIT>\" : __verbose_name , \"<STR_LIT>\" : __type } ) \n return result \n def __find_key ( self , dct : dict , \n target_key : str , \n level : int = - <NUM_LIT> , \n index : int = - <NUM_LIT> ) -> tuple : \n for k , v in dct . items ( ) : \n level += <NUM_LIT>", "output": "index += <NUM_LIT> \n if k == target_key : \n return level , index \n elif isinstance ( v , list ) : \n for i , dct_ in enumerate ( v ) : \n if isinstance ( dct_ , dict ) : \n result = self . __find_key ( dct_ , target_key ) \n if result is not None : \n return result \n else : \n continue \n elif isinstance ( v , str ) or isinstance ( v , int ) or isinstance ( v , float ) : \n continue \n def __update_nested_dict ( self , nested_dict : dict , \n target_key : str , \n new_value ) -> dict : \n split_target_key = target_key . split ( '<STR_LIT>' ) \n if len ( split_target_key ) > <NUM_LIT> : \n new_dict = nested_dict [ split_target_key [ <NUM_LIT> ] ] \n for item in split_target_key [ <NUM_LIT> : - <NUM_LIT> ] : \n new_dict = new_dict [ item ] \n self . __update_nested_dict ( new_dict , split_target_key [ - <NUM_LIT> ] , new_value ) \n else : \n nested_dict [ target_key ] = new_value \n return nested_dict \n def __handle_crud ( self ) : \n result = self . __get_field_attribute ( ) \n columns = dict ( ) \n for item in result : \n key = item . get ( '<STR_LIT>' ) \n title = item . get ( '<STR_LIT>' ) \n type = item . get ( '<STR_LIT>' ) \n columns [ key ] = { \n \"<STR_LIT>\" : title , \n \"<STR_LIT>\" : key , \n \"<STR_LIT>\" : type \n } \n if self . custom_crud_json and isinstance ( self . custom_crud_json , dict ) : \n columns = columns | self . custom_crud_json \n if self . crud_update_key_value and isinstance ( self . crud_update_key_value , dict ) : \n for key , value in self . crud_update_key_value . items ( ) : \n columns = self . __update_nested_dict ( columns , key , value ) \n return columns \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ AllowAny ] ) \n def init_crud ( self , request ) : \n self . permission_classes = [ AllowAny ] \n columns = self . __handle_crud ( ) \n expose = \"<STR_LIT>\" \n ret = \"<STR_LIT>\" \n res = \"<STR_LIT>\" \n data = \n return DetailResponse ( data = data )"}, {"input": "import logging \n import re \n from collections . abc import Callable , Iterable , MutableSequence , Sequence \n from . . types import TextSplitterProtocol \n logger = logging . getLogger ( __name__ ) \n def _split_text_with_regex ( \n text : str , separator : str , keep_separator : bool \n ) -> list [ str ] : \n if separator : \n if keep_separator : \n _splits = re . split ( f\"<STR_LIT>\" , text ) \n splits = [ _splits [ i ] + _splits [ i + <NUM_LIT> ] for i in range ( <NUM_LIT> , len ( _splits ) , <NUM_LIT> ) ] \n if len ( _splits ) % <NUM_LIT> == <NUM_LIT> : \n splits += _splits [ - <NUM_LIT> : ] \n splits = [ _splits [ <NUM_LIT> ] , * splits ] \n else : \n splits = re . split ( separator , text ) \n else : \n splits = list ( text ) \n return [ s for s in splits if s != \"<STR_LIT>\" ] \n class LangchainRecursiveCharacterTextSplitter ( TextSplitterProtocol ) : \n separators : Sequence [ str ] \n chunk_size : int \n chunk_overlap : int = <NUM_LIT> \n length_function : Callable [ [ str ] , int ] \n keep_separator = False \n strip_whitespace : bool = True \n def __init__ ( \n self , \n * , \n chunk_size : int , \n length_function : Callable [ [ str ] , int ] , \n ) -> None : \n self . separators = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n self . length_function = length_function \n self . chunk_size = chunk_size \n def split_text ( self , text : str ) -> list [ str ] : \n return self . _split_text ( text , self . separators ) \n def _split_text ( self , text : str , separators : Sequence [ str ] ) -> list [ str ] : \n final_chunks = [ ] \n separator = separators [ - <NUM_LIT> ] \n new_separators = [ ] \n for i , _s in enumerate ( separators ) : \n _separator = re . escape ( _s ) \n if _s == \"<STR_LIT>\" : \n separator = _s \n break \n if re . search ( _separator , text ) : \n separator = _s \n new_separators = separators [ i + <NUM_LIT> : ] \n break \n splits = _split_text_with_regex ( text , separator , self . keep_separator ) \n _good_splits = [ ] \n for s in splits : \n if self . length_function ( s ) < self . chunk_size : \n _good_splits . append ( s ) \n else : \n if _good_splits : \n merged_text = self . _merge_splits ( _good_splits , separator ) \n final_chunks . extend ( merged_text ) \n _good_splits = [ ] \n if not new_separators : \n final_chunks . append ( s ) \n else : \n other_info = self . _split_text ( s , new_separators ) \n final_chunks . extend ( other_info ) \n if _good_splits : \n merged_text = self . _merge_splits ( _good_splits , separator ) \n final_chunks . extend ( merged_text ) \n return final_chunks \n def _merge_splits ( self , splits : Iterable [ str ] , separator : str ) -> list [ str ] : \n separator_len = self . length_function ( separator ) \n docs = [ ] \n current_doc : MutableSequence [ str ] = [ ] \n total = <NUM_LIT> \n for d in splits : \n _len = self . length_function ( d ) \n if ( \n total + _len + ( separator_len if len ( current_doc ) > <NUM_LIT> else <NUM_LIT> ) \n > self . chunk_size \n ) : \n if total > self . chunk_size : \n logger . warning ( \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n ) \n if len ( current_doc ) > <NUM_LIT> : \n doc = self . _join_docs ( current_doc , separator ) \n if doc is not None : \n docs . append ( doc ) \n while total > self . chunk_overlap or ( \n total + _len + ( separator_len if len ( current_doc ) > <NUM_LIT> else <NUM_LIT> ) \n > self . chunk_size \n and total > <NUM_LIT> \n ) : \n total -= self . length_function ( current_doc [ <NUM_LIT> ] ) + ( \n separator_len if len ( current_doc ) > <NUM_LIT> else <NUM_LIT> \n ) \n current_doc = current_doc [ <NUM_LIT> : ] \n current_doc . append ( d )", "output": "total += _len + ( separator_len if len ( current_doc ) > <NUM_LIT> else <NUM_LIT> ) \n doc = self . _join_docs ( current_doc , separator ) \n if doc is not None : \n docs . append ( doc ) \n return docs \n def _join_docs ( self , docs : Sequence [ str ] , separator : str ) -> str | None : \n text = separator . join ( docs ) \n if self . strip_whitespace : \n text = text . strip ( ) \n if text == \"<STR_LIT>\" : \n return None \n else : \n return text"}, {"input": "from django . urls import path , re_path , include \n from django . views . generic import TemplateView \n from dj_rest_auth . registration . views import VerifyEmailView , ResendEmailVerificationView \n from . views import RegistrationView \n urlpatterns = [ \n path ( '<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n path ( '<STR_LIT>' , RegistrationView . as_view ( ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , VerifyEmailView . as_view ( ) , name = '<STR_LIT>' ) , \n path ( '<STR_LIT>' , ResendEmailVerificationView . as_view ( ) , name = \"<STR_LIT>\" ) , \n re_path ( \n r'<STR_LIT>' , TemplateView . as_view ( ) , \n name = '<STR_LIT>' , \n ) ,", "output": "path ( \n '<STR_LIT>' , TemplateView . as_view ( ) , \n name = '<STR_LIT>' , \n ) , \n ]"}, {"input": "from copy import deepcopy \n import re \n try : \n import psyco \n psyco . full ( ) \n except : \n pass \n try : \n from zh_wiki import zh2Hant , zh2Hans \n except ImportError : \n from utils . zhtools . zh_wiki import zh2Hant , zh2Hans \n import sys \n py3k = sys . version_info >= ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n if py3k : \n UEMPTY = '<STR_LIT>' \n else : \n _zh2Hant , _zh2Hans = { } , { } \n for old , new in ( ( zh2Hant , _zh2Hant ) , ( zh2Hans , _zh2Hans ) ) : \n for k , v in old . items ( ) : \n new [ k . decode ( '<STR_LIT>' ) ] = v . decode ( '<STR_LIT>' ) \n zh2Hant = _zh2Hant \n zh2Hans = _zh2Hans \n UEMPTY = '<STR_LIT>' . decode ( '<STR_LIT>' ) \n ( START , END , FAIL , WAIT_TAIL ) = list ( range ( <NUM_LIT> ) ) \n ( TAIL , ERROR , MATCHED_SWITCH , UNMATCHED_SWITCH , CONNECTOR ) = list ( range ( <NUM_LIT> ) ) \n MAPS = { } \n class Node ( object ) : \n def __init__ ( self , from_word , to_word = None , is_tail = True , \n have_child = False ) : \n self . from_word = from_word \n if to_word is None : \n self . to_word = from_word \n self . data = ( is_tail , have_child , from_word ) \n self . is_original = True \n else : \n self . to_word = to_word or from_word \n self . data = ( is_tail , have_child , to_word ) \n self . is_original = False \n self . is_tail = is_tail \n self . have_child = have_child \n def is_original_long_word ( self ) : \n return self . is_original and len ( self . from_word ) > <NUM_LIT> \n def is_follow ( self , chars ) : \n return chars != self . from_word [ : - <NUM_LIT> ] \n def __str__ ( self ) : \n return '<STR_LIT>' % ( repr ( self . from_word ) , \n repr ( self . to_word ) , self . is_tail , self . have_child ) \n __repr__ = __str__ \n class ConvertMap ( object ) : \n def __init__ ( self , name , mapping = None ) : \n self . name = name \n self . _map = { } \n if mapping : \n self . set_convert_map ( mapping )", "output": "def set_convert_map ( self , mapping ) : \n convert_map = { } \n have_child = { } \n max_key_length = <NUM_LIT> \n for key in sorted ( mapping . keys ( ) ) : \n if len ( key ) > <NUM_LIT> : \n for i in range ( <NUM_LIT> , len ( key ) ) : \n parent_key = key [ : i ] \n have_child [ parent_key ] = True \n have_child [ key ] = False \n max_key_length = max ( max_key_length , len ( key ) ) \n for key in sorted ( have_child . keys ( ) ) : \n convert_map [ key ] = ( key in mapping , have_child [ key ] , \n mapping . get ( key , UEMPTY ) ) \n self . _map = convert_map \n self . max_key_length = max_key_length \n def __getitem__ ( self , k ) : \n try : \n is_tail , have_child , to_word = self . _map [ k ] \n return Node ( k , to_word , is_tail , have_child ) \n except : \n return Node ( k ) \n def __contains__ ( self , k ) : \n return k in self . _map \n def __len__ ( self ) : \n return len ( self . _map ) \n class StatesMachineException ( Exception ) : pass \n class StatesMachine ( object ) : \n def __init__ ( self ) : \n self . state = START \n self . final = UEMPTY \n self . len = <NUM_LIT> \n self . pool = UEMPTY \n def clone ( self , pool ) : \n new = deepcopy ( self ) \n new . state = WAIT_TAIL \n new . pool = pool \n return new \n def feed ( self , char , map ) : \n node = map [ self . pool + char ] \n if node . have_child : \n if node . is_tail : \n if node . is_original : \n cond = UNMATCHED_SWITCH \n else : \n cond = MATCHED_SWITCH \n else : \n cond = CONNECTOR \n else : \n if node . is_tail : \n cond = TAIL \n else : \n cond = ERROR \n new = None \n if cond == ERROR : \n self . state = FAIL \n elif cond == TAIL : \n if self . state == WAIT_TAIL and node . is_original_long_word ( ) : \n self . state = FAIL \n else : \n self . final += node . to_word \n self . len += <NUM_LIT> \n self . pool = UEMPTY \n self . state = END \n elif self . state == START or self . state == WAIT_TAIL : \n if cond == MATCHED_SWITCH : \n new = self . clone ( node . from_word ) \n self . final += node . to_word \n self . len += <NUM_LIT> \n self . state = END \n self . pool = UEMPTY \n elif cond == UNMATCHED_SWITCH or cond == CONNECTOR : \n if self . state == START : \n new = self . clone ( node . from_word ) \n self . final += node . to_word \n self . len += <NUM_LIT> \n self . state = END \n else : \n if node . is_follow ( self . pool ) : \n self . state = FAIL \n else : \n self . pool = node . from_word \n elif self . state == END : \n self . state = START \n new = self . feed ( char , map ) \n elif self . state == FAIL : \n raise StatesMachineException ( '<STR_LIT>' \n '<STR_LIT>' % node ) \n return new \n def __len__ ( self ) : \n return self . len + <NUM_LIT> \n def __str__ ( self ) : \n return '<STR_LIT>' % ( \n id ( self ) , self . pool , self . state , self . final ) \n __repr__ = __str__ \n class Converter ( object ) : \n def __init__ ( self , to_encoding ) : \n self . to_encoding = to_encoding \n self . map = MAPS [ to_encoding ] \n self . start ( ) \n def feed ( self , char ) : \n branches = [ ] \n for fsm in self . machines : \n new = fsm . feed ( char , self . map ) \n if new : \n branches . append ( new ) \n if branches : \n self . machines . extend ( branches ) \n self . machines = [ fsm for fsm in self . machines if fsm . state != FAIL ] \n all_ok = True \n for fsm in self . machines : \n if fsm . state != END : \n all_ok = False \n if all_ok : \n self . _clean ( ) \n return self . get_result ( ) \n def _clean ( self ) : \n if len ( self . machines ) : \n self . machines . sort ( key = lambda x : len ( x ) ) \n self . final += self . machines [ <NUM_LIT> ] . final \n self . machines = [ StatesMachine ( ) ] \n def start ( self ) : \n self . machines = [ StatesMachine ( ) ] \n self . final = UEMPTY \n def end ( self ) : \n self . machines = [ fsm for fsm in self . machines \n if fsm . state == FAIL or fsm . state == END ] \n self . _clean ( ) \n def convert ( self , string ) : \n self . start ( ) \n for char in string : \n self . feed ( char ) \n self . end ( ) \n return self . get_result ( ) \n def get_result ( self ) : \n return self . final \n def registery ( name , mapping ) : \n global MAPS \n MAPS [ name ] = ConvertMap ( name , mapping ) \n registery ( '<STR_LIT>' , zh2Hant ) \n registery ( '<STR_LIT>' , zh2Hans ) \n del zh2Hant , zh2Hans \n def run ( ) : \n import sys \n from optparse import OptionParser \n parser = OptionParser ( ) \n parser . add_option ( '<STR_LIT>' , type = '<STR_LIT>' , dest = '<STR_LIT>' , \n help = '<STR_LIT>' ) \n parser . add_option ( '<STR_LIT>' , type = '<STR_LIT>' , dest = '<STR_LIT>' , \n help = '<STR_LIT>' ) \n parser . add_option ( '<STR_LIT>' , type = '<STR_LIT>' , dest = '<STR_LIT>' , \n help = '<STR_LIT>' ) \n ( options , args ) = parser . parse_args ( ) \n if not options . encoding : \n parser . error ( '<STR_LIT>' ) \n if options . file_in : \n if options . file_in == '<STR_LIT>' : \n file_in = sys . stdin \n else : \n file_in = open ( options . file_in ) \n else : \n file_in = sys . stdin \n if options . file_out : \n if options . file_out == '<STR_LIT>' : \n file_out = sys . stdout \n else : \n file_out = open ( options . file_out , '<STR_LIT>' ) \n else : \n file_out = sys . stdout \n c = Converter ( options . encoding ) \n for line in file_in : \n file_out . write ( c . convert ( line . rstrip ( '<STR_LIT>' ) . decode ( \n '<STR_LIT>' ) ) . encode ( '<STR_LIT>' ) ) \n if __name__ == '<STR_LIT>' : \n run ( )"}, {"input": "from typing import List \n from ninja import Router \n from examples . models import Department , Employee \n from examples . schemas import DepartmentIn , DepartmentOut , EmployeeIn , EmployeeOut \n from ninja_crud import views , viewsets \n router = Router ( ) \n class DepartmentViewSet ( viewsets . ModelViewSet ) : \n model = Department \n default_request_body = DepartmentIn \n default_response_body = DepartmentOut \n list_departments = views . ListModelView ( response_body = List [ DepartmentOut ] ) \n create_department = views . CreateModelView ( ) \n read_department = views . ReadModelView ( ) \n update_department = views . UpdateModelView ( ) \n delete_department = views . DeleteModelView ( ) \n list_employees = views . ListModelView ( \n path = \"<STR_LIT>\" , \n get_queryset = lambda request , path_parameters : Employee . objects . filter ( \n department_id = getattr ( path_parameters , \"<STR_LIT>\" , None ) \n ) , \n response_body = List [ EmployeeOut ] , \n ) \n create_employee = views . CreateModelView ( \n path = \"<STR_LIT>\" , \n request_body = EmployeeIn ,", "output": "response_body = EmployeeOut , \n init_model = lambda request , path_parameters : Employee ( \n department_id = getattr ( path_parameters , \"<STR_LIT>\" , None ) \n ) , \n ) \n DepartmentViewSet . register_routes ( router )"}, {"input": "import hashlib \n import logging \n from django . contrib . auth import get_user_model \n from django . contrib . auth . backends import ModelBackend \n from django . contrib . auth . hashers import check_password \n from django . utils import timezone \n from dvadmin . utils . validator import CustomValidationError \n logger = logging . getLogger ( __name__ ) \n UserModel = get_user_model ( ) \n class CustomBackend ( ModelBackend ) : \n def authenticate ( self , request , username = None , password = None , ** kwargs ) : \n msg = '<STR_LIT>' % username \n logger . info ( msg ) \n if username is None :", "output": "username = kwargs . get ( UserModel . USERNAME_FIELD ) \n try : \n user = UserModel . _default_manager . get_by_natural_key ( username ) \n except UserModel . DoesNotExist : \n UserModel ( ) . set_password ( password ) \n else : \n verify_password = check_password ( password , user . password ) \n if not verify_password : \n password = hashlib . md5 ( password . encode ( encoding = '<STR_LIT>' ) ) . hexdigest ( ) \n verify_password = check_password ( password , user . password ) \n if verify_password : \n if self . user_can_authenticate ( user ) : \n user . last_login = timezone . now ( ) \n user . save ( ) \n return user \n raise CustomValidationError ( \"<STR_LIT>\" )"}, {"input": "import requests , re , datetime , os \n from utils . general import headers \n from bs4 import BeautifulSoup as bs \n def get_epgs_mod ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n days = ( dt - datetime . datetime . now ( ) . date ( ) ) . days \n url = '<STR_LIT>' % ( \n channel_id , days ) \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n old_dt = datetime . datetime ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n lis = soup . select ( '<STR_LIT>' ) \n for li in lis [ <NUM_LIT> : ] : \n title = li . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . strip ( ) \n timestr = li . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text . strip ( ) \n starttime = datetime . datetime ( dt . year , dt . month , dt . day , int ( timestr [ : <NUM_LIT> ] ) , int ( timestr [ - <NUM_LIT> : ] ) ) \n if starttime < old_dt : \n epgs . pop ( <NUM_LIT> ) \n old_dt = datetime . datetime ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = {", "output": "'<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_mod ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n divs = soup . select ( '<STR_LIT>' ) \n divs2 = soup . select ( '<STR_LIT>' ) \n divs += divs2 \n channels = [ ] \n for div in divs : \n try : \n urlid = div . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . attrs [ '<STR_LIT>' ] \n name = div . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n id = name [ : <NUM_LIT> ] . strip ( ) \n img = '<STR_LIT>' + re . sub ( '<STR_LIT>' , '<STR_LIT>' , div . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . attrs [ '<STR_LIT>' ] ) . strip ( ) \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : '<STR_LIT>' % ( '<STR_LIT>' , urlid ) , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : img , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n channels . append ( channel ) \n except Exception as e : \n print ( div ) \n return channels"}, {"input": "from django . db . models import F \n from rest_framework . decorators import action \n from rest_framework . permissions import IsAuthenticated \n from dvadmin . system . models import FieldPermission , MenuField \n from dvadmin . utils . json_response import DetailResponse \n from dvadmin . utils . models import get_custom_app_models \n class FieldPermissionMixin : \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def field_permission ( self , request ) : \n finded = False \n for model in get_custom_app_models ( ) : \n if model [ '<STR_LIT>' ] is self . serializer_class . Meta . model : \n finded = True \n break \n if finded : \n break \n if finded is False : \n return [ ] \n user = request . user", "output": "if user . is_superuser == <NUM_LIT> : \n data = MenuField . objects . filter ( model = model [ '<STR_LIT>' ] ) . values ( '<STR_LIT>' ) \n for item in data : \n item [ '<STR_LIT>' ] = True \n item [ '<STR_LIT>' ] = True \n item [ '<STR_LIT>' ] = True \n else : \n roles = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n data = FieldPermission . objects . filter ( \n field__model = model [ '<STR_LIT>' ] , role__in = roles \n ) . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , field_name = F ( '<STR_LIT>' ) ) \n return DetailResponse ( data = data )"}, {"input": "from functools import wraps \n from django . db . models import Func , F , OuterRef , Exists \n from django . test import TestCase \n import django \n import os \n os . environ . setdefault ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n django . setup ( ) \n from dvadmin . system . models import Menu , RoleMenuPermission , RoleMenuButtonPermission , MenuButton \n import time \n def timing_decorator ( func ) : \n @ wraps ( func ) \n def wrapper ( * args , ** kwargs ) : \n start_time = time . time ( ) \n result = func ( * args , ** kwargs ) \n end_time = time . time ( ) \n run_time = end_time - start_time \n print ( f\"<STR_LIT>\" ) \n return result \n return wrapper \n @ timing_decorator \n def getMenu ( ) :", "output": "data = [ ] \n queryset = Menu . objects . filter ( status = <NUM_LIT> , is_catalog = False ) . values ( '<STR_LIT>' , '<STR_LIT>' ) \n for item in queryset : \n parent_list = Menu . get_all_parent ( item [ '<STR_LIT>' ] ) \n names = [ d [ \"<STR_LIT>\" ] for d in parent_list ] \n completeName = \"<STR_LIT>\" . join ( names ) \n isCheck = RoleMenuPermission . objects . filter ( \n menu__id = item [ '<STR_LIT>' ] , \n role__id = <NUM_LIT> , \n ) . exists ( ) \n mbCheck = RoleMenuButtonPermission . objects . filter ( \n menu_button = OuterRef ( \"<STR_LIT>\" ) , \n role__id = <NUM_LIT> , \n ) \n btns = MenuButton . objects . filter ( \n menu__id = item [ '<STR_LIT>' ] , \n ) . annotate ( isCheck = Exists ( mbCheck ) ) . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , data_range = F ( '<STR_LIT>' ) ) \n dicts = { \n '<STR_LIT>' : completeName , \n '<STR_LIT>' : item [ '<STR_LIT>' ] , \n '<STR_LIT>' : isCheck , \n '<STR_LIT>' : btns \n } \n print ( dicts ) \n data . append ( dicts ) \n if __name__ == '<STR_LIT>' : \n getMenu ( )"}, {"input": "import operator \n import re \n from collections import OrderedDict \n from functools import reduce \n import six \n from django . db import models \n from django . db . models import Q , F \n from django . db . models . constants import LOOKUP_SEP \n from django_filters import utils , FilterSet \n from django_filters . constants import ALL_FIELDS \n from django_filters . filters import CharFilter , DateTimeFromToRangeFilter \n from django_filters . rest_framework import DjangoFilterBackend \n from django_filters . utils import get_model_field \n from rest_framework . filters import BaseFilterBackend \n from django_filters . conf import settings \n from dvadmin . system . models import Dept , ApiWhiteList , RoleMenuButtonPermission \n from dvadmin . utils . models import CoreModel \n class CoreModelFilterBankend ( BaseFilterBackend ) : \n def filter_queryset ( self , request , queryset , view ) : \n create_datetime_after = request . query_params . get ( '<STR_LIT>' , None ) \n create_datetime_before = request . query_params . get ( '<STR_LIT>' , None ) \n update_datetime_after = request . query_params . get ( '<STR_LIT>' , None ) \n update_datetime_before = request . query_params . get ( '<STR_LIT>' , None ) \n if any ( [ create_datetime_after , create_datetime_before , update_datetime_after , update_datetime_before ] ) : \n create_filter = Q ( ) \n if create_datetime_after and create_datetime_before : \n create_filter &= Q ( create_datetime__gte = create_datetime_after ) & Q ( create_datetime__lte = create_datetime_before ) \n elif create_datetime_after : \n create_filter &= Q ( create_datetime__gte = create_datetime_after ) \n elif create_datetime_before : \n create_filter &= Q ( create_datetime__lte = create_datetime_before ) \n update_filter = Q ( ) \n if update_datetime_after and update_datetime_before : \n update_filter &= Q ( update_datetime__gte = update_datetime_after ) & Q ( update_datetime__lte = update_datetime_before ) \n elif update_datetime_after : \n update_filter &= Q ( update_datetime__gte = update_datetime_after ) \n elif update_datetime_before : \n update_filter &= Q ( update_datetime__lte = update_datetime_before ) \n queryset = queryset . filter ( create_filter & update_filter ) \n return queryset \n return queryset \n def get_dept ( dept_id : int , dept_all_list = None , dept_list = None ) : \n if not dept_all_list : \n dept_all_list = Dept . objects . all ( ) . values ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n if dept_list is None : \n dept_list = [ dept_id ] \n for ele in dept_all_list : \n if ele . get ( \"<STR_LIT>\" ) == dept_id : \n dept_list . append ( ele . get ( \"<STR_LIT>\" ) ) \n get_dept ( ele . get ( \"<STR_LIT>\" ) , dept_all_list , dept_list ) \n return list ( set ( dept_list ) ) \n class DataLevelPermissionsFilter ( BaseFilterBackend ) : \n def filter_queryset ( self , request , queryset , view ) : \n api = request . path \n method = request . method \n methodList = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n method = methodList . index ( method ) \n api_white_list = ApiWhiteList . objects . filter ( enable_datasource = False ) . values ( \n permission__api = F ( \"<STR_LIT>\" ) , permission__method = F ( \"<STR_LIT>\" ) \n ) \n api_white_list = [ \n str ( item . get ( \"<STR_LIT>\" ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ) \n + \"<STR_LIT>\" \n + str ( item . get ( \"<STR_LIT>\" ) ) \n for item in api_white_list \n if item . get ( \"<STR_LIT>\" ) \n ] \n for item in api_white_list : \n new_api = f\"<STR_LIT>\" \n matchObj = re . match ( item , new_api , re . M | re . I ) \n if matchObj is None : \n continue \n else : \n return queryset \n if request . user . is_superuser == <NUM_LIT> : \n return self . _extracted_from_filter_queryset_33 ( request , queryset , api , method ) \n else : \n return queryset \n def _extracted_from_filter_queryset_33 ( self , request , queryset , api , method ) : \n user_dept_id = getattr ( request . user , \"<STR_LIT>\" , None ) \n if not user_dept_id : \n return queryset . none ( ) \n if not getattr ( queryset . model , \"<STR_LIT>\" , None ) : \n return queryset \n if not hasattr ( request . user , \"<STR_LIT>\" ) : \n return queryset . filter ( dept_belong_id = user_dept_id ) \n re_api = api \n _pk = request . parser_context [ \"<STR_LIT>\" ] . get ( '<STR_LIT>' ) \n if _pk : \n re_api = re . sub ( _pk , '<STR_LIT>' , api ) \n role_id_list = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n role_permission_list = RoleMenuButtonPermission . objects . filter ( \n role__in = role_id_list , \n role__status = <NUM_LIT> , \n menu_button__api = re_api , \n menu_button__method = method ) . values (", "output": "'<STR_LIT>' \n ) \n dataScope_list = [ ] \n for ele in role_permission_list : \n if ele . get ( \"<STR_LIT>\" ) == <NUM_LIT> : \n return queryset \n dataScope_list . append ( ele . get ( \"<STR_LIT>\" ) ) \n dataScope_list = list ( set ( dataScope_list ) ) \n if <NUM_LIT> in dataScope_list : \n return queryset . filter ( \n creator = request . user , dept_belong_id = user_dept_id \n ) \n dept_list = [ ] \n for ele in dataScope_list : \n if ele == <NUM_LIT> : \n dept_list . append ( user_dept_id ) \n dept_list . extend ( \n get_dept ( \n user_dept_id , \n ) \n ) \n elif ele == <NUM_LIT> : \n dept_list . append ( user_dept_id ) \n elif ele == <NUM_LIT> : \n dept_ids = RoleMenuButtonPermission . objects . filter ( \n role__in = role_id_list , \n role__status = <NUM_LIT> , \n data_range = <NUM_LIT> ) . values_list ( \n '<STR_LIT>' , flat = True \n ) \n dept_list . extend ( \n dept_ids \n ) \n if queryset . model . _meta . model_name == '<STR_LIT>' : \n return queryset . filter ( id__in = list ( set ( dept_list ) ) ) \n return queryset . filter ( dept_belong_id__in = list ( set ( dept_list ) ) ) \n class CustomDjangoFilterBackend ( DjangoFilterBackend ) : \n lookup_prefixes = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n filter_fields = \"<STR_LIT>\" \n def construct_search ( self , field_name , lookup_expr = None ) : \n lookup = self . lookup_prefixes . get ( field_name [ <NUM_LIT> ] ) \n if lookup : \n field_name = field_name [ <NUM_LIT> : ] \n else : \n lookup = lookup_expr \n if lookup : \n if field_name . endswith ( lookup ) : \n return field_name \n return LOOKUP_SEP . join ( [ field_name , lookup ] ) \n return field_name \n def find_filter_lookups ( self , orm_lookups , search_term_key ) : \n for lookup in orm_lookups : \n new_lookup = LOOKUP_SEP . join ( lookup . split ( LOOKUP_SEP ) [ : - <NUM_LIT> ] ) if len ( lookup . split ( LOOKUP_SEP ) ) > <NUM_LIT> else lookup \n if new_lookup == search_term_key : \n return lookup \n return None \n def get_filterset_class ( self , view , queryset = None ) : \n filterset_class = getattr ( view , \"<STR_LIT>\" , None ) \n filterset_fields = getattr ( view , \"<STR_LIT>\" , None ) \n if filterset_class is None and hasattr ( view , \"<STR_LIT>\" ) : \n utils . deprecate ( \n \"<STR_LIT>\" % view . __class__ . __name__ \n ) \n filterset_class = getattr ( view , \"<STR_LIT>\" , None ) \n if filterset_fields is None and hasattr ( view , \"<STR_LIT>\" ) : \n utils . deprecate ( \n \"<STR_LIT>\" % view . __class__ . __name__ \n ) \n self . filter_fields = getattr ( view , \"<STR_LIT>\" , None ) \n if isinstance ( self . filter_fields , ( list , tuple ) ) : \n filterset_fields = [ \n field [ <NUM_LIT> : ] if field [ <NUM_LIT> ] in self . lookup_prefixes . keys ( ) else field for field in self . filter_fields \n ] \n else : \n filterset_fields = self . filter_fields \n if filterset_class : \n filterset_model = filterset_class . _meta . model \n if filterset_model and queryset is not None : \n assert issubclass ( \n queryset . model , filterset_model \n ) , \"<STR_LIT>\" % ( \n filterset_model , \n queryset . model , \n ) \n return filterset_class \n if filterset_fields and queryset is not None : \n MetaBase = getattr ( self . filterset_base , \"<STR_LIT>\" , object ) \n class AutoFilterSet ( self . filterset_base ) : \n @ classmethod \n def get_all_model_fields ( cls , model ) : \n opts = model . _meta \n return [ \n f . name \n for f in sorted ( opts . fields + opts . many_to_many ) \n if ( f . name == \"<STR_LIT>\" ) \n or not isinstance ( f , models . AutoField ) \n and not ( getattr ( f . remote_field , \"<STR_LIT>\" , False ) ) \n ] \n @ classmethod \n def get_fields ( cls ) : \n model = cls . _meta . model \n fields = cls . _meta . fields \n exclude = cls . _meta . exclude \n assert not ( fields is None and exclude is None ) , ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" % cls . __name__ \n ) \n if exclude is not None and fields is None : \n fields = ALL_FIELDS \n if fields == ALL_FIELDS : \n fields = cls . get_all_model_fields ( model ) \n exclude = exclude or [ ] \n if not isinstance ( fields , dict ) : \n fields = [ ( f , [ settings . DEFAULT_LOOKUP_EXPR ] ) for f in fields if f not in exclude ] \n else : \n fields = [ ( f , lookups ) for f , lookups in fields . items ( ) if f not in exclude ] \n return OrderedDict ( fields ) \n @ classmethod \n def get_filters ( cls ) : \n if not cls . _meta . model : \n return cls . declared_filters . copy ( ) \n filters = OrderedDict ( ) \n fields = cls . get_fields ( ) \n undefined = [ ] \n for field_name , lookups in fields . items ( ) : \n field = get_model_field ( cls . _meta . model , field_name ) \n from django . db import models \n from timezone_field import TimeZoneField \n if isinstance ( field , ( models . JSONField , TimeZoneField ) ) : \n continue \n if field is None : \n undefined . append ( field_name ) \n if ( \n isinstance ( field , ( models . CharField ) ) \n and filterset_fields == \"<STR_LIT>\" \n and lookups == [ \"<STR_LIT>\" ] \n ) : \n lookups = [ \"<STR_LIT>\" ] \n for lookup_expr in lookups : \n filter_name = cls . get_filter_name ( field_name , lookup_expr ) \n if filter_name in cls . declared_filters : \n filters [ filter_name ] = cls . declared_filters [ filter_name ] \n continue \n if field is not None : \n filters [ filter_name ] = cls . filter_for_field ( field , field_name , lookup_expr ) \n if isinstance ( cls . _meta . fields , ( list , tuple ) ) : \n undefined = [ f for f in undefined if f not in cls . declared_filters ] \n if undefined : \n raise TypeError ( \n \"<STR_LIT>\" % \"<STR_LIT>\" . join ( undefined ) \n ) \n filters . update ( cls . declared_filters ) \n return filters \n class Meta ( MetaBase ) : \n model = queryset . model \n fields = filterset_fields \n return AutoFilterSet \n return None \n def filter_queryset ( self , request , queryset , view ) : \n filterset = self . get_filterset ( request , queryset , view ) \n if filterset is None : \n return queryset \n if filterset . __class__ . __name__ == \"<STR_LIT>\" : \n queryset = filterset . queryset \n filter_fields = filterset . filters if self . filter_fields == \"<STR_LIT>\" else self . filter_fields \n orm_lookup_dict = dict ( \n zip ( \n [ field for field in filter_fields ] , \n [ filterset . filters [ lookup ] . lookup_expr for lookup in filterset . filters . keys ( ) ] , \n ) \n ) \n orm_lookups = [ \n self . construct_search ( lookup , lookup_expr ) for lookup , lookup_expr in orm_lookup_dict . items ( ) \n ] \n conditions = [ ] \n queries = [ ] \n for search_term_key in filterset . data . keys ( ) : \n orm_lookup = self . find_filter_lookups ( orm_lookups , search_term_key ) \n if not orm_lookup or filterset . data . get ( search_term_key ) == '<STR_LIT>' : \n continue \n filterset_data_len = len ( filterset . data . getlist ( search_term_key ) ) \n if filterset_data_len == <NUM_LIT> : \n query = Q ( ** { orm_lookup : filterset . data [ search_term_key ] } ) \n queries . append ( query ) \n elif filterset_data_len == <NUM_LIT> : \n orm_lookup += '<STR_LIT>' \n query = Q ( ** { orm_lookup : filterset . data . getlist ( search_term_key ) } ) \n queries . append ( query ) \n if len ( queries ) > <NUM_LIT> : \n conditions . append ( reduce ( operator . and_ , queries ) ) \n queryset = queryset . filter ( reduce ( operator . and_ , conditions ) ) \n return queryset \n else : \n return queryset \n if not filterset . is_valid ( ) and self . raise_exception : \n raise utils . translate_validation ( filterset . errors ) \n return filterset . qs"}, {"input": "from django . http import JsonResponse \n from django . shortcuts import render \n from django . http import HttpResponseRedirect , HttpResponse \n from django . contrib . auth . decorators import login_required \n from django . conf import settings as _settings", "output": "@ login_required ( login_url = '<STR_LIT>' ) \n def index ( request ) : \n if _settings . ID_SERVER == '<STR_LIT>' : \n _settings . ID_SERVER = request . get_host ( ) . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] \n return render ( request , '<STR_LIT>' )"}, {"input": "import django . utils . timezone \n from django . db import models , migrations", "output": "class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True , default = django . utils . timezone . now ) , \n preserve_default = False , \n ) , \n ]"}, {"input": "from django . utils . decorators import method_decorator \n from django . views . decorators . cache import cache_page \n from rest_framework . request import Request \n from rest_framework . response import Response \n from rest_framework . status import HTTP_200_OK \n from rest_framework . viewsets import GenericViewSet \n from rest_framework . exceptions import ValidationError \n from feeds . models import Location \n class BaseAreaViewSet ( GenericViewSet ) : \n queryset = Location . objects . select_related ( \"<STR_LIT>\" ) . all ( ) \n def get_queryset ( self ) : \n ne_lat = self . request . query_params . get ( \"<STR_LIT>\" ) \n ne_lng = self . request . query_params . get ( \"<STR_LIT>\" ) \n sw_lat = self . request . query_params . get ( \"<STR_LIT>\" ) \n sw_lng = self . request . query_params . get ( \"<STR_LIT>\" ) \n if not ne_lat : \n raise ValidationError ( \"<STR_LIT>\" ) \n if not ne_lng : \n raise ValidationError ( \"<STR_LIT>\" ) \n if not sw_lat : \n raise ValidationError ( \"<STR_LIT>\" ) \n if not sw_lng : \n raise ValidationError ( \"<STR_LIT>\" ) \n try : \n ne_lat = float ( ne_lat ) \n ne_lng = float ( ne_lng ) \n sw_lat = float ( sw_lat ) \n sw_lng = float ( sw_lng ) \n except ValueError : \n raise ValidationError ( \"<STR_LIT>\" ) \n return self . queryset . filter ( \n northeast_lat__lte = ne_lat , \n northeast_lng__lte = ne_lng , \n southwest_lat__gte = sw_lat , \n southwest_lng__gte = sw_lng ,", "output": ") \n @ method_decorator ( cache_page ( <NUM_LIT> * <NUM_LIT> ) ) \n def list ( self , request : Request , * args , ** kwargs ) -> Response : \n queryset = self . get_queryset ( ) \n serializer = self . serializer_class ( queryset , many = True ) \n return Response ( \n data = { \"<STR_LIT>\" : queryset . count ( ) , \"<STR_LIT>\" : serializer . data } , \n status = HTTP_200_OK , \n )"}, {"input": "import random \n import uuid \n from ninja_crud . testing . core . components import ( \n Headers , \n PathParameters , \n Payloads , \n QueryParameters , \n ) \n from ninja_crud . testing . views import ( \n CreateModelViewTest , \n DeleteModelViewTest , \n ListModelViewTest , \n ReadModelViewTest , \n UpdateModelViewTest , \n ) \n from ninja_crud . testing . viewsets import ModelViewSetTestCase \n from tests . test_app . tests . base_test_case import BaseTestCase \n from tests . test_app . views . collection_views import CollectionViewSet \n class TestCollectionViewSet ( ModelViewSetTestCase , BaseTestCase ) : \n model_viewset_class = CollectionViewSet \n base_path = \"<STR_LIT>\" \n def get_path_parameters ( self ) : \n return PathParameters ( \n ok = [ { \"<STR_LIT>\" : self . collection_1 . id } ] , not_found = { \"<STR_LIT>\" : uuid . uuid4 ( ) } \n ) \n def get_headers_ok ( self ) :", "output": "return Headers ( \n ok = [ { \"<STR_LIT>\" : f\"<STR_LIT>\" } ] , unauthorized = { } \n ) \n def get_headers_ok_forbidden ( self ) : \n return Headers ( \n ok = { \"<STR_LIT>\" : f\"<STR_LIT>\" } , \n unauthorized = { \"<STR_LIT>\" : f\"<STR_LIT>\" } , \n forbidden = { \"<STR_LIT>\" : f\"<STR_LIT>\" } , \n ) \n collection_payloads = Payloads ( \n ok = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n bad_request = { \"<STR_LIT>\" : [ ] } , \n conflict = { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) \n test_list_collections = ListModelViewTest ( \n headers = get_headers_ok , \n query_parameters = QueryParameters ( \n ok = [ { } , { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \"<STR_LIT>\" : <NUM_LIT> } ] , \n bad_request = { \"<STR_LIT>\" : [ \"<STR_LIT>\" ] } , \n ) , \n ) \n test_create_collection = CreateModelViewTest ( \n headers = get_headers_ok , \n payloads = collection_payloads , \n ) \n test_read_collection = ReadModelViewTest ( \n path_parameters = get_path_parameters , \n headers = get_headers_ok , \n ) \n test_update_collection = UpdateModelViewTest ( \n path_parameters = get_path_parameters , \n headers = get_headers_ok_forbidden , \n payloads = collection_payloads , \n ) \n test_delete_collection = DeleteModelViewTest ( \n path_parameters = get_path_parameters , headers = get_headers_ok_forbidden \n ) \n test_list_collection_items = ListModelViewTest ( \n path_parameters = get_path_parameters , headers = get_headers_ok_forbidden \n ) \n test_create_collection_item = CreateModelViewTest ( \n path_parameters = get_path_parameters , \n headers = get_headers_ok_forbidden , \n payloads = Payloads ( \n ok = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) , \n )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ,", "output": "] \n operations = [ \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now = True ) , \n ) , \n ]"}, {"input": "from pathlib import Path \n from typing import Annotated \n import cappa \n from falco . config import FalcoConfig \n from falco . config import read_falco_config \n from falco . config import write_falco_config \n from falco . utils import get_project_name \n from falco . utils import get_pyproject_file \n from falco . utils import simple_progress \n from rich import print as rich_print \n from . utils import extract_python_file_templates \n from . utils import get_crud_blueprints_path \n from . utils import render_to_string \n from . utils import run_python_formatters \n @ cappa . command ( help = \"<STR_LIT>\" , name = \"<STR_LIT>\" ) \n class InstallCrudUtils : \n output_dir : Annotated [ \n Path | None , \n cappa . Arg ( default = None , help = \"<STR_LIT>\" ) , \n ] = None \n def __call__ ( self , project_name : Annotated [ str , cappa . Dep ( get_project_name ) ] ) : \n try : \n pyproject_path = get_pyproject_file ( )", "output": "falco_config = read_falco_config ( pyproject_path ) \n except cappa . Exit : \n falco_config = { } \n pyproject_path = None \n output_dir = self . install ( project_name = project_name , falco_config = falco_config ) \n if pyproject_path : \n write_falco_config ( pyproject_path = pyproject_path , crud = { \"<STR_LIT>\" : str ( output_dir ) } ) \n rich_print ( f\"<STR_LIT>\" ) \n def install ( self , project_name : str , falco_config : FalcoConfig ) -> Path : \n output_dir = self . output_dir or self . get_install_path ( project_name = project_name , falco_config = falco_config ) [ <NUM_LIT> ] \n output_dir . mkdir ( parents = True , exist_ok = True ) \n ( output_dir / \"<STR_LIT>\" ) . touch ( exist_ok = True ) \n generated_files = [ ] \n context = { \"<STR_LIT>\" : project_name } \n with simple_progress ( \"<STR_LIT>\" ) : \n for file_path in ( get_crud_blueprints_path ( ) / \"<STR_LIT>\" ) . iterdir ( ) : \n imports_template , code_template = extract_python_file_templates ( file_path . read_text ( ) ) \n filename = \"<STR_LIT>\" . join ( file_path . name . split ( \"<STR_LIT>\" ) [ : - <NUM_LIT> ] ) \n output_file = output_dir / filename \n output_file . touch ( exist_ok = True ) \n output_file . write_text ( \n render_to_string ( imports_template , context ) \n + render_to_string ( code_template , context ) \n + output_file . read_text ( ) \n ) \n generated_files . append ( output_file ) \n for file in generated_files : \n run_python_formatters ( str ( file ) ) \n return output_dir \n @ classmethod \n def get_install_path ( cls , project_name : str , falco_config : FalcoConfig ) -> tuple [ Path , bool ] : \n if _import_path := falco_config . get ( \"<STR_LIT>\" , { } ) . get ( \"<STR_LIT>\" ) : \n return Path ( _import_path ) , True \n return Path ( f\"<STR_LIT>\" ) , False"}, {"input": "import logging \n import frontmatter \n import yaml \n READMEIO_CONFIG_PATH = \"<STR_LIT>\" \n def load_yaml_file ( file_path : str ) : \n with open ( file_path ) as yaml_file : \n return yaml . load ( yaml_file , Loader = yaml . FullLoader ) \n def apply_metadata_to_markdown ( markdown_file_path : str , metadata : dict ) : \n try : \n post = frontmatter . load ( markdown_file_path ) \n post . metadata = metadata \n frontmatter . dump ( post , markdown_file_path ) \n except FileNotFoundError : \n logging . error ( f\"<STR_LIT>\" ) \n except Exception as e : \n logging . error ( f\"<STR_LIT>\" ) \n raise e \n def main ( ) : \n readmeio_config = load_yaml_file ( READMEIO_CONFIG_PATH )", "output": "for doc in readmeio_config [ \"<STR_LIT>\" ] : \n markdown_file_path = doc . pop ( \"<STR_LIT>\" ) \n apply_metadata_to_markdown ( markdown_file_path = markdown_file_path , metadata = doc ) \n if __name__ == \"<STR_LIT>\" : \n logging . basicConfig ( level = logging . INFO ) \n main ( )"}, {"input": "import django . contrib . auth . models \n import django . contrib . auth . validators \n from django . db import migrations , models \n import django . utils . timezone \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . DateTimeField ( \n blank = True , null = True , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . BooleanField ( \n default = False , \n help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n error_messages = { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } , \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n unique = True , \n validators = [ \n django . contrib . auth . validators . UnicodeUsernameValidator ( ) \n ] , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . EmailField ( \n blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . BooleanField ( \n default = False , \n help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n (", "output": "\"<STR_LIT>\" , \n models . BooleanField ( \n default = True , \n help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . DateTimeField ( \n default = django . utils . timezone . now , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ManyToManyField ( \n blank = True , \n help_text = \"<STR_LIT>\" , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ManyToManyField ( \n blank = True , \n help_text = \"<STR_LIT>\" , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : False , \n } , \n managers = [ \n ( \"<STR_LIT>\" , django . contrib . auth . models . UserManager ( ) ) , \n ] , \n ) , \n ]"}, {"input": "import os \n import time \n import argparse \n import random \n import torch \n import numpy as np \n from tensorboardX import SummaryWriter \n from utils import load_config , save_checkpoint , load_checkpoint \n from dataset import get_crohme_dataset \n from models . can import CAN \n from training import train , eval \n parser = argparse . ArgumentParser ( description = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , action = '<STR_LIT>' , help = '<STR_LIT>' ) \n args = parser . parse_args ( ) \n if not args . dataset : \n print ( '<STR_LIT>' ) \n exit ( - <NUM_LIT> ) \n if args . dataset == '<STR_LIT>' :", "output": "config_file = '<STR_LIT>' \n params = load_config ( config_file ) \n random . seed ( params [ '<STR_LIT>' ] ) \n np . random . seed ( params [ '<STR_LIT>' ] ) \n torch . manual_seed ( params [ '<STR_LIT>' ] ) \n torch . cuda . manual_seed ( params [ '<STR_LIT>' ] ) \n os . environ [ '<STR_LIT>' ] = '<STR_LIT>' \n device = torch . device ( '<STR_LIT>' if torch . cuda . is_available ( ) else '<STR_LIT>' ) \n params [ '<STR_LIT>' ] = device \n if args . dataset == '<STR_LIT>' : \n train_loader , eval_loader = get_crohme_dataset ( params ) \n model = CAN ( params ) \n now = time . strftime ( \"<STR_LIT>\" , time . localtime ( ) ) \n model . name = f'<STR_LIT>' \n print ( model . name ) \n model = model . to ( device ) \n if args . check : \n writer = None \n else : \n writer = SummaryWriter ( f'<STR_LIT>' ) \n optimizer = getattr ( torch . optim , params [ '<STR_LIT>' ] ) ( model . parameters ( ) , lr = float ( params [ '<STR_LIT>' ] ) , \n eps = float ( params [ '<STR_LIT>' ] ) , weight_decay = float ( params [ '<STR_LIT>' ] ) ) \n if params [ '<STR_LIT>' ] : \n print ( '<STR_LIT>' ) \n print ( f'<STR_LIT>' ) \n load_checkpoint ( model , optimizer , params [ '<STR_LIT>' ] ) \n if not args . check : \n if not os . path . exists ( os . path . join ( params [ '<STR_LIT>' ] , model . name ) ) : \n os . makedirs ( os . path . join ( params [ '<STR_LIT>' ] , model . name ) , exist_ok = True ) \n os . system ( f'<STR_LIT>' ) \n if args . dataset == '<STR_LIT>' : \n min_score , init_epoch = <NUM_LIT> , <NUM_LIT> \n for epoch in range ( init_epoch , params [ '<STR_LIT>' ] ) : \n train_loss , train_word_score , train_exprate = train ( params , model , optimizer , epoch , train_loader , writer = writer ) \n if epoch >= params [ '<STR_LIT>' ] : \n eval_loss , eval_word_score , eval_exprate = eval ( params , model , epoch , eval_loader , writer = writer ) \n print ( f'<STR_LIT>' ) \n if eval_exprate > min_score and not args . check and epoch >= params [ '<STR_LIT>' ] : \n min_score = eval_exprate \n save_checkpoint ( model , optimizer , eval_word_score , eval_exprate , epoch + <NUM_LIT> , \n optimizer_save = params [ '<STR_LIT>' ] , path = params [ '<STR_LIT>' ] )"}, {"input": "from datetime import timedelta \n from django . apps import apps \n from django . conf import settings \n from django . db import models \n from django . db . models . signals import ModelSignal , post_delete , post_save \n from django . forms import model_to_dict \n from django_webhook . models import Webhook \n from . tasks import fire_webhook \n from . util import cache \n CREATE = \"<STR_LIT>\" \n UPDATE = \"<STR_LIT>\" \n DELETE = \"<STR_LIT>\" \n class SignalListener : \n def __init__ ( self , signal : ModelSignal , signal_name : str , model_cls : models . Model ) : \n valid_signals = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n if signal_name not in valid_signals : \n raise ValueError ( f\"<STR_LIT>\" ) \n self . signal = signal \n self . signal_name = signal_name \n self . model_cls = model_cls \n def run ( self , sender , created = False , instance = None , ** kwargs ) :", "output": "action_type = None \n match self . signal_name : \n case \"<STR_LIT>\" if created : \n action_type = CREATE \n case \"<STR_LIT>\" : \n action_type = UPDATE \n case \"<STR_LIT>\" : \n action_type = DELETE \n topic = f\"<STR_LIT>\" \n webhook_ids = _find_webhooks ( topic ) \n for id , uuid in webhook_ids : \n payload = dict ( \n topic = topic , \n object = model_dict ( instance ) , \n object_type = self . model_label , \n webhook_uuid = str ( uuid ) , \n ) \n fire_webhook . delay ( id , payload ) \n def connect ( self ) : \n self . signal . connect ( \n self . run , sender = self . model_cls , weak = False , dispatch_uid = self . uid \n ) \n @ property \n def uid ( self ) : \n return f\"<STR_LIT>\" \n @ property \n def model_label ( self ) : \n return self . model_cls . _meta . label \n def connect_signals ( ) : \n for cls in _active_models ( ) : \n post_save_listener = SignalListener ( \n signal = post_save , signal_name = \"<STR_LIT>\" , model_cls = cls \n ) \n post_delete_listener = SignalListener ( \n signal = post_delete , signal_name = \"<STR_LIT>\" , model_cls = cls \n ) \n post_save_listener . connect ( ) \n post_delete_listener . connect ( ) \n def model_dict ( model ) : \n fields = { \n field . name : field . value_from_object ( model ) for field in model . _meta . fields \n } \n return model_to_dict ( model , fields = fields ) \n def _active_models ( ) : \n model_names = settings . DJANGO_WEBHOOK . get ( \"<STR_LIT>\" , [ ] ) \n model_classes = [ ] \n for name in model_names : \n parts = name . split ( \"<STR_LIT>\" ) \n if len ( parts ) != <NUM_LIT> : \n continue \n app_label , model_label = parts \n try : \n model_class = apps . get_model ( app_label , model_label ) \n except LookupError : \n continue \n model_classes . append ( model_class ) \n return model_classes \n def _find_webhooks ( topic : str ) : \n if settings . DJANGO_WEBHOOK [ \"<STR_LIT>\" ] : \n return _query_webhooks_cached ( topic ) \n return _query_webhooks ( topic ) \n @ cache ( ttl = timedelta ( minutes = <NUM_LIT> ) ) \n def _query_webhooks_cached ( topic : str ) : \n return _query_webhooks ( topic ) \n def _query_webhooks ( topic : str ) : \n return Webhook . objects . filter ( active = True , topics__name = topic ) . values_list ( \n \"<STR_LIT>\" , \"<STR_LIT>\" \n )"}, {"input": "import os \n import cv2 \n import argparse \n import numpy as np \n import torch \n import json \n import pickle as pkl \n from tqdm import tqdm \n import time \n from utils import load_config , load_checkpoint , compute_edit_distance \n from models . infer_model import Inference \n from dataset import Words \n from counting_utils import gen_counting_label \n parser = argparse . ArgumentParser ( description = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = '<STR_LIT>' , type = str , help = '<STR_LIT>' ) \n parser . add_argument ( '<STR_LIT>' , default = False ) \n args = parser . parse_args ( ) \n if not args . dataset : \n print ( '<STR_LIT>' ) \n exit ( - <NUM_LIT> ) \n if args . dataset == '<STR_LIT>' : \n config_file = '<STR_LIT>' \n params = load_config ( config_file ) \n os . environ [ '<STR_LIT>' ] = '<STR_LIT>' \n device = torch . device ( '<STR_LIT>' if torch . cuda . is_available ( ) else '<STR_LIT>' ) \n params [ '<STR_LIT>' ] = device \n words = Words ( args . word_path ) \n params [ '<STR_LIT>' ] = len ( words ) \n if '<STR_LIT>' not in params : \n params [ '<STR_LIT>' ] = False \n print ( params [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) \n model = Inference ( params , draw_map = args . draw_map ) \n model = model . to ( device ) \n load_checkpoint ( model , None , params [ '<STR_LIT>' ] ) \n model . eval ( ) \n with open ( args . image_path , '<STR_LIT>' ) as f : \n images = pkl . load ( f ) \n with open ( args . label_path ) as f : \n lines = f . readlines ( ) \n line_right = <NUM_LIT> \n e1 , e2 , e3 = <NUM_LIT> , <NUM_LIT> , <NUM_LIT> \n bad_case = { } \n model_time = <NUM_LIT> \n mae_sum , mse_sum = <NUM_LIT> , <NUM_LIT> \n with torch . no_grad ( ) : \n for line in tqdm ( lines ) : \n name , * labels = line . split ( ) \n name = name . split ( '<STR_LIT>' ) [ <NUM_LIT> ] if name . endswith ( '<STR_LIT>' ) else name \n input_labels = labels \n labels = '<STR_LIT>' . join ( labels ) \n img = images [ name ] \n print ( np . shape ( img ) ) \n img = torch . Tensor ( <NUM_LIT> - img ) / <NUM_LIT> \n img = img . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> )", "output": "img = img . to ( device ) \n a = time . time ( ) \n input_labels = words . encode ( input_labels ) \n input_labels = torch . LongTensor ( input_labels ) \n input_labels = input_labels . unsqueeze ( <NUM_LIT> ) . to ( device ) \n probs , _ , mae , mse = model ( img , input_labels , os . path . join ( params [ '<STR_LIT>' ] [ '<STR_LIT>' ] , name ) ) \n mae_sum += mae \n mse_sum += mse \n model_time += ( time . time ( ) - a ) \n prediction = words . decode ( probs ) \n if prediction == labels : \n line_right += <NUM_LIT> \n else : \n bad_case [ name ] = { \n '<STR_LIT>' : labels , \n '<STR_LIT>' : prediction \n } \n print ( name , prediction , labels ) \n distance = compute_edit_distance ( prediction , labels ) \n if distance <= <NUM_LIT> : \n e1 += <NUM_LIT> \n if distance <= <NUM_LIT> : \n e2 += <NUM_LIT> \n if distance <= <NUM_LIT> : \n e3 += <NUM_LIT> \n print ( f'<STR_LIT>' ) \n print ( f'<STR_LIT>' ) \n print ( f'<STR_LIT>' ) \n print ( f'<STR_LIT>' ) \n print ( f'<STR_LIT>' ) \n print ( f'<STR_LIT>' ) \n print ( f'<STR_LIT>' ) \n with open ( f'<STR_LIT>' , '<STR_LIT>' ) as f : \n json . dump ( bad_case , f , ensure_ascii = False )"}, {"input": "import http \n import json \n import logging \n from typing import Optional , get_args \n import django . db . models \n import django . http \n import django . test \n import ninja . pagination \n from ninja_crud . testing . core import ArgOrCallable , TestCaseType , ViewTestManager \n from ninja_crud . testing . core . components import Headers , PathParameters , QueryParameters \n from ninja_crud . testing . views import AbstractModelViewTest \n from ninja_crud . views import ListModelView \n logger = logging . getLogger ( __name__ ) \n class ListModelViewTest ( AbstractModelViewTest ) : \n model_view : ListModelView \n def __init__ ( \n self , \n path_parameters : Optional [ ArgOrCallable [ PathParameters , TestCaseType ] ] = None , \n query_parameters : Optional [ ArgOrCallable [ QueryParameters , TestCaseType ] ] = None , \n headers : Optional [ ArgOrCallable [ Headers , TestCaseType ] ] = None , \n ) -> None : \n super ( ) . __init__ ( model_view_class = ListModelView ) \n self . view_test_manager = ViewTestManager ( \n simulate_request = self . simulate_request , \n path_parameters = path_parameters , \n query_parameters = query_parameters , \n headers = headers , \n ) \n def on_successful_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) : \n content = json . loads ( response . content ) \n queryset = self . _get_queryset ( \n response = response , \n path_parameters = path_parameters , \n query_parameters = query_parameters , \n ) \n if self . model_view . pagination_class is None : \n self . model_viewset_test_case . assertIsInstance ( content , list ) \n self . model_viewset_test_case . assertEqual ( len ( content ) , queryset . count ( ) ) \n self . _validate_response_items ( items = content , queryset = queryset ) \n elif self . model_view . pagination_class == ninja . pagination . LimitOffsetPagination : \n self . model_viewset_test_case . assertIsInstance ( content , dict ) \n self . model_viewset_test_case . assertIn ( \"<STR_LIT>\" , content ) \n self . model_viewset_test_case . assertIsInstance ( content [ \"<STR_LIT>\" ] , int ) \n self . model_viewset_test_case . assertEqual ( \n content [ \"<STR_LIT>\" ] , \n queryset . count ( ) , \n ) \n limit = query_parameters . get ( \"<STR_LIT>\" , <NUM_LIT> ) \n offset = query_parameters . get ( \"<STR_LIT>\" , <NUM_LIT> ) \n self . model_viewset_test_case . assertIn ( \"<STR_LIT>\" , content ) \n self . model_viewset_test_case . assertIsInstance ( content [ \"<STR_LIT>\" ] , list ) \n self . model_viewset_test_case . assertEqual ( \n len ( content [ \"<STR_LIT>\" ] ) , \n queryset [ offset : offset + limit ] . count ( ) , \n ) \n self . _validate_response_items ( items = content [ \"<STR_LIT>\" ] , queryset = queryset ) \n else : \n logger . warning ( \n f\"<STR_LIT>\" \n ) \n def _get_queryset ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n ) -> django . db . models . QuerySet : \n path_parameters_schema = ( \n self . model_view . path_parameters ( ** path_parameters )", "output": "if self . model_view . path_parameters \n else None \n ) \n query_parameters_schema = ( \n self . model_view . query_parameters ( ** query_parameters ) \n if self . model_view . query_parameters \n else None \n ) \n return self . model_view . list_models ( \n getattr ( response , \"<STR_LIT>\" , None ) , \n path_parameters_schema , \n query_parameters_schema , \n ) \n def _validate_response_items ( \n self , items : list , queryset : django . db . models . QuerySet \n ) : \n for item in items : \n self . model_viewset_test_case . assertIsInstance ( item , dict ) \n model = queryset . get ( id = item [ \"<STR_LIT>\" ] ) \n response_body_class = get_args ( self . model_view . response_body ) [ <NUM_LIT> ] \n response_body = response_body_class . from_orm ( model ) \n self . model_viewset_test_case . assertDictEqual ( \n item , json . loads ( response_body . json ( ) ) \n ) \n def on_failed_request ( \n self , \n response : django . http . HttpResponse , \n path_parameters : dict , \n query_parameters : dict , \n headers : dict , \n payload : dict , \n ) : \n pass \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_list_models_ok ( self ) : \n self . view_test_manager . test_view_ok ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_successful_request , \n status = http . HTTPStatus . OK , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_list_models_query_parameters_bad_request ( self ) : \n self . view_test_manager . test_view_query_parameters_bad_request ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_list_models_headers_unauthorized ( self ) : \n self . view_test_manager . test_view_headers_unauthorized ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_list_models_headers_forbidden ( self ) : \n self . view_test_manager . test_view_headers_forbidden ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n ) \n @ django . test . tag ( \"<STR_LIT>\" ) \n def test_list_models_path_parameters_not_found ( self ) : \n self . view_test_manager . test_view_path_parameters_not_found ( \n test_case = self . model_viewset_test_case , \n on_completion = self . on_failed_request , \n )"}, {"input": "from django . db import DataError \n from rest_framework . exceptions import APIException \n from rest_framework . validators import UniqueValidator \n class CustomValidationError ( APIException ) : \n def __init__ ( self , detail ) : \n self . detail = detail \n def qs_exists ( queryset ) : \n try : \n return queryset . exists ( ) \n except ( TypeError , ValueError , DataError ) : \n return False \n def qs_filter ( queryset , ** kwargs ) : \n try : \n return queryset . filter ( ** kwargs ) \n except ( TypeError , ValueError , DataError ) : \n return queryset . none ( ) \n class CustomUniqueValidator ( UniqueValidator ) : \n def filter_queryset ( self , value , queryset , field_name ) : \n filter_kwargs = { '<STR_LIT>' % ( field_name , self . lookup ) : value } \n return qs_filter ( queryset , ** filter_kwargs ) \n def exclude_current_instance ( self , queryset , instance ) : \n if instance is not None : \n return queryset . exclude ( pk = instance . pk ) \n return queryset \n def __call__ ( self , value , serializer_field ) :", "output": "field_name = serializer_field . source_attrs [ - <NUM_LIT> ] \n instance = getattr ( serializer_field . parent , '<STR_LIT>' , None ) \n queryset = self . queryset \n queryset = self . filter_queryset ( value , queryset , field_name ) \n queryset = self . exclude_current_instance ( queryset , instance ) \n if qs_exists ( queryset ) : \n raise CustomValidationError ( self . message ) \n def __repr__ ( self ) : \n return super ( ) . __repr__ ( )"}, {"input": "from importlib import import_module \n from django . apps import apps \n from django . db import models \n from django . conf import settings \n from application import settings \n table_prefix = settings . TABLE_PREFIX \n class SoftDeleteQuerySet ( models . QuerySet ) : \n pass \n class SoftDeleteManager ( models . Manager ) : \n def __init__ ( self , * args , ** kwargs ) : \n self . __add_is_del_filter = False \n super ( SoftDeleteManager , self ) . __init__ ( * args , ** kwargs ) \n def filter ( self , * args , ** kwargs ) : \n if not kwargs . get ( '<STR_LIT>' ) is None : \n self . __add_is_del_filter = True \n return super ( SoftDeleteManager , self ) . filter ( * args , ** kwargs ) \n def get_queryset ( self ) : \n if self . __add_is_del_filter : \n return SoftDeleteQuerySet ( self . model , using = self . _db ) . exclude ( is_deleted = False ) \n return SoftDeleteQuerySet ( self . model ) . exclude ( is_deleted = True ) \n def get_by_natural_key ( self , name ) : \n return SoftDeleteQuerySet ( self . model ) . get ( username = name ) \n class SoftDeleteModel ( models . Model ) : \n is_deleted = models . BooleanField ( verbose_name = \"<STR_LIT>\" , help_text = '<STR_LIT>' , default = False , db_index = True ) \n objects = SoftDeleteManager ( ) \n class Meta : \n abstract = True \n verbose_name = '<STR_LIT>' \n verbose_name_plural = verbose_name \n def delete ( self , using = None , soft_delete = True , * args , ** kwargs ) : \n self . is_deleted = True \n self . save ( using = using ) \n class CoreModel ( models . Model ) : \n id = models . BigAutoField ( primary_key = True , help_text = \"<STR_LIT>\" , verbose_name = \"<STR_LIT>\" ) \n description = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" , null = True , blank = True , help_text = \"<STR_LIT>\" ) \n creator = models . ForeignKey ( to = settings . AUTH_USER_MODEL , related_query_name = '<STR_LIT>' , null = True , \n verbose_name = '<STR_LIT>' , help_text = \"<STR_LIT>\" , on_delete = models . SET_NULL , \n db_constraint = False ) \n modifier = models . CharField ( max_length = <NUM_LIT> , null = True , blank = True , help_text = \"<STR_LIT>\" , verbose_name = \"<STR_LIT>\" ) \n dept_belong_id = models . CharField ( max_length = <NUM_LIT> , help_text = \"<STR_LIT>\" , null = True , blank = True , \n verbose_name = \"<STR_LIT>\" ) \n update_datetime = models . DateTimeField ( auto_now = True , null = True , blank = True , help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" ) \n create_datetime = models . DateTimeField ( auto_now_add = True , null = True , blank = True , help_text = \"<STR_LIT>\" , \n verbose_name = \"<STR_LIT>\" ) \n class Meta : \n abstract = True \n verbose_name = '<STR_LIT>' \n verbose_name_plural = verbose_name \n def get_all_models_objects ( model_name = None ) : \n settings . ALL_MODELS_OBJECTS = { } \n if not settings . ALL_MODELS_OBJECTS :", "output": "all_models = apps . get_models ( ) \n for item in list ( all_models ) : \n table = { \n \"<STR_LIT>\" : item . _meta . verbose_name , \n \"<STR_LIT>\" : item . __name__ , \n \"<STR_LIT>\" : [ ] \n } \n for field in item . _meta . fields : \n fields = { \n \"<STR_LIT>\" : field . verbose_name , \n \"<STR_LIT>\" : field . name \n } \n table [ '<STR_LIT>' ] . append ( fields ) \n settings . ALL_MODELS_OBJECTS . setdefault ( item . __name__ , { \"<STR_LIT>\" : table , \"<STR_LIT>\" : item } ) \n if model_name : \n return settings . ALL_MODELS_OBJECTS [ model_name ] or { } \n return settings . ALL_MODELS_OBJECTS or { } \n def get_model_from_app ( app_name ) : \n model_module = import_module ( app_name + '<STR_LIT>' ) \n filter_model = [ \n getattr ( model_module , item ) for item in dir ( model_module ) \n if item != '<STR_LIT>' and issubclass ( getattr ( model_module , item ) . __class__ , models . base . ModelBase ) \n ] \n model_list = [ ] \n for model in filter_model : \n if model . __name__ == '<STR_LIT>' : \n continue \n fields = [ \n { '<STR_LIT>' : field . verbose_name , '<STR_LIT>' : field . name , '<STR_LIT>' : field } \n for field in model . _meta . fields \n ] \n model_list . append ( { \n '<STR_LIT>' : app_name , \n '<STR_LIT>' : model . _meta . verbose_name , \n '<STR_LIT>' : model . __name__ , \n '<STR_LIT>' : model , \n '<STR_LIT>' : fields \n } ) \n return model_list \n def get_custom_app_models ( app_name = None ) : \n if app_name : \n return get_model_from_app ( app_name ) \n all_apps = apps . get_app_configs ( ) \n res = [ ] \n for app in all_apps : \n if app . name . startswith ( '<STR_LIT>' ) : \n continue \n if app . name in settings . COLUMN_EXCLUDE_APPS : \n continue \n try : \n all_models = get_model_from_app ( app . name ) \n if all_models : \n for model in all_models : \n res . append ( model ) \n except Exception as e : \n pass \n return res"}, {"input": "import os \n import dj_database_url \n PROJECT_DIR = os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) \n BASE_DIR = os . path . dirname ( PROJECT_DIR ) \n SECRET_KEY = \"<STR_LIT>\" \n DEBUG = True \n ALLOWED_HOSTS = [ \"<STR_LIT>\" ] \n INSTALLED_APPS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n MIDDLEWARE = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n ROOT_URLCONF = \"<STR_LIT>\" \n TEMPLATES = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ ] , \n \"<STR_LIT>\" : True , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n } , \n } \n ] \n CACHES = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n } \n PASSWORD_HASHERS = ( \"<STR_LIT>\" , ) \n DATABASES = { \n \"<STR_LIT>\" : dj_database_url . config ( default = \"<STR_LIT>\" ) , \n } \n AUTH_PASSWORD_VALIDATORS = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ] \n LANGUAGE_CODE = \"<STR_LIT>\"", "output": "TIME_ZONE = \"<STR_LIT>\" \n USE_I18N = True \n USE_TZ = True \n STATICFILES_FINDERS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n STATICFILES_DIRS = [ ] \n STATIC_ROOT = os . path . join ( BASE_DIR , \"<STR_LIT>\" ) \n STATIC_URL = \"<STR_LIT>\" \n MEDIA_ROOT = os . path . join ( BASE_DIR , \"<STR_LIT>\" ) \n WAGTAIL_SITE_NAME = \"<STR_LIT>\" \n if os . environ . get ( \"<STR_LIT>\" ) == \"<STR_LIT>\" : \n WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } , \n } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n else : \n WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } , \n } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n WAGTAILIMAGES_IMAGE_FORM_BASE = \"<STR_LIT>\" \n LOGGING = { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : False , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : False , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : False , \n } , \n } , \n } \n FORMS_URLFIELD_ASSUME_HTTPS = True"}, {"input": "import pytest \n from django . contrib . auth . models import Permission \n from dev . football . players . factories import PlayerFactory \n from dev . football . stadiums . factories import StadiumFactory \n from dev . football . teams . factories import TeamFactory \n from tests import request_search \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , \n [ ( False , False , <NUM_LIT> ) , ( False , True , <NUM_LIT> ) , ( True , False , <NUM_LIT> ) , ( True , True , <NUM_LIT> ) ] , \n ) \n def test_authenticated ( \n client_standard , user_standard , is_staff , is_superuser , status_code \n ) : \n user_standard . is_staff = is_staff \n user_standard . is_superuser = is_superuser \n user_standard . save ( ) \n response = request_search ( client_standard ) \n assert response . status_code == status_code \n def test_unauthenticated ( client_admin ) : \n client_admin . logout ( ) \n response = request_search ( client_admin ) \n assert response . status_code == <NUM_LIT> \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , \n [ \n ( [ \"<STR_LIT>\" ] , False ) ,", "output": "( [ \"<STR_LIT>\" ] , False ) , \n ( [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , False ) , \n ( [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , True ) , \n ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , True ) , \n ] , \n ) \n def test_permission_can_view ( client_admin , user_admin , permissions , can_add ) : \n obj = TeamFactory ( name = \"<STR_LIT>\" ) \n permission_ids = Permission . objects . filter ( codename__in = permissions ) . values_list ( \n \"<STR_LIT>\" , flat = True \n ) \n user_admin . user_permissions . add ( * permission_ids ) \n response = request_search ( client_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert len ( data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] == \"<STR_LIT>\" \n assert len ( data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] == \"<STR_LIT>\" \n assert ( data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] is not None ) is can_add \n assert len ( data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] == str ( obj . id ) \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , [ [ ] , [ \"<STR_LIT>\" ] , [ \"<STR_LIT>\" ] , [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ] \n ) \n def test_permission_cannot_view ( client_admin , user_admin , permissions ) : \n TeamFactory ( name = \"<STR_LIT>\" ) \n permission_ids = Permission . objects . filter ( codename__in = permissions ) . values_list ( \n \"<STR_LIT>\" , flat = True \n ) \n user_admin . user_permissions . add ( * permission_ids ) \n response = request_search ( client_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert len ( data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n @ pytest . mark . parametrize ( \"<STR_LIT>\" , [ PlayerFactory , StadiumFactory ] ) \n def test_permission_can_view_other ( client_admin , user_admin , factory ) : \n factory ( name = \"<STR_LIT>\" ) \n permissions = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n permission_ids = Permission . objects . filter ( codename__in = permissions ) . values_list ( \n \"<STR_LIT>\" , flat = True \n ) \n user_admin . user_permissions . add ( * permission_ids ) \n response = request_search ( client_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert response . status_code == <NUM_LIT> \n assert len ( data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> } \n def test_admin_not_registered ( client_super_admin ) : \n objects = Permission . objects . filter ( codename__startswith = \"<STR_LIT>\" ) \n response = request_search ( client_super_admin , query = \"<STR_LIT>\" ) \n data = response . json ( ) \n assert len ( objects ) > <NUM_LIT> \n assert response . status_code == <NUM_LIT> \n assert len ( data [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] ) == <NUM_LIT> \n assert data [ \"<STR_LIT>\" ] == { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : <NUM_LIT> }"}, {"input": "from unittest . mock import MagicMock \n from django . test import TestCase \n from ninja_crud import views , viewsets \n from tests . test_app . models import Item \n class TestDeleteModelView ( TestCase ) : \n def test_register_route_router_kwargs ( self ) : \n router_mock = MagicMock ( )", "output": "class ItemViewSet ( viewsets . ModelViewSet ) : \n model = Item \n delete_item = views . DeleteModelView ( router_kwargs = { \"<STR_LIT>\" : True } ) \n ItemViewSet . delete_item . register_route ( router_mock , \"<STR_LIT>\" ) \n router_mock . api_operation . assert_called_once ( ) \n self . assertTrue ( router_mock . api_operation . call_args [ <NUM_LIT> ] [ \"<STR_LIT>\" ] )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) ,", "output": "migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( blank = True , max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( max_length = <NUM_LIT> , verbose_name = \"<STR_LIT>\" ) , \n ) , \n ]"}, {"input": "import os \n from datetime import timedelta \n import dj_database_url \n from pathlib import Path \n from dotenv import load_dotenv \n load_dotenv ( ) \n BASE_DIR = Path ( __file__ ) . resolve ( ) . parent . parent \n SECRET_KEY = '<STR_LIT>' \n DEBUG = os . getenv ( '<STR_LIT>' , False ) == '<STR_LIT>' \n ALLOWED_HOSTS = [ '<STR_LIT>' ] \n app_domains = os . getenv ( '<STR_LIT>' , '<STR_LIT>' ) . split ( '<STR_LIT>' ) \n CSRF_TRUSTED_ORIGINS = [ ] \n for app_domain in app_domains : \n CSRF_TRUSTED_ORIGINS . append ( '<STR_LIT>' + app_domain ) \n CSRF_TRUSTED_ORIGINS . append ( '<STR_LIT>' + app_domain ) \n INSTALLED_APPS = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' \n ] \n MIDDLEWARE = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n ROOT_URLCONF = '<STR_LIT>' \n TEMPLATES = [ \n { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : [ ] , \n '<STR_LIT>' : True , \n '<STR_LIT>' : { \n '<STR_LIT>' : [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] , \n } , \n } , \n ]", "output": "WSGI_APPLICATION = '<STR_LIT>' \n db_config = dj_database_url . config ( '<STR_LIT>' , '<STR_LIT>' ) \n if db_config . get ( '<STR_LIT>' ) == '<STR_LIT>' : \n db_config [ '<STR_LIT>' ] = { '<STR_LIT>' : '<STR_LIT>' } \n DATABASES = { \n '<STR_LIT>' : db_config \n } \n AUTH_PASSWORD_VALIDATORS = [ \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n ] \n LANGUAGE_CODE = '<STR_LIT>' \n TIME_ZONE = '<STR_LIT>' \n USE_I18N = True \n USE_TZ = True \n STATIC_URL = '<STR_LIT>' \n STATIC_ROOT = os . path . join ( BASE_DIR , STATIC_URL ) \n DEFAULT_AUTO_FIELD = '<STR_LIT>' \n REST_FRAMEWORK = { \n '<STR_LIT>' : [ \n '<STR_LIT>' \n ] \n } \n SITE_ID = <NUM_LIT> \n REST_AUTH = { \n '<STR_LIT>' : True , \n '<STR_LIT>' : None , \n '<STR_LIT>' : False , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : True , \n '<STR_LIT>' : '<STR_LIT>' \n } \n SIMPLE_JWT = { \n \"<STR_LIT>\" : timedelta ( days = <NUM_LIT> ) , \n } \n ACCOUNT_ADAPTER = '<STR_LIT>' \n ACCOUNT_EMAIL_VERIFICATION = os . getenv ( '<STR_LIT>' , '<STR_LIT>' ) \n EMAIL_BACKEND = os . getenv ( '<STR_LIT>' , '<STR_LIT>' ) \n EMAIL_HOST = os . getenv ( '<STR_LIT>' , '<STR_LIT>' ) \n EMAIL_PORT = os . getenv ( '<STR_LIT>' , <NUM_LIT> ) \n EMAIL_HOST_USER = os . getenv ( '<STR_LIT>' , '<STR_LIT>' ) \n EMAIL_HOST_PASSWORD = os . getenv ( '<STR_LIT>' , '<STR_LIT>' ) \n EMAIL_USE_TLS = os . getenv ( '<STR_LIT>' , True ) == '<STR_LIT>' \n EMAIL_USE_SSL = os . getenv ( '<STR_LIT>' , False ) == '<STR_LIT>' \n DEFAULT_FROM_EMAIL = os . getenv ( '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "import os \n import sys \n from pathlib import Path \n from datetime import timedelta \n BASE_DIR = Path ( __file__ ) . resolve ( ) . parent . parent \n from conf . env import * \n SECRET_KEY = \"<STR_LIT>\" \n PLUGINS_PATH = os . path . join ( BASE_DIR , \"<STR_LIT>\" ) \n sys . path . insert ( <NUM_LIT> , os . path . join ( PLUGINS_PATH ) ) \n [ \n sys . path . insert ( <NUM_LIT> , os . path . join ( PLUGINS_PATH , ele ) ) \n for ele in os . listdir ( PLUGINS_PATH ) \n if os . path . isdir ( os . path . join ( PLUGINS_PATH , ele ) ) and not ele . startswith ( \"<STR_LIT>\" ) \n ] \n DEBUG = locals ( ) . get ( \"<STR_LIT>\" , True ) \n ALLOWED_HOSTS = locals ( ) . get ( \"<STR_LIT>\" , [ \"<STR_LIT>\" ] ) \n COLUMN_EXCLUDE_APPS = [ '<STR_LIT>' , '<STR_LIT>' ] + locals ( ) . get ( \"<STR_LIT>\" , [ ] ) \n INSTALLED_APPS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n MIDDLEWARE = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n ROOT_URLCONF = \"<STR_LIT>\" \n TEMPLATES = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ os . path . join ( BASE_DIR , \"<STR_LIT>\" ) ] , \n \"<STR_LIT>\" : True , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n } , \n } , \n ] \n WSGI_APPLICATION = \"<STR_LIT>\" \n DATABASES = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : DATABASE_ENGINE , \n \"<STR_LIT>\" : DATABASE_NAME , \n \"<STR_LIT>\" : DATABASE_USER , \n \"<STR_LIT>\" : DATABASE_PASSWORD , \n \"<STR_LIT>\" : DATABASE_HOST , \n \"<STR_LIT>\" : DATABASE_PORT , \n } \n } \n AUTH_USER_MODEL = \"<STR_LIT>\" \n USERNAME_FIELD = \"<STR_LIT>\" \n AUTH_PASSWORD_VALIDATORS = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ] \n LANGUAGE_CODE = \"<STR_LIT>\" \n TIME_ZONE = \"<STR_LIT>\" \n USE_I18N = True \n USE_L10N = True \n USE_TZ = False \n STATIC_URL = \"<STR_LIT>\" \n STATICFILES_DIRS = [ \n os . path . join ( BASE_DIR , \"<STR_LIT>\" ) , \n ] \n MEDIA_ROOT = \"<STR_LIT>\" \n MEDIA_URL = \"<STR_LIT>\" \n STATICFILES_FINDERS = ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" \n ) \n CORS_ORIGIN_ALLOW_ALL = True \n CORS_ALLOW_CREDENTIALS = True \n ASGI_APPLICATION = '<STR_LIT>' \n CHANNEL_LAYERS = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n } \n SERVER_LOGS_FILE = os . path . join ( BASE_DIR , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n ERROR_LOGS_FILE = os . path . join ( BASE_DIR , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n LOGS_FILE = os . path . join ( BASE_DIR , \"<STR_LIT>\" ) \n if not os . path . exists ( os . path . join ( BASE_DIR , \"<STR_LIT>\" ) ) : \n os . makedirs ( os . path . join ( BASE_DIR , \"<STR_LIT>\" ) ) \n STANDARD_LOG_FORMAT = ( \n \"<STR_LIT>\" \n ) \n CONSOLE_LOG_FORMAT = ( \n \"<STR_LIT>\" \n ) \n LOGGING = { \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \"<STR_LIT>\" : STANDARD_LOG_FORMAT } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : CONSOLE_LOG_FORMAT , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : CONSOLE_LOG_FORMAT , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : SERVER_LOGS_FILE , \n \"<STR_LIT>\" : <NUM_LIT> * <NUM_LIT> * <NUM_LIT> , \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ERROR_LOGS_FILE , \n \"<STR_LIT>\" : <NUM_LIT> * <NUM_LIT> * <NUM_LIT> , \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : False , \n } , \n '<STR_LIT>' : { \n '<STR_LIT>' : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n '<STR_LIT>' : False , \n '<STR_LIT>' : \"<STR_LIT>\" \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n } , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } , \n } , \n } \n REST_FRAMEWORK = { \n '<STR_LIT>' : ( \n '<STR_LIT>' , \n '<STR_LIT>' , \n ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ) , \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n ] , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n AUTHENTICATION_BACKENDS = [ \"<STR_LIT>\" ] \n SIMPLE_JWT = { \n \"<STR_LIT>\" : timedelta ( minutes = <NUM_LIT> ) , \n \"<STR_LIT>\" : timedelta ( days = <NUM_LIT> ) , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , ) , \n \"<STR_LIT>\" : True , \n } \n SWAGGER_SETTINGS = { \n \"<STR_LIT>\" : { \"<STR_LIT>\" : { \"<STR_LIT>\" : \"<STR_LIT>\" } } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : True , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : None , \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n CAPTCHA_IMAGE_SIZE = ( <NUM_LIT> , <NUM_LIT> ) \n CAPTCHA_LENGTH = <NUM_LIT> \n CAPTCHA_TIMEOUT = <NUM_LIT> \n CAPTCHA_OUTPUT_FORMAT = \"<STR_LIT>\" \n CAPTCHA_FONT_SIZE = <NUM_LIT> \n CAPTCHA_FOREGROUND_COLOR = \"<STR_LIT>\" \n CAPTCHA_BACKGROUND_COLOR = \"<STR_LIT>\" \n CAPTCHA_NOISE_FUNCTIONS = ( \n \"<STR_LIT>\" , \n ) \n CAPTCHA_CHALLENGE_FUNCT = \"<STR_LIT>\" \n DEFAULT_AUTO_FIELD = \"<STR_LIT>\" \n API_LOG_ENABLE = True \n API_LOG_METHODS = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n API_MODEL_MAP = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n DJANGO_CELERY_BEAT_TZ_AWARE = False \n CELERY_TIMEZONE = \"<STR_LIT>\" \n STATICFILES_STORAGE = \"<STR_LIT>\" \n ALL_MODELS_OBJECTS = [ ] \n INITIALIZE_LIST = [ ] \n INITIALIZE_RESET_LIST = [ ] \n TABLE_PREFIX = locals ( ) . get ( '<STR_LIT>' , \"<STR_LIT>\" ) \n SYSTEM_CONFIG = { } \n DICTIONARY_CONFIG = { } \n TENANT_SHARED_APPS = [ ] \n PLUGINS_URL_PATTERNS = [ ]"}, {"input": "from django . urls import path \n from index import views \n urlpatterns = [ \n path ( '<STR_LIT>' , views . login ) , \n path ( '<STR_LIT>' , views . register ) , \n path ( '<STR_LIT>' , views . paper_image_upload ) , \n path ( '<STR_LIT>' , views . student_image_upload ) , \n path ( '<STR_LIT>' , views . addPaper ) , \n path ( '<STR_LIT>' , views . removePaper ) , \n path ( '<STR_LIT>' , views . setPaperName ) ,", "output": "path ( '<STR_LIT>' , views . ans_set ) , \n path ( '<STR_LIT>' , views . showPapersForTeacher ) , \n path ( '<STR_LIT>' , views . showPaperForStudent ) , \n path ( '<STR_LIT>' , views . showPaperDetail ) , \n path ( '<STR_LIT>' , views . showPaperAnsDetail ) , \n path ( '<STR_LIT>' , views . deletePaperAnsPhoto ) , \n path ( '<STR_LIT>' , views . getScore ) \n ]"}, {"input": "from scipy . stats import pearsonr \n import numpy as np \n def confusion_matrix ( rater_a , rater_b , min_rating = None , max_rating = None ) : \n assert ( len ( rater_a ) == len ( rater_b ) ) \n if min_rating is None : \n min_rating = min ( rater_a + rater_b ) \n if max_rating is None : \n max_rating = max ( rater_a + rater_b ) \n num_ratings = int ( max_rating - min_rating + <NUM_LIT> ) \n conf_mat = [ [ <NUM_LIT> for i in range ( num_ratings ) ] \n for j in range ( num_ratings ) ] \n for a , b in zip ( rater_a , rater_b ) : \n conf_mat [ a - min_rating ] [ b - min_rating ] += <NUM_LIT> \n return conf_mat \n def histogram ( ratings , min_rating = None , max_rating = None ) : \n if min_rating is None : \n min_rating = min ( ratings ) \n if max_rating is None : \n max_rating = max ( ratings ) \n num_ratings = int ( max_rating - min_rating + <NUM_LIT> ) \n hist_ratings = [ <NUM_LIT> for x in range ( num_ratings ) ] \n for r in ratings : \n hist_ratings [ r - min_rating ] += <NUM_LIT> \n return hist_ratings \n def quadratic_weighted_kappa ( rater_a , rater_b , min_rating = None , max_rating = None ) : \n rater_a = np . array ( rater_a , dtype = int )", "output": "rater_b = np . array ( rater_b , dtype = int ) \n assert ( len ( rater_a ) == len ( rater_b ) ) \n if min_rating is None : \n min_rating = min ( min ( rater_a ) , min ( rater_b ) ) \n if max_rating is None : \n max_rating = max ( max ( rater_a ) , max ( rater_b ) ) \n conf_mat = confusion_matrix ( rater_a , rater_b , \n min_rating , max_rating ) \n num_ratings = len ( conf_mat ) \n num_scored_items = float ( len ( rater_a ) ) \n hist_rater_a = histogram ( rater_a , min_rating , max_rating ) \n hist_rater_b = histogram ( rater_b , min_rating , max_rating ) \n numerator = <NUM_LIT> \n denominator = <NUM_LIT> \n for i in range ( num_ratings ) : \n for j in range ( num_ratings ) : \n expected_count = ( hist_rater_a [ i ] * hist_rater_b [ j ] / num_scored_items ) \n if num_ratings == <NUM_LIT> : \n num_ratings += <NUM_LIT> \n d = pow ( i - j , <NUM_LIT> ) / pow ( num_ratings - <NUM_LIT> , <NUM_LIT> ) \n numerator += d * conf_mat [ i ] [ j ] / num_scored_items \n denominator += d * expected_count / num_scored_items \n if denominator <= <NUM_LIT> : \n denominator = <NUM_LIT> \n return <NUM_LIT> - numerator / denominator \n def evaluation ( true_label , pre_label , high_score = <NUM_LIT> , second_high_score = <NUM_LIT> , low_score = <NUM_LIT> , second_low_score = <NUM_LIT> ) : \n assert len ( pre_label ) == len ( true_label ) \n res = [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] \n for i in range ( len ( pre_label ) ) : \n if pre_label [ i ] is None : \n pre_label [ i ] = <NUM_LIT> \n index = int ( abs ( pre_label [ i ] - true_label [ i ] ) / <NUM_LIT> ) \n if index <= <NUM_LIT> : \n res [ index ] += <NUM_LIT> \n else : \n res [ <NUM_LIT> ] += <NUM_LIT> \n total_score = sum ( res ) \n result = [ float ( item ) / total_score for item in res ] \n result . append ( result [ <NUM_LIT> ] + result [ <NUM_LIT> ] ) \n result . append ( result [ <NUM_LIT> ] + result [ <NUM_LIT> ] + result [ <NUM_LIT> ] ) \n result . append ( pearsonr ( true_label , pre_label ) [ <NUM_LIT> ] ) \n result . append ( quadratic_weighted_kappa ( true_label , pre_label ) ) \n high_score_recall , high_score_precision , f1 = evaluation_high_score ( true_label , pre_label , high_score ) \n result . append ( high_score_recall ) \n result . append ( high_score_precision ) \n result . append ( f1 ) \n second_high_score_recall , second_high_score_precision , f1 = evaluation_high_score ( true_label , pre_label , \n second_high_score ) \n result . append ( second_high_score_recall ) \n result . append ( second_high_score_precision ) \n result . append ( f1 ) \n second_low_score_recall , second_low_score_precision , f1 = evaluation_low_score ( true_label , pre_label , second_low_score ) \n result . append ( second_low_score_recall ) \n result . append ( second_low_score_precision ) \n result . append ( f1 ) \n low_score_recall , low_score_precision , f1 = evaluation_low_score ( true_label , pre_label , low_score ) \n result . append ( low_score_recall ) \n result . append ( low_score_precision ) \n result . append ( f1 ) \n result = [ str ( round ( item , <NUM_LIT> ) ) for item in result ] \n return result \n def f1 ( precision , recall , weight = <NUM_LIT> ) : \n if precision == <NUM_LIT> or recall == <NUM_LIT> : \n return <NUM_LIT> \n return ( weight * weight + <NUM_LIT> ) * precision * recall / ( weight * weight * precision + recall ) \n def evaluation_high_score ( true_score , pre_score , high_score ) : \n assert len ( pre_score ) == len ( true_score ) \n true_high_score_num = <NUM_LIT> \n pred_high_score_num = <NUM_LIT> \n both_high_score_num = <NUM_LIT> \n qualified_num = <NUM_LIT> \n smooth_value = <NUM_LIT> \n for i in range ( len ( pre_score ) ) : \n if true_score [ i ] >= high_score : \n true_high_score_num += <NUM_LIT> \n if pre_score [ i ] >= high_score : \n pred_high_score_num += <NUM_LIT> \n if pre_score [ i ] >= high_score and true_score [ i ] >= high_score : \n both_high_score_num += <NUM_LIT> \n if pre_score [ i ] >= high_score and abs ( pre_score [ i ] - true_score [ i ] ) <= <NUM_LIT> : \n qualified_num += <NUM_LIT> \n high_score_recall = both_high_score_num / ( true_high_score_num + smooth_value ) \n high_score_precision = qualified_num / ( pred_high_score_num + smooth_value ) \n high_score_f1 = f1 ( high_score_precision , high_score_recall ) \n return high_score_recall , high_score_precision , high_score_f1 \n def evaluation_low_score ( true_score , pre_score , low_score ) : \n assert len ( pre_score ) == len ( true_score ) \n true_low_score_num = <NUM_LIT> \n pred_low_score_num = <NUM_LIT> \n both_low_score_num = <NUM_LIT> \n qualified_num = <NUM_LIT> \n smooth_value = <NUM_LIT> \n for i in range ( len ( pre_score ) ) : \n if true_score [ i ] <= low_score : \n true_low_score_num += <NUM_LIT> \n if pre_score [ i ] <= low_score : \n pred_low_score_num += <NUM_LIT> \n if pre_score [ i ] <= low_score and true_score [ i ] <= low_score : \n both_low_score_num += <NUM_LIT> \n if pre_score [ i ] <= low_score and abs ( pre_score [ i ] - true_score [ i ] ) <= <NUM_LIT> : \n qualified_num += <NUM_LIT> \n low_score_recall = both_low_score_num / ( true_low_score_num + smooth_value ) \n low_score_precision = qualified_num / ( pred_low_score_num + smooth_value ) \n low_score_f1 = f1 ( low_score_precision , low_score_recall ) \n return low_score_recall , low_score_precision , low_score_f1"}, {"input": "import argparse \n import json \n from django . core . management . base import BaseCommand , CommandParser \n from django . utils . module_loading import import_string \n from wagtail . models import Page \n class Command ( BaseCommand ) : \n def add_arguments ( self , parser : CommandParser ) -> None : \n parser . add_argument ( \"<STR_LIT>\" , nargs = <NUM_LIT> , type = argparse . FileType ( \"<STR_LIT>\" ) ) \n parser . add_argument ( \"<STR_LIT>\" , nargs = <NUM_LIT> , type = str ) \n parser . add_argument ( \"<STR_LIT>\" , nargs = <NUM_LIT> , type = int ) \n def handle ( self , * args , ** options ) :", "output": "file = options [ \"<STR_LIT>\" ] [ <NUM_LIT> ] \n model = import_string ( options [ \"<STR_LIT>\" ] [ <NUM_LIT> ] ) \n parent_page = Page . objects . get ( pk = options [ \"<STR_LIT>\" ] [ <NUM_LIT> ] ) \n sources = json . load ( file ) \n for item in sources : \n imported = model ( title = item [ \"<STR_LIT>\" ] , body = item [ \"<STR_LIT>\" ] ) \n parent_page . add_child ( instance = imported )"}, {"input": "from typing import Dict , List , Union \n def ensure_list_of_dicts ( data : Union [ Dict , List [ Dict ] ] ) -> List [ Dict ] : \n if isinstance ( data , dict ) : \n return [ data ] \n elif not isinstance ( data , list ) : \n raise TypeError ( \n f\"<STR_LIT>\" \n ) \n elif len ( data ) == <NUM_LIT> : \n raise ValueError ( \n \"<STR_LIT>\" \n )", "output": "return data"}, {"input": "import uuid \n from django . conf import settings \n from django . db import models \n class Collection ( models . Model ) : \n id = models . UUIDField ( primary_key = True , default = uuid . uuid4 , editable = False ) \n name = models . CharField ( max_length = <NUM_LIT> , unique = True ) \n description = models . TextField ( null = True , blank = True ) \n created_by = models . ForeignKey ( settings . AUTH_USER_MODEL , on_delete = models . CASCADE ) \n created_at = models . DateTimeField ( auto_now_add = True ) \n updated_at = models . DateTimeField ( auto_now = True )", "output": "class Item ( models . Model ) : \n id = models . UUIDField ( primary_key = True , default = uuid . uuid4 , editable = False ) \n name = models . CharField ( max_length = <NUM_LIT> , unique = True ) \n description = models . TextField ( null = True , blank = True ) \n collection = models . ForeignKey ( Collection , on_delete = models . CASCADE ) \n class Meta : \n constraints = [ \n models . UniqueConstraint ( \n fields = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n name = \"<STR_LIT>\" , \n ) , \n ] \n class Tag ( models . Model ) : \n id = models . UUIDField ( primary_key = True , default = uuid . uuid4 , editable = False ) \n name = models . CharField ( max_length = <NUM_LIT> , unique = True ) \n description = models . TextField ( null = True , blank = True ) \n items = models . ManyToManyField ( Item , related_name = \"<STR_LIT>\" )"}, {"input": "from django import forms \n from django_webhook . models import Webhook \n class WebhookForm ( forms . ModelForm ) :", "output": "class Meta : \n model = Webhook \n fields = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ]"}, {"input": "from django . shortcuts import render \n from django . http import HttpResponse , FileResponse \n from web . models import Channel , Epg \n from utils . general import noepgjson , crawl_info , root_dir \n from utils . aboutdb import get_html_info \n import datetime , re , json , os \n from dateutil import tz \n tz_sh = tz . gettz ( '<STR_LIT>' ) \n def d ( request ) : \n return render ( request , '<STR_LIT>' ) \n def index ( request ) : \n crawl_days = crawl_info [ '<STR_LIT>' ] \n start_date = datetime . datetime . now ( ) . strftime ( u'<STR_LIT>' ) . format ( y = '<STR_LIT>' , m = '<STR_LIT>' , d = '<STR_LIT>' ) \n start_date_no = datetime . datetime . now ( ) . strftime ( u'<STR_LIT>' ) \n end_date_date = datetime . datetime . now ( ) + datetime . timedelta ( days = crawl_days - <NUM_LIT> ) \n end_date = ( end_date_date ) . strftime ( u'<STR_LIT>' ) . format ( y = '<STR_LIT>' , m = '<STR_LIT>' , d = '<STR_LIT>' ) \n info = get_html_info ( end_date_date . date ( ) ) \n channel_no = info [ '<STR_LIT>' ] . count ( ) \n epg_no = info [ '<STR_LIT>' ] \n ret = { '<STR_LIT>' : channel_no , \n '<STR_LIT>' : crawl_days , \n '<STR_LIT>' : epg_no , \n '<STR_LIT>' : start_date , \n '<STR_LIT>' : start_date_no , \n '<STR_LIT>' : end_date , \n '<STR_LIT>' : info [ '<STR_LIT>' ] , \n '<STR_LIT>' : root_dir , \n '<STR_LIT>' : <NUM_LIT> , } \n return render ( request , \"<STR_LIT>\" , context = ret ) \n def download ( requests , title ) : \n file = open ( os . path . join ( root_dir , title ) , '<STR_LIT>' ) \n response = FileResponse ( file ) \n response [ '<STR_LIT>' ] = '<STR_LIT>' \n return response \n def diyp ( request ) : \n ret = single_channel_epg ( request ) \n ret_epgs = ret [ '<STR_LIT>' ] \n datas = [ ] \n if len ( ret [ '<STR_LIT>' ] ) == <NUM_LIT> : \n ret_epgs = noepgjson ( '<STR_LIT>' , '<STR_LIT>' , datetime . datetime . now ( ) . date ( ) ) \n for epg in ret_epgs : \n epg1 = { \n '<STR_LIT>' : epg [ '<STR_LIT>' ] , \n '<STR_LIT>' : epg [ '<STR_LIT>' ] , \n '<STR_LIT>' : epg [ '<STR_LIT>' ] , \n '<STR_LIT>' : epg [ '<STR_LIT>' ] , \n } \n datas . append ( epg1 ) \n ret1 = { \n \"<STR_LIT>\" : ret [ '<STR_LIT>' ] , \n \"<STR_LIT>\" : ret [ '<STR_LIT>' ] . strftime ( '<STR_LIT>' ) , \n \"<STR_LIT>\" : datas , \n } \n try : \n j = json . dumps ( ret1 , ensure_ascii = False ) \n except Exception as e : \n print ( e , datas ) \n j = '<STR_LIT>' \n return HttpResponse ( j , content_type = '<STR_LIT>' ) \n def web_single_channel_epg ( request ) : \n ret = single_channel_epg ( request ) \n ret_epgs = ret [ '<STR_LIT>' ] \n if len ( ret_epgs ) == <NUM_LIT> : \n epg = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' % ret [ '<STR_LIT>' ] , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n ret_epgs = [ epg ] \n title = '<STR_LIT>' % ( ret [ '<STR_LIT>' ] , ret [ '<STR_LIT>' ] . strftime ( '<STR_LIT>' ) ) \n tomorrow_date = ( ret [ '<STR_LIT>' ] + datetime . timedelta ( days = <NUM_LIT> ) ) . strftime ( '<STR_LIT>' ) \n tomorrow_url = '<STR_LIT>' % ( ret [ '<STR_LIT>' ] , tomorrow_date ) \n yesterday_date = ( ret [ '<STR_LIT>' ] - datetime . timedelta ( days = <NUM_LIT> ) ) . strftime ( '<STR_LIT>' ) \n yesterday_url = '<STR_LIT>' % ( ret [ '<STR_LIT>' ] , yesterday_date ) \n source = ret [ '<STR_LIT>' ] \n ret = { \n '<STR_LIT>' : title , \n '<STR_LIT>' : tomorrow_url , \n '<STR_LIT>' : yesterday_url , \n '<STR_LIT>' : ret_epgs , \n '<STR_LIT>' : source , \n } \n return render ( request , '<STR_LIT>' , context = ret ) \n def single_channel_epg ( request ) : \n tvg_name = '<STR_LIT>' \n success = <NUM_LIT> \n epgs = [ ] \n need_date = datetime . datetime . now ( ) . date ( ) \n msg = '<STR_LIT>' \n if request . method == \"<STR_LIT>\" and '<STR_LIT>' in request . GET and '<STR_LIT>' in request . GET : \n tvg_name = request . GET [ '<STR_LIT>' ] \n if tvg_name in [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n tvg_name = tvg_name . strip ( ) + '<STR_LIT>' \n date_re = re . search ( '<STR_LIT>' , request . GET [ '<STR_LIT>' ] ) \n if date_re : \n need_date = datetime . date ( int ( date_re . group ( <NUM_LIT> ) ) , int ( date_re . group ( <NUM_LIT> ) ) , int ( date_re . group ( <NUM_LIT> ) ) ) \n channels = Channel . get_spec_channel_strict ( Channel , tvg_name ) \n if channels . count ( ) == <NUM_LIT> : \n msg = '<STR_LIT>'", "output": "channel_name = tvg_name \n source = '<STR_LIT>' \n else : \n channel = channels . first ( ) \n channel_name = channel . name \n epgs = Epg . get_single_epg ( Epg , channel , need_date ) \n source = channel . source \n if len ( epgs ) > <NUM_LIT> : \n success = <NUM_LIT> \n else : \n msg = '<STR_LIT>' \n channel_name = '<STR_LIT>' \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : channel_name , \n '<STR_LIT>' : tvg_name , \n '<STR_LIT>' : need_date , \n '<STR_LIT>' : source , \n } \n return ret"}, {"input": "import pytest \n from django . core . exceptions import ValidationError \n from wagtail_ai . models import Prompt \n from wagtail_ai . prompts import DEFAULT_PROMPTS \n from wagtail_ai . wagtail_hooks import get_prompts \n @ pytest . mark . django_db \n def test_prompt_model ( setup_prompt_object , test_prompt_values ) : \n assert setup_prompt_object . is_default is False \n assert str ( setup_prompt_object ) == test_prompt_values [ \"<STR_LIT>\" ] \n assert setup_prompt_object . label == test_prompt_values [ \"<STR_LIT>\" ] \n assert setup_prompt_object . prompt_value == test_prompt_values [ \"<STR_LIT>\" ] \n assert setup_prompt_object . description == test_prompt_values [ \"<STR_LIT>\" ] \n assert setup_prompt_object . method == test_prompt_values [ \"<STR_LIT>\" ] \n @ pytest . mark . django_db \n def test_get_prompts_returns_default_prompts ( ) : \n prompts = get_prompts ( ) \n assert { ( p [ \"<STR_LIT>\" ] , p [ \"<STR_LIT>\" ] ) for p in prompts } == { \n ( p [ \"<STR_LIT>\" ] , p [ \"<STR_LIT>\" ] ) for p in DEFAULT_PROMPTS \n } \n def find_prompt_by_label ( prompts , label ) : \n return next ( ( prompt for prompt in prompts if prompt [ \"<STR_LIT>\" ] == label ) , None ) \n @ pytest . mark . django_db \n def test_editing_default_prompts ( ) : \n prompts = get_prompts ( ) \n default_prompt = Prompt . objects . get ( \n default_prompt_id = DEFAULT_PROMPTS [ <NUM_LIT> ] [ \"<STR_LIT>\" ] \n ) \n prompt_from_get_prompts = find_prompt_by_label ( prompts , default_prompt . label ) \n assert prompt_from_get_prompts is not None \n assert default_prompt . prompt is None \n assert prompt_from_get_prompts [ \"<STR_LIT>\" ] == default_prompt . prompt_value \n default_prompt . prompt = \"<STR_LIT>\" \n default_prompt . save ( ) \n assert default_prompt . prompt_value == \"<STR_LIT>\" \n prompts = get_prompts ( ) \n prompt_from_get_prompts = find_prompt_by_label ( prompts , default_prompt . label ) \n assert prompt_from_get_prompts is not None \n assert prompt_from_get_prompts [ \"<STR_LIT>\" ] == default_prompt . prompt_value \n assert prompt_from_get_prompts [ \"<STR_LIT>\" ] == default_prompt . prompt \n @ pytest . mark . django_db \n def test_get_prompts_returns_new_prompts_and_default_prompts ( setup_prompt_object ) : \n prompt_object = setup_prompt_object \n prompts = get_prompts ( ) \n assert { p [ \"<STR_LIT>\" ] for p in prompts } == set ( \n [ p [ \"<STR_LIT>\" ] for p in DEFAULT_PROMPTS ] + [ prompt_object . label ] \n ) \n assert setup_prompt_object . label in [ prompt [ \"<STR_LIT>\" ] for prompt in prompts ] \n assert setup_prompt_object . prompt in [ prompt [ \"<STR_LIT>\" ] for prompt in prompts ] \n for prompt in DEFAULT_PROMPTS : \n assert prompt [ \"<STR_LIT>\" ] in [ prompt [ \"<STR_LIT>\" ] for prompt in prompts ] \n assert prompt [ \"<STR_LIT>\" ] in [ prompt [ \"<STR_LIT>\" ] for prompt in prompts ] \n @ pytest . mark . django_db \n def test_prompts_return_uuids_and_not_ids ( ) : \n prompts = get_prompts ( ) \n assert prompts [ <NUM_LIT> ] [ \"<STR_LIT>\" ] is not None \n assert \"<STR_LIT>\" not in prompts [ <NUM_LIT> ] \n @ pytest . mark . django_db \n def test_prompts_can_not_save_and_invalid_method ( test_prompt_values ) :", "output": "with pytest . raises ( ValidationError , match = \"<STR_LIT>\" ) : \n prompt = Prompt ( \n label = test_prompt_values [ \"<STR_LIT>\" ] , \n description = test_prompt_values [ \"<STR_LIT>\" ] , \n prompt = test_prompt_values [ \"<STR_LIT>\" ] , \n method = \"<STR_LIT>\" , \n ) \n prompt . full_clean ( )"}, {"input": "import requests , datetime , os \n from utils . general import headers \n def get_epgs_mytvsuper ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n start_date_str = dt . strftime ( '<STR_LIT>' ) \n end_date = dt + datetime . timedelta ( days = <NUM_LIT> ) \n end_date_str = end_date . strftime ( '<STR_LIT>' ) \n url = '<STR_LIT>' % ( channel_id , start_date_str , end_date_str ) \n try : \n res = requests . get ( url , timeout = <NUM_LIT> , headers = headers ) \n res . encoding = '<STR_LIT>' \n res_j = res . json ( )", "output": "items = res_j [ <NUM_LIT> ] [ '<STR_LIT>' ] \n for item in items : \n epg_list = item [ '<STR_LIT>' ] \n firtst_line_date = <NUM_LIT> \n for li in epg_list : \n starttime = datetime . datetime . strptime ( li [ '<STR_LIT>' ] , '<STR_LIT>' ) \n title = li [ '<STR_LIT>' ] \n title_en = li [ '<STR_LIT>' ] \n desc = li [ '<STR_LIT>' ] \n desc_en = li [ '<STR_LIT>' ] \n url = '<STR_LIT>' % li [ '<STR_LIT>' ] \n program_date = starttime . date ( ) if '<STR_LIT>' in locals ( ) else dt \n if firtst_line_date : \n last_program_date = starttime \n first_line_date = <NUM_LIT> \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : '<STR_LIT>' % ( title , title_en ) , \n '<STR_LIT>' : title_en , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : desc_en , \n '<STR_LIT>' : program_date , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : last_program_date if '<STR_LIT>' in locals ( ) else dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_mytvsuper ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url , headers = headers ) \n res_channels = res . json ( ) [ '<STR_LIT>' ] \n channels = [ ] \n for li in res_channels : \n name = li [ '<STR_LIT>' ] \n name_en = li [ '<STR_LIT>' ] \n cn = li [ '<STR_LIT>' ] \n href = '<STR_LIT>' % cn \n logo = li [ '<STR_LIT>' ] if '<STR_LIT>' in li else '<STR_LIT>' \n id = li [ '<STR_LIT>' ] \n desc = '<STR_LIT>' \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : name_en , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : href , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : logo , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n channels . append ( channel ) \n return channels"}, {"input": "from rest_framework import serializers \n from rest_framework . fields import empty \n from rest_framework . request import Request \n from rest_framework . serializers import ModelSerializer \n from django . utils . functional import cached_property \n from rest_framework . utils . serializer_helpers import BindingDict \n from dvadmin . system . models import Users \n from django_restql . mixins import DynamicFieldsMixin \n class CustomModelSerializer ( DynamicFieldsMixin , ModelSerializer ) : \n modifier_field_id = \"<STR_LIT>\" \n modifier_name = serializers . SerializerMethodField ( read_only = True ) \n dept_belong_id = serializers . IntegerField ( required = False , allow_null = True ) \n def get_modifier_name ( self , instance ) : \n if not hasattr ( instance , \"<STR_LIT>\" ) :", "output": "return None \n queryset = ( \n Users . objects . filter ( id = instance . modifier ) \n . values_list ( \"<STR_LIT>\" , flat = True ) \n . first ( ) \n ) \n if queryset : \n return queryset \n return None \n creator_field_id = \"<STR_LIT>\" \n creator_name = serializers . SlugRelatedField ( \n slug_field = \"<STR_LIT>\" , source = \"<STR_LIT>\" , read_only = True \n ) \n dept_belong_id_field_name = \"<STR_LIT>\" \n create_datetime = serializers . DateTimeField ( \n format = \"<STR_LIT>\" , required = False , read_only = True \n ) \n update_datetime = serializers . DateTimeField ( \n format = \"<STR_LIT>\" , required = False \n ) \n def __init__ ( self , instance = None , data = empty , request = None , ** kwargs ) : \n super ( ) . __init__ ( instance , data , ** kwargs ) \n self . request : Request = request or self . context . get ( \"<STR_LIT>\" , None ) \n def save ( self , ** kwargs ) : \n return super ( ) . save ( ** kwargs ) \n def create ( self , validated_data ) : \n if self . request : \n if str ( self . request . user ) != \"<STR_LIT>\" : \n if self . modifier_field_id in self . fields . fields : \n validated_data [ self . modifier_field_id ] = self . get_request_user_id ( ) \n if self . creator_field_id in self . fields . fields : \n validated_data [ self . creator_field_id ] = self . request . user \n if ( \n self . dept_belong_id_field_name in self . fields . fields \n and validated_data . get ( self . dept_belong_id_field_name , None ) is None \n ) : \n validated_data [ self . dept_belong_id_field_name ] = getattr ( \n self . request . user , \"<STR_LIT>\" , None \n ) \n return super ( ) . create ( validated_data ) \n def update ( self , instance , validated_data ) : \n if self . request : \n if str ( self . request . user ) != \"<STR_LIT>\" : \n if self . modifier_field_id in self . fields . fields : \n validated_data [ self . modifier_field_id ] = self . get_request_user_id ( ) \n if hasattr ( self . instance , self . modifier_field_id ) : \n setattr ( \n self . instance , self . modifier_field_id , self . get_request_user_id ( ) \n ) \n return super ( ) . update ( instance , validated_data ) \n def get_request_username ( self ) : \n if getattr ( self . request , \"<STR_LIT>\" , None ) : \n return getattr ( self . request . user , \"<STR_LIT>\" , None ) \n return None \n def get_request_name ( self ) : \n if getattr ( self . request , \"<STR_LIT>\" , None ) : \n return getattr ( self . request . user , \"<STR_LIT>\" , None ) \n return None \n def get_request_user_id ( self ) : \n if getattr ( self . request , \"<STR_LIT>\" , None ) : \n return getattr ( self . request . user , \"<STR_LIT>\" , None ) \n return None \n @ property \n def errors ( self ) : \n errors = super ( ) . errors \n verbose_errors = { } \n fields = { field . name : field . verbose_name for field in \n self . Meta . model . _meta . get_fields ( ) if hasattr ( field , '<STR_LIT>' ) } \n for field_name , error in errors . items ( ) : \n if field_name in fields : \n verbose_errors [ str ( fields [ field_name ] ) ] = error \n else : \n verbose_errors [ field_name ] = error \n return verbose_errors"}, {"input": "from rest_framework import serializers \n from rest_framework . decorators import action \n from rest_framework . permissions import IsAuthenticated \n from dvadmin . system . models import Dept , RoleMenuButtonPermission , Users \n from dvadmin . utils . json_response import DetailResponse , SuccessResponse , ErrorResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class DeptSerializer ( CustomModelSerializer ) : \n parent_name = serializers . CharField ( read_only = True , source = '<STR_LIT>' ) \n status_label = serializers . SerializerMethodField ( ) \n has_children = serializers . SerializerMethodField ( ) \n hasChild = serializers . SerializerMethodField ( ) \n dept_user_count = serializers . SerializerMethodField ( ) \n def get_dept_user_count ( self , obj : Dept ) : \n return Users . objects . filter ( dept = obj ) . count ( ) \n def get_hasChild ( self , instance ) : \n hasChild = Dept . objects . filter ( parent = instance . id ) \n if hasChild : \n return True \n return False \n def get_status_label ( self , obj : Dept ) : \n if obj . status : \n return \"<STR_LIT>\" \n return \"<STR_LIT>\" \n def get_has_children ( self , obj : Dept ) : \n return Dept . objects . filter ( parent_id = obj . id ) . count ( ) \n class Meta : \n model = Dept \n fields = '<STR_LIT>' \n read_only_fields = [ \"<STR_LIT>\" ] \n class DeptImportSerializer ( CustomModelSerializer ) : \n class Meta : \n model = Dept \n fields = '<STR_LIT>' \n read_only_fields = [ \"<STR_LIT>\" ] \n class DeptCreateUpdateSerializer ( CustomModelSerializer ) : \n def create ( self , validated_data ) : \n value = validated_data . get ( '<STR_LIT>' , None ) \n if value is None : \n validated_data [ '<STR_LIT>' ] = self . request . user . dept \n dept_obj = Dept . objects . filter ( parent = self . request . user . dept ) . order_by ( '<STR_LIT>' ) . first ( ) \n last_sort = dept_obj . sort if dept_obj else <NUM_LIT> \n validated_data [ '<STR_LIT>' ] = last_sort + <NUM_LIT> \n instance = super ( ) . create ( validated_data ) \n instance . dept_belong_id = instance . id", "output": "instance . save ( ) \n return instance \n class Meta : \n model = Dept \n fields = '<STR_LIT>' \n class DeptViewSet ( CustomModelViewSet ) : \n queryset = Dept . objects . all ( ) \n serializer_class = DeptSerializer \n create_serializer_class = DeptCreateUpdateSerializer \n update_serializer_class = DeptCreateUpdateSerializer \n filter_fields = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n search_fields = [ ] \n import_serializer_class = DeptImportSerializer \n import_field_dict = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n def list ( self , request , * args , ** kwargs ) : \n request . query_params . _mutable = True \n params = request . query_params \n parent = params . get ( '<STR_LIT>' , None ) \n page = params . get ( '<STR_LIT>' , None ) \n limit = params . get ( '<STR_LIT>' , None ) \n if page : \n del params [ '<STR_LIT>' ] \n if limit : \n del params [ '<STR_LIT>' ] \n if params and parent : \n queryset = self . queryset . filter ( status = True , parent = parent ) \n else : \n queryset = self . queryset . filter ( status = True ) \n queryset = self . filter_queryset ( queryset ) \n serializer = DeptSerializer ( queryset , many = True , request = request ) \n data = serializer . data \n return SuccessResponse ( data = data ) \n @ action ( methods = [ \"<STR_LIT>\" ] , detail = False , permission_classes = [ IsAuthenticated ] , extra_filter_class = [ ] ) \n def dept_lazy_tree ( self , request , * args , ** kwargs ) : \n parent = self . request . query_params . get ( '<STR_LIT>' ) \n is_superuser = request . user . is_superuser \n if is_superuser : \n queryset = Dept . objects . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n else : \n role_ids = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n data_range = RoleMenuButtonPermission . objects . filter ( role__in = role_ids ) . values_list ( '<STR_LIT>' , flat = True ) \n user_dept_id = request . user . dept . id \n dept_list = [ user_dept_id ] \n data_range_list = list ( set ( data_range ) ) \n for item in data_range_list : \n if item in [ <NUM_LIT> , <NUM_LIT> ] : \n dept_list = [ user_dept_id ] \n elif item == <NUM_LIT> : \n dept_list = Dept . recursion_all_dept ( dept_id = user_dept_id ) \n elif item == <NUM_LIT> : \n dept_list = Dept . objects . values_list ( '<STR_LIT>' , flat = True ) \n elif item == <NUM_LIT> : \n dept_list = request . user . role . values_list ( '<STR_LIT>' , flat = True ) \n else : \n dept_list = [ ] \n queryset = Dept . objects . filter ( id__in = dept_list ) . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n return DetailResponse ( data = queryset , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ \"<STR_LIT>\" ] , detail = False , permission_classes = [ IsAuthenticated ] , extra_filter_class = [ ] ) \n def all_dept ( self , request , * args , ** kwargs ) : \n queryset = self . filter_queryset ( self . get_queryset ( ) ) \n data = queryset . filter ( status = True ) . order_by ( '<STR_LIT>' ) . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n return DetailResponse ( data = data , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def move_up ( self , request ) : \n dept_id = request . data . get ( '<STR_LIT>' ) \n try : \n dept = Dept . objects . get ( id = dept_id ) \n except Dept . DoesNotExist : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n previous_menu = Dept . objects . filter ( sort__lt = dept . sort , parent = dept . parent ) . order_by ( '<STR_LIT>' ) . first ( ) \n if previous_menu : \n previous_menu . sort , dept . sort = dept . sort , previous_menu . sort \n previous_menu . save ( ) \n dept . save ( ) \n return SuccessResponse ( data = [ ] , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ IsAuthenticated ] ) \n def move_down ( self , request ) : \n dept_id = request . data [ '<STR_LIT>' ] \n try : \n dept = Dept . objects . get ( id = dept_id ) \n except Dept . DoesNotExist : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n next_menu = Dept . objects . filter ( sort__gt = dept . sort , parent = dept . parent ) . order_by ( '<STR_LIT>' ) . first ( ) \n if next_menu : \n next_menu . sort , dept . sort = dept . sort , next_menu . sort \n next_menu . save ( ) \n dept . save ( ) \n return SuccessResponse ( data = [ ] , msg = \"<STR_LIT>\" ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False , permission_classes = [ ] ) \n def dept_info ( self , request ) : \n def inner ( did , li ) : \n sub = Dept . objects . filter ( parent_id = did ) \n if not sub . exists ( ) : \n return li \n for i in sub : \n li . append ( i . pk ) \n inner ( i , li ) \n return li \n dept_id = request . query_params . get ( '<STR_LIT>' ) \n show_all = request . query_params . get ( '<STR_LIT>' ) \n if dept_id is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n if not show_all : \n show_all = <NUM_LIT> \n if int ( show_all ) : \n all_did = [ dept_id ] \n inner ( dept_id , all_did ) \n users = Users . objects . filter ( dept_id__in = all_did ) \n else : \n if dept_id != '<STR_LIT>' : \n users = Users . objects . filter ( dept_id = dept_id ) \n else : \n users = Users . objects . none ( ) \n dept_obj = Dept . objects . get ( id = dept_id ) if dept_id != '<STR_LIT>' else None \n sub_dept = Dept . objects . filter ( parent_id = dept_obj . pk ) if dept_id != '<STR_LIT>' else [ ] \n data = { \n '<STR_LIT>' : dept_obj and dept_obj . name , \n '<STR_LIT>' : users . count ( ) , \n '<STR_LIT>' : dept_obj and dept_obj . owner , \n '<STR_LIT>' : dept_obj and dept_obj . description , \n '<STR_LIT>' : { \n '<STR_LIT>' : users . filter ( gender = <NUM_LIT> ) . count ( ) , \n '<STR_LIT>' : users . filter ( gender = <NUM_LIT> ) . count ( ) , \n '<STR_LIT>' : users . filter ( gender = <NUM_LIT> ) . count ( ) , \n } , \n '<STR_LIT>' : [ ] \n } \n for dept in sub_dept : \n all_did = [ dept . pk ] \n inner ( dept . pk , all_did ) \n sub_data = { \n '<STR_LIT>' : dept . name , \n '<STR_LIT>' : Users . objects . filter ( dept_id__in = all_did ) . count ( ) \n } \n data [ '<STR_LIT>' ] . append ( sub_data ) \n return SuccessResponse ( data )"}, {"input": "import logging \n import uuid \n from celery import states \n from django . conf import settings \n from django . core import validators \n from django . core . serializers . json import DjangoJSONEncoder \n from django . db import models \n from django . db . models . fields import DateTimeField \n from . validators import validate_topic_model \n topic_regex = r\"<STR_LIT>\"", "output": "STATES = [ \n ( states . PENDING , states . PENDING ) , \n ( states . FAILURE , states . FAILURE ) , \n ( states . SUCCESS , states . SUCCESS ) , \n ] \n class Webhook ( models . Model ) : \n url = models . URLField ( ) \n topics = models . ManyToManyField ( \n \"<STR_LIT>\" , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n ) \n active = models . BooleanField ( default = True ) \n uuid = models . UUIDField ( default = uuid . uuid4 , editable = False ) \n created = DateTimeField ( auto_now_add = True ) \n modified = DateTimeField ( auto_now = True ) \n def __str__ ( self ) : \n return f\"<STR_LIT>\" \n class WebhookTopic ( models . Model ) : \n name = models . CharField ( \n max_length = <NUM_LIT> , \n unique = True , \n validators = [ \n validators . RegexValidator ( \n topic_regex , message = \"<STR_LIT>\" + topic_regex \n ) , \n validate_topic_model , \n ] , \n ) \n def __str__ ( self ) : \n return self . name \n class WebhookSecret ( models . Model ) : \n webhook = models . ForeignKey ( \n Webhook , \n on_delete = models . CASCADE , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n editable = False , \n ) \n token = models . CharField ( \n max_length = <NUM_LIT> , \n validators = [ validators . MinLengthValidator ( <NUM_LIT> ) ] , \n ) \n created = DateTimeField ( auto_now_add = True ) \n class WebhookEvent ( models . Model ) : \n webhook = models . ForeignKey ( \n Webhook , \n on_delete = models . SET_NULL , \n null = True , \n editable = False , \n related_name = \"<STR_LIT>\" , \n related_query_name = \"<STR_LIT>\" , \n ) \n object = models . JSONField ( \n max_length = <NUM_LIT> , \n encoder = DjangoJSONEncoder , \n editable = False , \n ) \n object_type = models . CharField ( max_length = <NUM_LIT> , null = True , editable = False ) \n status = models . CharField ( \n max_length = <NUM_LIT> , \n default = states . PENDING , \n choices = STATES , \n editable = False , \n ) \n created = DateTimeField ( auto_now_add = True ) \n url = models . URLField ( editable = False ) \n topic = models . CharField ( max_length = <NUM_LIT> , null = True , editable = False ) \n def populate_topics_from_settings ( ) : \n from django . db . utils import OperationalError , ProgrammingError \n from django_webhook . signals import CREATE , DELETE , UPDATE \n try : \n Webhook . objects . count ( ) \n except ( OperationalError , ProgrammingError ) as ex : \n if \"<STR_LIT>\" in ex . args [ <NUM_LIT> ] : \n return \n if \"<STR_LIT>\" in ex . args [ <NUM_LIT> ] : \n return \n if \"<STR_LIT>\" in ex . args [ <NUM_LIT> ] : \n return \n if \"<STR_LIT>\" in ex . args [ <NUM_LIT> ] and \"<STR_LIT>\" in ex . args [ <NUM_LIT> ] : \n return \n raise ex \n webhook_settings = getattr ( settings , \"<STR_LIT>\" , { } ) \n enabled_models = webhook_settings . get ( \"<STR_LIT>\" ) \n if not enabled_models : \n return \n allowed_topics = set ( ) \n for model in enabled_models : \n model_allowed_topics = { \n f\"<STR_LIT>\" , \n f\"<STR_LIT>\" , \n f\"<STR_LIT>\" , \n } \n allowed_topics . update ( model_allowed_topics ) \n WebhookTopic . objects . exclude ( name__in = allowed_topics ) . delete ( ) \n logging . info ( f\"<STR_LIT>\" ) \n for topic in allowed_topics : \n if not WebhookTopic . objects . filter ( name = topic ) . exists ( ) : \n WebhookTopic . objects . create ( name = topic ) \n logging . info ( f\"<STR_LIT>\" )"}, {"input": "import subprocess \n from pathlib import Path \n from typing import Annotated \n import cappa \n from falco . utils import get_project_name \n from falco . utils import run_in_shell \n from falco . utils import simple_progress \n from rich import print as rich_print \n from . rm_migrations import RmMigrations \n def reset_migrations_table ( ) -> None : \n from django . db import connection \n with connection . cursor ( ) as cursor : \n cursor . execute ( \"<STR_LIT>\" ) \n @ cappa . command ( help = \"<STR_LIT>\" , name = \"<STR_LIT>\" ) \n class ResetMigrations : \n apps_dir : Annotated [ \n Path | None , \n cappa . Arg ( default = None , help = \"<STR_LIT>\" ) , \n ] \n skip_git_check : Annotated [ \n bool ,", "output": "cappa . Arg ( \n default = False , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] \n def __call__ ( self , project_name : Annotated [ str , cappa . Dep ( get_project_name ) ] ) : \n with simple_progress ( \"<STR_LIT>\" ) : \n result = subprocess . run ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n check = False , \n capture_output = True , \n text = True , \n ) \n if result . returncode != <NUM_LIT> : \n raise cappa . Exit ( code = <NUM_LIT> ) \n RmMigrations ( skip_git_check = self . skip_git_check , apps_dir = self . apps_dir ) ( project_name ) \n with simple_progress ( \"<STR_LIT>\" ) : \n run_in_shell ( reset_migrations_table , eval_result = False ) \n subprocess . run ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n check = True , \n stdout = subprocess . DEVNULL , \n stderr = subprocess . DEVNULL , \n ) \n subprocess . run ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n check = True , \n stdout = subprocess . DEVNULL , \n stderr = subprocess . DEVNULL , \n ) \n rich_print ( \"<STR_LIT>\" )"}, {"input": "import django . db . models . deletion \n from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AddField (", "output": "model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False ) , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \"<STR_LIT>\" , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . BooleanField ( default = False ) ) , \n ( \"<STR_LIT>\" , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = \"<STR_LIT>\" ) ) , \n ] , \n ) , \n ]"}, {"input": "import torch \n import csv \n import pickle \n class Dataset ( torch . utils . data . Dataset ) : \n def __init__ ( self ) : \n self . id = [ ] \n self . essay = [ ] \n self . score = [ ] \n self . prediction_id = [ ] \n def __len__ ( self ) : \n return len ( self . essay ) \n def __getitem__ ( self , i ) : \n id = self . id [ i ] \n essay = self . essay [ i ] \n score = self . score [ i ] \n prediction_id = self . prediction_id [ i ] \n return id , essay , score , prediction_id \n if __name__ == '<STR_LIT>' : \n p1_dataset = Dataset ( ) \n p2_d1_dataset = Dataset ( ) \n p2_d2_dataset = Dataset ( ) \n p3_dataset = Dataset ( ) \n p4_dataset = Dataset ( ) \n p5_dataset = Dataset ( ) \n p6_dataset = Dataset ( ) \n p7_dataset = Dataset ( ) \n p8_dataset = Dataset ( ) \n p1_val_dataset = Dataset ( ) \n p2_d1_val_dataset = Dataset ( ) \n p2_d2_val_dataset = Dataset ( ) \n p3_val_dataset = Dataset ( ) \n p4_val_dataset = Dataset ( ) \n p5_val_dataset = Dataset ( ) \n p6_val_dataset = Dataset ( ) \n p7_val_dataset = Dataset ( ) \n p8_val_dataset = Dataset ( ) \n with open ( '<STR_LIT>' , encoding = '<STR_LIT>' ) as tsvfile : \n text = tsvfile . read ( ) \n lines = text . split ( '<STR_LIT>' ) \n for line in lines [ <NUM_LIT> : ] : \n item = line . split ( '<STR_LIT>' ) \n if len ( item ) == <NUM_LIT> : \n continue \n essay_id = item [ <NUM_LIT> ] \n essay_set = item [ <NUM_LIT> ] \n essay = item [ <NUM_LIT> ] \n domain_1 = int ( item [ <NUM_LIT> ] ) \n domain_2 = item [ <NUM_LIT> ] \n if essay_set == '<STR_LIT>' : \n p1_dataset . id . append ( essay_id ) \n p1_dataset . essay . append ( essay ) \n p1_dataset . score . append ( domain_1 ) \n p1_dataset . prediction_id . append ( '<STR_LIT>' ) \n elif essay_set == '<STR_LIT>' : \n p2_d1_dataset . id . append ( essay_id ) \n p2_d1_dataset . essay . append ( essay ) \n p2_d1_dataset . score . append ( domain_1 ) \n p2_d1_dataset . prediction_id . append ( '<STR_LIT>' ) \n p2_d2_dataset . id . append ( essay_id ) \n p2_d2_dataset . essay . append ( essay ) \n p2_d2_dataset . score . append ( int ( domain_2 ) ) \n p2_d2_dataset . prediction_id . append ( '<STR_LIT>' ) \n elif essay_set == '<STR_LIT>' : \n p3_dataset . id . append ( essay_id ) \n p3_dataset . essay . append ( essay ) \n p3_dataset . score . append ( domain_1 ) \n p3_dataset . prediction_id . append ( '<STR_LIT>' ) \n elif essay_set == '<STR_LIT>' : \n p4_dataset . id . append ( essay_id ) \n p4_dataset . essay . append ( essay ) \n p4_dataset . score . append ( domain_1 ) \n p4_dataset . prediction_id . append ( '<STR_LIT>' ) \n elif essay_set == '<STR_LIT>' : \n p5_dataset . id . append ( essay_id ) \n p5_dataset . essay . append ( essay ) \n p5_dataset . score . append ( domain_1 ) \n p5_dataset . prediction_id . append ( '<STR_LIT>' ) \n elif essay_set == '<STR_LIT>' : \n p6_dataset . id . append ( essay_id ) \n p6_dataset . essay . append ( essay ) \n p6_dataset . score . append ( domain_1 ) \n p6_dataset . prediction_id . append ( '<STR_LIT>' ) \n elif essay_set == '<STR_LIT>' : \n p7_dataset . id . append ( essay_id ) \n p7_dataset . essay . append ( essay ) \n p7_dataset . score . append ( domain_1 ) \n p7_dataset . prediction_id . append ( '<STR_LIT>' ) \n elif essay_set == '<STR_LIT>' : \n p8_dataset . id . append ( essay_id ) \n p8_dataset . essay . append ( essay ) \n p8_dataset . score . append ( domain_1 ) \n p8_dataset . prediction_id . append ( '<STR_LIT>' ) \n score_dit = { } \n with open ( '<STR_LIT>' ) as csvfile : \n csv_reader = csv . reader ( csvfile ) \n header = next ( csv_reader ) \n for row in csv_reader : \n prediction_id = row [ <NUM_LIT> ] \n score = row [ <NUM_LIT> ] \n score_dit [ prediction_id ] = int ( score ) \n with open ( '<STR_LIT>' , encoding = '<STR_LIT>' ) as tsvfile : \n text = tsvfile . read ( ) \n lines = text . split ( '<STR_LIT>' ) \n for line in lines [ <NUM_LIT> : ] : \n item = line . split ( '<STR_LIT>' ) \n if len ( item ) == <NUM_LIT> : \n continue \n essay_id = item [ <NUM_LIT> ] \n essay_set = item [ <NUM_LIT> ] \n essay = item [ <NUM_LIT> ] \n domain1_predictionid = item [ <NUM_LIT> ] \n domain2_predictionid = item [ <NUM_LIT> ] \n if essay_set == '<STR_LIT>' : \n p1_val_dataset . id . append ( essay_id ) \n p1_val_dataset . essay . append ( essay ) \n p1_val_dataset . score . append ( score_dit [ domain1_predictionid ] ) \n p1_val_dataset . prediction_id . append ( domain1_predictionid ) \n elif essay_set == '<STR_LIT>' : \n p2_d1_val_dataset . id . append ( essay_id ) \n p2_d1_val_dataset . essay . append ( essay ) \n p2_d1_val_dataset . score . append ( score_dit [ domain1_predictionid ] ) \n p2_d1_val_dataset . prediction_id . append ( domain1_predictionid ) \n p2_d2_val_dataset . id . append ( essay_id ) \n p2_d2_val_dataset . essay . append ( essay ) \n p2_d2_val_dataset . score . append ( score_dit [ domain2_predictionid ] ) \n p2_d2_val_dataset . prediction_id . append ( domain2_predictionid ) \n elif essay_set == '<STR_LIT>' : \n p3_val_dataset . id . append ( essay_id ) \n p3_val_dataset . essay . append ( essay ) \n p3_val_dataset . score . append ( score_dit [ domain1_predictionid ] ) \n p3_val_dataset . prediction_id . append ( domain1_predictionid ) \n elif essay_set == '<STR_LIT>' : \n p4_val_dataset . id . append ( essay_id ) \n p4_val_dataset . essay . append ( essay ) \n p4_val_dataset . score . append ( score_dit [ domain1_predictionid ] ) \n p4_val_dataset . prediction_id . append ( domain1_predictionid ) \n elif essay_set == '<STR_LIT>' : \n p5_val_dataset . id . append ( essay_id ) \n p5_val_dataset . essay . append ( essay ) \n p5_val_dataset . score . append ( score_dit [ domain1_predictionid ] ) \n p5_val_dataset . prediction_id . append ( domain1_predictionid ) \n elif essay_set == '<STR_LIT>' : \n p6_val_dataset . id . append ( essay_id ) \n p6_val_dataset . essay . append ( essay ) \n p6_val_dataset . score . append ( score_dit [ domain1_predictionid ] ) \n p6_val_dataset . prediction_id . append ( domain1_predictionid ) \n elif essay_set == '<STR_LIT>' : \n p7_val_dataset . id . append ( essay_id )", "output": "p7_val_dataset . essay . append ( essay ) \n p7_val_dataset . score . append ( score_dit [ domain1_predictionid ] ) \n p7_val_dataset . prediction_id . append ( domain1_predictionid ) \n elif essay_set == '<STR_LIT>' : \n p8_val_dataset . id . append ( essay_id ) \n p8_val_dataset . essay . append ( essay ) \n p8_val_dataset . score . append ( score_dit [ domain1_predictionid ] ) \n p8_val_dataset . prediction_id . append ( domain1_predictionid ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p1_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p2_d1_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p2_d2_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p3_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p4_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p5_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p6_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p7_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p8_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p1_val_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p2_d1_val_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p2_d2_val_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p3_val_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p4_val_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p5_val_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p6_val_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p7_val_dataset , f ) \n with open ( \"<STR_LIT>\" , '<STR_LIT>' ) as f : \n pickle . dump ( p8_val_dataset , f )"}, {"input": "import os \n from channels . auth import AuthMiddlewareStack \n from channels . security . websocket import AllowedHostsOriginValidator \n from channels . routing import ProtocolTypeRouter , URLRouter \n from django . core . asgi import get_asgi_application", "output": "os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n os . environ [ \"<STR_LIT>\" ] = \"<STR_LIT>\" \n http_application = get_asgi_application ( ) \n from application . routing import websocket_urlpatterns \n application = ProtocolTypeRouter ( { \n \"<STR_LIT>\" : http_application , \n '<STR_LIT>' : AllowedHostsOriginValidator ( \n AuthMiddlewareStack ( \n URLRouter ( \n websocket_urlpatterns \n ) \n ) \n ) , \n } )"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) ) ,", "output": "] , \n ) , \n ]"}, {"input": "from django . db import migrations \n from django . db import models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterField (", "output": "model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False ) , \n ) , \n ]"}, {"input": "import os \n import sys \n def main ( ) : \n os . environ . setdefault ( '<STR_LIT>' , '<STR_LIT>' ) \n try : \n from django . core . management import execute_from_command_line \n except ImportError as exc : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) from exc", "output": "execute_from_command_line ( sys . argv ) \n if __name__ == '<STR_LIT>' : \n main ( )"}, {"input": "import http \n from typing import Callable , Dict , List , Optional , Type \n from django . db . models import ManyToManyField , Model \n from django . http import HttpRequest \n from ninja import Schema \n from ninja_crud . views . abstract_model_view import AbstractModelView \n from ninja_crud . views . enums import HTTPMethod \n class CreateModelView ( AbstractModelView ) : \n def __init__ ( \n self , \n path : str = \"<STR_LIT>\" , \n path_parameters : Optional [ Schema ] = None , \n request_body : Optional [ Type [ Schema ] ] = None , \n response_body : Optional [ Type [ Schema ] ] = None , \n decorators : Optional [ List [ Callable ] ] = None , \n router_kwargs : Optional [ Dict ] = None , \n init_model : Optional [ Callable [ [ HttpRequest , Optional [ Schema ] ] , Model ] ] = None , \n pre_save : Optional [ Callable [ [ HttpRequest , Model ] , None ] ] = None , \n post_save : Optional [ Callable [ [ HttpRequest , Model ] , None ] ] = None , \n create_model : Optional [ \n Callable [ [ HttpRequest , Optional [ Schema ] , Optional [ Schema ] ] , Model ] \n ] = None , \n ) -> None : \n super ( ) . __init__ ( \n method = HTTPMethod . POST , \n path = path , \n path_parameters = path_parameters , \n query_parameters = None , \n request_body = request_body , \n response_body = response_body , \n response_status = http . HTTPStatus . CREATED , \n decorators = decorators , \n router_kwargs = router_kwargs , \n ) \n self . init_model = init_model or self . _default_init_model \n self . pre_save = pre_save or self . _default_pre_save \n self . post_save = post_save or self . _default_post_save \n self . create_model = create_model or self . _default_create_model \n def _default_init_model ( \n self , request : HttpRequest , path_parameters : Optional [ Schema ] \n ) -> Model : \n return self . model_viewset_class . model ( ) \n @ staticmethod \n def _default_pre_save ( request : HttpRequest , instance : Model ) -> None : \n instance . full_clean ( ) \n @ staticmethod \n def _default_post_save ( request : HttpRequest , instance : Model ) -> None : \n pass \n def _default_create_model ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] , \n request_body : Optional [ Schema ] , \n ) -> Model : \n instance = self . init_model ( request , path_parameters ) \n m2m_fields_to_set = [ ] \n if request_body : \n for field , value in request_body . dict ( ) . items ( ) : \n if isinstance ( instance . _meta . get_field ( field ) , ManyToManyField ) : \n m2m_fields_to_set . append ( ( field , value ) ) \n else : \n setattr ( instance , field , value ) \n self . pre_save ( request , instance ) \n instance . save ( ) \n self . post_save ( request , instance ) \n for field , value in m2m_fields_to_set : \n getattr ( instance , field ) . set ( value ) \n return instance \n def handle_request ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] ,", "output": "query_parameters : Optional [ Schema ] , \n request_body : Optional [ Schema ] , \n ) -> Model : \n return self . create_model ( request , path_parameters , request_body ) \n def _inherit_model_viewset_class_attributes ( self ) -> None : \n if self . request_body is None : \n self . request_body = self . model_viewset_class . default_request_body \n if self . response_body is None : \n self . response_body = self . model_viewset_class . default_response_body"}, {"input": "import django . db . models . deletion \n import django . contrib . postgres . fields \n from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \"<STR_LIT>\" , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . BooleanField ( default = False ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( blank = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . TextField ( ) ) , \n ( \n \"<STR_LIT>\" , \n django . contrib . postgres . fields . ArrayField ( base_field = models . CharField ( max_length = <NUM_LIT> ) , size = None ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \"<STR_LIT>\" , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . TextField ( ) ) , \n ( \"<STR_LIT>\" , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = \"<STR_LIT>\" ) ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] ,", "output": "} , \n ) , \n ]"}, {"input": "from django . conf import settings \n from django . core . exceptions import ValidationError \n def validate_topic_model ( value ) : \n webhook_settings = getattr ( settings , \"<STR_LIT>\" , { } ) \n allowed_models = webhook_settings . get ( \"<STR_LIT>\" , [ ] ) \n if not webhook_settings or not allowed_models : \n raise ValidationError ( \"<STR_LIT>\" ) \n parts = value . split ( \"<STR_LIT>\" ) \n if len ( parts ) != <NUM_LIT> : \n raise ValidationError ( f\"<STR_LIT>\" ) \n [ model_name , _ ] = value . split ( \"<STR_LIT>\" )", "output": "if model_name not in allowed_models : \n raise ValidationError ( \n f\"<STR_LIT>\" \n )"}, {"input": "import urllib \n from asgiref . sync import sync_to_async , async_to_sync \n from channels . db import database_sync_to_async \n from channels . generic . websocket import AsyncJsonWebsocketConsumer , AsyncWebsocketConsumer \n import json \n from channels . layers import get_channel_layer \n from jwt import InvalidSignatureError \n from rest_framework . request import Request \n from application import settings \n from dvadmin . system . models import MessageCenter , Users , MessageCenterTargetUser \n from dvadmin . system . views . message_center import MessageCenterTargetUserSerializer \n from dvadmin . utils . serializers import CustomModelSerializer \n send_dict = { } \n def set_message ( sender , msg_type , msg , unread = <NUM_LIT> ) : \n text = { \n '<STR_LIT>' : sender , \n '<STR_LIT>' : msg_type , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : unread \n } \n return text \n @ database_sync_to_async \n def _get_message_center_instance ( message_id ) : \n from dvadmin . system . models import MessageCenter \n _MessageCenter = MessageCenter . objects . filter ( id = message_id ) . values_list ( '<STR_LIT>' , flat = True ) \n if _MessageCenter : \n return _MessageCenter \n else : \n return [ ] \n @ database_sync_to_async \n def _get_message_unread ( user_id ) : \n from dvadmin . system . models import MessageCenterTargetUser \n count = MessageCenterTargetUser . objects . filter ( users = user_id , is_read = False ) . count ( ) \n return count or <NUM_LIT> \n def request_data ( scope ) : \n query_string = scope . get ( '<STR_LIT>' , b'<STR_LIT>' ) . decode ( '<STR_LIT>' ) \n qs = urllib . parse . parse_qs ( query_string ) \n return qs \n class DvadminWebSocket ( AsyncJsonWebsocketConsumer ) : \n async def connect ( self ) : \n try : \n import jwt \n self . service_uid = self . scope [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n decoded_result = jwt . decode ( self . service_uid , settings . SECRET_KEY , algorithms = [ \"<STR_LIT>\" ] ) \n if decoded_result : \n self . user_id = decoded_result . get ( '<STR_LIT>' ) \n self . chat_group_name = \"<STR_LIT>\" + str ( self . user_id ) \n await self . channel_layer . group_add ( \n self . chat_group_name , \n self . channel_name \n ) \n await self . accept ( ) \n unread_count = await _get_message_unread ( self . user_id ) \n if unread_count == <NUM_LIT> : \n await self . send_json ( set_message ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) ) \n else : \n await self . send_json ( \n set_message ( '<STR_LIT>' , '<STR_LIT>' , \"<STR_LIT>\" , \n unread = unread_count ) ) \n except InvalidSignatureError : \n await self . disconnect ( None ) \n async def disconnect ( self , close_code ) : \n await self . channel_layer . group_discard ( self . chat_group_name , self . channel_name ) \n print ( \"<STR_LIT>\" ) \n try : \n await self . close ( close_code ) \n except Exception : \n pass \n class MegCenter ( DvadminWebSocket ) : \n async def receive ( self , text_data ) : \n text_data_json = json . loads ( text_data ) \n message_id = text_data_json . get ( '<STR_LIT>' , None ) \n user_list = await _get_message_center_instance ( message_id ) \n for send_user in user_list : \n await self . channel_layer . group_send ( \n \"<STR_LIT>\" + str ( send_user ) , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : text_data_json } \n ) \n async def push_message ( self , event ) : \n message = event [ '<STR_LIT>' ] \n await self . send ( text_data = json . dumps ( message ) ) \n class MessageCreateSerializer ( CustomModelSerializer ) : \n class Meta : \n model = MessageCenter \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n def websocket_push ( user_id , message ) : \n username = \"<STR_LIT>\" + str ( user_id ) \n channel_layer = get_channel_layer ( ) \n async_to_sync ( channel_layer . group_send ) ( \n username , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : message \n } \n ) \n def create_message_push ( title : str , content : str , target_type : int = <NUM_LIT> , target_user : list = None , target_dept = None , \n target_role = None , message : dict = None , request = Request ) : \n if message is None : \n message = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : None } \n if target_role is None : \n target_role = [ ] \n if target_dept is None : \n target_dept = [ ] \n data = { \n \"<STR_LIT>\" : title , \n \"<STR_LIT>\" : content , \n \"<STR_LIT>\" : target_type , \n \"<STR_LIT>\" : target_user , \n \"<STR_LIT>\" : target_dept , \n \"<STR_LIT>\" : target_role \n } \n message_center_instance = MessageCreateSerializer ( data = data , request = request ) \n message_center_instance . is_valid ( raise_exception = True ) \n message_center_instance . save ( ) \n users = target_user or [ ] \n if target_type in [ <NUM_LIT> ] : \n users = Users . objects . filter ( role__id__in = target_role ) . values_list ( '<STR_LIT>' , flat = True ) \n if target_type in [ <NUM_LIT> ] :", "output": "users = Users . objects . filter ( dept__id__in = target_dept ) . values_list ( '<STR_LIT>' , flat = True ) \n if target_type in [ <NUM_LIT> ] : \n users = Users . objects . values_list ( '<STR_LIT>' , flat = True ) \n targetuser_data = [ ] \n for user in users : \n targetuser_data . append ( { \n \"<STR_LIT>\" : message_center_instance . instance . id , \n \"<STR_LIT>\" : user \n } ) \n targetuser_instance = MessageCenterTargetUserSerializer ( data = targetuser_data , many = True , request = request ) \n targetuser_instance . is_valid ( raise_exception = True ) \n targetuser_instance . save ( ) \n for user in users : \n username = \"<STR_LIT>\" + str ( user ) \n unread_count = async_to_sync ( _get_message_unread ) ( user ) \n channel_layer = get_channel_layer ( ) \n async_to_sync ( channel_layer . group_send ) ( \n username , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { ** message , '<STR_LIT>' : unread_count } \n } \n )"}, {"input": "import torch \n from tqdm import tqdm \n from utils import update_lr , Meter , cal_score \n from dataset import Words \n def train ( params , model , optimizer , epoch , train_loader , writer = None ) : \n model . train ( ) \n device = params [ '<STR_LIT>' ] \n loss_meter = Meter ( ) \n word_right , exp_right , length , cal_num = <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> \n with tqdm ( train_loader , total = len ( train_loader ) // params [ '<STR_LIT>' ] ) as pbar : \n for batch_idx , ( images , image_masks , labels , label_masks ) in enumerate ( pbar ) : \n images , image_masks , labels , label_masks = images . to ( device ) , image_masks . to ( \n device ) , labels . to ( device ) , label_masks . to ( device ) \n batch , time = labels . shape [ : <NUM_LIT> ] \n if not '<STR_LIT>' in params or params [ '<STR_LIT>' ] == '<STR_LIT>' : \n update_lr ( optimizer , epoch , batch_idx , len ( train_loader ) , params [ '<STR_LIT>' ] , params [ '<STR_LIT>' ] ) \n optimizer . zero_grad ( ) \n probs , counting_preds , word_loss , counting_loss = model ( images , image_masks , labels , label_masks ) \n loss = word_loss + counting_loss \n loss . backward ( ) \n if params [ '<STR_LIT>' ] : \n torch . nn . utils . clip_grad_norm_ ( model . parameters ( ) , params [ '<STR_LIT>' ] ) \n optimizer . step ( ) \n loss_meter . add ( loss . item ( ) ) \n wordRate , ExpRate = cal_score ( probs , labels , label_masks ) \n word_right = word_right + wordRate * time \n exp_right = exp_right + ExpRate * batch \n length = length + time \n cal_num = cal_num + batch", "output": "if writer : \n current_step = epoch * len ( train_loader ) // params [ '<STR_LIT>' ] + batch_idx + <NUM_LIT> \n writer . add_scalar ( '<STR_LIT>' , word_loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , counting_loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , wordRate , current_step ) \n writer . add_scalar ( '<STR_LIT>' , ExpRate , current_step ) \n writer . add_scalar ( '<STR_LIT>' , optimizer . param_groups [ <NUM_LIT> ] [ '<STR_LIT>' ] , current_step ) \n pbar . set_description ( f'<STR_LIT>' \n f'<STR_LIT>' ) \n if batch_idx >= len ( train_loader ) // params [ '<STR_LIT>' ] : \n break \n if writer : \n writer . add_scalar ( '<STR_LIT>' , loss_meter . mean , epoch + <NUM_LIT> ) \n writer . add_scalar ( '<STR_LIT>' , word_right / length , epoch + <NUM_LIT> ) \n writer . add_scalar ( '<STR_LIT>' , exp_right / cal_num , epoch + <NUM_LIT> ) \n return loss_meter . mean , word_right / length , exp_right / cal_num \n def eval ( params , model , epoch , eval_loader , writer = None ) : \n model . eval ( ) \n device = params [ '<STR_LIT>' ] \n loss_meter = Meter ( ) \n word_right , exp_right , length , cal_num = <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> \n with tqdm ( eval_loader , total = len ( eval_loader ) // params [ '<STR_LIT>' ] ) as pbar , torch . no_grad ( ) : \n for batch_idx , ( images , image_masks , labels , label_masks ) in enumerate ( pbar ) : \n images , image_masks , labels , label_masks = images . to ( device ) , image_masks . to ( \n device ) , labels . to ( device ) , label_masks . to ( device ) \n batch , time = labels . shape [ : <NUM_LIT> ] \n probs , counting_preds , word_loss , counting_loss = model ( images , image_masks , labels , label_masks , is_train = False ) \n loss = word_loss + counting_loss \n loss_meter . add ( loss . item ( ) ) \n wordRate , ExpRate = cal_score ( probs , labels , label_masks ) \n word_right = word_right + wordRate * time \n exp_right = exp_right + ExpRate * batch \n length = length + time \n cal_num = cal_num + batch \n if writer : \n current_step = epoch * len ( eval_loader ) // params [ '<STR_LIT>' ] + batch_idx + <NUM_LIT> \n writer . add_scalar ( '<STR_LIT>' , word_loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , counting_loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , loss . item ( ) , current_step ) \n writer . add_scalar ( '<STR_LIT>' , wordRate , current_step ) \n writer . add_scalar ( '<STR_LIT>' , ExpRate , current_step ) \n pbar . set_description ( f'<STR_LIT>' \n f'<STR_LIT>' ) \n if batch_idx >= len ( eval_loader ) // params [ '<STR_LIT>' ] : \n break \n if writer : \n writer . add_scalar ( '<STR_LIT>' , loss_meter . mean , epoch + <NUM_LIT> ) \n writer . add_scalar ( '<STR_LIT>' , word_right / length , epoch + <NUM_LIT> ) \n writer . add_scalar ( '<STR_LIT>' , exp_right / len ( eval_loader . dataset ) , epoch + <NUM_LIT> ) \n return loss_meter . mean , word_right / length , exp_right / cal_num"}, {"input": "from django . db import transaction \n from django_filters import DateTimeFromToRangeFilter \n from django_filters . rest_framework import FilterSet \n from drf_yasg import openapi \n from drf_yasg . utils import swagger_auto_schema \n from rest_framework . decorators import action \n from rest_framework . viewsets import ModelViewSet \n from dvadmin . utils . filters import DataLevelPermissionsFilter , CoreModelFilterBankend \n from dvadmin . utils . import_export_mixin import ExportSerializerMixin , ImportSerializerMixin \n from dvadmin . utils . json_response import SuccessResponse , ErrorResponse , DetailResponse \n from dvadmin . utils . permission import CustomPermission \n from dvadmin . utils . models import get_custom_app_models , CoreModel \n from dvadmin . system . models import FieldPermission , MenuField \n from django_restql . mixins import QueryArgumentsMixin \n class CustomModelViewSet ( ModelViewSet , ImportSerializerMixin , ExportSerializerMixin , QueryArgumentsMixin ) : \n values_queryset = None \n ordering_fields = '<STR_LIT>' \n create_serializer_class = None \n update_serializer_class = None \n filter_fields = '<STR_LIT>' \n search_fields = ( ) \n extra_filter_class = [ CoreModelFilterBankend , DataLevelPermissionsFilter ] \n permission_classes = [ CustomPermission ] \n import_field_dict = { } \n export_field_label = { } \n def filter_queryset ( self , queryset ) : \n for backend in set ( set ( self . filter_backends ) | set ( self . extra_filter_class or [ ] ) ) : \n queryset = backend ( ) . filter_queryset ( self . request , queryset , self ) \n return queryset \n def get_queryset ( self ) : \n if getattr ( self , '<STR_LIT>' , None ) : \n return self . values_queryset \n return super ( ) . get_queryset ( ) \n def get_serializer_class ( self ) : \n action_serializer_name = f\"<STR_LIT>\" \n action_serializer_class = getattr ( self , action_serializer_name , None ) \n if action_serializer_class : \n return action_serializer_class \n return super ( ) . get_serializer_class ( ) \n def get_serializer ( self , * args , ** kwargs ) : \n serializer_class = self . get_serializer_class ( ) \n kwargs . setdefault ( '<STR_LIT>' , self . get_serializer_context ( ) ) \n can_see = self . get_menu_field ( serializer_class ) \n self . request . permission_fields = can_see \n if isinstance ( self . request . data , list ) : \n with transaction . atomic ( ) : \n return serializer_class ( many = True , * args , ** kwargs ) \n else : \n return serializer_class ( * args , ** kwargs ) \n def get_menu_field ( self , serializer_class ) : \n finded = False \n for model in get_custom_app_models ( ) : \n if model [ '<STR_LIT>' ] is serializer_class . Meta . model : \n finded = True \n break \n if finded is False : \n return [ ] \n return MenuField . objects . filter ( model = model [ '<STR_LIT>' ] \n ) . values ( '<STR_LIT>' , '<STR_LIT>' ) \n def create ( self , request , * args , ** kwargs ) : \n serializer = self . get_serializer ( data = request . data , request = request ) \n serializer . is_valid ( raise_exception = True ) \n self . perform_create ( serializer ) \n return DetailResponse ( data = serializer . data , msg = \"<STR_LIT>\" ) \n def list ( self , request , * args , ** kwargs ) : \n queryset = self . filter_queryset ( self . get_queryset ( ) ) \n page = self . paginate_queryset ( queryset ) \n if page is not None : \n serializer = self . get_serializer ( page , many = True , request = request ) \n return self . get_paginated_response ( serializer . data ) \n serializer = self . get_serializer ( queryset , many = True , request = request ) \n return SuccessResponse ( data = serializer . data , msg = \"<STR_LIT>\" ) \n def retrieve ( self , request , * args , ** kwargs ) : \n instance = self . get_object ( ) \n serializer = self . get_serializer ( instance ) \n return DetailResponse ( data = serializer . data , msg = \"<STR_LIT>\" ) \n def update ( self , request , * args , ** kwargs ) : \n partial = kwargs . pop ( '<STR_LIT>' , False ) \n instance = self . get_object ( ) \n serializer = self . get_serializer ( instance , data = request . data , request = request , partial = partial ) \n serializer . is_valid ( raise_exception = True ) \n self . perform_update ( serializer ) \n if getattr ( instance , '<STR_LIT>' , None ) : \n instance . _prefetched_objects_cache = { } \n return DetailResponse ( data = serializer . data , msg = \"<STR_LIT>\" ) \n def destroy ( self , request , * args , ** kwargs ) :", "output": "instance = self . get_object ( ) \n instance . delete ( ) \n return DetailResponse ( data = [ ] , msg = \"<STR_LIT>\" ) \n keys = openapi . Schema ( description = '<STR_LIT>' , type = openapi . TYPE_ARRAY , items = openapi . TYPE_STRING ) \n @ swagger_auto_schema ( request_body = openapi . Schema ( \n type = openapi . TYPE_OBJECT , \n required = [ '<STR_LIT>' ] , \n properties = { '<STR_LIT>' : keys } \n ) , operation_summary = '<STR_LIT>' ) \n @ action ( methods = [ '<STR_LIT>' ] , detail = False ) \n def multiple_delete ( self , request , * args , ** kwargs ) : \n request_data = request . data \n keys = request_data . get ( '<STR_LIT>' , None ) \n if keys : \n self . get_queryset ( ) . filter ( id__in = keys ) . delete ( ) \n return SuccessResponse ( data = [ ] , msg = \"<STR_LIT>\" ) \n else : \n return ErrorResponse ( msg = \"<STR_LIT>\" )"}, {"input": "from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( \n choices = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] , \n max_length = <NUM_LIT> ,", "output": ") , \n ) , \n ]"}, {"input": "import subprocess \n from pathlib import Path \n from typing import Annotated \n import cappa \n import parso \n from falco . commands . crud . utils import run_python_formatters \n from falco . utils import get_project_name \n from falco . utils import run_in_shell \n from falco . utils import simple_progress \n def get_settings_file_path ( ) -> str : \n from django . conf import settings \n s = settings . SETTINGS_MODULE \n s = s . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" )", "output": "return f\"<STR_LIT>\" \n @ cappa . command ( help = \"<STR_LIT>\" ) \n class StartApp : \n app_name : Annotated [ str , cappa . Arg ( help = \"<STR_LIT>\" ) ] \n def __call__ ( self , project_name : Annotated [ str , cappa . Dep ( get_project_name ) ] ) : \n apps_dir = Path ( ) / project_name \n app_dir = apps_dir / self . app_name \n final_app_name = f\"<STR_LIT>\" \n try : \n app_dir . mkdir ( ) \n except FileExistsError as e : \n msg = f\"<STR_LIT>\" \n raise cappa . Exit ( msg , code = <NUM_LIT> ) from e \n with simple_progress ( f\"<STR_LIT>\" ) : \n result = subprocess . run ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , self . app_name , app_dir ] , \n capture_output = True , \n text = True , \n check = False , \n ) \n if result . returncode != <NUM_LIT> : \n msg = result . stderr . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n raise cappa . Exit ( msg , code = <NUM_LIT> ) \n ( app_dir / \"<STR_LIT>\" ) . unlink ( ) \n model_name = self . app_name [ : - <NUM_LIT> ] . capitalize ( ) if self . app_name . endswith ( \"<STR_LIT>\" ) else self . app_name . capitalize ( ) \n models_file = app_dir / \"<STR_LIT>\" \n models_file . write_text ( \n ) \n ( app_dir / \"<STR_LIT>\" ) . write_text ( \"<STR_LIT>\" ) \n ( app_dir / \"<STR_LIT>\" ) . write_text ( \"<STR_LIT>\" ) \n app_config_file = app_dir / \"<STR_LIT>\" \n app_config_file . write_text ( app_config_file . read_text ( ) . replace ( self . app_name , final_app_name ) ) \n run_python_formatters ( models_file ) \n run_python_formatters ( self . register_app ( app_name = final_app_name ) ) \n @ simple_progress ( \"<STR_LIT>\" ) \n def register_app ( self , app_name : str ) -> Path : \n names = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n settings_file = Path ( run_in_shell ( get_settings_file_path , eval_result = False ) ) \n module = parso . parse ( settings_file . read_text ( ) ) \n for node in module . children : \n try : \n if ( \n node . children [ <NUM_LIT> ] . type == parso . python . tree . ExprStmt . type \n and node . children [ <NUM_LIT> ] . children [ <NUM_LIT> ] . value in names \n ) : \n apps = node . children [ <NUM_LIT> ] . children [ <NUM_LIT> ] \n elements = apps . children [ <NUM_LIT> ] \n elements . children . append ( parso . parse ( f\"<STR_LIT>\" ) ) \n new_content = module . get_code ( ) \n settings_file . write_text ( new_content ) \n break \n except AttributeError : \n continue \n return settings_file"}, {"input": "from django . db import migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) ,", "output": "] \n operations = [ \n migrations . RenameModel ( \n old_name = '<STR_LIT>' , \n new_name = '<STR_LIT>' , \n ) , \n ]"}, {"input": "from abc import ABCMeta \n from dataclasses import dataclass \n from enum import Enum \n from typing import ( \n Any , \n ClassVar , \n Generic , \n NotRequired , \n Protocol , \n Required , \n Self , \n TypedDict , \n TypeVar , \n ) \n from django . core . exceptions import ImproperlyConfigured \n from django . core . files import File \n from . . import tokens \n from . . types import ( \n AIResponse , \n TextSplitterLengthCalculatorProtocol , \n TextSplitterProtocol , \n ) \n class BackendFeature ( Enum ) : \n TEXT_COMPLETION = \"<STR_LIT>\" \n IMAGE_DESCRIPTION = \"<STR_LIT>\" \n class BaseAIBackendConfigSettings ( TypedDict ) : \n MODEL_ID : Required [ str ] \n TOKEN_LIMIT : NotRequired [ int | None ] \n AIBackendConfigSettings = TypeVar ( \n \"<STR_LIT>\" , bound = BaseAIBackendConfigSettings , contravariant = True \n ) \n class ConfigClassProtocol ( Protocol [ AIBackendConfigSettings ] ) : \n @ classmethod \n def from_settings ( cls , config : AIBackendConfigSettings , ** kwargs : Any ) -> Self : \n ... \n @ dataclass ( kw_only = True ) \n class BaseAIBackendConfig ( ConfigClassProtocol [ AIBackendConfigSettings ] ) : \n model_id : str \n token_limit : int \n text_splitter_class : type [ TextSplitterProtocol ] \n text_splitter_length_calculator_class : type [ TextSplitterLengthCalculatorProtocol ] \n @ classmethod \n def from_settings ( \n cls , \n config : AIBackendConfigSettings , \n * , \n text_splitter_class : type [ TextSplitterProtocol ] , \n text_splitter_length_calculator_class : type [ \n TextSplitterLengthCalculatorProtocol \n ] , \n ** kwargs : Any , \n ) -> Self : \n token_limit = cls . get_token_limit ( \n model_id = config [ \"<STR_LIT>\" ] , custom_value = config . get ( \"<STR_LIT>\" ) \n ) \n return cls ( \n model_id = config [ \"<STR_LIT>\" ] , \n token_limit = token_limit , \n text_splitter_class = text_splitter_class , \n text_splitter_length_calculator_class = text_splitter_length_calculator_class , \n ** kwargs , \n )", "output": "@ classmethod \n def get_token_limit ( cls , * , model_id : str , custom_value : int | None ) -> int : \n if custom_value is not None : \n try : \n return int ( custom_value ) \n except ValueError as e : \n raise ImproperlyConfigured ( \n f'<STR_LIT>' \n ) from e \n try : \n return tokens . get_default_token_limit ( model_id = model_id ) \n except tokens . NoTokenLimitFound as e : \n raise ImproperlyConfigured ( \n f'<STR_LIT>' \n ) from e \n AIBackendConfig = TypeVar ( \"<STR_LIT>\" , bound = BaseAIBackendConfig ) \n class AIBackend ( Generic [ AIBackendConfig ] , metaclass = ABCMeta ) : \n config_cls : ClassVar [ type [ ConfigClassProtocol ] ] \n config : AIBackendConfig \n def __init__ ( \n self , \n * , \n config : AIBackendConfig , \n ) -> None : \n self . config = config \n def prompt_with_context ( \n self , * , pre_prompt : str , context : str , post_prompt : str | None = None \n ) -> AIResponse : \n raise NotImplementedError ( \"<STR_LIT>\" ) \n def get_text_splitter ( self ) -> TextSplitterProtocol : \n return self . config . text_splitter_class ( \n chunk_size = self . config . token_limit , \n length_function = self . get_splitter_length_calculator ( ) . get_splitter_length , \n ) \n def get_splitter_length_calculator ( self ) -> TextSplitterLengthCalculatorProtocol : \n return self . config . text_splitter_length_calculator_class ( ) \n def describe_image ( self , * , image_file : File , prompt : str ) -> AIResponse : \n raise NotImplementedError ( \"<STR_LIT>\" )"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) ,", "output": "( \"<STR_LIT>\" , models . TextField ( ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n choices = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] , \n max_length = <NUM_LIT> , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True ) ) , \n ( \"<STR_LIT>\" , models . FileField ( upload_to = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . ForeignKey ( \n on_delete = django . db . models . deletion . CASCADE , \n to = settings . AUTH_USER_MODEL , \n ) , \n ) , \n ] , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . FileField ( upload_to = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . TextField ( ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . ForeignKey ( \n on_delete = django . db . models . deletion . CASCADE , \n related_name = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ForeignKey ( \n on_delete = django . db . models . deletion . CASCADE , \n to = settings . AUTH_USER_MODEL , \n ) , \n ) , \n ] , \n ) , \n ]"}, {"input": "import torch \n import torch . nn as nn \n import torch . nn . functional as F \n import models \n from models . densenet import DenseNet \n from models . counting import CountingDecoder as counting_decoder \n from counting_utils import gen_counting_label \n class CAN ( nn . Module ) : \n def __init__ ( self , params = None ) : \n super ( CAN , self ) . __init__ ( )", "output": "self . params = params \n self . use_label_mask = params [ '<STR_LIT>' ] \n self . encoder = DenseNet ( params = self . params ) \n self . in_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . out_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . counting_decoder1 = counting_decoder ( self . in_channel , self . out_channel , <NUM_LIT> ) \n self . counting_decoder2 = counting_decoder ( self . in_channel , self . out_channel , <NUM_LIT> ) \n self . decoder = getattr ( models , params [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) ( params = self . params ) \n self . cross = nn . CrossEntropyLoss ( reduction = '<STR_LIT>' ) if self . use_label_mask else nn . CrossEntropyLoss ( ) \n self . counting_loss = nn . SmoothL1Loss ( reduction = '<STR_LIT>' ) \n self . ratio = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n def forward ( self , images , images_mask , labels , labels_mask , is_train = True ) : \n cnn_features = self . encoder ( images ) \n counting_mask = images_mask [ : , : , : : self . ratio , : : self . ratio ] \n counting_labels = gen_counting_label ( labels , self . out_channel , True ) \n counting_preds1 , _ = self . counting_decoder1 ( cnn_features , counting_mask ) \n counting_preds2 , _ = self . counting_decoder2 ( cnn_features , counting_mask ) \n counting_preds = ( counting_preds1 + counting_preds2 ) / <NUM_LIT> \n counting_loss = self . counting_loss ( counting_preds1 , counting_labels ) + self . counting_loss ( counting_preds2 , counting_labels ) + self . counting_loss ( counting_preds , counting_labels ) \n word_probs , word_alphas = self . decoder ( cnn_features , labels , counting_preds , images_mask , labels_mask , is_train = is_train ) \n word_loss = self . cross ( word_probs . contiguous ( ) . view ( - <NUM_LIT> , word_probs . shape [ - <NUM_LIT> ] ) , labels . view ( - <NUM_LIT> ) ) \n word_average_loss = ( word_loss * labels_mask . view ( - <NUM_LIT> ) ) . sum ( ) / ( labels_mask . sum ( ) + <NUM_LIT> ) if self . use_label_mask else word_loss \n return word_probs , counting_preds , word_average_loss , counting_loss"}, {"input": "from django . contrib . auth import get_user_model \n from django . db import models \n from rest_framework_api_key . models import APIKey \n User = get_user_model ( ) \n class CollectionStatus ( models . TextChoices ) : \n COMPLETE = \"<STR_LIT>\" \n RUNNING = \"<STR_LIT>\" \n QUEUED = \"<STR_LIT>\" \n ERROR = \"<STR_LIT>\" \n class Document ( models . Model ) : \n collection = models . ForeignKey ( \n \"<STR_LIT>\" , related_name = \"<STR_LIT>\" , on_delete = models . CASCADE \n ) \n file = models . FileField ( upload_to = \"<STR_LIT>\" ) \n description = models . TextField ( ) \n created = models . DateTimeField ( auto_now_add = True )", "output": "modified = models . DateTimeField ( auto_now = True ) \n class Collection ( models . Model ) : \n api_key = models . ForeignKey ( APIKey , blank = True , null = True , on_delete = models . CASCADE ) \n title = models . CharField ( max_length = <NUM_LIT> ) \n description = models . TextField ( ) \n status = models . CharField ( max_length = <NUM_LIT> , choices = CollectionStatus . choices ) \n created = models . DateTimeField ( auto_now_add = True ) \n modified = models . DateTimeField ( auto_now = True ) \n model = models . FileField ( upload_to = \"<STR_LIT>\" ) \n processing = models . BooleanField ( blank = True , null = True , default = False ) \n def __str__ ( self ) : \n return self . title"}, {"input": "import inspect \n import logging \n from typing import List , Type \n import django . test \n from ninja_crud . testing . views import AbstractModelViewTest \n from ninja_crud . views import AbstractModelView \n from ninja_crud . viewsets import ModelViewSet \n logger = logging . getLogger ( __name__ ) \n class ModelViewSetTestCase ( django . test . TestCase ) : \n model_viewset_class : Type [ ModelViewSet ] \n base_path : str \n def __init_subclass__ ( cls , ** kwargs ) : \n super ( ) . __init_subclass__ ( ** kwargs ) \n if hasattr ( cls , \"<STR_LIT>\" ) : \n cls . _bind_test_model_views ( ) \n cls . _register_test_methods ( ) \n @ classmethod \n def _bind_test_model_views ( cls ) : \n associated_model_views = [ ] \n cls_instance = cls ( ) \n for attr_name , attr_value in inspect . getmembers ( cls ) : \n if attr_name . startswith ( \"<STR_LIT>\" ) and isinstance ( \n attr_value , AbstractModelViewTest \n ) : \n test_model_view_name , test_model_view = attr_name , attr_value \n test_model_view . bind_to_model_viewset_test_case (", "output": "model_viewset_test_case = cls_instance \n ) \n associated_model_view = cls . _get_associated_model_view ( \n test_attr_name = test_model_view_name , \n model_view_class = test_model_view . model_view_class , \n ) \n test_model_view . bind_to_model_view ( model_view = associated_model_view ) \n associated_model_views . append ( associated_model_view ) \n cls . _check_all_model_views_associated ( \n associated_model_views = associated_model_views \n ) \n @ classmethod \n def _register_test_methods ( cls ) : \n for attr_name , attr_value in inspect . getmembers ( cls ) : \n if attr_name . startswith ( \"<STR_LIT>\" ) and isinstance ( \n attr_value , AbstractModelViewTest \n ) : \n for method_name , method in inspect . getmembers ( \n attr_value , predicate = inspect . ismethod \n ) : \n if method_name . startswith ( \"<STR_LIT>\" ) : \n new_test_method_name = f\"<STR_LIT>\" \n setattr ( cls , new_test_method_name , method ) \n @ classmethod \n def _get_associated_model_view ( \n cls , test_attr_name : str , model_view_class : Type [ AbstractModelView ] \n ) -> AbstractModelView : \n for attr_name , attr_value in inspect . getmembers ( cls . model_viewset_class ) : \n if ( \n isinstance ( attr_value , model_view_class ) \n and test_attr_name == f\"<STR_LIT>\" \n ) : \n return attr_value \n raise ValueError ( \n f\"<STR_LIT>\" \n ) \n @ classmethod \n def _check_all_model_views_associated ( \n cls , associated_model_views : List [ AbstractModelView ] \n ) -> None : \n for attr_name , attr_value in inspect . getmembers ( cls . model_viewset_class ) : \n if ( \n isinstance ( attr_value , AbstractModelView ) \n and attr_value not in associated_model_views \n ) : \n logger . warning ( \n f\"<STR_LIT>\" \n )"}, {"input": "from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) :", "output": "dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . TextField ( ) ) , \n ( '<STR_LIT>' , models . BooleanField ( default = False ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( blank = True , null = True , on_delete = django . db . models . deletion . CASCADE , related_name = '<STR_LIT>' , to = '<STR_LIT>' ) ) , \n ] , \n ) , \n ]"}, {"input": "class NoTokenLimitFound ( Exception ) : \n pass \n def get_default_token_limit ( model_id : str ) -> int : \n match model_id : \n case \"<STR_LIT>\" : \n return <NUM_LIT> \n case \"<STR_LIT>\" : \n return <NUM_LIT> \n case \"<STR_LIT>\" :", "output": "return <NUM_LIT> \n case \"<STR_LIT>\" : \n return <NUM_LIT> \n case _ : \n raise NoTokenLimitFound ( model_id )"}, {"input": "import django . db . models . deletion \n from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True , null = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . SlugField ( \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n unique = True , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n choices = [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ] , \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . URLField ( help_text = \"<STR_LIT>\" ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> ,", "output": ") , \n ) , \n ( \n \"<STR_LIT>\" , \n models . TextField ( \n help_text = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ForeignKey ( \n blank = True , \n help_text = \"<STR_LIT>\" , \n null = True , \n on_delete = django . db . models . deletion . SET_NULL , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : False , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True , null = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n choices = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] , \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ManyToManyField ( \n blank = True , \n help_text = \"<STR_LIT>\" , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . ForeignKey ( \n help_text = \"<STR_LIT>\" , \n on_delete = django . db . models . deletion . CASCADE , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : False , \n } , \n ) , \n ]"}, {"input": "from typing import List \n from django . contrib . auth . models import User \n from ninja import Router \n from ninja_crud import views \n from ninja_crud . viewsets import ModelViewSet \n from tests . test_app . schemas import ( \n UserQueryParameters , \n UserRequestBody , \n UserResponseBody , \n ) \n router = Router ( ) \n class UserViewSet ( ModelViewSet ) : \n model = User \n list_users = views . ListModelView ( \n query_parameters = UserQueryParameters , \n response_body = List [ UserResponseBody ] , \n pagination_class = None , \n ) \n create_user = views . CreateModelView ( \n request_body = UserRequestBody , response_body = UserResponseBody", "output": ") \n read_user = views . ReadModelView ( response_body = UserResponseBody ) \n update_user = views . UpdateModelView ( \n request_body = UserRequestBody , response_body = UserResponseBody \n ) \n delete_user = views . DeleteModelView ( ) \n UserViewSet . register_routes ( router )"}, {"input": "import pathlib \n from tempfile import TemporaryDirectory \n from falco . commands import StartProject \n from rich . console import Console \n from rich . markup import escape \n from rich . terminal_theme import DIMMED_MONOKAI \n from rich . text import Text \n from rich . tree import Tree \n def walk_directory ( directory : pathlib . Path , tree : Tree ) -> None : \n paths = sorted ( \n pathlib . Path ( directory ) . iterdir ( ) , \n key = lambda path : ( path . is_file ( ) , path . name . lower ( ) ) , \n ) \n for path in paths : \n if path . is_dir ( ) : \n style = \"<STR_LIT>\" if path . name . startswith ( \"<STR_LIT>\" ) else \"<STR_LIT>\" \n branch = tree . add ( \n f\"<STR_LIT>\" , \n style = style , \n guide_style = style , \n ) \n walk_directory ( path , branch ) \n else : \n text_filename = Text ( path . name , \"<STR_LIT>\" ) \n text_filename . highlight_regex ( r\"<STR_LIT>\" , \"<STR_LIT>\" ) \n text_filename . stylize ( f\"<STR_LIT>\" ) \n icon = \"<STR_LIT>\" if path . suffix == \"<STR_LIT>\" else \"<STR_LIT>\" \n tree . add ( Text ( icon ) + text_filename ) \n def main ( ) : \n tree = Tree ( \n \"<STR_LIT>\" \n ) \n with TemporaryDirectory ( ) as temp : \n temp_dir = pathlib . Path ( temp ) \n StartProject ( \n project_name = \"<STR_LIT>\" , \n directory = temp_dir . resolve ( ) , \n is_root = True , \n skip_new_version_check = True , \n ) ( ) \n walk_directory ( temp_dir , tree ) \n console = Console ( record = True ) \n with console . capture ( ) :", "output": "console . print ( tree ) \n console . save_svg ( \n \"<STR_LIT>\" , \n title = \"<STR_LIT>\" , \n theme = DIMMED_MONOKAI , \n ) \n if __name__ == \"<STR_LIT>\" : \n main ( )"}, {"input": "import logging \n import httpx \n from asgiref . sync import sync_to_async \n from django . contrib . auth import get_user_model \n from django . test import AsyncClient , TransactionTestCase \n from rest_framework_api_key . models import APIKey \n from config import asgi \n from config . api . endpoints import collections_router \n from delphic . indexes . models import Collection , Document \n User = get_user_model ( ) \n logging . basicConfig ( \n format = \"<STR_LIT>\" , \n datefmt = \"<STR_LIT>\" , \n level = logging . DEBUG , \n ) \n class CollectionTestCase ( TransactionTestCase ) : \n @ sync_to_async \n def get_request_key ( self ) : \n api_key , request_key = APIKey . objects . create_key ( name = \"<STR_LIT>\" ) \n return request_key \n def setUp ( self ) : \n self . user = User . objects . create_user ( \n username = \"<STR_LIT>\" , password = \"<STR_LIT>\" \n ) \n self . client = AsyncClient ( collections_router ) \n async def test_create_collection ( self ) : \n request_key = await self . get_request_key ( ) \n print ( f\"<STR_LIT>\" ) \n file_content = b\"<STR_LIT>\" \n collection_data = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n headers = { \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n } \n files = [ \n ( \"<STR_LIT>\" , ( \"<STR_LIT>\" , file_content , \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , ( \"<STR_LIT>\" , file_content , \"<STR_LIT>\" ) ) ,", "output": "] \n async with httpx . AsyncClient ( \n app = asgi . application , base_url = \"<STR_LIT>\" \n ) as client : \n response = await client . post ( \n \"<STR_LIT>\" , \n data = collection_data , \n files = files , \n headers = headers , \n ) \n print ( response . text ) \n print ( f\"<STR_LIT>\" ) \n self . assertEqual ( response . status_code , <NUM_LIT> ) \n response_data = response . json ( ) \n self . assertEqual ( response_data [ \"<STR_LIT>\" ] , collection_data [ \"<STR_LIT>\" ] ) \n self . assertEqual ( response_data [ \"<STR_LIT>\" ] , collection_data [ \"<STR_LIT>\" ] ) \n self . assertEqual ( response_data [ \"<STR_LIT>\" ] , \"<STR_LIT>\" ) \n collection_instance = await Collection . objects . aget ( id = response_data [ \"<STR_LIT>\" ] ) \n collection_doc_count = await sync_to_async ( \n collection_instance . documents . count \n ) ( ) \n self . assertEqual ( collection_doc_count , <NUM_LIT> ) \n async for document in collection_instance . documents . all ( ) : \n await sync_to_async ( document . file . delete ) ( ) \n await sync_to_async ( collection_instance . delete ) ( ) \n async def test_add_file_to_collection ( self ) : \n key = await self . get_request_key ( ) \n api_key = await sync_to_async ( APIKey . objects . get_from_key ) ( key ) \n collection = await sync_to_async ( Collection . objects . create ) ( \n api_key = api_key , \n title = \"<STR_LIT>\" , \n description = \"<STR_LIT>\" , \n status = \"<STR_LIT>\" , \n ) \n file_content = b\"<STR_LIT>\" \n file_name = \"<STR_LIT>\" \n file_content_type = \"<STR_LIT>\" \n file = ( file_name , file_content , file_content_type ) \n headers = { \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n } \n data = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n files = [ \n ( \"<STR_LIT>\" , file ) , \n ] \n async with httpx . AsyncClient ( \n app = asgi . application , base_url = \"<STR_LIT>\" \n ) as client : \n response = await client . post ( \n f\"<STR_LIT>\" , \n data = data , \n files = files , \n headers = headers , \n ) \n self . assertEqual ( response . status_code , <NUM_LIT> ) \n response_data = response . json ( ) \n self . assertEqual ( \n response_data [ \"<STR_LIT>\" ] , \n f\"<STR_LIT>\" , \n ) \n collection_instance = await Collection . objects . aget ( id = collection . id ) \n collection_doc_count = await sync_to_async ( \n collection_instance . documents . count \n ) ( ) \n self . assertEqual ( collection_doc_count , <NUM_LIT> ) \n document = await sync_to_async ( Document . objects . get ) ( \n collection = collection_instance \n ) \n self . assertEqual ( document . file . name , f\"<STR_LIT>\" ) \n self . assertEqual ( document . description , data [ \"<STR_LIT>\" ] ) \n await sync_to_async ( document . file . delete ) ( ) \n await sync_to_async ( collection_instance . delete ) ( )"}, {"input": "from typing import Dict , List , Union \n from core . address_api import AddressAPI \n from feeds . models import Entry , Location \n from feeds . serializers import BulkEntrySerializer \n from trquake . celery import app \n @ app . task \n def process_entry ( entry_id : int ) : \n address_api = AddressAPI ( ) \n entry = Entry . objects . get ( id = entry_id ) \n address_text = entry . full_text \n if not entry . is_resolved and not entry . is_geolocated : \n regex_response = address_api . regex_api_request ( entry . full_text ) \n if regex_response [ \"<STR_LIT>\" ] < <NUM_LIT> : \n return \n address_text = regex_response [ \"<STR_LIT>\" ] \n if not entry . is_geolocated : \n geolocation = address_api . trendyol_bff_api_request ( address_text ) \n if geolocation . get ( \"<STR_LIT>\" , False ) : \n entry . is_resolved = True \n entry . save ( ) \n Location . objects . create ( \n entry = entry , \n latitude = geolocation [ \"<STR_LIT>\" ] , \n longitude = geolocation [ \"<STR_LIT>\" ] , \n northeast_lat = geolocation [ \"<STR_LIT>\" ] ,", "output": "northeast_lng = geolocation [ \"<STR_LIT>\" ] , \n southwest_lat = geolocation [ \"<STR_LIT>\" ] , \n southwest_lng = geolocation [ \"<STR_LIT>\" ] , \n formatted_address = geolocation [ \"<STR_LIT>\" ] , \n ) \n else : \n Location . objects . create ( entry = entry , latitude = entry . location [ <NUM_LIT> ] , longitude = entry . location [ <NUM_LIT> ] ) \n @ app . task \n def write_bulk_entries ( entries : List [ Dict [ str , Union [ str , bool ] ] ] ) : \n for entry_data in entries : \n serializer = BulkEntrySerializer ( data = entry_data ) \n if serializer . is_valid ( ) : \n entry : Entry = serializer . save ( ) \n process_entry ( entry_id = entry . id )"}, {"input": "import base64 \n import hashlib \n from datetime import datetime , timedelta \n from captcha . views import CaptchaStore , captcha_image \n from django . contrib import auth \n from django . contrib . auth import login \n from django . shortcuts import redirect \n from django . utils . translation import gettext_lazy as _ \n from drf_yasg import openapi \n from drf_yasg . utils import swagger_auto_schema \n from rest_framework import serializers \n from rest_framework . views import APIView \n from rest_framework_simplejwt . serializers import TokenObtainPairSerializer \n from rest_framework_simplejwt . views import TokenObtainPairView \n from django . conf import settings \n from application import dispatch \n from dvadmin . system . models import Users \n from dvadmin . utils . json_response import ErrorResponse , DetailResponse \n from dvadmin . utils . request_util import save_login_log \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . validator import CustomValidationError \n class CaptchaView ( APIView ) : \n authentication_classes = [ ] \n permission_classes = [ ] \n @ swagger_auto_schema ( \n responses = { \"<STR_LIT>\" : openapi . Response ( \"<STR_LIT>\" ) } , \n security = [ ] , \n operation_id = \"<STR_LIT>\" , \n operation_description = \"<STR_LIT>\" , \n ) \n def get ( self , request ) : \n data = { } \n if dispatch . get_system_config_values ( \"<STR_LIT>\" ) : \n hashkey = CaptchaStore . generate_key ( ) \n id = CaptchaStore . objects . filter ( hashkey = hashkey ) . first ( ) . id \n imgage = captcha_image ( request , hashkey ) \n image_base = base64 . b64encode ( imgage . content ) \n data = { \n \"<STR_LIT>\" : id , \n \"<STR_LIT>\" : \"<STR_LIT>\" + image_base . decode ( \"<STR_LIT>\" ) , \n } \n return DetailResponse ( data = data ) \n class LoginSerializer ( TokenObtainPairSerializer ) : \n captcha = serializers . CharField ( \n max_length = <NUM_LIT> , required = False , allow_null = True , allow_blank = True \n ) \n class Meta : \n model = Users", "output": "fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n default_error_messages = { \"<STR_LIT>\" : _ ( \"<STR_LIT>\" ) } \n def validate ( self , attrs ) : \n captcha = self . initial_data . get ( \"<STR_LIT>\" , None ) \n if dispatch . get_system_config_values ( \"<STR_LIT>\" ) : \n if captcha is None : \n raise CustomValidationError ( \"<STR_LIT>\" ) \n self . image_code = CaptchaStore . objects . filter ( \n id = self . initial_data [ \"<STR_LIT>\" ] \n ) . first ( ) \n five_minute_ago = datetime . now ( ) - timedelta ( hours = <NUM_LIT> , minutes = <NUM_LIT> , seconds = <NUM_LIT> ) \n if self . image_code and five_minute_ago > self . image_code . expiration : \n self . image_code and self . image_code . delete ( ) \n raise CustomValidationError ( \"<STR_LIT>\" ) \n else : \n if self . image_code and ( \n self . image_code . response == captcha \n or self . image_code . challenge == captcha \n ) : \n self . image_code and self . image_code . delete ( ) \n else : \n self . image_code and self . image_code . delete ( ) \n raise CustomValidationError ( \"<STR_LIT>\" ) \n user = Users . objects . get ( username = attrs [ '<STR_LIT>' ] ) \n if not user . is_active : \n raise CustomValidationError ( \"<STR_LIT>\" ) \n data = super ( ) . validate ( attrs ) \n data [ \"<STR_LIT>\" ] = self . user . name \n data [ \"<STR_LIT>\" ] = self . user . id \n data [ \"<STR_LIT>\" ] = self . user . avatar \n data [ '<STR_LIT>' ] = self . user . user_type \n dept = getattr ( self . user , '<STR_LIT>' , None ) \n if dept : \n data [ '<STR_LIT>' ] = { \n '<STR_LIT>' : dept . id , \n '<STR_LIT>' : dept . name , \n } \n role = getattr ( self . user , '<STR_LIT>' , None ) \n if role : \n data [ '<STR_LIT>' ] = role . values ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n request = self . context . get ( \"<STR_LIT>\" ) \n request . user = self . user \n save_login_log ( request = request ) \n return { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : data } \n class LoginView ( TokenObtainPairView ) : \n serializer_class = LoginSerializer \n permission_classes = [ ] \n class LoginTokenSerializer ( TokenObtainPairSerializer ) : \n class Meta : \n model = Users \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n default_error_messages = { \"<STR_LIT>\" : _ ( \"<STR_LIT>\" ) } \n def validate ( self , attrs ) : \n if not getattr ( settings , \"<STR_LIT>\" , False ) : \n return { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : None } \n data = super ( ) . validate ( attrs ) \n data [ \"<STR_LIT>\" ] = self . user . name \n data [ \"<STR_LIT>\" ] = self . user . id \n return { \"<STR_LIT>\" : <NUM_LIT> , \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : data } \n class LoginTokenView ( TokenObtainPairView ) : \n serializer_class = LoginTokenSerializer \n permission_classes = [ ] \n class LogoutView ( APIView ) : \n def post ( self , request ) : \n return DetailResponse ( msg = \"<STR_LIT>\" ) \n class ApiLoginSerializer ( CustomModelSerializer ) : \n username = serializers . CharField ( ) \n password = serializers . CharField ( ) \n class Meta : \n model = Users \n fields = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n class ApiLogin ( APIView ) : \n serializer_class = ApiLoginSerializer \n authentication_classes = [ ] \n permission_classes = [ ] \n def post ( self , request ) : \n username = request . data . get ( \"<STR_LIT>\" ) \n password = request . data . get ( \"<STR_LIT>\" ) \n user_obj = auth . authenticate ( \n request , \n username = username , \n password = hashlib . md5 ( password . encode ( encoding = \"<STR_LIT>\" ) ) . hexdigest ( ) , \n ) \n if user_obj : \n login ( request , user_obj ) \n return redirect ( \"<STR_LIT>\" ) \n else : \n return ErrorResponse ( msg = \"<STR_LIT>\" )"}, {"input": "from typing import List \n from unittest . mock import MagicMock \n from django . test import TestCase \n from ninja_crud import views , viewsets \n from tests . test_app . models import Item \n from tests . test_app . schemas import ItemOut \n class TestListModelView ( TestCase ) : \n def test_register_route_with_router_kwargs ( self ) : \n router_mock = MagicMock ( ) \n class ItemViewSet ( viewsets . ModelViewSet ) : \n model = Item \n list_items = views . ListModelView ( \n response_body = List [ ItemOut ] , \n router_kwargs = { \"<STR_LIT>\" : True } , \n ) \n ItemViewSet . list_items . register_route ( router_mock , \"<STR_LIT>\" ) \n router_mock . api_operation . assert_called_once ( ) \n self . assertTrue ( router_mock . api_operation . call_args [ <NUM_LIT> ] [ \"<STR_LIT>\" ] ) \n def test_bind_to_viewset_without_response_body_error ( self ) :", "output": "model_view = views . ListModelView ( ) \n class ItemModelViewSet ( viewsets . ModelViewSet ) : \n model = Item \n with self . assertRaises ( AttributeError ) : \n model_view . model_viewset_class = ItemModelViewSet"}, {"input": "import http \n from typing import Callable , Dict , List , Optional , Type \n from django . db . models import Model \n from django . http import HttpRequest \n from ninja import Schema \n from ninja_crud . views . abstract_model_view import AbstractModelView \n from ninja_crud . views . enums import HTTPMethod \n class ReadModelView ( AbstractModelView ) : \n def __init__ ( \n self , \n path : str = \"<STR_LIT>\" , \n path_parameters : Optional [ Type [ Schema ] ] = None , \n query_parameters : Optional [ Type [ Schema ] ] = None , \n response_body : Optional [ Type [ Schema ] ] = None , \n decorators : Optional [ List [ Callable ] ] = None ,", "output": "router_kwargs : Optional [ Dict ] = None , \n read_model : Optional [ \n Callable [ [ HttpRequest , Optional [ Schema ] , Optional [ Schema ] ] , Model ] \n ] = None , \n ) -> None : \n super ( ) . __init__ ( \n method = HTTPMethod . GET , \n path = path , \n path_parameters = path_parameters , \n query_parameters = query_parameters , \n request_body = None , \n response_body = response_body , \n response_status = http . HTTPStatus . OK , \n decorators = decorators , \n router_kwargs = router_kwargs , \n ) \n self . read_model = read_model or self . _default_read_model \n def _default_read_model ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] , \n query_parameters : Optional [ Schema ] , \n ) -> Model : \n return self . model_viewset_class . model . objects . get ( \n ** ( path_parameters . dict ( ) if path_parameters else { } ) \n ) \n def handle_request ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] , \n query_parameters : Optional [ Schema ] , \n request_body : Optional [ Schema ] , \n ) -> Model : \n return self . read_model ( request , path_parameters , query_parameters ) \n def _inherit_model_viewset_class_attributes ( self ) -> None : \n if self . response_body is None : \n self . response_body = self . model_viewset_class . default_response_body"}, {"input": "from __future__ import annotations \n import os \n import secrets \n import shutil \n import subprocess \n from contextlib import contextmanager \n from contextlib import suppress \n from pathlib import Path \n from typing import Annotated \n import cappa \n import httpx \n from cookiecutter . config import get_user_config \n from cookiecutter . exceptions import CookiecutterException \n from cookiecutter . main import cookiecutter \n from falco . commands import InstallCrudUtils \n from falco . commands . crud . utils import run_html_formatters \n from falco . commands . htmx import get_latest_tag as htmx_latest_tag \n from falco . commands . htmx import Htmx \n from falco . config import read_falco_config \n from falco . config import write_falco_config \n from falco . utils import clean_project_name \n from falco . utils import is_new_falco_cli_available \n from falco . utils import RICH_INFO_MARKER \n from falco . utils import RICH_SUCCESS_MARKER \n from falco . utils import simple_progress \n from rich import print as rich_print \n from rich . prompt import Prompt \n DEFAULT_SKIP = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n @ cappa . command ( help = \"<STR_LIT>\" ) \n class StartProject : \n project_name : Annotated [ \n str , \n cappa . Arg ( parse = clean_project_name , help = \"<STR_LIT>\" ) , \n ] \n directory : Annotated [ Path | None , cappa . Arg ( help = \"<STR_LIT>\" ) ] = None \n is_root : Annotated [ \n bool , \n cappa . Arg ( \n default = False , \n short = \"<STR_LIT>\" , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] = False \n skip_new_version_check : Annotated [ \n bool , \n cappa . Arg ( \n default = False , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] = False \n blueprint : Annotated [ \n str , \n cappa . Arg ( \n default = \"<STR_LIT>\" , \n long = \"<STR_LIT>\" , \n short = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] = \"<STR_LIT>\" \n local : Annotated [ \n bool , \n cappa . Arg ( \n default = False ,", "output": "long = \"<STR_LIT>\" , \n short = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] = False \n checkout : Annotated [ str | None , cappa . Arg ( default = None , long = \"<STR_LIT>\" , short = \"<STR_LIT>\" , hidden = True ) ] = None \n def __call__ ( self ) -> None : \n if self . is_root and not self . directory : \n raise cappa . Exit ( \"<STR_LIT>\" , code = <NUM_LIT> ) \n if not self . skip_new_version_check and is_new_falco_cli_available ( ) : \n message = ( \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n ) \n rich_print ( message ) \n response = Prompt . ask ( \n f\"<STR_LIT>\" , \n default = \"<STR_LIT>\" , \n ) \n if response . lower ( ) == \"<STR_LIT>\" : \n rich_print ( \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n ) \n raise cappa . Exit ( code = <NUM_LIT> ) \n with simple_progress ( \"<STR_LIT>\" ) : \n self . blueprint , revision = resolve_blueprint ( self . blueprint , use_local = self . local ) \n project_dir = self . init_project ( ) \n with change_directory ( project_dir ) : \n pyproject_path = Path ( \"<STR_LIT>\" ) \n falco_config = read_falco_config ( pyproject_path ) \n crud_utils = InstallCrudUtils ( ) . install ( project_name = self . project_name , falco_config = falco_config ) \n env_file = Path ( \"<STR_LIT>\" ) \n env_file . touch ( ) \n env_file . write_text ( \"<STR_LIT>\" ) \n config = { \n \"<STR_LIT>\" : { \"<STR_LIT>\" : str ( crud_utils ) } , \n \"<STR_LIT>\" : revision , \n \"<STR_LIT>\" : DEFAULT_SKIP , \n \"<STR_LIT>\" : self . blueprint , \n } \n if not self . local : \n with suppress ( cappa . Exit , httpx . TimeoutException , httpx . ConnectError ) : \n version = htmx_latest_tag ( ) \n filepath = Htmx ( ) . download ( version = htmx_latest_tag ( ) , falco_config = falco_config ) \n config [ \"<STR_LIT>\" ] = Htmx . format_for_config ( filepath , version ) \n write_falco_config ( pyproject_path = pyproject_path , ** config ) \n run_html_formatters ( project_dir / self . project_name / \"<STR_LIT>\" ) \n msg = f\"<STR_LIT>\" \n msg += ( \n f\"<STR_LIT>\" \n f\"<STR_LIT>\" \n ) \n rich_print ( msg ) \n def init_project ( self ) -> Path : \n author_name , author_email = get_authors_info ( ) \n with simple_progress ( \"<STR_LIT>\" ) : \n try : \n project_dir = cookiecutter ( \n self . blueprint , \n no_input = True , \n output_dir = self . directory or Path ( ) , \n checkout = self . checkout , \n extra_context = { \n \"<STR_LIT>\" : self . project_name , \n \"<STR_LIT>\" : author_name , \n \"<STR_LIT>\" : author_email , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n } , \n ) \n except CookiecutterException as e : \n msg = str ( e ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n raise cappa . Exit ( msg , code = <NUM_LIT> ) from e \n if self . is_root : \n renamed_project_dir = self . directory / \"<STR_LIT>\" \n shutil . move ( project_dir , renamed_project_dir ) \n for obj in Path ( renamed_project_dir ) . iterdir ( ) : \n shutil . move ( obj , self . directory ) \n renamed_project_dir . rmdir ( ) \n project_dir = self . directory \n return Path ( project_dir ) \n def find_local_cookiecutter ( repo : str ) -> Path | None : \n repo_name = repo . split ( \"<STR_LIT>\" ) [ - <NUM_LIT> ] . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n cookiecutters_dir = Path ( get_user_config ( ) [ \"<STR_LIT>\" ] ) \n if not cookiecutters_dir . exists ( ) : \n return None \n for directory in cookiecutters_dir . iterdir ( ) : \n if not directory . is_dir ( ) : \n continue \n is_empty = not list ( directory . iterdir ( ) ) \n if directory . is_dir ( ) and not is_empty and directory . name == repo_name : \n return directory \n return None \n def resolve_blueprint ( blueprint : str , * , use_local : bool = False ) -> tuple [ str , str ] : \n name_to_urls = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n repo = name_to_urls . get ( blueprint , blueprint ) \n if repo . startswith ( \"<STR_LIT>\" ) and use_local : \n if local_repo := find_local_cookiecutter ( repo ) : \n repo = str ( local_repo . resolve ( ) ) \n else : \n msg = f\"<STR_LIT>\" \n raise cappa . Exit ( msg , code = <NUM_LIT> ) \n result = subprocess . run ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , repo , \"<STR_LIT>\" ] , \n capture_output = True , \n text = True , \n check = False , \n ) \n if result . returncode != <NUM_LIT> : \n msg = f\"<STR_LIT>\" \n raise cappa . Exit ( msg , code = <NUM_LIT> ) \n revision = result . stdout . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] . split ( ) [ <NUM_LIT> ] . strip ( ) \n return repo , revision \n def get_authors_info ( ) -> tuple [ str , str ] : \n default_author_name = \"<STR_LIT>\" \n default_author_email = \"<STR_LIT>\" \n git_config_cmd = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] \n try : \n user_name_cmd = subprocess . run ( [ * git_config_cmd , \"<STR_LIT>\" ] , capture_output = True , text = True , check = False ) \n user_email_cmd = subprocess . run ( [ * git_config_cmd , \"<STR_LIT>\" ] , capture_output = True , text = True , check = False ) \n except FileNotFoundError : \n return default_author_name , default_author_email \n if user_email_cmd . returncode != <NUM_LIT> : \n return default_author_name , default_author_email \n return ( \n user_name_cmd . stdout . strip ( \"<STR_LIT>\" ) , \n user_email_cmd . stdout . strip ( \"<STR_LIT>\" ) , \n ) \n @ contextmanager \n def change_directory ( new_directory : str | Path ) : \n current_directory = Path . cwd ( ) \n try : \n os . chdir ( new_directory ) \n yield \n finally : \n os . chdir ( current_directory )"}, {"input": "from django . apps import AppConfig \n class WebhooksConfig ( AppConfig ) :", "output": "name = \"<STR_LIT>\" \n def ready ( self ) : \n from django . conf import settings \n from . settings import defaults \n d = getattr ( settings , \"<STR_LIT>\" , { } ) \n for k , v in defaults . items ( ) : \n if k not in d : \n d [ k ] = v \n settings . DJANGO_WEBHOOK = d \n import django_webhook . checks \n from django_webhook . models import populate_topics_from_settings \n from django_webhook . signals import connect_signals \n connect_signals ( ) \n populate_topics_from_settings ( )"}, {"input": "import random \n import time \n from collections . abc import Generator , Iterator \n from dataclasses import dataclass \n from typing import Any , NotRequired , Self \n from django . core . exceptions import ImproperlyConfigured \n from django . core . files import File \n from . base import ( \n AIBackend , \n AIResponse , \n BaseAIBackendConfig , \n BaseAIBackendConfigSettings , \n ) \n class EchoResponse ( AIResponse ) : \n _text : str | None = None \n response_iterator : Iterator [ str ] \n def __init__ ( self , response_iterator : Iterator [ str ] ) -> None : \n self . response_iterator = response_iterator \n def __iter__ ( self ) -> Iterator [ str ] : \n return self . response_iterator \n def text ( self ) -> str : \n if self . _text is not None : \n return self . _text \n self . _text = \"<STR_LIT>\" . join ( self . response_iterator ) \n return self . _text \n @ dataclass ( kw_only = True ) \n class EchoBackendSettingsDict ( BaseAIBackendConfigSettings ) : \n MAX_WORD_SLEEP_SECONDS : NotRequired [ int ] \n @ dataclass ( kw_only = True ) \n class EchoBackendConfig ( BaseAIBackendConfig [ EchoBackendSettingsDict ] ) : \n max_word_sleep_seconds : int \n @ classmethod \n def from_settings ( cls , config : EchoBackendSettingsDict , ** kwargs : Any ) -> Self : \n max_word_sleep_seconds = config . get ( \"<STR_LIT>\" ) \n if max_word_sleep_seconds is None : \n max_word_sleep_seconds = <NUM_LIT> \n try : \n max_word_sleep_seconds = int ( max_word_sleep_seconds ) \n except ValueError as e : \n raise ImproperlyConfigured (", "output": "f'<STR_LIT>' \n ) from e \n kwargs . setdefault ( \"<STR_LIT>\" , max_word_sleep_seconds ) \n return super ( ) . from_settings ( config , ** kwargs ) \n class EchoBackend ( AIBackend [ EchoBackendConfig ] ) : \n config_cls = EchoBackendConfig \n def prompt_with_context ( \n self , * , pre_prompt : str , context : str , post_prompt : str | None = None \n ) -> AIResponse : \n return self . get_response ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , * context . split ( ) ] \n ) \n def describe_image ( self , * , image_file : File , prompt : str ) -> AIResponse : \n return self . get_response ( \n [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , image_file . name ] \n ) \n def get_response ( self , words ) : \n def response_iterator ( ) -> Generator [ str , None , None ] : \n for word in words : \n if ( \n self . config . max_word_sleep_seconds is not None \n and self . config . max_word_sleep_seconds > <NUM_LIT> \n ) : \n time . sleep ( \n random . random ( ) \n * random . randint ( <NUM_LIT> , self . config . max_word_sleep_seconds ) \n ) \n yield word \n return EchoResponse ( response_iterator ( ) )"}, {"input": "import os \n import django \n from config . api . websockets . middleware import TokenAuthMiddleware \n django . setup ( ) \n import sys \n from pathlib import Path \n from channels . routing import ProtocolTypeRouter , URLRouter", "output": "from django . core . asgi import get_asgi_application \n from django . urls import re_path \n from config . api . websockets . queries import CollectionQueryConsumer \n BASE_DIR = Path ( __file__ ) . resolve ( strict = True ) . parent . parent \n sys . path . append ( str ( BASE_DIR / \"<STR_LIT>\" ) ) \n os . environ . setdefault ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n django_application = get_asgi_application ( ) \n application = ProtocolTypeRouter ( \n { \n \"<STR_LIT>\" : get_asgi_application ( ) , \n \"<STR_LIT>\" : TokenAuthMiddleware ( \n URLRouter ( \n [ \n re_path ( \n r\"<STR_LIT>\" , \n CollectionQueryConsumer . as_asgi ( ) , \n ) , \n ] \n ) \n ) , \n } \n )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [", "output": "( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . RemoveField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n ) , \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . CharField ( default = '<STR_LIT>' , max_length = <NUM_LIT> ) , \n ) , \n ]"}, {"input": "from playwright . sync_api import expect \n from tests . browser . conftest import ( \n expect_modal_closed , \n expect_modal_open , \n open_modal , \n search_box , \n search_button , \n ) \n def test_modal_admin_pages ( page_admin ) : \n for path in [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n page_admin . goto ( f\"<STR_LIT>\" ) \n expect ( search_button ( page_admin ) ) . to_be_visible ( ) \n expect_modal_closed ( page_admin ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n expect_modal_open ( page_admin ) \n def test_modal_other_pages ( page_admin ) : \n for path in [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n page_admin . goto ( f\"<STR_LIT>\" ) \n expect ( search_button ( page_admin ) ) . not_to_be_visible ( )", "output": "expect_modal_closed ( page_admin ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n expect_modal_closed ( page_admin ) \n def test_modal_click ( page_admin ) : \n expect_modal_closed ( page_admin ) \n button = search_button ( page_admin ) \n expect ( search_button ( page_admin ) ) . to_be_visible ( ) \n button . click ( ) \n expect_modal_open ( page_admin ) \n def test_modal_keyboard ( page_admin ) : \n expect_modal_closed ( page_admin ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n expect_modal_open ( page_admin ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n expect_modal_closed ( page_admin ) \n def test_results_display ( page_admin ) : \n open_modal ( page_admin ) \n expect ( page_admin . get_by_text ( \"<STR_LIT>\" ) ) . to_be_visible ( ) \n search_box ( page_admin ) . type ( \"<STR_LIT>\" ) \n expect ( \n page_admin . get_by_text ( \"<STR_LIT>\" ) \n ) . to_be_visible ( ) \n expect ( page_admin . get_by_text ( \"<STR_LIT>\" ) ) . not_to_be_visible ( ) \n for result in [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] : \n expect ( page_admin . get_by_role ( \"<STR_LIT>\" , name = result , exact = True ) ) . to_be_visible ( ) \n def test_results_none ( page_admin ) : \n open_modal ( page_admin ) \n expect ( page_admin . get_by_text ( \"<STR_LIT>\" ) ) . to_be_visible ( ) \n search_box ( page_admin ) . type ( \"<STR_LIT>\" ) \n expect ( page_admin . get_by_text ( '<STR_LIT>' ) ) . to_be_visible ( ) \n expect ( page_admin . get_by_text ( \"<STR_LIT>\" ) ) . not_to_be_visible ( ) \n def test_results_keyboard ( page_admin ) : \n open_modal ( page_admin , with_keyboard = True ) \n search_box ( page_admin ) . type ( \"<STR_LIT>\" ) \n expect ( \n page_admin . get_by_text ( \"<STR_LIT>\" ) \n ) . to_be_visible ( ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n search_box ( page_admin ) . type ( \"<STR_LIT>\" ) \n expect ( \n page_admin . get_by_text ( \"<STR_LIT>\" ) \n ) . to_be_visible ( ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n page_admin . keyboard . press ( \"<STR_LIT>\" ) \n expect ( page_admin . get_by_text ( \"<STR_LIT>\" , exact = True ) ) . to_be_visible ( ) \n expect ( page_admin . get_by_label ( \"<STR_LIT>\" ) ) . to_have_value ( \"<STR_LIT>\" )"}, {"input": "import torch \n import torch . nn as nn \n from CAN . models . attention import Attention \n import math \n class PositionEmbeddingSine ( nn . Module ) : \n def __init__ ( self , num_pos_feats = <NUM_LIT> , temperature = <NUM_LIT> , normalize = False , scale = None ) : \n super ( ) . __init__ ( ) \n self . num_pos_feats = num_pos_feats \n self . temperature = temperature \n self . normalize = normalize \n if scale is not None and normalize is False : \n raise ValueError ( \"<STR_LIT>\" ) \n if scale is None : \n scale = <NUM_LIT> * math . pi \n self . scale = scale \n def forward ( self , x , mask ) : \n y_embed = mask . cumsum ( <NUM_LIT> , dtype = torch . float32 ) \n x_embed = mask . cumsum ( <NUM_LIT> , dtype = torch . float32 ) \n if self . normalize : \n eps = <NUM_LIT> \n y_embed = y_embed / ( y_embed [ : , - <NUM_LIT> : , : ] + eps ) * self . scale \n x_embed = x_embed / ( x_embed [ : , : , - <NUM_LIT> : ] + eps ) * self . scale \n dim_t = torch . arange ( self . num_pos_feats , dtype = torch . float32 , device = x . device ) \n dim_t = self . temperature ** ( <NUM_LIT> * ( dim_t // <NUM_LIT> ) / self . num_pos_feats ) \n pos_x = x_embed [ : , : , : , None ] / dim_t \n pos_y = y_embed [ : , : , : , None ] / dim_t \n pos_x = torch . stack ( ( pos_x [ : , : , : , <NUM_LIT> : : <NUM_LIT> ] . sin ( ) , pos_x [ : , : , : , <NUM_LIT> : : <NUM_LIT> ] . cos ( ) ) , dim = <NUM_LIT> ) . flatten ( <NUM_LIT> ) \n pos_y = torch . stack ( ( pos_y [ : , : , : , <NUM_LIT> : : <NUM_LIT> ] . sin ( ) , pos_y [ : , : , : , <NUM_LIT> : : <NUM_LIT> ] . cos ( ) ) , dim = <NUM_LIT> ) . flatten ( <NUM_LIT> ) \n pos = torch . cat ( ( pos_y , pos_x ) , dim = <NUM_LIT> ) . permute ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n return pos \n class AttDecoder ( nn . Module ) : \n def __init__ ( self , params ) : \n super ( AttDecoder , self ) . __init__ ( ) \n self . params = params", "output": "self . input_size = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . hidden_size = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . out_channel = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . attention_dim = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . dropout_prob = params [ '<STR_LIT>' ] \n self . device = params [ '<STR_LIT>' ] \n self . word_num = params [ '<STR_LIT>' ] \n self . counting_num = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . ratio = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n self . init_weight = nn . Linear ( self . out_channel , self . hidden_size ) \n self . embedding = nn . Embedding ( self . word_num , self . input_size ) \n self . word_input_gru = nn . GRUCell ( self . input_size , self . hidden_size ) \n self . word_attention = Attention ( params ) \n self . encoder_feature_conv = nn . Conv2d ( self . out_channel , self . attention_dim , \n kernel_size = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] , \n padding = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] // <NUM_LIT> ) \n self . word_state_weight = nn . Linear ( self . hidden_size , self . hidden_size ) \n self . word_embedding_weight = nn . Linear ( self . input_size , self . hidden_size ) \n self . word_context_weight = nn . Linear ( self . out_channel , self . hidden_size ) \n self . counting_context_weight = nn . Linear ( self . counting_num , self . hidden_size ) \n self . word_convert = nn . Linear ( self . hidden_size , self . word_num ) \n if params [ '<STR_LIT>' ] : \n self . dropout = nn . Dropout ( params [ '<STR_LIT>' ] ) \n def forward ( self , cnn_features , labels , counting_preds , images_mask , labels_mask , is_train = True ) : \n batch_size , num_steps = labels . shape \n height , width = cnn_features . shape [ <NUM_LIT> : ] \n word_probs = torch . zeros ( ( batch_size , num_steps , self . word_num ) ) . to ( device = self . device ) \n images_mask = images_mask [ : , : , : : self . ratio , : : self . ratio ] \n word_alpha_sum = torch . zeros ( ( batch_size , <NUM_LIT> , height , width ) ) . to ( device = self . device ) \n word_alphas = torch . zeros ( ( batch_size , num_steps , height , width ) ) . to ( device = self . device ) \n hidden = self . init_hidden ( cnn_features , images_mask ) \n counting_context_weighted = self . counting_context_weight ( counting_preds ) \n cnn_features_trans = self . encoder_feature_conv ( cnn_features ) \n position_embedding = PositionEmbeddingSine ( <NUM_LIT> , normalize = True ) \n pos = position_embedding ( cnn_features_trans , images_mask [ : , <NUM_LIT> , : , : ] ) \n cnn_features_trans = cnn_features_trans + pos \n if is_train : \n for i in range ( num_steps ) : \n word_embedding = self . embedding ( labels [ : , i - <NUM_LIT> ] ) if i else self . embedding ( torch . ones ( [ batch_size ] ) . long ( ) . to ( self . device ) ) \n hidden = self . word_input_gru ( word_embedding , hidden ) \n word_context_vec , word_alpha , word_alpha_sum = self . word_attention ( cnn_features , cnn_features_trans , hidden , \n word_alpha_sum , images_mask ) \n current_state = self . word_state_weight ( hidden ) \n word_weighted_embedding = self . word_embedding_weight ( word_embedding ) \n word_context_weighted = self . word_context_weight ( word_context_vec ) \n if self . params [ '<STR_LIT>' ] : \n word_out_state = self . dropout ( current_state + word_weighted_embedding + word_context_weighted + counting_context_weighted ) \n else : \n word_out_state = current_state + word_weighted_embedding + word_context_weighted + counting_context_weighted \n word_prob = self . word_convert ( word_out_state ) \n word_probs [ : , i ] = word_prob \n word_alphas [ : , i ] = word_alpha \n else : \n word_embedding = self . embedding ( torch . ones ( [ batch_size ] ) . long ( ) . to ( device = self . device ) ) \n for i in range ( num_steps ) : \n hidden = self . word_input_gru ( word_embedding , hidden ) \n word_context_vec , word_alpha , word_alpha_sum = self . word_attention ( cnn_features , cnn_features_trans , hidden , \n word_alpha_sum , images_mask ) \n current_state = self . word_state_weight ( hidden ) \n word_weighted_embedding = self . word_embedding_weight ( word_embedding ) \n word_context_weighted = self . word_context_weight ( word_context_vec ) \n if self . params [ '<STR_LIT>' ] : \n word_out_state = self . dropout ( current_state + word_weighted_embedding + word_context_weighted + counting_context_weighted ) \n else : \n word_out_state = current_state + word_weighted_embedding + word_context_weighted + counting_context_weighted \n word_prob = self . word_convert ( word_out_state ) \n _ , word = word_prob . max ( <NUM_LIT> ) \n word_embedding = self . embedding ( word ) \n word_probs [ : , i ] = word_prob \n word_alphas [ : , i ] = word_alpha \n return word_probs , word_alphas \n def init_hidden ( self , features , feature_mask ) : \n average = ( features * feature_mask ) . sum ( - <NUM_LIT> ) . sum ( - <NUM_LIT> ) / feature_mask . sum ( - <NUM_LIT> ) . sum ( - <NUM_LIT> ) \n average = self . init_weight ( average ) \n return torch . tanh ( average )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True ) , \n ) , \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" ,", "output": "name = \"<STR_LIT>\" , \n field = models . DateTimeField ( auto_now_add = True ) , \n ) , \n ]"}, {"input": "import torch \n import torch . nn as nn \n import torch . nn . functional as F \n class ChannelAtt ( nn . Module ) : \n def __init__ ( self , channel , reduction ) : \n super ( ChannelAtt , self ) . __init__ ( ) \n self . avg_pool = nn . AdaptiveAvgPool2d ( <NUM_LIT> ) \n self . fc = nn . Sequential ( \n nn . Linear ( channel , channel // reduction ) , \n nn . ReLU ( ) , \n nn . Linear ( channel // reduction , channel ) , \n nn . Sigmoid ( ) ) \n def forward ( self , x ) : \n b , c , _ , _ = x . size ( ) \n y = self . avg_pool ( x ) . view ( b , c ) \n y = self . fc ( y ) . view ( b , c , <NUM_LIT> , <NUM_LIT> ) \n return x * y \n class CountingDecoder ( nn . Module ) : \n def __init__ ( self , in_channel , out_channel , kernel_size ) : \n super ( CountingDecoder , self ) . __init__ ( ) \n self . in_channel = in_channel \n self . out_channel = out_channel \n self . trans_layer = nn . Sequential ( \n nn . Conv2d ( self . in_channel , <NUM_LIT> , kernel_size = kernel_size , padding = kernel_size // <NUM_LIT> , bias = False ) , \n nn . BatchNorm2d ( <NUM_LIT> ) ) \n self . channel_att = ChannelAtt ( <NUM_LIT> , <NUM_LIT> ) \n self . pred_layer = nn . Sequential ( \n nn . Conv2d ( <NUM_LIT> , self . out_channel , kernel_size = <NUM_LIT> , bias = False ) , \n nn . Sigmoid ( ) ) \n def forward ( self , x , mask ) : \n b , c , h , w = x . size ( ) \n x = self . trans_layer ( x )", "output": "x = self . channel_att ( x ) \n x = self . pred_layer ( x ) \n if mask is not None : \n x = x * mask \n x = x . view ( b , self . out_channel , - <NUM_LIT> ) \n x1 = torch . sum ( x , dim = - <NUM_LIT> ) \n return x1 , x . view ( b , self . out_channel , h , w )"}, {"input": "from django . urls import path \n from rest_framework import routers \n from dvadmin . system . views . api_white_list import ApiWhiteListViewSet \n from dvadmin . system . views . area import AreaViewSet \n from dvadmin . system . views . clause import PrivacyView , TermsServiceView \n from dvadmin . system . views . dept import DeptViewSet \n from dvadmin . system . views . dictionary import DictionaryViewSet \n from dvadmin . system . views . file_list import FileViewSet \n from dvadmin . system . views . login_log import LoginLogViewSet \n from dvadmin . system . views . menu import MenuViewSet \n from dvadmin . system . views . menu_button import MenuButtonViewSet \n from dvadmin . system . views . message_center import MessageCenterViewSet \n from dvadmin . system . views . operation_log import OperationLogViewSet \n from dvadmin . system . views . role import RoleViewSet \n from dvadmin . system . views . role_menu import RoleMenuPermissionViewSet \n from dvadmin . system . views . role_menu_button_permission import RoleMenuButtonPermissionViewSet \n from dvadmin . system . views . system_config import SystemConfigViewSet \n from dvadmin . system . views . user import UserViewSet \n from dvadmin . system . views . menu_field import MenuFieldViewSet \n system_url = routers . SimpleRouter ( ) \n system_url . register ( r'<STR_LIT>' , MenuViewSet ) \n system_url . register ( r'<STR_LIT>' , MenuButtonViewSet ) \n system_url . register ( r'<STR_LIT>' , RoleViewSet ) \n system_url . register ( r'<STR_LIT>' , DeptViewSet ) \n system_url . register ( r'<STR_LIT>' , UserViewSet ) \n system_url . register ( r'<STR_LIT>' , OperationLogViewSet ) \n system_url . register ( r'<STR_LIT>' , DictionaryViewSet ) \n system_url . register ( r'<STR_LIT>' , AreaViewSet ) \n system_url . register ( r'<STR_LIT>' , FileViewSet ) \n system_url . register ( r'<STR_LIT>' , ApiWhiteListViewSet ) \n system_url . register ( r'<STR_LIT>' , SystemConfigViewSet ) \n system_url . register ( r'<STR_LIT>' , MessageCenterViewSet ) \n system_url . register ( r'<STR_LIT>' , RoleMenuButtonPermissionViewSet ) \n system_url . register ( r'<STR_LIT>' , RoleMenuPermissionViewSet ) \n system_url . register ( r'<STR_LIT>' , MenuFieldViewSet ) \n urlpatterns = [ \n path ( '<STR_LIT>' , UserViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' , } ) ) , \n path ( '<STR_LIT>' , UserViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) ) , \n path ( '<STR_LIT>' , SystemConfigViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' } ) ) , \n path ( '<STR_LIT>' , SystemConfigViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' } ) ) , \n path ( '<STR_LIT>' , SystemConfigViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' } ) ) , \n path ( '<STR_LIT>' , SystemConfigViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' } ) ) , \n path ( '<STR_LIT>' , LoginLogViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' } ) ) , \n path ( '<STR_LIT>' , LoginLogViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' } ) ) , \n path ( '<STR_LIT>' , DeptViewSet . as_view ( { '<STR_LIT>' : '<STR_LIT>' } ) ) , \n path ( '<STR_LIT>' , PrivacyView . as_view ( ) ) , \n path ( '<STR_LIT>' , TermsServiceView . as_view ( ) ) , \n ]", "output": "urlpatterns += system_url . urls"}, {"input": "import uuid \n from ninja_crud . testing . core . components import ( \n Headers , \n PathParameters , \n Payloads , \n QueryParameters , \n ) \n from ninja_crud . testing . views import ( \n DeleteModelViewTest , \n ListModelViewTest , \n ReadModelViewTest , \n UpdateModelViewTest , \n ) \n from ninja_crud . testing . viewsets import ModelViewSetTestCase \n from tests . test_app . tests . base_test_case import BaseTestCase \n from tests . test_app . views . item_views import ItemViewSet \n class TestItemViewSet ( ModelViewSetTestCase , BaseTestCase ) : \n model_viewset_class = ItemViewSet \n base_path = \"<STR_LIT>\" \n def get_path_parameters ( self ) : \n return PathParameters ( ok = { \"<STR_LIT>\" : self . item_1 . id } , not_found = { \"<STR_LIT>\" : uuid . uuid4 ( ) } ) \n def get_headers_ok ( self ) : \n return Headers ( \n ok = { \"<STR_LIT>\" : f\"<STR_LIT>\" } , unauthorized = { } \n ) \n def get_headers_ok_forbidden ( self ) : \n return Headers ( \n ok = { \"<STR_LIT>\" : f\"<STR_LIT>\" } , \n unauthorized = { } , \n forbidden = { \"<STR_LIT>\" : f\"<STR_LIT>\" } , \n ) \n test_list_items = ListModelViewTest ( \n headers = get_headers_ok , \n query_parameters = lambda self : QueryParameters (", "output": "ok = [ { } , { \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \"<STR_LIT>\" : <NUM_LIT> } ] \n ) , \n ) \n test_read_item = ReadModelViewTest ( \n path_parameters = get_path_parameters , \n headers = get_headers_ok_forbidden , \n ) \n test_update_item = UpdateModelViewTest ( \n path_parameters = get_path_parameters , \n headers = get_headers_ok_forbidden , \n payloads = Payloads ( \n ok = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) , \n ) \n test_delete_item = DeleteModelViewTest ( \n path_parameters = get_path_parameters , headers = get_headers_ok_forbidden \n ) \n test_list_tags = ListModelViewTest ( \n path_parameters = lambda self : PathParameters ( ok = { \"<STR_LIT>\" : self . item_1 . id } ) , \n headers = get_headers_ok , \n )"}, {"input": "from unittest . mock import MagicMock \n from django . test import TestCase \n from ninja_crud import views , viewsets \n from tests . test_app . models import Item \n from tests . test_app . schemas import ItemIn , ItemOut \n class TestCreateModelView ( TestCase ) : \n def test_register_route_with_router_kwargs ( self ) : \n router_mock = MagicMock ( ) \n class ItemViewSet ( viewsets . ModelViewSet ) : \n model = Item \n create_item = views . CreateModelView (", "output": "request_body = ItemIn , \n response_body = ItemOut , \n router_kwargs = { \"<STR_LIT>\" : True } , \n ) \n ItemViewSet . create_item . register_route ( router_mock , \"<STR_LIT>\" ) \n router_mock . api_operation . assert_called_once ( ) \n self . assertTrue ( router_mock . api_operation . call_args [ <NUM_LIT> ] [ \"<STR_LIT>\" ] )"}, {"input": "import requests , re , datetime , os \n from utils . general import headers \n from bs4 import BeautifulSoup as bs \n def get_epgs_cabletv ( channel , channel_id , dt , func_arg ) : \n url = '<STR_LIT>' % ( channel_id , dt . strftime ( '<STR_LIT>' ) ) \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n epgs = [ ] \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n trs = soup . select ( '<STR_LIT>' ) \n old_dt = datetime . datetime ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n for tr in trs : \n divs = tr . select ( '<STR_LIT>' ) \n starttime_str = divs [ <NUM_LIT> ] . text . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n title = divs [ <NUM_LIT> ] . text . replace ( '<STR_LIT>' , '<STR_LIT>' ) . strip ( ) \n starttime = datetime . datetime ( year = dt . year , month = dt . month , day = dt . day , hour = int ( starttime_str [ : <NUM_LIT> ] ) , minute = int ( starttime_str [ - <NUM_LIT> : ] ) ) \n if starttime < old_dt : \n starttime = starttime + datetime . timedelta ( hours = <NUM_LIT> ) \n if starttime < old_dt : \n starttime = starttime + datetime . timedelta ( hours = <NUM_LIT> ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg ) \n old_dt = starttime \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_cabletv ( ) : \n dds = [ ] \n lis = [ ] \n ds = [ ] \n dsinfo = { } \n ls = { } \n nx = <NUM_LIT> \n headers1 = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' \n } \n for x in range ( <NUM_LIT> ) : \n url = '<STR_LIT>' % ( x + <NUM_LIT> ) \n res = requests . get ( url , headers = headers1 ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n dds1 = soup . select ( '<STR_LIT>' ) \n dds += dds1 \n us = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n for u in us : \n url = '<STR_LIT>' % u \n res = requests . get ( url , headers = headers ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n lis1 = soup . select ( '<STR_LIT>' ) \n lis += lis1 \n for li in lis :", "output": "try : \n id1 = re . search ( '<STR_LIT>' , li [ '<STR_LIT>' ] ) \n id = id1 . group ( <NUM_LIT> ) \n except Exception as e : \n print ( e ) \n continue \n name = li . text . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( \"<STR_LIT>\" , '<STR_LIT>' ) \n ls . update ( { id : name } ) \n for dd in dds : \n title = re . sub ( '<STR_LIT>' , '<STR_LIT>' , dd . text . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) ) \n id = dd . attrs [ '<STR_LIT>' ] . replace ( \"<STR_LIT>\" , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( \"<STR_LIT>\" , '<STR_LIT>' ) \n img = '<STR_LIT>' + dd . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . attrs [ '<STR_LIT>' ] \n if id in ls : \n title = ls [ id ] \n else : \n print ( '<STR_LIT>' % dd ) \n if title in ds : \n idold = dsinfo [ title ] [ <NUM_LIT> ] \n id = '<STR_LIT>' % ( idold , id ) \n dsinfo . update ( { title : [ id , img ] } ) \n else : \n nx += <NUM_LIT> \n dsinfo . update ( { title : [ id , img ] } ) \n ds . append ( title ) \n channels = [ ] \n for x in dsinfo : \n channel = { \n '<STR_LIT>' : x , \n '<STR_LIT>' : dsinfo [ x ] [ <NUM_LIT> ] . split ( '<STR_LIT>' ) , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : dsinfo [ x ] [ <NUM_LIT> ] , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' \n } \n channels . append ( channel ) \n print ( '<STR_LIT>' % ( len ( dds ) , len ( lis ) , nx ) ) \n return channels"}, {"input": "import http \n from typing import Callable , Dict , List , Optional \n from django . db . models import Model \n from django . http import HttpRequest \n from ninja import Schema \n from ninja_crud . views . abstract_model_view import AbstractModelView \n from ninja_crud . views . enums import HTTPMethod \n class DeleteModelView ( AbstractModelView ) : \n def __init__ ( \n self , \n path : str = \"<STR_LIT>\" , \n path_parameters : Optional [ Schema ] = None , \n decorators : Optional [ List [ Callable ] ] = None , \n router_kwargs : Optional [ Dict ] = None , \n get_model : Optional [ Callable [ [ HttpRequest , Optional [ Schema ] ] , Model ] ] = None , \n pre_delete : Optional [ Callable [ [ HttpRequest , Model ] , None ] ] = None , \n post_delete : Optional [ Callable [ [ HttpRequest , Model ] , None ] ] = None , \n delete_model : Optional [ Callable [ [ HttpRequest , Optional [ Schema ] ] , None ] ] = None , \n ) -> None : \n super ( ) . __init__ ( \n method = HTTPMethod . DELETE , \n path = path , \n path_parameters = path_parameters , \n query_parameters = None , \n request_body = None , \n response_body = None , \n response_status = http . HTTPStatus . NO_CONTENT , \n decorators = decorators , \n router_kwargs = router_kwargs ,", "output": ") \n self . get_model = get_model or self . _default_get_model \n self . pre_delete = pre_delete or self . _default_pre_delete \n self . post_delete = post_delete or self . _default_post_delete \n self . delete_model = delete_model or self . _default_delete_model \n def _default_get_model ( \n self , request : HttpRequest , path_parameters : Optional [ Schema ] \n ) -> Model : \n return self . model_viewset_class . model . objects . get ( \n ** ( path_parameters . dict ( ) if path_parameters else { } ) \n ) \n @ staticmethod \n def _default_pre_delete ( request : HttpRequest , instance : Model ) -> None : \n pass \n @ staticmethod \n def _default_post_delete ( request : HttpRequest , instance : Model ) -> None : \n pass \n def _default_delete_model ( \n self , request : HttpRequest , path_parameters : Optional [ Schema ] \n ) -> None : \n instance = self . get_model ( request , path_parameters ) \n self . pre_delete ( request , instance ) \n instance . delete ( ) \n self . post_delete ( request , instance ) \n def handle_request ( \n self , \n request : HttpRequest , \n path_parameters : Optional [ Schema ] , \n query_parameters : Optional [ Schema ] , \n request_body : Optional [ Schema ] , \n ) -> None : \n self . delete_model ( request , path_parameters )"}, {"input": "from datetime import date \n from typing import Optional \n from uuid import UUID \n from ninja import Schema \n class DepartmentIn ( Schema ) : \n title : str \n class DepartmentOut ( Schema ) : \n id : UUID \n title : str \n class EmployeeIn ( Schema ) :", "output": "first_name : str \n last_name : str \n birthdate : Optional [ date ] = None \n class EmployeeOut ( Schema ) : \n id : UUID \n first_name : str \n last_name : str \n birthdate : Optional [ date ] = None \n department_id : UUID"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ,", "output": "] \n operations = [ \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( blank = True , default = False , null = True ) , \n ) , \n ]"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [ \n migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) ,", "output": "( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . TextField ( ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) ) , \n ] , \n ) , \n ]"}, {"input": "import django . db . models . deletion \n import wagtail . fields \n from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [", "output": "( \n \"<STR_LIT>\" , \n models . OneToOneField ( \n auto_created = True , \n on_delete = django . db . models . deletion . CASCADE , \n parent_link = True , \n primary_key = True , \n serialize = False , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , wagtail . fields . RichTextField ( ) ) , \n ] , \n options = { \n \"<STR_LIT>\" : False , \n } , \n bases = ( \"<STR_LIT>\" , models . Model ) , \n ) , \n ]"}, {"input": "from django . conf import settings \n from django . conf . urls . static import static \n from django . contrib import admin \n from django . contrib . staticfiles . urls import staticfiles_urlpatterns \n from django . urls import include , path \n from wagtail import urls as wagtail_urls \n from wagtail . admin import urls as wagtailadmin_urls \n from wagtail . documents import urls as wagtaildocs_urls \n urlpatterns = [ \n path ( \"<STR_LIT>\" , admin . site . urls ) ,", "output": "path ( \"<STR_LIT>\" , include ( wagtailadmin_urls ) ) , \n path ( \"<STR_LIT>\" , include ( wagtaildocs_urls ) ) , \n * static ( settings . MEDIA_URL , document_root = settings . MEDIA_ROOT ) , \n * staticfiles_urlpatterns ( ) , \n path ( \"<STR_LIT>\" , include ( wagtail_urls ) ) , \n ]"}, {"input": "from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . RemoveField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n ) , \n migrations . RemoveField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' ,", "output": ") , \n migrations . RemoveField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n ) , \n migrations . RemoveField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n ) , \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . TextField ( blank = True , null = True ) ) , \n ( '<STR_LIT>' , models . CharField ( default = '<STR_LIT>' , max_length = <NUM_LIT> ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = '<STR_LIT>' ) ) , \n ] , \n ) , \n ]"}, {"input": "import os \n import secrets \n from pathlib import Path \n from typing import Annotated \n import cappa \n import tomlkit \n from falco . utils import get_project_name \n from rich import print as rich_print \n from rich . prompt import Prompt \n @ cappa . command ( help = \"<STR_LIT>\" ) \n class SyncDotenv : \n fill_missing : Annotated [ \n bool , \n cappa . Arg ( \n False , \n short = \"<STR_LIT>\" , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] = False \n print_env : Annotated [ \n bool , \n cappa . Arg ( \n False , \n short = \"<STR_LIT>\" , \n long = \"<STR_LIT>\" , \n help = \"<STR_LIT>\" , \n ) , \n ] = False \n def __call__ ( self , project_name : Annotated [ str , cappa . Dep ( get_project_name ) ] ) : \n dotenv_file = Path ( \"<STR_LIT>\" ) \n dotenv_template_file = Path ( \"<STR_LIT>\" ) \n dotenv_content = dotenv_file . read_text ( ) if dotenv_file . exists ( ) else \"<STR_LIT>\" \n dotenv_template_content = dotenv_template_file . read_text ( ) if dotenv_template_file . exists ( ) else \"<STR_LIT>\" \n debug = os . getenv ( \"<STR_LIT>\" , \"<STR_LIT>\" ) . lower ( ) == \"<STR_LIT>\" \n base_config = { \"<STR_LIT>\" : True } if debug else self . get_prod_config ( project_name ) \n config = { \n ** parse ( dotenv_template_content ) , \n ** base_config , \n ** parse ( dotenv_content ) , \n } \n if self . fill_missing : \n for key , value in config . items ( ) : \n if not value : \n config [ key . upper ( ) ] = Prompt . ask ( f\"<STR_LIT>\" ) \n dotenv_content = get_updated ( dotenv_content , config ) \n if self . print_env : \n rich_print ( dotenv_content ) \n return \n dotenv_file . touch ( exist_ok = True ) \n dotenv_file . write_text ( dotenv_content ) \n dotenv_template_content = get_updated ( \n dotenv_template_content , \n { key : \"<STR_LIT>\" for key in config } , \n keep_original = True , \n keep_whitespace = True , \n ) \n dotenv_template_file . touch ( exist_ok = True ) \n dotenv_template_file . write_text ( dotenv_template_content ) \n rich_print ( f\"<STR_LIT>\" ) \n def get_prod_config ( self , project_name : str ) -> dict : \n return { \n \"<STR_LIT>\" : False , \n \"<STR_LIT>\" : secrets . token_urlsafe ( <NUM_LIT> ) , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n \"<STR_LIT>\" : get_superuser_email ( project_name ) , \n \"<STR_LIT>\" : secrets . token_urlsafe ( <NUM_LIT> ) , \n } \n def get_superuser_email ( project_name : str ) : \n pyproject_file = Path ( \"<STR_LIT>\" ) \n if pyproject_file . exists ( ) : \n pyproject = tomlkit . parse ( pyproject_file . read_text ( ) ) \n if authors := pyproject . get ( \"<STR_LIT>\" , { } ) . get ( \"<STR_LIT>\" , [ ] ) : \n return authors [ <NUM_LIT> ] [ \"<STR_LIT>\" ] \n return f\"<STR_LIT>\" \n def parse ( env_content : str ) -> dict : \n result = { } \n for line in env_content . split ( \"<STR_LIT>\" ) : \n stripped_line = line . strip ( ) \n if stripped_line . startswith ( \"<STR_LIT>\" ) or not stripped_line : \n continue \n try : \n key , value = stripped_line . split ( \"<STR_LIT>\" , <NUM_LIT> ) \n except ValueError as e : \n msg = f\"<STR_LIT>\" \n raise cappa . Exit ( msg , code = <NUM_LIT> ) from e \n result [ key ] = value \n return result \n def get_updated ( env_content : str , config : dict , * , keep_original = False , keep_whitespace = False ) -> str : \n content_list = env_content . split ( \"<STR_LIT>\" ) \n content_dict = { line . split ( \"<STR_LIT>\" ) [ <NUM_LIT> ] : line for line in content_list if \"<STR_LIT>\" in line } \n new_content_list = content_list . copy ( ) \n for key , value in config . items ( ) : \n line = content_dict . get ( key ) \n if line is not None : \n index = new_content_list . index ( line ) \n if not keep_original : \n new_content_list [ index ] = f\"<STR_LIT>\" \n else : \n new_content_list . append ( f\"<STR_LIT>\" ) \n if not keep_whitespace :", "output": "new_content_list = [ line . strip ( ) for line in new_content_list if line . strip ( ) ] \n return \"<STR_LIT>\" . join ( new_content_list )"}, {"input": "import os \n BASE_DIR = os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) \n SECRET_KEY = '<STR_LIT>' \n DEBUG = True \n ALLOWED_HOSTS = [ ] \n INSTALLED_APPS = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' \n ] \n MIDDLEWARE = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n ROOT_URLCONF = '<STR_LIT>' \n TEMPLATES = [ \n { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : [ \"<STR_LIT>\" ] , \n '<STR_LIT>' : True , \n '<STR_LIT>' : { \n '<STR_LIT>' : [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] , \n } , \n } , \n ] \n WSGI_APPLICATION = '<STR_LIT>' \n DATABASES = { \n '<STR_LIT>' : { \n '<STR_LIT>' : '<STR_LIT>' , \n \"<STR_LIT>\" : str ( BASE_DIR ) + \"<STR_LIT>\" \n } \n }", "output": "AUTH_PASSWORD_VALIDATORS = [ \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n ] \n LANGUAGE_CODE = '<STR_LIT>' \n TIME_ZONE = '<STR_LIT>' \n USE_I18N = True \n USE_L10N = True \n USE_TZ = False \n MEDIA_URL = '<STR_LIT>' \n MEDIA_ROOT = os . path . join ( BASE_DIR , '<STR_LIT>' ) \n STATIC_URL = '<STR_LIT>' \n STATICFILES_DIRS = [ \n os . path . join ( BASE_DIR , '<STR_LIT>' ) \n ]"}, {"input": "from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \"<STR_LIT>\" , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . TextField ( ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( blank = True , null = True ) ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] ,", "output": "} , \n ) , \n migrations . RemoveField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n ) , \n migrations . DeleteModel ( \n name = \"<STR_LIT>\" , \n ) , \n migrations . DeleteModel ( \n name = \"<STR_LIT>\" , \n ) , \n migrations . DeleteModel ( \n name = \"<STR_LIT>\" , \n ) , \n ]"}, {"input": "import environ \n from django . contrib . auth . models import User \n from django . core . management import BaseCommand \n class Command ( BaseCommand ) : \n def handle ( self , * args , ** options ) : \n env = environ . Env ( ) \n default_password = env ( \"<STR_LIT>\" ) \n default_username = \"<STR_LIT>\"", "output": "if not User . objects . filter ( username = default_username ) . exists ( ) : \n user = User . objects . create ( username = default_username , is_active = True , is_staff = True , is_superuser = True ) \n user . set_password ( default_password ) \n user . save ( )"}, {"input": "import django . contrib . sites . models \n from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ ( \"<STR_LIT>\" , \"<STR_LIT>\" ) ]", "output": "operations = [ \n migrations . AlterField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( \n max_length = <NUM_LIT> , \n unique = True , \n validators = [ django . contrib . sites . models . _simple_domain_name_validator ] , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) \n ]"}, {"input": "import os \n import sys \n def main ( ) : \n os . environ . setdefault ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n try : \n from django . core . management import execute_from_command_line", "output": "except ImportError as exc : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) from exc \n execute_from_command_line ( sys . argv ) \n if __name__ == \"<STR_LIT>\" : \n main ( )"}, {"input": "import uuid \n from typing import NotRequired , Required , TypedDict \n from django . urls import include , path , reverse \n from django . utils . html import json_script \n from django . utils . safestring import mark_safe \n from django . views . i18n import JavaScriptCatalog \n from wagtail import hooks \n from wagtail . admin . rich_text . editors . draftail . features import ControlFeature \n from . models import Prompt \n from . views import describe_image , prompt_viewset , text_completion \n @ hooks . register ( \"<STR_LIT>\" ) \n def register_admin_urls ( ) : \n urls = [ \n path ( \n \"<STR_LIT>\" , \n JavaScriptCatalog . as_view ( packages = [ \"<STR_LIT>\" ] ) , \n name = \"<STR_LIT>\" , \n ) , \n path ( \n \"<STR_LIT>\" , \n text_completion , \n name = \"<STR_LIT>\" , \n ) , \n path ( \n \"<STR_LIT>\" , \n describe_image , \n name = \"<STR_LIT>\" , \n ) , \n ] \n return [ \n path ( \n \"<STR_LIT>\" , \n include ( \n ( urls , \"<STR_LIT>\" ) , \n namespace = \"<STR_LIT>\" , \n ) , \n ) \n ] \n @ hooks . register ( \"<STR_LIT>\" ) \n def register_ai_feature ( features ) : \n feature_name = \"<STR_LIT>\" \n features . default_features . append ( feature_name ) \n features . register_editor_plugin ( \n \"<STR_LIT>\" , \n feature_name , \n ControlFeature ( \n { \n \"<STR_LIT>\" : feature_name , \n } , \n js = [ \"<STR_LIT>\" ] , \n css = { \"<STR_LIT>\" : [ \"<STR_LIT>\" ] } ,", "output": ") , \n ) \n class PromptDict ( TypedDict ) : \n uuid : Required [ uuid . UUID ] \n label : Required [ str ] \n description : NotRequired [ str ] \n prompt : Required [ str ] \n method : Required [ str ] \n def _serialize_prompt ( prompt : Prompt ) -> PromptDict : \n return { \n \"<STR_LIT>\" : prompt . uuid , \n \"<STR_LIT>\" : prompt . label , \n \"<STR_LIT>\" : prompt . description , \n \"<STR_LIT>\" : prompt . prompt_value , \n \"<STR_LIT>\" : prompt . method , \n } \n def get_prompts ( ) : \n return [ _serialize_prompt ( prompt ) for prompt in Prompt . objects . all ( ) ] \n @ hooks . register ( \"<STR_LIT>\" ) \n def ai_editor_js ( ) : \n config = { \n \"<STR_LIT>\" : get_prompts ( ) , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : reverse ( \"<STR_LIT>\" ) , \n \"<STR_LIT>\" : reverse ( \"<STR_LIT>\" ) , \n } , \n } \n return mark_safe ( json_script ( config , \"<STR_LIT>\" ) ) \n @ hooks . register ( \"<STR_LIT>\" ) \n def register_viewset ( ) : \n return prompt_viewset"}, {"input": "import math \n import torch \n import torch . nn as nn \n import torch . nn . functional as F \n from thop import profile \n class Bottleneck ( nn . Module ) : \n def __init__ ( self , nChannels , growthRate , use_dropout ) : \n super ( Bottleneck , self ) . __init__ ( ) \n interChannels = <NUM_LIT> * growthRate \n self . bn1 = nn . BatchNorm2d ( interChannels ) \n self . conv1 = nn . Conv2d ( nChannels , interChannels , kernel_size = <NUM_LIT> , bias = False ) \n self . bn2 = nn . BatchNorm2d ( growthRate ) \n self . conv2 = nn . Conv2d ( interChannels , growthRate , kernel_size = <NUM_LIT> , padding = <NUM_LIT> , bias = False ) \n self . use_dropout = use_dropout \n self . dropout = nn . Dropout ( p = <NUM_LIT> ) \n def forward ( self , x ) : \n out = F . relu ( self . bn1 ( self . conv1 ( x ) ) , inplace = True ) \n if self . use_dropout : \n out = self . dropout ( out ) \n out = F . relu ( self . bn2 ( self . conv2 ( out ) ) , inplace = True ) \n if self . use_dropout : \n out = self . dropout ( out ) \n out = torch . cat ( ( x , out ) , <NUM_LIT> ) \n return out \n class SingleLayer ( nn . Module ) : \n def __init__ ( self , nChannels , growthRate , use_dropout ) : \n super ( SingleLayer , self ) . __init__ ( ) \n self . bn1 = nn . BatchNorm2d ( nChannels ) \n self . conv1 = nn . Conv2d ( nChannels , growthRate , kernel_size = <NUM_LIT> , padding = <NUM_LIT> , bias = False ) \n self . use_dropout = use_dropout \n self . dropout = nn . Dropout ( p = <NUM_LIT> ) \n def forward ( self , x ) : \n out = self . conv1 ( F . relu ( x , inplace = True ) ) \n if self . use_dropout : \n out = self . dropout ( out ) \n out = torch . cat ( ( x , out ) , <NUM_LIT> ) \n return out \n class Transition ( nn . Module ) : \n def __init__ ( self , nChannels , nOutChannels , use_dropout ) : \n super ( Transition , self ) . __init__ ( ) \n self . bn1 = nn . BatchNorm2d ( nOutChannels ) \n self . conv1 = nn . Conv2d ( nChannels , nOutChannels , kernel_size = <NUM_LIT> , bias = False ) \n self . use_dropout = use_dropout \n self . dropout = nn . Dropout ( p = <NUM_LIT> ) \n def forward ( self , x ) : \n out = F . relu ( self . bn1 ( self . conv1 ( x ) ) , inplace = True ) \n if self . use_dropout : \n out = self . dropout ( out ) \n out = F . avg_pool2d ( out , <NUM_LIT> , ceil_mode = True ) \n return out \n class DenseNet ( nn . Module ) : \n def __init__ ( self , params ) : \n super ( DenseNet , self ) . __init__ ( ) \n growthRate = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n reduction = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n bottleneck = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n use_dropout = params [ '<STR_LIT>' ] [ '<STR_LIT>' ] \n nDenseBlocks = <NUM_LIT> \n nChannels = <NUM_LIT> * growthRate \n self . conv1 = nn . Conv2d ( params [ '<STR_LIT>' ] [ '<STR_LIT>' ] , nChannels , kernel_size = <NUM_LIT> , padding = <NUM_LIT> , stride = <NUM_LIT> , bias = False ) \n self . dense1 = self . _make_dense ( nChannels , growthRate , nDenseBlocks , bottleneck , use_dropout )", "output": "nChannels += nDenseBlocks * growthRate \n nOutChannels = int ( math . floor ( nChannels * reduction ) ) \n self . trans1 = Transition ( nChannels , nOutChannels , use_dropout ) \n nChannels = nOutChannels \n self . dense2 = self . _make_dense ( nChannels , growthRate , nDenseBlocks , bottleneck , use_dropout ) \n nChannels += nDenseBlocks * growthRate \n nOutChannels = int ( math . floor ( nChannels * reduction ) ) \n self . trans2 = Transition ( nChannels , nOutChannels , use_dropout ) \n nChannels = nOutChannels \n self . dense3 = self . _make_dense ( nChannels , growthRate , nDenseBlocks , bottleneck , use_dropout ) \n def _make_dense ( self , nChannels , growthRate , nDenseBlocks , bottleneck , use_dropout ) : \n layers = [ ] \n for i in range ( int ( nDenseBlocks ) ) : \n if bottleneck : \n layers . append ( Bottleneck ( nChannels , growthRate , use_dropout ) ) \n else : \n layers . append ( SingleLayer ( nChannels , growthRate , use_dropout ) ) \n nChannels += growthRate \n return nn . Sequential ( * layers ) \n def forward ( self , x ) : \n out = self . conv1 ( x ) \n out = F . relu ( out , inplace = True ) \n out = F . max_pool2d ( out , <NUM_LIT> , ceil_mode = True ) \n out = self . dense1 ( out ) \n out = self . trans1 ( out ) \n out = self . dense2 ( out ) \n out = self . trans2 ( out ) \n out = self . dense3 ( out ) \n return out"}, {"input": "from pathlib import Path \n import os \n BASE_DIR = Path ( __file__ ) . resolve ( ) . parent . parent \n SECRET_KEY = '<STR_LIT>' \n DEBUG = True \n ALLOWED_HOSTS = [ '<STR_LIT>' ] \n INSTALLED_APPS = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n MIDDLEWARE = [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] \n ROOT_URLCONF = '<STR_LIT>' \n TEMPLATES = [ \n { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : [ ] , \n '<STR_LIT>' : True , \n '<STR_LIT>' : { \n '<STR_LIT>' : [ \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n '<STR_LIT>' , \n ] , \n } , \n } , \n ] \n WSGI_APPLICATION = '<STR_LIT>' \n DATABASES = { \n '<STR_LIT>' : { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : BASE_DIR / '<STR_LIT>' , \n } , \n } \n AUTH_PASSWORD_VALIDATORS = [ \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n { \n '<STR_LIT>' : '<STR_LIT>' , \n } , \n {", "output": "'<STR_LIT>' : '<STR_LIT>' , \n } , \n ] \n LANGUAGE_CODE = '<STR_LIT>' \n TIME_ZONE = '<STR_LIT>' \n USE_I18N = True \n USE_L10N = True \n USE_TZ = True \n STATIC_URL = '<STR_LIT>' \n STATICFILES_DIRS = [ os . path . join ( BASE_DIR , '<STR_LIT>' ) ] \n DEFAULT_AUTO_FIELD = '<STR_LIT>'"}, {"input": "from pathlib import Path \n BASE_DIR = Path ( __file__ ) . resolve ( ) . parent . parent \n SECRET_KEY = \"<STR_LIT>\" \n DEBUG = True \n ALLOWED_HOSTS = [ ] \n AUTH_USER_MODEL = \"<STR_LIT>\" \n INSTALLED_APPS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n MIDDLEWARE = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n ROOT_URLCONF = \"<STR_LIT>\" \n TEMPLATES = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ BASE_DIR / \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : True , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] , \n } , \n } , \n ] \n WSGI_APPLICATION = \"<STR_LIT>\" \n DATABASES = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : BASE_DIR / \"<STR_LIT>\" , \n } \n } \n AUTH_PASSWORD_VALIDATORS = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n ] \n LANGUAGE_CODE = \"<STR_LIT>\" \n TIME_ZONE = \"<STR_LIT>\" \n USE_I18N = True \n USE_TZ = True \n STATIC_URL = \"<STR_LIT>\"", "output": "DEFAULT_AUTO_FIELD = \"<STR_LIT>\" \n CRISPY_ALLOWED_TEMPLATE_PACKS = \"<STR_LIT>\" \n CRISPY_TEMPLATE_PACK = \"<STR_LIT>\" \n SUPERUSER_EMAIL = \"<STR_LIT>\" \n SUPERUSER_PASSWORD = \"<STR_LIT>\""}, {"input": "from dvadmin . system . models import OperationLog \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class OperationLogSerializer ( CustomModelSerializer ) : \n class Meta : \n model = OperationLog \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class OperationLogCreateUpdateSerializer ( CustomModelSerializer ) : \n class Meta : \n model = OperationLog \n fields = '<STR_LIT>' \n class OperationLogViewSet ( CustomModelViewSet ) :", "output": "queryset = OperationLog . objects . order_by ( '<STR_LIT>' ) \n serializer_class = OperationLogSerializer"}, {"input": "import base64 \n import os \n from collections . abc import Iterator \n from dataclasses import dataclass \n from typing import Any , NotRequired , Self \n import requests \n from django . core . files import File \n from wagtail_ai . types import AIResponse \n from . base import AIBackend , BaseAIBackendConfig , BaseAIBackendConfigSettings \n class OpenAIBackendConfigSettingsDict ( BaseAIBackendConfigSettings ) :", "output": "TIMEOUT_SECONDS : NotRequired [ int | None ] \n OPENAI_API_KEY : NotRequired [ str | None ] \n @ dataclass ( kw_only = True ) \n class OpenAIBackendConfig ( BaseAIBackendConfig [ OpenAIBackendConfigSettingsDict ] ) : \n timeout_seconds : int \n openai_api_key : str | None \n @ classmethod \n def from_settings ( \n cls , config : OpenAIBackendConfigSettingsDict , ** kwargs : Any \n ) -> Self : \n timeout_seconds = config . get ( \"<STR_LIT>\" ) \n if timeout_seconds is None : \n timeout_seconds = <NUM_LIT> \n kwargs . setdefault ( \"<STR_LIT>\" , timeout_seconds ) \n kwargs . setdefault ( \"<STR_LIT>\" , config . get ( \"<STR_LIT>\" ) ) \n return super ( ) . from_settings ( config , ** kwargs ) \n class OpenAIResponse ( AIResponse ) : \n def __init__ ( self , response : requests . Response ) : \n self . response = response \n self . _text = response . json ( ) [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n def __iter__ ( self ) -> Iterator [ str ] : \n yield self . _text \n def text ( self ) -> str : \n return self . _text \n def __str__ ( self ) : \n return self . text ( ) \n class OpenAIBackend ( AIBackend [ OpenAIBackendConfig ] ) : \n config_cls = OpenAIBackendConfig \n def prompt_with_context ( \n self , * , pre_prompt : str , context : str , post_prompt : str | None = None \n ) -> OpenAIResponse : \n messages = [ \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : pre_prompt } ] } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : context } ] } , \n ] \n if post_prompt is not None : \n messages . append ( \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : post_prompt } ] } \n ) \n return self . chat_completions ( messages ) \n def describe_image ( self , * , image_file : File , prompt : str ) -> OpenAIResponse : \n if not prompt : \n raise ValueError ( \"<STR_LIT>\" ) \n with image_file . open ( ) as f : \n base64_image = base64 . b64encode ( f . read ( ) ) . decode ( \"<STR_LIT>\" ) \n return self . chat_completions ( \n messages = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : prompt , \n } , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : f\"<STR_LIT>\" \n } , \n } , \n ] , \n } , \n ] , \n ) \n def chat_completions ( self , messages : list [ dict [ str , Any ] ] ) -> OpenAIResponse : \n headers = { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : f\"<STR_LIT>\" , \n } \n payload = { \n \"<STR_LIT>\" : self . config . model_id , \n \"<STR_LIT>\" : messages , \n \"<STR_LIT>\" : self . config . token_limit , \n } \n response = requests . post ( \n \"<STR_LIT>\" , \n headers = headers , \n json = payload , \n timeout = self . config . timeout_seconds , \n ) \n response . raise_for_status ( ) \n return OpenAIResponse ( response ) \n def get_openai_api_key ( self ) -> str : \n if config_key := self . config . openai_api_key : \n return config_key \n if env_key := os . environ . get ( \"<STR_LIT>\" ) : \n return env_key \n raise RuntimeError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . TextField ( default = '<STR_LIT>' ) , \n ) ,", "output": "migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . IntegerField ( default = <NUM_LIT> ) , \n ) , \n ]"}, {"input": "import itertools \n import pandas as pd \n from pytz import timezone \n import snscrape . modules . twitter as sntwitter \n def fetch_tweets ( query : str ) : \n turkey = timezone ( \"<STR_LIT>\" ) \n df = pd . DataFrame ( itertools . islice ( sntwitter . TwitterSearchScraper ( f\"<STR_LIT>\" ) . get_items ( ) , <NUM_LIT> ) ) \n try : \n df [ \"<STR_LIT>\" ] = df . date . apply ( lambda x : pd . to_datetime ( str ( pd . to_datetime ( x ) . astimezone ( turkey ) ) [ : - <NUM_LIT> ] ) ) \n except AttributeError : \n return [ ] \n for ind in df . index : \n links = df [ \"<STR_LIT>\" ] [ ind ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] if df [ \"<STR_LIT>\" ] [ ind ] else \"<STR_LIT>\" \n user_id = df [ \"<STR_LIT>\" ] [ ind ] [ \"<STR_LIT>\" ] \n screen_name = df [ \"<STR_LIT>\" ] [ ind ] [ \"<STR_LIT>\" ] \n name = df [ \"<STR_LIT>\" ] [ ind ] [ \"<STR_LIT>\" ] \n tweet_id = df [ \"<STR_LIT>\" ] [ ind ] \n created_at = df [ \"<STR_LIT>\" ] [ ind ] \n full_text = df [ \"<STR_LIT>\" ] [ ind ] \n hashtags = [ i for i in df [ \"<STR_LIT>\" ] ] [ ind ] \n user_account_created_at = df [ \"<STR_LIT>\" ] [ ind ] [ \"<STR_LIT>\" ] \n try :", "output": "media = df [ \"<STR_LIT>\" ] [ ind ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] \n except ( KeyError , TypeError ) : \n media = None \n yield { \n \"<STR_LIT>\" : str ( full_text ) , \n \"<STR_LIT>\" : str ( user_id ) , \n \"<STR_LIT>\" : str ( screen_name ) , \n \"<STR_LIT>\" : str ( name ) , \n \"<STR_LIT>\" : str ( tweet_id ) , \n \"<STR_LIT>\" : str ( created_at ) , \n \"<STR_LIT>\" : str ( hashtags ) , \n \"<STR_LIT>\" : str ( user_account_created_at ) , \n \"<STR_LIT>\" : str ( media ) , \n \"<STR_LIT>\" : links , \n }"}, {"input": "from django . db import models \n from django . utils . translation import gettext_lazy as _ \n from dev . football . core . models import BaseModel \n from dev . football . teams . enums import SquadType , TeamType \n class Team ( BaseModel ) : \n name = models . CharField ( \n max_length = <NUM_LIT> , help_text = _ ( \"<STR_LIT>\" ) \n ) \n key = models . SlugField ( \n max_length = <NUM_LIT> ,", "output": "help_text = _ ( \"<STR_LIT>\" ) , \n unique = True , \n ) \n type = models . CharField ( \n max_length = <NUM_LIT> , \n choices = [ ( t . name , t . value ) for t in TeamType ] , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n website = models . URLField ( help_text = _ ( \"<STR_LIT>\" ) ) \n motto = models . CharField ( \n max_length = <NUM_LIT> , help_text = _ ( \"<STR_LIT>\" ) \n ) \n description = models . TextField ( \n help_text = _ ( \"<STR_LIT>\" ) \n ) \n stadium = models . ForeignKey ( \n \"<STR_LIT>\" , \n on_delete = models . SET_NULL , \n blank = True , \n null = True , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n def __str__ ( self ) : \n return self . name \n class Squad ( BaseModel ) : \n team = models . ForeignKey ( \n Team , \n on_delete = models . CASCADE , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n type = models . CharField ( \n max_length = <NUM_LIT> , \n choices = [ ( t . name , t . value ) for t in SquadType ] , \n help_text = _ ( \"<STR_LIT>\" ) , \n ) \n players = models . ManyToManyField ( \n \"<STR_LIT>\" , \n help_text = _ ( \"<STR_LIT>\" ) , \n blank = True , \n )"}, {"input": "import pytest \n from django . contrib . auth . models import User \n from django . test . client import Client \n @ pytest . fixture ( autouse = True ) \n def enable_db_access_for_all_tests ( db ) : \n pass \n @ pytest . fixture ( ) \n def user_standard ( client ) : \n user = User . objects . create_user ( username = \"<STR_LIT>\" , password = \"<STR_LIT>\" )", "output": "client . force_login ( user ) \n return user \n @ pytest . fixture ( ) \n def user_admin ( client , admin_user ) : \n user = User . objects . create_user ( \n username = \"<STR_LIT>\" , password = \"<STR_LIT>\" , is_staff = True \n ) \n client . force_login ( user ) \n return user \n @ pytest . fixture ( ) \n def user_super ( client ) : \n user = User . objects . create_user ( \n username = \"<STR_LIT>\" , password = \"<STR_LIT>\" , is_superuser = True \n ) \n client . force_login ( user ) \n return user \n @ pytest . fixture ( ) \n def client_standard ( user_standard ) : \n client = Client ( ) \n client . force_login ( user_standard ) \n return client \n @ pytest . fixture ( ) \n def client_admin ( user_admin ) : \n client = Client ( ) \n client . force_login ( user_admin ) \n return client \n @ pytest . fixture ( ) \n def client_super ( user_super ) : \n client = Client ( ) \n client . force_login ( user_super ) \n return client \n @ pytest . fixture ( ) \n def client_unauthenticated ( ) : \n client = Client ( ) \n client . logout ( ) \n return client \n @ pytest . fixture ( ) \n def client_super_admin ( client_admin , user_admin ) : \n user_admin . is_superuser = True \n user_admin . save ( ) \n return client_admin"}, {"input": "import requests , datetime , os \n from utils . general import chuanliu_Authorization \n headers = { \n '<STR_LIT>' : chuanliu_Authorization , \n } \n def get_epgs_chuanliu ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n if len ( chuanliu_Authorization ) < <NUM_LIT> : \n return { \n '<STR_LIT>' : <NUM_LIT> , \n '<STR_LIT>' : [ ] , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n need_date = dt . strftime ( '<STR_LIT>' ) \n url = '<STR_LIT>' % ( channel_id , need_date , need_date ) \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n ret_data = res . json ( ) [ '<STR_LIT>' ] \n n = <NUM_LIT> \n for j in ret_data : \n n += <NUM_LIT> \n title = j [ '<STR_LIT>' ] \n channel_name = j [ '<STR_LIT>' ] \n desc = j [ '<STR_LIT>' ] \n starttime = j [ '<STR_LIT>' ] \n endtime = j [ '<STR_LIT>' ] \n starttime = datetime . datetime . strptime ( starttime , '<STR_LIT>' ) \n endtime = datetime . datetime . strptime ( endtime , '<STR_LIT>' ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : endtime , \n '<STR_LIT>' : title , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg )", "output": "except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e ) \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_chuanliu ( ) : \n channels = [ ] \n sorts = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n url = '<STR_LIT>' \n res = requests . get ( url , headers = headers ) \n res . encoding = '<STR_LIT>' \n j = res . json ( ) \n ret_data = j [ '<STR_LIT>' ] \n for c in ret_data : \n name = c [ '<STR_LIT>' ] \n name2 = c [ '<STR_LIT>' ] \n name = name if len ( name ) > <NUM_LIT> else name2 \n id = c [ '<STR_LIT>' ] \n sort_type = c [ '<STR_LIT>' ] \n sort = sorts [ sort_type ] if sort_type in sorts else '<STR_LIT>' \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : sort , \n } \n channels . append ( channel ) \n return channels \n def get_sorts_type ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url , headers = headers ) \n ret_data = res . json ( ) [ '<STR_LIT>' ] \n n = <NUM_LIT> \n for j in ret_data : \n if n == <NUM_LIT> : \n n += <NUM_LIT> \n continue \n key = j [ '<STR_LIT>' ] \n sortname = j [ '<STR_LIT>' ] \n print ( key , sortname )"}, {"input": "import torch \n from torch import nn \n from torch . nn import Conv2d , MaxPool2d , AvgPool2d , Flatten , Linear , Sequential , Dropout , PReLU , Softmax , BatchNorm2d , ReLU , ZeroPad2d , AdaptiveAvgPool2d \n import math \n import torch . nn . functional as F \n class VGG ( nn . Module ) : \n def two_conv_pool ( self , in_channels , f1 , f2 ) : \n s = nn . Sequential ( \n nn . Conv2d ( in_channels , f1 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f1 ) , \n nn . ReLU ( inplace = True ) , \n nn . Conv2d ( f1 , f2 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f2 ) , \n nn . ReLU ( inplace = True ) , \n nn . MaxPool2d ( kernel_size = <NUM_LIT> , stride = <NUM_LIT> ) , \n ) \n for m in s . children ( ) : \n if isinstance ( m , nn . Conv2d ) : \n n = m . kernel_size [ <NUM_LIT> ] * m . kernel_size [ <NUM_LIT> ] * m . out_channels \n m . weight . data . normal_ ( <NUM_LIT> , math . sqrt ( <NUM_LIT> / n ) ) \n elif isinstance ( m , nn . BatchNorm2d ) : \n m . weight . data . fill_ ( <NUM_LIT> ) \n m . bias . data . zero_ ( ) \n return s \n def three_conv_pool ( self , in_channels , f1 , f2 , f3 ) : \n s = nn . Sequential ( \n nn . Conv2d ( in_channels , f1 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f1 ) , \n nn . ReLU ( inplace = True ) , \n nn . Conv2d ( f1 , f2 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f2 ) , \n nn . ReLU ( inplace = True ) , \n nn . Conv2d ( f2 , f3 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f3 ) , \n nn . ReLU ( inplace = True ) , \n nn . MaxPool2d ( kernel_size = <NUM_LIT> , stride = <NUM_LIT> ) , \n ) \n for m in s . children ( ) : \n if isinstance ( m , nn . Conv2d ) : \n n = m . kernel_size [ <NUM_LIT> ] * m . kernel_size [ <NUM_LIT> ] * m . out_channels \n m . weight . data . normal_ ( <NUM_LIT> , math . sqrt ( <NUM_LIT> / n ) ) \n elif isinstance ( m , nn . BatchNorm2d ) : \n m . weight . data . fill_ ( <NUM_LIT> ) \n m . bias . data . zero_ ( ) \n return s \n def __init__ ( self , num_classes = <NUM_LIT> ) : \n super ( VGG , self ) . __init__ ( ) \n self . l1 = self . two_conv_pool ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . l2 = self . two_conv_pool ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . l3 = self . three_conv_pool ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . l4 = self . three_conv_pool ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . classifier = nn . Sequential ( \n nn . Dropout ( p = <NUM_LIT> ) , \n nn . Linear ( <NUM_LIT> , <NUM_LIT> ) , \n nn . BatchNorm1d ( <NUM_LIT> ) , \n nn . ReLU ( inplace = True ) ,", "output": "nn . Dropout ( p = <NUM_LIT> ) , \n nn . Linear ( <NUM_LIT> , num_classes ) , \n ) \n def forward ( self , x ) : \n x = self . l1 ( x ) \n x = self . l2 ( x ) \n x = self . l3 ( x ) \n x = self . l4 ( x ) \n x = x . view ( x . size ( <NUM_LIT> ) , - <NUM_LIT> ) \n x = self . classifier ( x ) \n return F . log_softmax ( x , dim = <NUM_LIT> ) \n Half_width = <NUM_LIT> \n layer_width = <NUM_LIT> \n class SpinalVGG ( nn . Module ) : \n def two_conv_pool ( self , in_channels , f1 , f2 ) : \n s = nn . Sequential ( \n nn . Conv2d ( in_channels , f1 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f1 ) , \n nn . ReLU ( inplace = True ) , \n nn . Conv2d ( f1 , f2 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f2 ) , \n nn . ReLU ( inplace = True ) , \n nn . MaxPool2d ( kernel_size = <NUM_LIT> , stride = <NUM_LIT> ) , \n ) \n for m in s . children ( ) : \n if isinstance ( m , nn . Conv2d ) : \n n = m . kernel_size [ <NUM_LIT> ] * m . kernel_size [ <NUM_LIT> ] * m . out_channels \n m . weight . data . normal_ ( <NUM_LIT> , math . sqrt ( <NUM_LIT> / n ) ) \n elif isinstance ( m , nn . BatchNorm2d ) : \n m . weight . data . fill_ ( <NUM_LIT> ) \n m . bias . data . zero_ ( ) \n return s \n def three_conv_pool ( self , in_channels , f1 , f2 , f3 ) : \n s = nn . Sequential ( \n nn . Conv2d ( in_channels , f1 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f1 ) , \n nn . ReLU ( inplace = True ) , \n nn . Conv2d ( f1 , f2 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f2 ) , \n nn . ReLU ( inplace = True ) , \n nn . Conv2d ( f2 , f3 , kernel_size = <NUM_LIT> , stride = <NUM_LIT> , padding = <NUM_LIT> ) , \n nn . BatchNorm2d ( f3 ) , \n nn . ReLU ( inplace = True ) , \n nn . MaxPool2d ( kernel_size = <NUM_LIT> , stride = <NUM_LIT> ) , \n ) \n for m in s . children ( ) : \n if isinstance ( m , nn . Conv2d ) : \n n = m . kernel_size [ <NUM_LIT> ] * m . kernel_size [ <NUM_LIT> ] * m . out_channels \n m . weight . data . normal_ ( <NUM_LIT> , math . sqrt ( <NUM_LIT> / n ) ) \n elif isinstance ( m , nn . BatchNorm2d ) : \n m . weight . data . fill_ ( <NUM_LIT> ) \n m . bias . data . zero_ ( ) \n return s \n def __init__ ( self , num_classes = <NUM_LIT> ) : \n super ( SpinalVGG , self ) . __init__ ( ) \n self . l1 = self . two_conv_pool ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . l2 = self . two_conv_pool ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . l3 = self . three_conv_pool ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . l4 = self . three_conv_pool ( <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ) \n self . fc_spinal_layer1 = nn . Sequential ( \n nn . Dropout ( p = <NUM_LIT> ) , nn . Linear ( Half_width , layer_width ) , \n nn . BatchNorm1d ( layer_width ) , nn . ReLU ( inplace = True ) , ) \n self . fc_spinal_layer2 = nn . Sequential ( \n nn . Dropout ( p = <NUM_LIT> ) , nn . Linear ( Half_width + layer_width , layer_width ) , \n nn . BatchNorm1d ( layer_width ) , nn . ReLU ( inplace = True ) , ) \n self . fc_spinal_layer3 = nn . Sequential ( \n nn . Dropout ( p = <NUM_LIT> ) , nn . Linear ( Half_width + layer_width , layer_width ) , \n nn . BatchNorm1d ( layer_width ) , nn . ReLU ( inplace = True ) , ) \n self . fc_spinal_layer4 = nn . Sequential ( \n nn . Dropout ( p = <NUM_LIT> ) , nn . Linear ( Half_width + layer_width , layer_width ) , \n nn . BatchNorm1d ( layer_width ) , nn . ReLU ( inplace = True ) , ) \n self . fc_out = nn . Sequential ( \n nn . Dropout ( p = <NUM_LIT> ) , nn . Linear ( layer_width * <NUM_LIT> , num_classes ) , ) \n def forward ( self , x ) : \n x = self . l1 ( x ) \n x = self . l2 ( x ) \n x = self . l3 ( x ) \n x = self . l4 ( x ) \n x = x . view ( x . size ( <NUM_LIT> ) , - <NUM_LIT> ) \n x1 = self . fc_spinal_layer1 ( x [ : , <NUM_LIT> : Half_width ] ) \n x2 = self . fc_spinal_layer2 ( torch . cat ( [ x [ : , Half_width : <NUM_LIT> * Half_width ] , x1 ] , dim = <NUM_LIT> ) ) \n x3 = self . fc_spinal_layer3 ( torch . cat ( [ x [ : , <NUM_LIT> : Half_width ] , x2 ] , dim = <NUM_LIT> ) ) \n x4 = self . fc_spinal_layer4 ( torch . cat ( [ x [ : , Half_width : <NUM_LIT> * Half_width ] , x3 ] , dim = <NUM_LIT> ) ) \n x = torch . cat ( [ x1 , x2 ] , dim = <NUM_LIT> ) \n x = torch . cat ( [ x , x3 ] , dim = <NUM_LIT> ) \n x = torch . cat ( [ x , x4 ] , dim = <NUM_LIT> ) \n x = self . fc_out ( x ) \n return F . log_softmax ( x , dim = <NUM_LIT> )"}, {"input": "from typing import List , Optional , Union \n from ninja_crud . testing . core . components import utils \n class QueryParameters : \n def __init__ ( \n self , \n ok : Union [ dict , List [ dict ] ] , \n bad_request : Union [ dict , List [ dict ] , None ] = None , \n ) -> None :", "output": "self . ok : List [ dict ] = utils . ensure_list_of_dicts ( ok ) \n self . bad_request : Optional [ List [ dict ] ] = ( \n utils . ensure_list_of_dicts ( bad_request ) if bad_request is not None else None \n )"}, {"input": "import logging \n import os \n import subprocess \n import yaml \n GLOBAL_CONFIG_PATH = \"<STR_LIT>\" \n PYDOC_MARKDOWN_CONFIG_PATH = \"<STR_LIT>\" \n def load_yaml_file ( file_path : str ) : \n with open ( file_path ) as yaml_file : \n return yaml . load ( yaml_file , Loader = yaml . FullLoader ) \n def convert_docstrings_to_markdown ( \n input_path : str , output_path : str , markdown_config : dict \n ) : \n try : \n os . makedirs ( os . path . dirname ( output_path ) , exist_ok = True ) \n markdown_config [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] = output_path \n absolute_input_path = os . path . join ( os . getcwd ( ) , input_path ) \n subprocess . run ( \n [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n absolute_input_path , \n yaml . dump ( markdown_config ) , \n ] \n ) \n except Exception as e : \n logging . error ( f\"<STR_LIT>\" ) \n def main ( ) : \n global_config = load_yaml_file ( GLOBAL_CONFIG_PATH ) \n pydoc_markdown_config = load_yaml_file ( PYDOC_MARKDOWN_CONFIG_PATH )", "output": "settings = global_config [ \"<STR_LIT>\" ] \n for module in global_config [ \"<STR_LIT>\" ] : \n input_path = os . path . join ( settings [ \"<STR_LIT>\" ] , module [ \"<STR_LIT>\" ] ) \n output_path = os . path . join ( settings [ \"<STR_LIT>\" ] , module [ \"<STR_LIT>\" ] ) \n convert_docstrings_to_markdown ( \n input_path = input_path , \n output_path = output_path , \n markdown_config = pydoc_markdown_config , \n ) \n if __name__ == \"<STR_LIT>\" : \n logging . basicConfig ( level = logging . INFO ) \n main ( )"}, {"input": "import django . db . models . deletion \n from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True , null = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n help_text = \"<STR_LIT>\" , max_length = <NUM_LIT> \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . SlugField ( \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n unique = True , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . IntegerField ( help_text = \"<STR_LIT>\" ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : False , \n } , \n ) , \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \n \"<STR_LIT>\" , \n models . BigAutoField ( \n auto_created = True , \n primary_key = True , \n serialize = False , \n verbose_name = \"<STR_LIT>\" , \n ) , \n ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now_add = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . DateTimeField ( auto_now = True , null = True ) ) , \n ( \n \"<STR_LIT>\" , \n models . CharField ( \n choices = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] , \n help_text = \"<STR_LIT>\" , \n max_length = <NUM_LIT> , \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . PositiveSmallIntegerField ( \n help_text = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . PositiveSmallIntegerField ( \n help_text = \"<STR_LIT>\" \n ) , \n ) , \n ( \n \"<STR_LIT>\" , \n models . OneToOneField ( \n help_text = \"<STR_LIT>\" , \n on_delete = django . db . models . deletion . CASCADE ,", "output": "to = \"<STR_LIT>\" , \n ) , \n ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : False , \n } , \n ) , \n ]"}, {"input": "from django . contrib import admin \n from django . urls import include , path , re_path \n from django . conf import settings \n from django . conf . urls . i18n import i18n_patterns \n from django . contrib . sitemaps . views import sitemap \n from django . contrib . sitemaps import GenericSitemap \n from summarizer . sitemaps import StaticViewSitemap \n from summarizer . models import ArxivPaper \n app_name = '<STR_LIT>' \n sitemaps = { \n '<STR_LIT>' : StaticViewSitemap \n } \n def get_absolute_url2 ( obj ) : \n return f\"<STR_LIT>\" \n sitemaps = { \n '<STR_LIT>' : GenericSitemap ( { \n '<STR_LIT>' : ArxivPaper . objects . filter ( arxiv_id__isnull = False ) , \n '<STR_LIT>' : '<STR_LIT>' , \n } , priority = <NUM_LIT> , protocol = '<STR_LIT>' ) , \n '<STR_LIT>' : StaticViewSitemap , \n } \n urlpatterns = [ \n path ( '<STR_LIT>' , admin . site . urls ) , \n path ( '<STR_LIT>' , sitemap , { '<STR_LIT>' : sitemaps } ) , \n path ( '<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n ] \n if '<STR_LIT>' in settings . INSTALLED_APPS : \n urlpatterns += [ \n re_path ( r'<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n ]", "output": "urlpatterns += i18n_patterns ( \n path ( '<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n )"}, {"input": "project = \"<STR_LIT>\" \n copyright = \"<STR_LIT>\" \n author = \"<STR_LIT>\"", "output": "release = \"<STR_LIT>\" \n version = \"<STR_LIT>\" \n extensions = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n intersphinx_mapping = { \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , None ) , \n \"<STR_LIT>\" : ( \"<STR_LIT>\" , None ) , \n } \n intersphinx_disabled_domains = [ \"<STR_LIT>\" ] \n templates_path = [ \"<STR_LIT>\" ] \n html_theme = \"<STR_LIT>\" \n epub_show_urls = \"<STR_LIT>\""}, {"input": "from typing import List , Optional , Union \n from ninja_crud . testing . core . components import utils \n class Payloads : \n def __init__ ( \n self , \n ok : Union [ dict , List [ dict ] ] , \n bad_request : Union [ dict , List [ dict ] , None ] = None ,", "output": "conflict : Union [ dict , List [ dict ] , None ] = None , \n ) -> None : \n self . ok : List [ dict ] = utils . ensure_list_of_dicts ( ok ) \n self . bad_request : Optional [ List [ dict ] ] = ( \n utils . ensure_list_of_dicts ( bad_request ) if bad_request is not None else None \n ) \n self . conflict : Optional [ List [ dict ] ] = ( \n utils . ensure_list_of_dicts ( conflict ) if conflict is not None else None \n )"}, {"input": "import re \n from django . test import Client , override_settings \n from django . urls import reverse \n from admin_site_search . views import AdminSiteSearchView \n def request_script_element ( client : Client ) :", "output": "response = client . get ( reverse ( \"<STR_LIT>\" ) , follow = True ) \n content = str ( response . content ) \n script_element = re . search ( \n r'<STR_LIT>' , content \n ) . group ( <NUM_LIT> ) \n return script_element \n @ override_settings ( ROOT_URLCONF = \"<STR_LIT>\" ) \n def test_default ( client_super_admin ) : \n element = request_script_element ( client_super_admin ) \n assert '<STR_LIT>' in element \n assert '<STR_LIT>' in element \n @ override_settings ( ROOT_URLCONF = \"<STR_LIT>\" ) \n def test_custom ( client_super_admin ) : \n element = request_script_element ( client_super_admin ) \n assert '<STR_LIT>' in element \n assert '<STR_LIT>' in element \n @ override_settings ( ROOT_URLCONF = \"<STR_LIT>\" ) \n def test_index ( client_super_admin ) : \n element = request_script_element ( client_super_admin ) \n assert '<STR_LIT>' in element \n assert '<STR_LIT>' in element \n def test_path_attr ( ) : \n assert hasattr ( AdminSiteSearchView , \"<STR_LIT>\" ) \n assert reverse ( \"<STR_LIT>\" ) . endswith ( AdminSiteSearchView . site_search_path )"}, {"input": "from typing import Any , Optional \n from django . contrib . auth . models import User \n from django . http import HttpRequest \n from ninja . security import HttpBearer \n class TokenBearer ( HttpBearer ) : \n def authenticate ( self , request : HttpRequest , token : str ) -> Optional [ Any ] : \n user_queryset = User . objects . filter ( id = token )", "output": "if user_queryset . exists ( ) : \n return user_queryset . get ( ) \n return None"}, {"input": "from django . conf import settings \n from django . core . checks import Error , register \n @ register ( ) \n def warn_about_webhooks_settings ( app_configs , ** kwargs ) : \n webhook_settings = getattr ( settings , \"<STR_LIT>\" ) \n errors = [ ] \n if not webhook_settings : \n errors . append ( \n Error ( \n \"<STR_LIT>\" , \n id = \"<STR_LIT>\" , \n ) \n ) \n if webhook_settings : \n base_msg = \"<STR_LIT>\" \n models = webhook_settings . get ( \"<STR_LIT>\" ) \n if not isinstance ( models , list ) : \n errors . append ( \n Error (", "output": "base_msg , \n hint = \"<STR_LIT>\" , \n id = \"<STR_LIT>\" , \n ) \n ) \n else : \n from django . apps import apps \n for model_name in models : \n app_label , model_label = model_name . split ( \"<STR_LIT>\" ) \n try : \n apps . get_model ( app_label , model_label ) \n except LookupError : \n errors . append ( \n Error ( \n base_msg , \n hint = f\"<STR_LIT>\" , \n id = \"<STR_LIT>\" , \n ) \n ) \n return errors"}, {"input": "import platform \n import logging \n from . models_user import UserProfile", "output": "logger = logging . getLogger ( __name__ ) \n from django . conf import settings as _settings \n def settings ( request ) : \n context = { '<STR_LIT>' : _settings } \n try : \n username = request . user \n u = UserProfile . objects . get ( username = username ) \n context [ '<STR_LIT>' ] = '<STR_LIT>' \n context [ '<STR_LIT>' ] = u \n context [ '<STR_LIT>' ] = username \n context [ '<STR_LIT>' ] = u . is_admin \n context [ '<STR_LIT>' ] = u . is_active \n context [ '<STR_LIT>' ] = _settings . ID_SERVER \n context [ '<STR_LIT>' ] = True if platform . system ( ) == '<STR_LIT>' else False \n logger . info ( \"<STR_LIT>\" ) \n except Exception as e : \n logger . error ( \"<STR_LIT>\" . format ( e ) ) \n return context"}, {"input": "import os \n import sys \n from pathlib import Path \n if __name__ == \"<STR_LIT>\" : \n os . environ . setdefault ( \"<STR_LIT>\" , \"<STR_LIT>\" ) \n try : \n from django . core . management import execute_from_command_line \n except ImportError : \n try : \n import django \n except ImportError : \n raise ImportError ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) \n raise \n current_path = Path ( __file__ ) . parent . resolve ( ) \n sys . path . append ( str ( current_path / \"<STR_LIT>\" ) )", "output": "execute_from_command_line ( sys . argv )"}, {"input": "from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [", "output": "migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . TextField ( blank = True , null = True ) , \n ) , \n ]"}, {"input": "from django . db . models import F \n from rest_framework . decorators import action \n from rest_framework . permissions import IsAuthenticated \n from dvadmin . system . models import RoleMenuPermission , Menu , MenuButton \n from dvadmin . utils . json_response import DetailResponse , ErrorResponse \n from dvadmin . utils . serializers import CustomModelSerializer \n from dvadmin . utils . viewset import CustomModelViewSet \n class RoleMenuPermissionSerializer ( CustomModelSerializer ) : \n class Meta : \n model = RoleMenuPermission \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class RoleMenuPermissionInitSerializer ( CustomModelSerializer ) : \n class Meta : \n model = RoleMenuPermission \n fields = \"<STR_LIT>\"", "output": "read_only_fields = [ \"<STR_LIT>\" ] \n class RoleMenuPermissionCreateUpdateSerializer ( CustomModelSerializer ) : \n class Meta : \n model = RoleMenuPermission \n fields = \"<STR_LIT>\" \n read_only_fields = [ \"<STR_LIT>\" ] \n class RoleMenuPermissionViewSet ( CustomModelViewSet ) : \n queryset = RoleMenuPermission . objects . all ( ) \n serializer_class = RoleMenuPermissionSerializer \n create_serializer_class = RoleMenuPermissionCreateUpdateSerializer \n update_serializer_class = RoleMenuPermissionCreateUpdateSerializer \n extra_filter_class = [ ] \n @ action ( methods = [ '<STR_LIT>' ] , detail = False ) \n def save_auth ( self , request ) : \n body = request . data \n role_id = body . get ( '<STR_LIT>' , None ) \n if role_id is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n menu_list = body . get ( '<STR_LIT>' , None ) \n if menu_list is None : \n return ErrorResponse ( msg = \"<STR_LIT>\" ) \n obj_list = RoleMenuPermission . objects . filter ( role__id = role_id ) . values_list ( '<STR_LIT>' , flat = True ) \n old_set = set ( obj_list ) \n new_set = set ( menu_list ) \n need_del = old_set . difference ( new_set ) \n need_add = new_set . difference ( old_set ) \n RoleMenuPermission . objects . filter ( role__id = role_id , menu__in = list ( need_del ) ) . delete ( ) \n data = [ { \"<STR_LIT>\" : role_id , \"<STR_LIT>\" : item } for item in list ( need_add ) ] \n serializer = RoleMenuPermissionSerializer ( data = data , many = True , request = request ) \n if serializer . is_valid ( raise_exception = True ) : \n serializer . save ( ) \n return DetailResponse ( msg = \"<STR_LIT>\" , data = serializer . data )"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) :", "output": "dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . AutoField ( primary_key = True , serialize = False ) , \n ) , \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . AutoField ( primary_key = True , serialize = False ) , \n ) , \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . AutoField ( primary_key = True , serialize = False ) , \n ) , \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . AutoField ( primary_key = True , serialize = False ) , \n ) , \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . AutoField ( primary_key = True , serialize = False ) , \n ) , \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . AutoField ( primary_key = True , serialize = False ) , \n ) , \n ]"}, {"input": "import torch \n import numpy as np \n from CAN . utils import load_config , load_checkpoint , compute_edit_distance \n from CAN . dataset import Words \n import sys \n from CAN . models . infer_model import Inference \n import cv2 \n class model : \n def __init__ ( self ) : \n self . params = load_config ( '<STR_LIT>' ) \n self . words = Words ( '<STR_LIT>' ) \n self . params [ '<STR_LIT>' ] = len ( self . words ) \n self . params [ '<STR_LIT>' ] = '<STR_LIT>' \n if '<STR_LIT>' not in self . params : \n self . params [ '<STR_LIT>' ] = False \n self . model = Inference ( self . params , draw_map = False ) \n load_checkpoint ( self . model , None , '<STR_LIT>' ) \n def output ( self , img_path ) : \n img = cv2 . imread ( img_path ) \n image = cv2 . cvtColor ( img , cv2 . COLOR_BGR2GRAY ) \n image = np . asarray ( image ) \n image = torch . Tensor ( <NUM_LIT> - image ) / <NUM_LIT> \n image = image . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) \n pre , _ , mae , mse = self . model ( image , None , None ) \n pre = self . words . decode ( pre )", "output": "print ( pre ) \n return pre \n def output_img ( self , img ) : \n image = cv2 . cvtColor ( img , cv2 . COLOR_BGR2GRAY ) \n image = np . asarray ( image ) \n image = torch . Tensor ( <NUM_LIT> - image ) / <NUM_LIT> \n image = image . unsqueeze ( <NUM_LIT> ) . unsqueeze ( <NUM_LIT> ) \n pre , _ , mae , mse = self . model ( image , None , None ) \n pre = self . words . decode ( pre ) \n return pre \n if __name__ == '<STR_LIT>' : \n model = model ( ) \n image_path = '<STR_LIT>' \n model . output ( img_path = image_path )"}, {"input": "import unittest . mock \n import django . core . exceptions \n import django . test \n from ninja_crud import views \n class TestAbstractView ( django . test . TestCase ) : \n def test_docstrings ( self ) : \n import http \n from typing import Any , Optional , Tuple , Union \n import django . http \n import ninja \n from ninja_crud import views \n class HelloWorldSchema ( ninja . Schema ) : \n message : str \n class HelloWorldView ( views . AbstractView ) : \n def __init__ ( self ) -> None : \n super ( ) . __init__ ( \n method = views . enums . HTTPMethod . GET , \n path = \"<STR_LIT>\" , \n response_body = HelloWorldSchema , \n ) \n def handle_request ( \n self , \n request : django . http . HttpRequest , \n path_parameters : Optional [ ninja . Schema ] , \n query_parameters : Optional [ ninja . Schema ] , \n request_body : Optional [ ninja . Schema ] , \n ) -> Union [ Any , Tuple [ http . HTTPStatus , Any ] ] : \n return { \"<STR_LIT>\" : \"<STR_LIT>\" } \n router = ninja . Router ( ) \n view = HelloWorldView ( ) \n view . register_route ( router , route_name = \"<STR_LIT>\" ) \n self . assertEqual ( \n view . handle_request ( \n request = django . http . HttpRequest ( ) , \n path_parameters = None , \n query_parameters = None , \n request_body = None , \n ) , \n { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n )", "output": "def test_sanitize_and_merge_router_kwargs ( self ) : \n router_kwargs = { \"<STR_LIT>\" : True , \"<STR_LIT>\" : \"<STR_LIT>\" } \n sanitized_router_kwargs = views . AbstractView . _clean_router_kwargs ( router_kwargs ) \n self . assertDictEqual ( sanitized_router_kwargs , router_kwargs ) \n def test_sanitize_and_merge_router_kwargs_with_path ( self ) : \n router_kwargs = { \"<STR_LIT>\" : \"<STR_LIT>\" } \n with unittest . mock . patch ( \n \"<STR_LIT>\" \n ) as mock_logger : \n sanitized_router_kwargs = views . AbstractView . _clean_router_kwargs ( \n router_kwargs \n ) \n mock_logger . warning . assert_called_once ( ) \n self . assertDictEqual ( sanitized_router_kwargs , { } )"}, {"input": "import django . db . models . deletion \n from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . CreateModel (", "output": "name = \"<STR_LIT>\" , \n fields = [ \n ( \"<STR_LIT>\" , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . TextField ( blank = True , null = True ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . FloatField ( default = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , to = \"<STR_LIT>\" ) ) , \n ] , \n ) , \n ]"}, {"input": "from django . db import migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . RenameField ( \n model_name = '<STR_LIT>' ,", "output": "old_name = '<STR_LIT>' , \n new_name = '<STR_LIT>' , \n ) , \n ]"}, {"input": "import os \n import subprocess \n from unittest . mock import MagicMock \n from unittest . mock import patch \n import pytest \n from cappa . testing import CommandRunner \n from falco . __main__ import Falco \n @ pytest . fixture ( autouse = True ) \n def change_test_dir ( monkeypatch , tmp_path ) : \n monkeypatch . chdir ( tmp_path ) \n @ pytest . fixture \n def runner ( ) : \n return CommandRunner ( Falco ) \n @ pytest . fixture \n def django_project ( tmp_path ) : \n project_dir = tmp_path / \"<STR_LIT>\" \n subprocess . run ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , check = True ) \n os . chdir ( project_dir ) \n subprocess . run ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , check = True ) \n model_code = \n ( project_dir / \"<STR_LIT>\" / \"<STR_LIT>\" ) . write_text ( model_code ) \n settings_file = project_dir / \"<STR_LIT>\" / \"<STR_LIT>\" \n settings_content = settings_file . read_text ( ) \n settings_file . write_text ( settings_content + \"<STR_LIT>\" + \"<STR_LIT>\" ) \n ( project_dir / \"<STR_LIT>\" ) . write_text ( \n ) \n yield project_dir \n os . chdir ( tmp_path ) \n @ pytest . fixture \n def set_git_repo_to_clean ( ) : \n def mock_run ( args , ** kwargs ) : \n if args == [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n mock = MagicMock ( ) \n mock . returncode = <NUM_LIT> \n mock . stdout = \"<STR_LIT>\" \n return mock \n return original_run ( args , ** kwargs ) \n original_run = subprocess . run \n with patch ( \"<STR_LIT>\" , side_effect = mock_run ) :", "output": "yield \n @ pytest . fixture \n def pyproject_toml ( tmp_path ) : \n pyproject_toml = tmp_path / \"<STR_LIT>\" \n pyproject_toml . write_text ( \n ) \n yield pyproject_toml \n pyproject_toml . unlink ( ) \n @ pytest . fixture \n def git_user_infos ( ) : \n name = \"<STR_LIT>\" \n email = \"<STR_LIT>\" \n def mock_run ( args , ** kwargs ) : \n if args == [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n mock = MagicMock ( ) \n mock . returncode = <NUM_LIT> \n mock . stdout = name \n return mock \n if args == [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n mock = MagicMock ( ) \n mock . returncode = <NUM_LIT> \n mock . stdout = email \n return mock \n return original_run ( args , ** kwargs ) \n original_run = subprocess . run \n with patch ( \"<STR_LIT>\" , side_effect = mock_run ) : \n yield name , email"}, {"input": "import django \n if django . __version__ . split ( '<STR_LIT>' ) [ <NUM_LIT> ] >= '<STR_LIT>' : \n from django . urls import re_path as url \n else : \n from django . conf . urls import url , include \n from webui import views \n urlpatterns = [", "output": "url ( r'<STR_LIT>' , django . views . static . serve , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) , \n url ( r'<STR_LIT>' , django . views . static . serve , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) , \n url ( r'<STR_LIT>' , django . views . static . serve , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) , \n url ( r'<STR_LIT>' , django . views . static . serve , { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ) , \n url ( r'<STR_LIT>' , views . index ) , \n url ( r'<STR_LIT>' , django . views . static . serve , { '<STR_LIT>' : '<STR_LIT>' } , name = '<STR_LIT>' ) , \n url ( r'<STR_LIT>' , django . views . static . serve , { '<STR_LIT>' : '<STR_LIT>' } , name = '<STR_LIT>' ) , \n url ( r'<STR_LIT>' , django . views . static . serve , { '<STR_LIT>' : '<STR_LIT>' } , name = '<STR_LIT>' ) , \n ]"}, {"input": "from django . db import models , migrations \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . CharField ( default = \"<STR_LIT>\" , max_length = <NUM_LIT> ) ,", "output": ") , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . TextField ( null = True ) , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . BooleanField ( default = False ) , \n ) , \n ]"}, {"input": "import hashlib \n import random \n CHAR_SET = ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \n \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \n \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \n \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" )", "output": "def random_str ( number = <NUM_LIT> ) : \n result = \"<STR_LIT>\" \n for i in range ( <NUM_LIT> , number ) : \n inx = random . randint ( <NUM_LIT> , len ( CHAR_SET ) - <NUM_LIT> ) \n result += CHAR_SET [ inx ] \n return result \n def has_md5 ( str , salt = '<STR_LIT>' ) : \n str = str + salt \n md = hashlib . md5 ( ) \n md . update ( str . encode ( ) ) \n res = md . hexdigest ( ) \n return res"}, {"input": "from django . contrib import admin \n from . models import Conversation , Message , Setting \n @ admin . register ( Conversation )", "output": "class ConversationAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n @ admin . register ( Message ) \n class MessageAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n def get_conversation_topic ( self , obj ) : \n return obj . conversation . topic \n get_conversation_topic . short_description = '<STR_LIT>' \n @ admin . register ( Setting ) \n class SettingAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . AutoField ( primary_key = True , serialize = False ) ) ,", "output": "( '<STR_LIT>' , models . FloatField ( ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now_add = True ) ) , \n ( '<STR_LIT>' , models . DateTimeField ( auto_now = True ) ) , \n ( '<STR_LIT>' , models . BooleanField ( default = True ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , related_name = '<STR_LIT>' , to = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . ForeignKey ( on_delete = django . db . models . deletion . CASCADE , related_name = '<STR_LIT>' , to = '<STR_LIT>' ) ) , \n ] , \n ) , \n migrations . AddField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . ManyToManyField ( related_name = '<STR_LIT>' , through = '<STR_LIT>' , to = '<STR_LIT>' ) , \n ) , \n ]"}, {"input": "import requests , datetime , os \n from bs4 import BeautifulSoup as bs \n from utils . general import headers \n def get_epgs_gxntv ( channel , channel_id , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n dt_str = dt . strftime ( '<STR_LIT>' ) \n data = { \n '<STR_LIT>' : channel_id , \n '<STR_LIT>' : dt_str , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' \n } \n try : \n url = '<STR_LIT>' \n res = requests . post ( url , headers = headers , timeout = <NUM_LIT> , data = data ) \n res . encoding = '<STR_LIT>' \n res_json = res . json ( ) \n epgs_contents = res_json [ '<STR_LIT>' ] \n epgs = [ ] \n for epga in epgs_contents : \n starttime_str = epga [ '<STR_LIT>' ] \n time_delay = epga [ '<STR_LIT>' ] \n starttime = datetime . datetime . strptime ( starttime_str , '<STR_LIT>' ) \n endtime = starttime + datetime . timedelta ( seconds = time_delay ) \n title = epga [ '<STR_LIT>' ] . strip ( ) \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : endtime , \n '<STR_LIT>' : title , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg ) \n except Exception as e : \n success = <NUM_LIT> \n spidername = os . path . basename ( __file__ ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n msg = '<STR_LIT>' % ( spidername , e )", "output": "ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_gxntv ( ) : \n url = '<STR_LIT>' \n res = requests . get ( url , headers = headers ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n contents = soup . select ( '<STR_LIT>' ) \n channels = [ ] \n for content in contents : \n id = content . attrs [ '<STR_LIT>' ] \n name = content . text \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n } \n channels . append ( channel ) \n return channels"}, {"input": "from http import HTTPStatus \n from typing import cast \n from unittest . mock import ANY , Mock , call \n import pytest \n from django . contrib . auth . models import Permission , User \n from django . urls import reverse \n from wagtail . images . models import Image \n from wagtail_ai . ai import echo \n from wagtail_factories import ImageFactory \n pytestmark = pytest . mark . django_db \n def test_get_request ( admin_client ) : \n response = admin_client . get ( reverse ( \"<STR_LIT>\" ) ) \n assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \"<STR_LIT>\" : \"<STR_LIT>\" } \n def test_image_not_found ( admin_client ) : \n response = admin_client . post ( \n reverse ( \"<STR_LIT>\" ) , data = { \"<STR_LIT>\" : <NUM_LIT> } \n ) \n assert response . status_code == <NUM_LIT> \n def test_access_denied ( client ) : \n user = User . objects . create_user ( username = \"<STR_LIT>\" ) \n user . user_permissions . add ( Permission . objects . get ( codename = \"<STR_LIT>\" ) ) \n client . force_login ( user ) \n image = cast ( Image , ImageFactory ( ) ) \n response = client . post ( \n reverse ( \"<STR_LIT>\" ) , data = { \"<STR_LIT>\" : image . pk } \n ) \n assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \"<STR_LIT>\" : \"<STR_LIT>\" } \n def test_backend_not_configured ( settings , admin_client ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } , \n } , \n } \n image = cast ( Image , ImageFactory ( ) ) \n response = admin_client . post ( \n reverse ( \"<STR_LIT>\" ) , data = { \"<STR_LIT>\" : image . pk } \n ) \n assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \n \"<STR_LIT>\" : ( \n \"<STR_LIT>\" \n \"<STR_LIT>\" \n ) , \n } \n def test_success ( admin_client , settings ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" : <NUM_LIT> , \n } , \n } , \n } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n image = cast ( Image , ImageFactory ( ) ) \n response = admin_client . post ( \n reverse ( \"<STR_LIT>\" ) , data = { \"<STR_LIT>\" : image . pk } \n ) \n assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n def test_custom_prompt ( admin_client , settings , monkeypatch : pytest . MonkeyPatch ) : \n describe_image = Mock ( return_value = echo . EchoResponse ( iter ( [ ] ) ) ) \n monkeypatch . setattr ( echo . EchoBackend , \"<STR_LIT>\" , describe_image ) \n CUSTOM_PROMPT = \"<STR_LIT>\" \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } , \n } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : CUSTOM_PROMPT , \n } \n image = cast ( Image , ImageFactory ( ) ) \n admin_client . post ( reverse ( \"<STR_LIT>\" ) , data = { \"<STR_LIT>\" : image . pk } ) \n assert describe_image . call_args == call ( image_file = ANY , prompt = CUSTOM_PROMPT ) \n def test_custom_rendition_filter ( admin_client , settings ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } , \n } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n image = cast ( Image , ImageFactory ( ) ) \n response = admin_client . post ( \n reverse ( \"<STR_LIT>\" ) , data = { \"<STR_LIT>\" : image . pk } \n ) \n assert response . status_code == <NUM_LIT> \n assert response . json ( ) == { \n \"<STR_LIT>\" : \"<STR_LIT>\" \n } \n @ pytest . mark . parametrize ( \n \"<STR_LIT>\" , \n [ \n ( <NUM_LIT> , HTTPStatus . OK , None ) , \n ( \n - <NUM_LIT> , \n HTTPStatus . BAD_REQUEST , \n \"<STR_LIT>\" , \n ) , \n ( \n <NUM_LIT> , \n HTTPStatus . BAD_REQUEST , \n \"<STR_LIT>\" , \n ) , \n ] , \n ) \n def test_maxlength_validation ( \n admin_client , settings , maxlength , expected_status , error_message \n ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } , \n } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n image = cast ( Image , ImageFactory ( ) ) \n response = admin_client . post ( \n reverse ( \"<STR_LIT>\" ) , \n data = { \"<STR_LIT>\" : image . pk , \"<STR_LIT>\" : maxlength } , \n ) \n assert response . status_code == expected_status \n if error_message is not None : \n assert response . json ( ) == { \"<STR_LIT>\" : error_message }"}, {"input": "from typing import cast \n from unittest . mock import ANY , Mock \n import pytest \n from wagtail . images . models import Image \n from wagtail_ai . ai import get_ai_backend , get_backend \n from wagtail_ai . ai . base import BackendFeature \n from wagtail_ai . ai . openai import OpenAIBackend \n from wagtail_factories import ImageFactory \n pytestmark = pytest . mark . django_db \n MOCK_API_KEY = \"<STR_LIT>\" \n MOCK_OUTPUT = \"<STR_LIT>\" \n @ pytest . fixture ( autouse = True ) \n def stub_image_title_signal ( monkeypatch : pytest . MonkeyPatch ) : \n monkeypatch . setenv ( \"<STR_LIT>\" , MOCK_API_KEY ) \n @ pytest . fixture \n def mock_post ( monkeypatch : pytest . MonkeyPatch ) : \n mock = Mock ( ) \n monkeypatch . setattr ( \"<STR_LIT>\" , mock ) \n return mock \n def test_get_as_image_backend ( settings ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : <NUM_LIT> , \n } , \n } , \n } , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } \n backend = get_backend ( BackendFeature . IMAGE_DESCRIPTION ) \n assert isinstance ( backend , OpenAIBackend ) \n assert backend . config . model_id == \"<STR_LIT>\" \n assert backend . config . token_limit == <NUM_LIT> \n assert backend . config . timeout_seconds == <NUM_LIT> \n def test_describe_image ( settings , mock_post ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n } , \n } \n mock_post . return_value . json . return_value = { \n \"<STR_LIT>\" : [ { \"<STR_LIT>\" : { \"<STR_LIT>\" : MOCK_OUTPUT } } ] , \n } \n image = cast ( Image , ImageFactory ( ) ) \n backend = get_ai_backend ( \"<STR_LIT>\" ) \n prompt = \"<STR_LIT>\" \n response = backend . describe_image ( image_file = image . file , prompt = prompt ) \n assert response . text ( ) == MOCK_OUTPUT \n headers = mock_post . call_args . kwargs [ \"<STR_LIT>\" ] \n assert headers [ \"<STR_LIT>\" ] == f\"<STR_LIT>\" \n messages = mock_post . call_args . kwargs [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n assert messages == [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : prompt } , \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : { \"<STR_LIT>\" : ANY } } , \n ] , \n } \n ] \n url = messages [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ <NUM_LIT> ] [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n assert url . startswith ( \"<STR_LIT>\" ) \n def test_text_completion ( settings , mock_post ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n } , \n } \n mock_post . return_value . json . return_value = { \n \"<STR_LIT>\" : [ { \"<STR_LIT>\" : { \"<STR_LIT>\" : MOCK_OUTPUT } } ] , \n } \n backend = get_ai_backend ( \"<STR_LIT>\" ) \n pre_prompt = \"<STR_LIT>\" \n context = \"<STR_LIT>\" \n post_prompt = \"<STR_LIT>\"", "output": "response = backend . prompt_with_context ( \n pre_prompt = pre_prompt , context = context , post_prompt = post_prompt \n ) \n assert \"<STR_LIT>\" . join ( response ) == MOCK_OUTPUT \n assert response . text ( ) == MOCK_OUTPUT \n headers = mock_post . call_args . kwargs [ \"<STR_LIT>\" ] \n assert headers [ \"<STR_LIT>\" ] == f\"<STR_LIT>\" \n messages = mock_post . call_args . kwargs [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n assert messages == [ \n { \"<STR_LIT>\" : [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : pre_prompt } ] , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : context } ] , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : post_prompt } ] , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ] \n def test_text_completion_without_post_prompt ( settings , mock_post ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n } , \n } \n mock_post . return_value . json . return_value = { \n \"<STR_LIT>\" : [ { \"<STR_LIT>\" : { \"<STR_LIT>\" : MOCK_OUTPUT } } ] , \n } \n backend = get_ai_backend ( \"<STR_LIT>\" ) \n pre_prompt = \"<STR_LIT>\" \n context = \"<STR_LIT>\" \n response = backend . prompt_with_context ( pre_prompt = pre_prompt , context = context ) \n assert response . text ( ) == MOCK_OUTPUT \n messages = mock_post . call_args . kwargs [ \"<STR_LIT>\" ] [ \"<STR_LIT>\" ] \n assert messages == [ \n { \"<STR_LIT>\" : [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : pre_prompt } ] , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n { \"<STR_LIT>\" : [ { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : context } ] , \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ] \n def test_default_token_limit ( settings ) : \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n } , \n } \n backend = get_ai_backend ( \"<STR_LIT>\" ) \n assert backend . config . token_limit == <NUM_LIT> \n def test_api_key_in_environ ( settings , monkeypatch : pytest . MonkeyPatch ) : \n test_key = \"<STR_LIT>\" \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n } , \n } , \n } \n monkeypatch . setenv ( \"<STR_LIT>\" , test_key ) \n backend = cast ( OpenAIBackend , get_ai_backend ( \"<STR_LIT>\" ) ) \n assert backend . get_openai_api_key ( ) == test_key \n def test_api_key_in_settings ( settings ) : \n test_key = \"<STR_LIT>\" \n settings . WAGTAIL_AI = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : test_key , \n } , \n } , \n } , \n } \n backend = cast ( OpenAIBackend , get_ai_backend ( \"<STR_LIT>\" ) ) \n assert backend . get_openai_api_key ( ) == test_key"}, {"input": "from torch import nn \n import torch \n class multi_loss ( nn . Module ) : \n def __init__ ( self , args ) : \n super ( ) . __init__ ( ) \n self . args = args \n self . weight = [ args [ '<STR_LIT>' ] , args [ '<STR_LIT>' ] , args [ '<STR_LIT>' ] ] \n self . MSE = nn . MSELoss ( ) . to ( device = self . args [ '<STR_LIT>' ] ) \n self . CosineEmbeddingLoss = nn . CosineEmbeddingLoss ( ) . to ( device = self . args [ '<STR_LIT>' ] ) \n self . MarginRankingLoss = nn . MarginRankingLoss ( ) . to ( device = self . args [ '<STR_LIT>' ] ) \n def forward ( self , y_trues , y_preds ) : \n m , n = y_trues . size ( ) \n batchsize = y_preds . shape [ <NUM_LIT> ] \n mseloss = self . MSE ( y_trues , y_preds ) \n simloss = torch . max ( torch . tensor ( <NUM_LIT> , device = self . args [ '<STR_LIT>' ] ) , self . CosineEmbeddingLoss ( y_trues . resize ( n , m ) , y_preds . resize ( n , m ) , torch . ones ( batchsize , dtype = torch . int , device = self . args [ '<STR_LIT>' ] ) ) ) \n rankloss = torch . tensor ( <NUM_LIT> , device = self . args [ '<STR_LIT>' ] ) \n for i in range ( batchsize ) : \n for j in range ( i + <NUM_LIT> , batchsize ) : \n input1_pred = y_preds [ i ] \n input2_pred = y_preds [ j ] \n input1_true = y_trues [ i ] \n input2_true = y_trues [ j ] \n target = <NUM_LIT> \n if input1_true > input2_true : \n target = <NUM_LIT> \n elif input1_true < input2_true : \n target = - <NUM_LIT> \n else : \n if input1_pred > input2_pred : \n target = - <NUM_LIT> \n elif input1_pred < input2_pred : \n target = <NUM_LIT> \n target = torch . tensor ( [ target ] , device = self . args [ '<STR_LIT>' ] ) \n rankloss += self . MarginRankingLoss ( input1_pred , input2_pred , target ) \n print ( f'<STR_LIT>' ) \n return self . weight [ <NUM_LIT> ] * mseloss + self . weight [ <NUM_LIT> ] * simloss + self . weight [ <NUM_LIT> ] * rankloss \n if __name__ == '<STR_LIT>' : \n x1 = torch . tensor ( [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , device = '<STR_LIT>' ) . resize ( <NUM_LIT> , <NUM_LIT> )", "output": "x2 = torch . tensor ( [ <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> , <NUM_LIT> ] , device = '<STR_LIT>' ) . resize ( <NUM_LIT> , <NUM_LIT> ) \n print ( x1 , x2 ) \n loss = multi_loss ( args = { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : <NUM_LIT> , '<STR_LIT>' : <NUM_LIT> } ) \n print ( loss ( x1 , x2 ) )"}, {"input": "from django . db import models , migrations", "output": "class Migration ( migrations . Migration ) : \n initial = True \n dependencies = [ ] \n operations = [ \n migrations . CreateModel ( \n name = \"<STR_LIT>\" , \n fields = [ \n ( \"<STR_LIT>\" , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = \"<STR_LIT>\" ) ) , \n ( \"<STR_LIT>\" , models . TextField ( ) ) , \n ( \"<STR_LIT>\" , models . BooleanField ( default = False ) ) , \n ( \"<STR_LIT>\" , models . CharField ( max_length = <NUM_LIT> ) ) , \n ( \"<STR_LIT>\" , models . TextField ( ) ) , \n ] , \n options = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n } , \n ) , \n ]"}, {"input": "from django . contrib import admin \n from django . urls import path \n from django . urls import include \n import web . views", "output": "urlpatterns = [ \n path ( '<STR_LIT>' , web . views . index ) , \n path ( '<STR_LIT>' , web . views . download ) , \n path ( '<STR_LIT>' , include ( '<STR_LIT>' ) ) , \n path ( '<STR_LIT>' , admin . site . urls ) , \n path ( '<STR_LIT>' , web . views . d ) , \n ]"}, {"input": "from pathlib import Path \n from typing import cast \n from typing import TypedDict \n import tomlkit \n from typing_extensions import Unpack \n class FalcoConfig ( TypedDict , total = False ) : \n revision : str \n blueprint : str \n skip : list [ str ] \n work : dict [ str , str ] \n htmx : str \n crud : \"<STR_LIT>\" \n class CRUDConfig ( TypedDict ) :", "output": "blueprints : str \n utils_path : str \n login_required : bool \n skip_git_check : bool \n always_migrate : bool \n def parse_crud_config_from_pyproject ( values : dict ) -> dict : \n return { key . lower ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : value for key , value in values . items ( ) } \n def parse_crud_config_to_pyproject ( values : dict ) -> dict : \n return { key . lower ( ) . replace ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : value for key , value in values . items ( ) } \n def write_falco_config ( pyproject_path : Path , ** kwargs : Unpack [ TypedDict ] ) -> None : \n new_falco_config = kwargs \n new_crud_config = parse_crud_config_to_pyproject ( new_falco_config . pop ( \"<STR_LIT>\" , { } ) ) \n pyproject = tomlkit . parse ( pyproject_path . read_text ( ) ) \n existing_falco_config = pyproject . get ( \"<STR_LIT>\" , { } ) . get ( \"<STR_LIT>\" , { } ) \n existing_crud_config = existing_falco_config . pop ( \"<STR_LIT>\" , { } ) \n existing_crud_config . update ( new_crud_config ) \n existing_falco_config . update ( { ** new_falco_config , \"<STR_LIT>\" : existing_crud_config } ) \n tool = pyproject . get ( \"<STR_LIT>\" , { } ) \n tool . update ( { \"<STR_LIT>\" : existing_falco_config } ) \n pyproject [ \"<STR_LIT>\" ] = tool \n pyproject_path . write_text ( tomlkit . dumps ( pyproject ) ) \n def read_falco_config ( pyproject_path : Path ) -> FalcoConfig : \n pyproject = tomlkit . parse ( pyproject_path . read_text ( ) ) \n falco_config = pyproject . get ( \"<STR_LIT>\" , { } ) . get ( \"<STR_LIT>\" , { } ) \n crud_config = falco_config . pop ( \"<STR_LIT>\" , { } ) \n crud_config = parse_crud_config_from_pyproject ( crud_config ) \n return cast ( FalcoConfig , { ** falco_config , \"<STR_LIT>\" : crud_config } )"}, {"input": "from http import HTTPStatus \n from django . core . exceptions import ( \n FieldError , \n ObjectDoesNotExist , \n PermissionDenied , \n ValidationError , \n ) \n from ninja import NinjaAPI \n from ninja . errors import ValidationError as NinjaValidationError \n from examples . views . department_views import router as department_router \n from examples . views . employee_views import router as employee_router \n from tests . test_app . views . collection_views import router as collection_router", "output": "from tests . test_app . views . item_views import router as item_router \n from tests . test_app . views . user_views import router as user_router \n from tests . test_authentication import TokenBearer \n api = NinjaAPI ( urls_namespace = \"<STR_LIT>\" ) \n api . add_router ( \n \"<STR_LIT>\" , collection_router , auth = TokenBearer ( ) , tags = [ \"<STR_LIT>\" ] \n ) \n api . add_router ( \"<STR_LIT>\" , item_router , auth = TokenBearer ( ) , tags = [ \"<STR_LIT>\" ] ) \n api . add_router ( \"<STR_LIT>\" , user_router , tags = [ \"<STR_LIT>\" ] ) \n api . add_router ( \"<STR_LIT>\" , department_router , auth = None , tags = [ \"<STR_LIT>\" ] ) \n api . add_router ( \"<STR_LIT>\" , employee_router , auth = None , tags = [ \"<STR_LIT>\" ] ) \n @ api . exception_handler ( ObjectDoesNotExist ) \n def handle_object_does_not_exist ( request , exc ) : \n return api . create_response ( \n request , \n { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : str ( exc ) } , \n status = HTTPStatus . NOT_FOUND , \n ) \n @ api . exception_handler ( PermissionDenied ) \n def handle_permission_error ( request , exc : PermissionDenied ) : \n return api . create_response ( \n request , \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n } , \n status = HTTPStatus . FORBIDDEN , \n ) \n @ api . exception_handler ( NinjaValidationError ) \n def handle_ninja_validation_error ( request , exc : NinjaValidationError ) : \n mapped_msg = { error [ \"<STR_LIT>\" ] [ - <NUM_LIT> ] : error [ \"<STR_LIT>\" ] for error in exc . errors } \n return api . create_response ( \n request , \n data = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : mapped_msg } , \n status = HTTPStatus . BAD_REQUEST , \n ) \n @ api . exception_handler ( ValidationError ) \n def handle_validation_error ( request , exc : ValidationError ) : \n status = HTTPStatus . BAD_REQUEST \n for _ , errors in exc . error_dict . items ( ) : \n for error in errors : \n if error . code in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : \n status = HTTPStatus . CONFLICT \n return api . create_response ( \n request , \n data = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : exc . message_dict } , \n status = status , \n ) \n @ api . exception_handler ( FieldError ) \n def handle_field_error ( request , exc : FieldError ) : \n return api . create_response ( \n request , \n data = { \"<STR_LIT>\" : \"<STR_LIT>\" , \"<STR_LIT>\" : str ( exc ) } , \n status = HTTPStatus . BAD_REQUEST , \n )"}, {"input": "import requests , datetime \n from utils . general import headers \n from bs4 import BeautifulSoup as bs \n def get_desc_tvsou ( url ) : \n return '<STR_LIT>' \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n s = soup . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n desc = s . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n except Exception as e : \n desc = '<STR_LIT>' \n return desc \n def get_epgs_tvsou ( channel , channel_id_ , dt , func_arg ) : \n epgs = [ ] \n msg = '<STR_LIT>' \n success = <NUM_LIT> \n desc = '<STR_LIT>' \n need_weekday = dt . weekday ( ) + <NUM_LIT> \n if \"<STR_LIT>\" in channel_id_ : \n channel_id , sort_class = channel_id_ . split ( '<STR_LIT>' ) \n url = '<STR_LIT>' % ( channel_id , need_weekday ) \n else : \n url = '<STR_LIT>' % ( channel_id_ , need_weekday ) \n try : \n res = requests . get ( url , headers = headers , timeout = <NUM_LIT> ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n rows = soup . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . select ( '<STR_LIT>' ) \n except Exception as e : \n msg = '<STR_LIT>' % e \n success = <NUM_LIT> \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n program_urls = { } \n for row in rows : \n try : \n if row . select ( '<STR_LIT>' ) : \n starttime_str = row . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n title = row . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n else : \n starttime_str = row . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n title = row . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . text \n starttime = datetime . datetime . combine ( dt , datetime . time ( int ( starttime_str [ : <NUM_LIT> ] ) , int ( starttime_str [ - <NUM_LIT> : ] ) ) ) \n program_url = None \n if row . select ( '<STR_LIT>' ) and '<STR_LIT>' in row . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . attrs : \n program_url = '<STR_LIT>' + row . select ( '<STR_LIT>' ) [ <NUM_LIT> ] . attrs [ '<STR_LIT>' ] \n program_url = program_url . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n if program_url in program_urls : \n desc = program_urls [ program_url ] \n else : \n if len ( program_url ) > <NUM_LIT> : \n desc = get_desc_tvsou ( program_url ) \n program_urls . update ( { program_url : desc } ) \n else : \n program_url , desc = '<STR_LIT>' , '<STR_LIT>' \n else : \n program_url , desc = '<STR_LIT>' , '<STR_LIT>' \n epg = { '<STR_LIT>' : channel . id , \n '<STR_LIT>' : starttime , \n '<STR_LIT>' : None , \n '<STR_LIT>' : title , \n '<STR_LIT>' : desc , \n '<STR_LIT>' : dt , \n } \n epgs . append ( epg ) \n except Exception as e : \n msg = '<STR_LIT>' % e \n continue \n ret = { \n '<STR_LIT>' : success , \n '<STR_LIT>' : epgs , \n '<STR_LIT>' : msg , \n '<STR_LIT>' : dt , \n '<STR_LIT>' : <NUM_LIT> , \n } \n return ret \n def get_channels_tvsou ( ) : \n channels = [ ] \n sorts = [ ] \n host = '<STR_LIT>' \n url = '<STR_LIT>' % ( host , '<STR_LIT>' ) \n res = requests . get ( url , headers = headers ) \n res . encoding = '<STR_LIT>' \n soup = bs ( res . text , '<STR_LIT>' ) \n div_sorts = soup . select ( '<STR_LIT>' ) \n div_channels = soup . select ( '<STR_LIT>' ) \n n = <NUM_LIT> \n for div_channel in div_channels : \n sort_name = div_sorts [ n ] . text . strip ( )", "output": "lis = div_channel . select ( '<STR_LIT>' ) \n n += <NUM_LIT> \n for li in lis : \n name = li . a . text . strip ( ) \n url = host + li . a [ '<STR_LIT>' ] \n id = li . a [ '<STR_LIT>' ] . replace ( '<STR_LIT>' , '<STR_LIT>' ) . replace ( '<STR_LIT>' , '<STR_LIT>' ) \n if len ( id ) < <NUM_LIT> : \n continue \n channel = { \n '<STR_LIT>' : name , \n '<STR_LIT>' : [ id ] , \n '<STR_LIT>' : url , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : sort_name , \n } \n channels . append ( channel ) \n print ( '<STR_LIT>' % ( n , len ( channels ) ) ) \n return channels"}, {"input": "from pathlib import Path \n DEBUG = True \n USE_TZ = True \n SECRET_KEY = \"<STR_LIT>\" \n DATABASES = { \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : \"<STR_LIT>\" ,", "output": "\"<STR_LIT>\" : True , \n } \n } \n ROOT_URLCONF = \"<STR_LIT>\" \n DJANGO_APPS = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n THIRD_PARTY_APPS = [ \n \"<STR_LIT>\" , \n ] \n LOCAL_APPS = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] \n INSTALLED_APPS = DJANGO_APPS + THIRD_PARTY_APPS + LOCAL_APPS \n MIDDLEWARE = [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n TEMPLATES = [ \n { \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : [ ] , \n \"<STR_LIT>\" : True , \n \"<STR_LIT>\" : { \n \"<STR_LIT>\" : [ \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n ] \n } , \n } \n ] \n SITE_ID = <NUM_LIT> \n STATIC_URL = \"<STR_LIT>\" \n MEDIA_URL = \"<STR_LIT>\" \n MEDIA_ROOT = Path ( __file__ ) . parent / \"<STR_LIT>\" \n DEFAULT_AUTO_FIELD = \"<STR_LIT>\" \n CELERY_BROKER_URL = \"<STR_LIT>\" \n DJANGO_WEBHOOK = dict ( MODELS = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] )"}, {"input": "from django . conf import settings \n from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [", "output": "migrations . swappable_dependency ( settings . AUTH_USER_MODEL ) , \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . AlterField ( \n model_name = '<STR_LIT>' , \n name = '<STR_LIT>' , \n field = models . ForeignKey ( blank = True , null = True , on_delete = django . db . models . deletion . CASCADE , to = settings . AUTH_USER_MODEL ) , \n ) , \n ]"}, {"input": "from django . db import migrations , models \n class Migration ( migrations . Migration ) : \n dependencies = [ \n ( '<STR_LIT>' , '<STR_LIT>' ) , \n ] \n operations = [ \n migrations . CreateModel ( \n name = '<STR_LIT>' , \n fields = [ \n ( '<STR_LIT>' , models . BigAutoField ( auto_created = True , primary_key = True , serialize = False , verbose_name = '<STR_LIT>' ) ) , \n ( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> ) ) ,", "output": "( '<STR_LIT>' , models . CharField ( max_length = <NUM_LIT> ) ) , \n ] , \n ) , \n ]"}, {"input": "from django . db import migrations , models \n import django . db . models . deletion \n class Migration ( migrations . Migration ) : \n dependencies = [", "output": "( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ] \n operations = [ \n migrations . RemoveField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n ) , \n migrations . AddField ( \n model_name = \"<STR_LIT>\" , \n name = \"<STR_LIT>\" , \n field = models . ForeignKey ( \n blank = True , \n null = True , \n on_delete = django . db . models . deletion . CASCADE , \n to = \"<STR_LIT>\" , \n ) , \n ) , \n ]"}, {"input": "from django . db import models \n from django . contrib . auth . models import ( \n BaseUserManager , AbstractBaseUser , PermissionsMixin \n ) \n from . models_work import * \n from django . utils . translation import gettext as _ \n class MyUserManager ( BaseUserManager ) : \n def create_user ( self , username , password = None ) : \n if not username : \n raise ValueError ( '<STR_LIT>' )", "output": "user = self . model ( username = username , \n ) \n user . set_password ( password ) \n user . save ( using = self . _db ) \n return user \n def create_superuser ( self , username , password ) : \n user = self . create_user ( username , \n password = password , \n ) \n user . is_admin = True \n user . save ( using = self . _db ) \n return user \n class UserProfile ( AbstractBaseUser , PermissionsMixin ) : \n username = models . CharField ( _ ( '<STR_LIT>' ) , \n unique = True , \n max_length = <NUM_LIT> ) \n rid = models . CharField ( verbose_name = '<STR_LIT>' , max_length = <NUM_LIT> ) \n uuid = models . CharField ( verbose_name = '<STR_LIT>' , max_length = <NUM_LIT> ) \n autoLogin = models . BooleanField ( verbose_name = '<STR_LIT>' , default = True ) \n rtype = models . CharField ( verbose_name = '<STR_LIT>' , max_length = <NUM_LIT> ) \n deviceInfo = models . TextField ( verbose_name = _ ( '<STR_LIT>' ) , blank = True ) \n is_active = models . BooleanField ( verbose_name = _ ( '<STR_LIT>' ) , default = True ) \n is_admin = models . BooleanField ( verbose_name = _ ( '<STR_LIT>' ) , default = False ) \n objects = MyUserManager ( ) \n USERNAME_FIELD = '<STR_LIT>' \n REQUIRED_FIELDS = [ '<STR_LIT>' ] \n def get_full_name ( self ) : \n return self . username \n def get_short_name ( self ) : \n return self . username \n def __str__ ( self ) : \n return self . username \n def has_perm ( self , perm , obj = None ) : \n \"<STR_LIT>\" \n return True \n def has_module_perms ( self , app_label ) : \n \"<STR_LIT>\" \n return True \n @ property \n def is_staff ( self ) : \n \"<STR_LIT>\" \n return self . is_admin \n class Meta : \n verbose_name = _ ( \"<STR_LIT>\" ) \n verbose_name_plural = _ ( \"<STR_LIT>\" ) \n permissions = ( \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n ( \"<STR_LIT>\" , \"<STR_LIT>\" ) , \n )"}, {"input": "from django . contrib import admin \n from . models import Channel , Epg , Crawl_log , Channel_list \n admin . site . site_header = '<STR_LIT>' \n admin . site . site_title = \"<STR_LIT>\" \n admin . site . index_title = \"<STR_LIT>\" \n class ChannelAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n list_per_page = <NUM_LIT>", "output": "ordering = ( '<STR_LIT>' , ) \n list_display_links = ( '<STR_LIT>' , '<STR_LIT>' ) \n list_filter = ( '<STR_LIT>' , ) \n search_fields = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n admin . site . register ( Channel , ChannelAdmin ) \n class EpgAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n date_hierarchy = '<STR_LIT>' \n search_fields = ( '<STR_LIT>' , ) \n admin . site . register ( Epg , EpgAdmin ) \n class Crawl_logAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n admin . site . register ( Crawl_log , Crawl_logAdmin ) \n class Channel_listAdmin ( admin . ModelAdmin ) : \n list_display = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) \n list_filter = ( '<STR_LIT>' , ) \n list_display_links = ( '<STR_LIT>' , '<STR_LIT>' ) \n admin . site . register ( Channel_list , Channel_listAdmin )"}, {"input": "import operator \n from functools import reduce \n from django . db . models import Q , Count \n from django . utils . decorators import method_decorator \n from django . views . decorators . cache import cache_page \n from rest_framework . views import APIView \n from rest_framework . request import Request \n from rest_framework . response import Response \n from feeds . models import Location \n from feeds . views . base import BaseAreaViewSet \n from feeds . serializers import LocationSerializer , LocationLiteSerializer \n class AreaViewSet ( BaseAreaViewSet ) : \n serializer_class = LocationSerializer \n class AreaLiteViewSet ( BaseAreaViewSet ) : \n serializer_class = LocationLiteSerializer \n class AreasCountViewSet ( AreaViewSet ) : \n @ method_decorator ( cache_page ( <NUM_LIT> * <NUM_LIT> ) ) \n def list ( self , request : Request , * args , ** kwargs ) -> Response : \n return Response ( { \"<STR_LIT>\" : self . get_queryset ( ) . count ( ) } ) \n class CityByCityCountView ( APIView ) : \n CITY_LIST = { \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] , \n \"<STR_LIT>\" : [ \"<STR_LIT>\" ] ,", "output": "\"<STR_LIT>\" : [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] , \n } \n @ method_decorator ( cache_page ( <NUM_LIT> * <NUM_LIT> ) ) \n def get ( self , request : Request ) -> Response : \n kwargs = { } \n for city , keywords in self . CITY_LIST . items ( ) : \n kwargs [ city ] = Count ( \n \"<STR_LIT>\" , \n filter = reduce ( operator . or_ , ( Q ( formatted_address__icontains = k ) for k in keywords ) ) , \n ) \n return Response ( data = Location . objects . aggregate ( ** kwargs ) )"}]