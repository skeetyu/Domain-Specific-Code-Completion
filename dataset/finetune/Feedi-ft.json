[{"input": "from logging . config import fileConfig \n from alembic import context \n from feedi . models import db \n from sqlalchemy import engine_from_config , pool \n config = context . config \n if config . config_file_name is not None : \n fileConfig ( config . config_file_name ) \n target_metadata = db . Model . metadata \n def run_migrations_offline ( ) -> None : \n url = config . get_main_option ( \"<STR_LIT>\" ) \n context . configure ( \n url = url , \n target_metadata = target_metadata , \n literal_binds = True , \n render_as_batch = True , \n dialect_opts = { \"<STR_LIT>\" : \"<STR_LIT>\" } , \n ) \n with context . begin_transaction ( ) : \n context . run_migrations ( ) \n def run_migrations_online ( ) -> None : \n connectable = engine_from_config ( \n config . get_section ( config . config_ini_section , { } ) , \n prefix = \"<STR_LIT>\" , \n poolclass = pool . NullPool , \n ) \n with connectable . connect ( ) as connection : \n context . configure ( \n connection = connection , \n target_metadata = target_metadata , \n render_as_batch = True \n ) \n with context . begin_transaction ( ) : \n context . run_migrations ( ) \n if context . is_offline_mode ( ) : \n run_migrations_offline ( ) \n else :", "output": "run_migrations_online ( )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n pass \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op :", "output": "pass"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_column ( '<STR_LIT>' ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op :", "output": "batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . BOOLEAN ( ) , nullable = True ) )"}, {"input": "import csv \n import datetime \n from functools import wraps \n import click \n import flask \n import opml \n import sqlalchemy as sa \n from huey import crontab \n from huey . contrib . mini import MiniHuey \n import feedi . models as models \n import feedi . parsers as parsers \n from feedi . app import create_huey_app \n from feedi . models import db \n app = create_huey_app ( ) \n huey = MiniHuey ( pool_size = app . config [ '<STR_LIT>' ] ) \n feed_cli = flask . cli . AppGroup ( '<STR_LIT>' ) \n user_cli = flask . cli . AppGroup ( '<STR_LIT>' )", "output": "flask . current_app . cli . add_command ( feed_cli ) \n flask . current_app . cli . add_command ( user_cli ) \n def huey_task ( * huey_args ) : \n \"<STR_LIT>\" \n huey_decorator = huey . task ( * huey_args ) \n def with_context ( f ) : \n @ wraps ( f ) \n def decorator ( * args , ** kwargs ) : \n with app . app_context ( ) : \n fargs = '<STR_LIT>' . join ( [ str ( arg ) for arg in args ] ) \n fkwargs = '<STR_LIT>' . join ( [ f'<STR_LIT>' for ( k , v ) in kwargs . items ( ) ] ) \n app . logger . info ( \"<STR_LIT>\" , f . __name__ , fargs , fkwargs ) \n try : \n f ( * args , ** kwargs ) \n app . logger . info ( \"<STR_LIT>\" , f . __name__ , fargs , fkwargs ) \n except Exception : \n app . logger . exception ( \"<STR_LIT>\" , f . __name__ , fargs , fkwargs ) \n return decorator \n def composed_decorator ( f ) : \n return huey_decorator ( with_context ( f ) ) \n return composed_decorator \n @ feed_cli . command ( '<STR_LIT>' ) \n @ huey_task ( crontab ( minute = app . config [ '<STR_LIT>' ] ) ) \n def sync_all_feeds ( ) : \n feeds = db . session . execute ( db . select ( models . Feed . id , models . Feed . name ) ) . all ( ) \n tasks = [ ] \n for feed in feeds : \n tasks . append ( ( feed . name , sync_feed ( feed . id , feed . name ) ) ) \n for name , task in tasks : \n try : \n task . get ( ) \n except Exception : \n app . logger . exception ( \"<STR_LIT>\" , name ) \n continue \n @ huey_task ( ) \n def sync_feed ( feed_id , _feed_name , force = False ) : \n db_feed = db . session . get ( models . Feed , feed_id ) \n db_feed . sync_with_remote ( force = force ) \n db . session . commit ( ) \n @ feed_cli . command ( '<STR_LIT>' ) \n @ huey_task ( crontab ( minute = app . config [ '<STR_LIT>' ] ) ) \n def content_prefetch ( ) : \n for user_id in db . session . scalars ( db . select ( models . User . id ) ) : \n start_at = datetime . datetime . utcnow ( ) \n query = models . Entry . sorted_by ( \n user_id , models . Entry . ORDER_FREQUENCY , start_at , hide_seen = True ) . filter ( models . Entry . content_full . is_ ( None ) , models . Entry . content_url . isnot ( None ) ) . limit ( <NUM_LIT> ) \n for entry in db . session . scalars ( query ) : \n app . logger . debug ( '<STR_LIT>' , entry . content_url ) \n entry . fetch_content ( ) \n db . session . commit ( ) \n @ feed_cli . command ( '<STR_LIT>' ) \n @ huey_task ( crontab ( minute = '<STR_LIT>' , hour = app . config [ '<STR_LIT>' ] ) ) \n def delete_old_entries ( ) : \n older_than_date = ( datetime . datetime . utcnow ( ) - \n datetime . timedelta ( days = app . config [ '<STR_LIT>' ] ) ) \n minimum = app . config [ '<STR_LIT>' ] \n feeds_q = db . select ( models . Feed . id , models . Feed . name ) . join ( models . Feed . entries ) . filter ( models . Entry . sort_date < older_than_date , \n models . Entry . favorited . is_ ( None ) , \n models . Entry . backlogged . is_ ( None ) , \n models . Entry . pinned . is_ ( None ) \n ) . group_by ( models . Feed . id ) . having ( sa . func . count ( models . Feed . entries ) > <NUM_LIT> ) \n for ( feed_id , feed_name ) in db . session . execute ( feeds_q ) . all ( ) : \n min_sort_date = db . session . scalar ( \n db . select ( models . Entry . sort_date ) \n . filter_by ( feed_id = feed_id ) \n . order_by ( models . Entry . sort_date . desc ( ) ) \n . limit ( <NUM_LIT> ) \n . offset ( minimum - <NUM_LIT> ) ) \n if not min_sort_date : \n continue \n q = db . delete ( models . Entry ) . where ( \n models . Entry . favorited . is_ ( None ) , \n models . Entry . backlogged . is_ ( None ) , \n models . Entry . pinned . is_ ( None ) , \n models . Entry . feed_id == feed_id , \n models . Entry . sort_date < min_sort_date , \n models . Entry . sort_date < older_than_date ) \n res = db . session . execute ( q ) \n db . session . commit ( ) \n if res . rowcount : \n app . logger . info ( \"<STR_LIT>\" , res . rowcount , feed_id , feed_name ) \n q = db . delete ( models . Entry ) . where ( \n models . Entry . feed_id . is_ ( None ) , \n models . Entry . favorited . is_ ( None ) , \n models . Entry . pinned . is_ ( None ) , \n models . Entry . sort_date < older_than_date ) \n res = db . session . execute ( q ) \n db . session . commit ( ) \n if res . rowcount : \n app . logger . info ( \"<STR_LIT>\" , res . rowcount ) \n @ feed_cli . command ( '<STR_LIT>' ) \n @ huey_task ( crontab ( minute = '<STR_LIT>' , hour = '<STR_LIT>' ) ) \n def pop_backlog ( ) : \n \"<STR_LIT>\" \n week_ago = datetime . datetime . utcnow ( ) - datetime . timedelta ( days = <NUM_LIT> ) \n backlogged_date = sa . func . min ( models . Entry . backlogged ) . label ( '<STR_LIT>' ) \n query = db . select ( models . Entry ) . group_by ( models . Entry . user_id ) . having ( backlogged_date < week_ago ) \n for entry in db . session . scalars ( query ) : \n entry . unbacklog ( ) \n app . logger . info ( \"<STR_LIT>\" , entry . user_id , entry . target_url ) \n db . session . commit ( ) \n @ feed_cli . command ( '<STR_LIT>' ) \n @ click . argument ( '<STR_LIT>' ) \n def debug_feed ( url ) : \n parsers . rss . pretty_print ( url ) \n def load_user_arg ( _ctx , _param , email ) : \n if not email : \n email = app . config . get ( '<STR_LIT>' ) \n if not email : \n raise click . UsageError ( '<STR_LIT>' ) \n user = db . session . scalar ( db . select ( models . User ) . filter_by ( email = email ) ) \n if not user : \n raise click . UsageError ( f'<STR_LIT>' ) \n return user \n @ feed_cli . command ( '<STR_LIT>' ) \n @ click . argument ( \"<STR_LIT>\" ) \n @ click . argument ( '<STR_LIT>' , required = False , callback = load_user_arg ) \n def csv_load ( file , user ) : \n \"<STR_LIT>\" \n with open ( file ) as csv_file : \n for values in csv . reader ( csv_file ) : \n cls = models . Feed . resolve ( values [ <NUM_LIT> ] ) \n feed = cls . from_valuelist ( * values ) \n feed . user_id = user . id \n add_if_not_exists ( feed ) \n @ feed_cli . command ( '<STR_LIT>' ) \n @ click . argument ( \"<STR_LIT>\" ) \n @ click . argument ( '<STR_LIT>' , required = False , callback = load_user_arg ) \n def csv_dump ( file , user ) : \n \"<STR_LIT>\" \n with open ( file , '<STR_LIT>' ) as csv_file : \n feed_writer = csv . writer ( csv_file ) \n for feed in db . session . execute ( db . select ( models . Feed ) \n . filter_by ( user_id = user . id , is_mastodon = False ) ) . scalars ( ) : \n feed_writer . writerow ( feed . to_valuelist ( ) ) \n app . logger . info ( '<STR_LIT>' , feed ) \n @ feed_cli . command ( '<STR_LIT>' ) \n @ click . argument ( \"<STR_LIT>\" ) \n @ click . argument ( '<STR_LIT>' , required = False , callback = load_user_arg ) \n def opml_load ( file , user ) : \n document = opml . OpmlDocument . load ( file ) \n for outline in document . outlines : \n if outline . outlines : \n folder = outline . text \n for feed in outline . outlines : \n add_if_not_exists ( models . RssFeed ( name = feed . title or feed . text , \n user_id = user . id , \n url = feed . xml_url , \n folder = folder ) ) \n else : \n add_if_not_exists ( models . RssFeed ( name = feed . title or feed . text , \n user_id = user . id , \n url = feed . xml_url ) ) \n @ feed_cli . command ( '<STR_LIT>' ) \n @ click . argument ( \"<STR_LIT>\" ) \n @ click . argument ( '<STR_LIT>' , required = False , callback = load_user_arg ) \n def opml_dump ( file , user ) : \n document = opml . OpmlDocument ( ) \n folder_outlines = { } \n for feed in db . session . execute ( db . select ( models . RssFeed ) \n . filter_by ( user_id = user . id ) \n ) . scalars ( ) : \n if feed . folder : \n if feed . folder in folder_outlines : \n folder_outlines [ feed . folder ] = document . add_outline ( feed . folder ) \n target = folder_outlines [ feed . folder ] \n else : \n target = document \n target . add_rss ( feed . name , \n feed . url , \n title = feed . name , \n categories = [ feed . folder ] if feed . folder else [ ] , \n created = datetime . datetime . now ( ) ) \n document . dump ( file ) \n def add_if_not_exists ( feed ) : \n query = db . select ( db . exists ( models . Feed ) \n . where ( models . Feed . name == feed . name , models . Feed . user_id == feed . user_id ) ) \n if db . session . execute ( query ) . scalar ( ) : \n app . logger . info ( '<STR_LIT>' , feed . name ) \n return \n db . session . add ( feed ) \n db . session . commit ( ) \n feed . load_icon ( ) \n db . session . commit ( ) \n app . logger . info ( '<STR_LIT>' , feed ) \n @ user_cli . command ( '<STR_LIT>' ) \n @ click . argument ( '<STR_LIT>' ) \n @ click . password_option ( ) \n def user_add ( email , password ) : \n user = models . User ( email = email ) \n user . set_password ( password ) \n db . session . add ( user ) \n db . session . commit ( ) \n @ user_cli . command ( '<STR_LIT>' ) \n @ click . argument ( '<STR_LIT>' ) \n def user_delete ( email ) : \n stmt = db . delete ( models . User ) . where ( models . User . email == email ) \n db . session . execute ( stmt ) \n db . session . commit ( )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = True ) ) \n batch_op . create_foreign_key ( '<STR_LIT>' , '<STR_LIT>' , [ \n '<STR_LIT>' ] , [ '<STR_LIT>' ] ) \n batch_op . drop_column ( '<STR_LIT>' ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op :", "output": "batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . VARCHAR ( ) , nullable = True ) ) \n batch_op . drop_constraint ( '<STR_LIT>' , type_ = '<STR_LIT>' ) \n batch_op . drop_column ( '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None :", "output": "op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = True , server_default = \"<STR_LIT>\" ) ) \n def downgrade ( ) -> None : \n op . drop_column ( '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_index ( '<STR_LIT>' ) \n batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) \n batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' )", "output": "batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa", "output": "revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_column ( '<STR_LIT>' ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . INTEGER ( ) , server_default = sa . text ( \"<STR_LIT>\" ) , nullable = False ) )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op", "output": "revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = True ) ) \n batch_op . create_index ( batch_op . f ( '<STR_LIT>' ) , [ '<STR_LIT>' ] , unique = False ) \n batch_op . create_foreign_key ( '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] , [ '<STR_LIT>' ] ) \n op . execute ( \n '<STR_LIT>' ) \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . alter_column ( '<STR_LIT>' , nullable = False ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_constraint ( '<STR_LIT>' , type_ = '<STR_LIT>' ) \n batch_op . drop_index ( batch_op . f ( '<STR_LIT>' ) ) \n batch_op . drop_column ( '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op", "output": "revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = False , server_default = '<STR_LIT>' ) ) \n batch_op . create_index ( batch_op . f ( '<STR_LIT>' ) , [ '<STR_LIT>' ] , unique = False ) \n batch_op . create_foreign_key ( '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] , [ '<STR_LIT>' ] ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_constraint ( '<STR_LIT>' , type_ = '<STR_LIT>' ) \n batch_op . drop_index ( batch_op . f ( '<STR_LIT>' ) ) \n batch_op . drop_column ( '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) \n op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) \n op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False )", "output": "def downgrade ( ) -> None : \n op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) \n op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) \n op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' )"}, {"input": "import urllib \n import flask \n import flask_login \n from flask import current_app as app \n from flask_login import current_user , login_required \n import feedi . models as models \n from feedi . models import db \n def init ( ) : \n login_manager = flask_login . LoginManager ( ) \n login_manager . login_view = '<STR_LIT>' \n login_manager . init_app ( app ) \n @ login_manager . user_loader \n def load_user ( user_id ) : \n return db . session . get ( models . User , int ( user_id ) ) \n @ app . get ( \"<STR_LIT>\" ) \n def login ( ) : \n default_email = app . config . get ( '<STR_LIT>' ) \n if default_email : \n app . logger . debug ( \"<STR_LIT>\" , default_email ) \n user = db . session . scalar ( db . select ( models . User ) . filter_by ( email = default_email ) ) \n flask_login . login_user ( user , remember = True ) \n return flask . redirect ( flask . url_for ( '<STR_LIT>' ) ) \n return flask . render_template ( '<STR_LIT>' ) \n @ app . post ( '<STR_LIT>' ) \n def login_post ( ) : \n email = flask . request . form . get ( '<STR_LIT>' ) \n password = flask . request . form . get ( '<STR_LIT>' ) \n if not email or not password :", "output": "return flask . render_template ( '<STR_LIT>' , error_msg = \"<STR_LIT>\" ) \n user = db . session . scalar ( db . select ( models . User ) . filter_by ( email = email ) ) \n if not user or not user . check_password ( password ) : \n return flask . render_template ( '<STR_LIT>' , error_msg = \"<STR_LIT>\" ) \n flask_login . login_user ( user , remember = True ) \n return flask . redirect ( flask . url_for ( '<STR_LIT>' ) ) \n @ app . get ( \"<STR_LIT>\" ) \n @ login_required \n def kindle_add ( ) : \n verifier , url = models . KindleDevice . signin_url ( ) \n return flask . render_template ( '<STR_LIT>' , signin_url = url , verifier = verifier ) \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def kindle_add_submit ( ) : \n verifier = flask . request . form . get ( '<STR_LIT>' ) \n redirect_url = flask . request . form . get ( '<STR_LIT>' ) \n models . KindleDevice . add_from_url ( current_user . id , verifier , redirect_url ) \n db . session . commit ( ) \n return flask . redirect ( flask . url_for ( '<STR_LIT>' ) ) \n @ app . get ( \"<STR_LIT>\" ) \n @ login_required \n def mastodon_oauth ( ) : \n \"<STR_LIT>\" \n return flask . render_template ( '<STR_LIT>' ) \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def mastodon_oauth_submit ( ) : \n base_url = flask . request . form . get ( '<STR_LIT>' ) \n if not base_url : \n return flask . render_template ( '<STR_LIT>' , error_msg = \"<STR_LIT>\" ) \n url_parts = urllib . parse . urlparse ( base_url ) \n base_url = f'<STR_LIT>' \n app . logger . info ( '<STR_LIT>' , base_url ) \n masto_app = models . MastodonApp . get_or_create ( base_url ) \n return flask . redirect ( masto_app . auth_redirect_url ( ) ) \n @ app . get ( \"<STR_LIT>\" ) \n @ login_required \n def mastodon_oauth_callback ( ) : \n code = flask . request . args . get ( '<STR_LIT>' ) \n base_url = flask . request . args . get ( '<STR_LIT>' ) \n if not code or not base_url : \n app . logger . error ( \"<STR_LIT>\" ) \n flask . abort ( <NUM_LIT> ) \n masto_app = db . session . scalar ( db . select ( models . MastodonApp ) . filter_by ( api_base_url = base_url ) ) \n if not masto_app : \n app . logger . error ( \"<STR_LIT>\" , base_url ) \n flask . abort ( <NUM_LIT> ) \n app . logger . info ( \"<STR_LIT>\" , current_user . id , base_url ) \n account = masto_app . create_account ( current_user . id , code ) \n app . logger . info ( \"<STR_LIT>\" ) \n return flask . redirect ( flask . url_for ( '<STR_LIT>' , masto_acct = account . id ) )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n from werkzeug . security import generate_password_hash \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n table = op . create_table ( '<STR_LIT>' , \n sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = False ) , \n sa . Column ( '<STR_LIT>' , sa . String ( length = <NUM_LIT> ) , nullable = False ) , \n sa . Column ( '<STR_LIT>' , sa . String ( length = <NUM_LIT> ) , nullable = False ) , \n sa . PrimaryKeyConstraint ( '<STR_LIT>' ) , \n sa . UniqueConstraint ( '<STR_LIT>' ) \n ) \n op . bulk_insert ( \n table , \n [ { \"<STR_LIT>\" : <NUM_LIT> , \n \"<STR_LIT>\" : \"<STR_LIT>\" , \n \"<STR_LIT>\" : generate_password_hash ( \"<STR_LIT>\" ) } ] )", "output": "def downgrade ( ) -> None : \n op . drop_table ( '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op", "output": "revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True , server_default = None ) ) \n op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True , server_default = None ) ) \n op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True , server_default = None ) ) \n def downgrade ( ) -> None : \n op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) \n op . drop_column ( '<STR_LIT>' , '<STR_LIT>' ) \n op . drop_column ( '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "import json \n import logging \n import shutil \n import subprocess \n import urllib \n import zipfile \n import favicon . favicon as favicon \n from bs4 import BeautifulSoup \n from feedi . requests import USER_AGENT , requests \n logger = logging . getLogger ( __name__ ) \n def get_favicon ( url , html = None ) : \n \"<STR_LIT>\" \n url_parts = urllib . parse . urlparse ( url ) \n url = f'<STR_LIT>' \n try : \n if not html : \n favicons = favicon . get ( url , headers = { '<STR_LIT>' : USER_AGENT } , timeout = <NUM_LIT> ) \n else : \n favicons = sorted ( favicon . tags ( url , html ) , \n key = lambda i : i . width + i . height , reverse = True ) \n except Exception : \n logger . exception ( \"<STR_LIT>\" , url ) \n return \n ico_format = [ f for f in favicons if f . format == '<STR_LIT>' ] \n if ico_format : \n return ico_format [ <NUM_LIT> ] . url \n return favicons [ <NUM_LIT> ] . url if favicons else None \n class CachingRequestsMixin : \n def __init__ ( self ) : \n self . response_cache = { } \n def request ( self , url ) : \n if url in self . response_cache : \n logger . debug ( \"<STR_LIT>\" , url ) \n return self . response_cache [ url ] \n logger . debug ( \"<STR_LIT>\" , url ) \n content = requests . get ( url ) . content \n self . response_cache [ url ] = content \n return content", "output": "def fetch_meta ( self , url , * tags ) : \n soup = BeautifulSoup ( self . request ( url ) , '<STR_LIT>' ) \n return extract_meta ( soup , * tags ) \n def extract_meta ( soup , * tags ) : \n for tag in tags : \n for attr in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : \n meta_tag = soup . find ( \"<STR_LIT>\" , { attr : tag } , content = True ) \n if meta_tag : \n return meta_tag [ '<STR_LIT>' ] \n def all_meta ( soup ) : \n result = { } \n for attr in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] : \n for meta_tag in soup . find_all ( \"<STR_LIT>\" , { attr : True } , content = True ) : \n result [ meta_tag [ attr ] ] = meta_tag [ '<STR_LIT>' ] \n return result \n def extract_links ( url , html ) : \n soup = BeautifulSoup ( html , '<STR_LIT>' ) \n links = soup . find_all ( lambda tag : tag . name == '<STR_LIT>' and tag . text and '<STR_LIT>' in tag ) \n return [ ( make_absolute ( url , a [ '<STR_LIT>' ] ) , a . text ) for a in links ] \n def make_absolute ( url , path ) : \n \"<STR_LIT>\" \n if not urllib . parse . urlparse ( path ) . netloc : \n path = urllib . parse . urljoin ( url , path ) \n return path \n def extract ( url = None , html = None ) : \n if url : \n html = requests . get ( url ) . content \n elif not html : \n raise ValueError ( '<STR_LIT>' ) \n r = subprocess . run ( [ \"<STR_LIT>\" , \"<STR_LIT>\" , url ] , input = html , \n capture_output = True , check = True ) \n article = json . loads ( r . stdout ) \n soup = BeautifulSoup ( article [ '<STR_LIT>' ] , '<STR_LIT>' ) \n LAZY_DATA_ATTRS = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n for data_attr in LAZY_DATA_ATTRS : \n for img in soup . findAll ( '<STR_LIT>' , attrs = { data_attr : True } ) : \n img . attrs = { '<STR_LIT>' : img [ data_attr ] } \n for iframe in soup . findAll ( '<STR_LIT>' , height = True ) : \n del iframe [ '<STR_LIT>' ] \n article [ '<STR_LIT>' ] = str ( soup ) \n return article \n def compress ( outfilename , article ) : \n soup = BeautifulSoup ( article [ '<STR_LIT>' ] , '<STR_LIT>' ) \n with zipfile . ZipFile ( outfilename , '<STR_LIT>' , compression = zipfile . ZIP_DEFLATED ) as zip : \n for img in soup . findAll ( '<STR_LIT>' ) : \n img_url = img [ '<STR_LIT>' ] \n img_filename = '<STR_LIT>' + img [ '<STR_LIT>' ] . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n img [ '<STR_LIT>' ] = img_filename \n with requests . get ( img_url , stream = True ) as img_src , zip . open ( img_filename , mode = '<STR_LIT>' ) as img_dest : \n shutil . copyfileobj ( img_src . raw , img_dest ) \n zip . writestr ( '<STR_LIT>' , str ( soup ) )"}, {"input": "SQLALCHEMY_DATABASE_URI = \"<STR_LIT>\"", "output": "ENTRY_PAGE_SIZE = <NUM_LIT> \n SYNC_FEEDS_CRON_MINUTES = '<STR_LIT>' \n DELETE_OLD_CRON_HOURS = '<STR_LIT>' \n SKIP_RECENTLY_UPDATED_MINUTES = <NUM_LIT> \n CONTENT_PREFETCH_MINUTES = '<STR_LIT>' \n RSS_SKIP_OLDER_THAN_DAYS = <NUM_LIT> \n DELETE_AFTER_DAYS = <NUM_LIT> \n RSS_MINIMUM_ENTRY_AMOUNT = <NUM_LIT> \n MASTODON_FETCH_LIMIT = <NUM_LIT> \n HUEY_POOL_SIZE = <NUM_LIT> \n DEFAULT_AUTH_USER = '<STR_LIT>'"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) \n def downgrade ( ) -> None :", "output": "with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_column ( '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True ) )", "output": "op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) \n def downgrade ( ) -> None : \n op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) \n op . drop_column ( '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) \n op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) \n op . create_index ( op . f ( '<STR_LIT>' ) , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = True ) \n def downgrade ( ) -> None : \n op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' ) \n op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' )", "output": "op . drop_index ( op . f ( '<STR_LIT>' ) , table_name = '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None :", "output": "with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True ) ) \n batch_op . create_index ( batch_op . f ( '<STR_LIT>' ) , [ '<STR_LIT>' ] , unique = False ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_index ( batch_op . f ( '<STR_LIT>' ) ) \n batch_op . drop_column ( '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>'", "output": "down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' ) as batch_op : \n batch_op . alter_column ( '<STR_LIT>' , \n existing_type = sa . String ( ) , \n nullable = False ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' ) as batch_op : \n batch_op . alter_column ( '<STR_LIT>' , \n existing_type = sa . String ( ) , \n nullable = True )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>'", "output": "down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . alter_column ( '<STR_LIT>' , '<STR_LIT>' , new_column_name = '<STR_LIT>' ) \n def downgrade ( ) -> None : \n op . alter_column ( '<STR_LIT>' , '<STR_LIT>' , new_column_name = '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>'", "output": "down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . alter_column ( '<STR_LIT>' , \n server_default = None , \n nullable = True ) \n def downgrade ( ) -> None : \n pass"}, {"input": "import datetime \n import json \n import dateparser \n from bs4 import BeautifulSoup \n from feedi import scraping \n from feedi . requests import requests \n def fetch ( url ) : \n response = requests . get ( url ) \n response . raise_for_status ( ) \n if not response . ok : \n raise Exception ( ) \n soup = BeautifulSoup ( response . content , '<STR_LIT>' )", "output": "metadata = scraping . all_meta ( soup ) \n title = metadata . get ( '<STR_LIT>' , metadata . get ( '<STR_LIT>' , getattr ( soup . title , '<STR_LIT>' ) ) ) \n if not title : \n raise ValueError ( f\"<STR_LIT>\" ) \n if '<STR_LIT>' in metadata : \n display_date = dateparser . parse ( metadata [ '<STR_LIT>' ] ) \n else : \n display_date = datetime . datetime . utcnow ( ) \n username = metadata . get ( '<STR_LIT>' , '<STR_LIT>' ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n icon_url = scraping . get_favicon ( url , html = response . content ) \n entry = { \n '<STR_LIT>' : url , \n '<STR_LIT>' : title , \n '<STR_LIT>' : username , \n '<STR_LIT>' : display_date , \n '<STR_LIT>' : datetime . datetime . utcnow ( ) , \n '<STR_LIT>' : metadata . get ( '<STR_LIT>' , metadata . get ( '<STR_LIT>' ) ) , \n '<STR_LIT>' : metadata . get ( '<STR_LIT>' , metadata . get ( '<STR_LIT>' ) ) , \n '<STR_LIT>' : url , \n '<STR_LIT>' : url , \n '<STR_LIT>' : json . dumps ( metadata ) , \n '<STR_LIT>' : icon_url } \n return entry"}, {"input": "import datetime \n import html \n import json \n import logging \n import pprint \n import time \n import traceback \n import urllib \n import feedparser \n from bs4 import BeautifulSoup \n from feedi import scraping \n from feedi . requests import USER_AGENT , requests \n from feedi . scraping import CachingRequestsMixin \n logger = logging . getLogger ( __name__ ) \n feedparser . USER_AGENT = USER_AGENT \n def fetch ( feed_name , url , skip_older_than , min_amount , \n previous_fetch , etag , modified , filters ) : \n parser_cls = RSSParser \n for cls in RSSParser . __subclasses__ ( ) : \n if cls . is_compatible ( url ) : \n parser_cls = cls \n parser = parser_cls ( feed_name , url , skip_older_than , min_amount ) \n return parser . fetch ( previous_fetch , etag , modified , filters ) \n def fetch_icon ( url ) : \n feed = feedparser . parse ( url ) \n feed_link = feed [ '<STR_LIT>' ] . get ( '<STR_LIT>' , url ) \n icon_url = scraping . get_favicon ( feed_link ) \n if icon_url : \n logger . debug ( \"<STR_LIT>\" , icon_url ) \n return icon_url \n icon_url = feed [ '<STR_LIT>' ] . get ( '<STR_LIT>' , feed [ '<STR_LIT>' ] . get ( '<STR_LIT>' ) ) \n if icon_url and requests . get ( icon_url ) . ok : \n logger . debug ( \"<STR_LIT>\" , icon_url ) \n return icon_url \n logger . debug ( \"<STR_LIT>\" , url ) \n class RSSParser ( CachingRequestsMixin ) : \n FIELDS = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , ] \n @ staticmethod \n def is_compatible ( _feed_url ) : \n raise NotImplementedError \n def __init__ ( self , feed_name , url , skip_older_than , min_amount ) : \n super ( ) . __init__ ( ) \n self . feed_name = feed_name \n self . url = url \n self . skip_older_than = skip_older_than \n self . min_amount = min_amount \n def fetch ( self , previous_fetch , etag , modified , filters = None ) : \n feed = feedparser . parse ( self . url , etag = etag , modified = modified ) \n if feed . bozo : \n logger . warning ( \"<STR_LIT>\" , self . feed_name , feed . bozo_exception ) \n if not feed [ '<STR_LIT>' ] : \n logger . info ( '<STR_LIT>' , self . url , feed . get ( '<STR_LIT>' ) ) \n return None , [ ] , None , None \n etag = getattr ( feed , '<STR_LIT>' , None ) \n modified = getattr ( feed , '<STR_LIT>' , None ) \n entries = [ ] \n for item in feed [ '<STR_LIT>' ] : \n try : \n entry = self . parse ( item , len ( entries ) , previous_fetch , filters ) \n if entry : \n entry [ '<STR_LIT>' ] = json . dumps ( item ) \n entries . append ( entry ) \n except Exception as error : \n exc_desc_lines = traceback . format_exception_only ( type ( error ) , error ) \n exc_desc = '<STR_LIT>' . join ( exc_desc_lines ) . rstrip ( ) \n logger . error ( \"<STR_LIT>\" , \n self . feed_name , \n item . get ( '<STR_LIT>' ) , \n exc_desc ) \n logger . debug ( traceback . format_exc ( ) ) \n return feed [ '<STR_LIT>' ] , entries , etag , modified \n def parse ( self , item , parsed_count , previous_fetch , filters ) : \n if self . should_skip ( item ) : \n return \n is_first_load = previous_fetch is None \n published = item . get ( '<STR_LIT>' , item . get ( '<STR_LIT>' ) ) \n if ( self . skip_older_than and published and to_datetime ( published ) < self . skip_older_than ) : \n if not is_first_load or not self . min_amount or parsed_count >= self . min_amount : \n logger . debug ( '<STR_LIT>' , item . get ( '<STR_LIT>' ) ) \n return \n if filters and not self . _matches ( item , filters ) : \n logger . debug ( '<STR_LIT>' , item . get ( '<STR_LIT>' ) , filters ) \n return \n result = { } \n for field in self . FIELDS : \n method = '<STR_LIT>' + field \n result [ field ] = getattr ( self , method ) ( item ) \n return result \n @ staticmethod \n def should_skip ( _entry ) : \n return False \n @ staticmethod \n def _matches ( entry , filters ) : \n filters = filters . split ( '<STR_LIT>' ) \n for filter in filters : \n field , value = filter . strip ( ) . split ( '<STR_LIT>' ) \n field = field . lower ( ) . strip ( ) \n value = value . lower ( ) . strip ( ) \n if value not in entry . get ( field , '<STR_LIT>' ) . lower ( ) : \n return False \n return True \n def parse_title ( self , entry ) : \n return entry . get ( '<STR_LIT>' ) or self . fetch_meta ( self . parse_content_url ( entry ) , '<STR_LIT>' ) \n def parse_content_url ( self , entry ) : \n return entry [ '<STR_LIT>' ] \n def parse_target_url ( self , entry ) : \n return self . parse_content_url ( entry ) \n def parse_comments_url ( self , entry ) : \n return entry . get ( '<STR_LIT>' ) \n def parse_username ( self , entry ) : \n author = entry . get ( '<STR_LIT>' , '<STR_LIT>' ) \n if author : \n author = BeautifulSoup ( author , '<STR_LIT>' ) . text \n author = author . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n if '<STR_LIT>' in author : \n author = author . split ( '<STR_LIT>' ) [ <NUM_LIT> ] . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n return author \n def parse_avatar_url ( self , entry ) : \n url = entry . get ( '<STR_LIT>' , { } ) . get ( '<STR_LIT>' )", "output": "if url and requests . get ( url ) . ok : \n logger . debug ( '<STR_LIT>' , url ) \n return url \n def parse_content_short ( self , entry ) : \n content_url = self . parse_content_url ( entry ) \n summary = entry . get ( '<STR_LIT>' ) \n if summary : \n footer = summary . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] \n if content_url . split ( '<STR_LIT>' ) [ <NUM_LIT> ] in footer : \n summary = summary . replace ( footer , '<STR_LIT>' ) . strip ( ) \n summary = html . unescape ( summary ) \n else : \n if not content_url : \n return \n summary = self . fetch_meta ( content_url , '<STR_LIT>' , '<STR_LIT>' ) \n if not summary : \n return \n soup = BeautifulSoup ( summary , '<STR_LIT>' ) \n for tag in soup ( '<STR_LIT>' ) : \n tag . decompose ( ) \n return str ( soup ) \n def parse_content_full ( self , _entry ) : \n return None \n def parse_media_url ( self , entry ) : \n if '<STR_LIT>' in entry : \n return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] \n if '<STR_LIT>' in entry and entry [ '<STR_LIT>' ] [ <NUM_LIT> ] . get ( '<STR_LIT>' ) == '<STR_LIT>' : \n return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] \n if '<STR_LIT>' in entry : \n soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) \n if soup . img : \n return soup . img [ '<STR_LIT>' ] \n parsed_dest_url = self . parse_content_url ( entry ) \n return self . fetch_meta ( parsed_dest_url , \"<STR_LIT>\" , \"<STR_LIT>\" ) \n def parse_remote_id ( self , entry ) : \n return entry . get ( '<STR_LIT>' , entry [ '<STR_LIT>' ] ) \n def parse_display_date ( self , entry ) : \n dt = to_datetime ( entry . get ( '<STR_LIT>' , entry . get ( '<STR_LIT>' ) ) ) \n if dt > datetime . datetime . utcnow ( ) : \n raise ValueError ( f\"<STR_LIT>\" ) \n return dt \n def parse_sort_date ( self , entry ) : \n dt = to_datetime ( entry [ '<STR_LIT>' ] ) \n if dt > datetime . datetime . utcnow ( ) : \n raise ValueError ( \"<STR_LIT>\" ) \n return dt \n def parse_header ( self , entry ) : \n return None \n def discover_feed ( url ) : \n res = requests . get ( url ) \n if not res . ok : \n logger . warn ( \"<STR_LIT>\" , url , res ) \n return \n parsed = feedparser . parse ( res . content ) \n if not parsed . bozo : \n title = parsed . feed . get ( '<STR_LIT>' ) \n return url , title \n soup = BeautifulSoup ( res . content , '<STR_LIT>' ) \n title = scraping . extract_meta ( soup , '<STR_LIT>' , '<STR_LIT>' ) \n if not title : \n title = soup . find ( '<STR_LIT>' ) \n if title : \n title = title . text \n link_types = [ \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" , \n \"<STR_LIT>\" ] \n feed_url = None \n for type in link_types : \n link = soup . find ( '<STR_LIT>' , type = type , href = True ) \n if link : \n feed_url = scraping . make_absolute ( url , link [ '<STR_LIT>' ] ) \n return feed_url , title \n common_paths = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] \n for path in common_paths : \n rss_url = scraping . make_absolute ( url , path ) \n res = requests . get ( rss_url ) \n mime = res . headers . get ( '<STR_LIT>' , '<STR_LIT>' ) . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n if res . ok and mime . endswith ( '<STR_LIT>' ) : \n return rss_url , title \n return None , title \n def pretty_print ( url ) : \n feed = feedparser . parse ( url ) \n pp = pprint . PrettyPrinter ( depth = <NUM_LIT> ) \n pp . pprint ( feed ) \n def to_datetime ( struct_time ) : \n try : \n return datetime . datetime . fromtimestamp ( time . mktime ( struct_time ) ) \n except Exception : \n logger . error ( \"<STR_LIT>\" , struct_time ) \n raise \n def short_date_handler ( date_str ) : \n return datetime . datetime . strptime ( date_str , '<STR_LIT>' ) . timetuple ( ) \n feedparser . registerDateHandler ( short_date_handler ) \n class RedditInboxParser ( RSSParser ) : \n \"<STR_LIT>\" \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url \n def parse_content_short ( self , entry ) : \n return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] \n def parse_title ( self , entry ) : \n return entry [ '<STR_LIT>' ] . split ( '<STR_LIT>' ) [ - <NUM_LIT> ] . capitalize ( ) \n class RedditParser ( RSSParser ) : \n \"<STR_LIT>\" \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url and '<STR_LIT>' not in feed_url \n def parse_content_short ( self , entry ) : \n soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) \n link_anchor = soup . find ( \"<STR_LIT>\" , string = \"<STR_LIT>\" ) \n comments_anchor = soup . find ( \"<STR_LIT>\" , string = \"<STR_LIT>\" ) \n if link_anchor [ '<STR_LIT>' ] == comments_anchor [ '<STR_LIT>' ] : \n link_anchor . decompose ( ) \n comments_anchor . decompose ( ) \n return str ( soup ) \n return self . fetch_meta ( link_anchor [ '<STR_LIT>' ] , '<STR_LIT>' , '<STR_LIT>' ) \n def parse_content_url ( self , entry ) : \n soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) \n return soup . find ( \"<STR_LIT>\" , string = \"<STR_LIT>\" ) [ '<STR_LIT>' ] \n def parse_comments_url ( self , entry ) : \n return entry [ '<STR_LIT>' ] \n def parse_username ( self , entry ) : \n if entry . get ( '<STR_LIT>' , [ ] ) : \n return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] \n return super ( ) . parse_username ( entry ) \n class LobstersParser ( RSSParser ) : \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url \n def parse_content_short ( self , entry ) : \n if '<STR_LIT>' in entry [ '<STR_LIT>' ] : \n url = self . parse_content_url ( entry ) \n return self . fetch_meta ( url , '<STR_LIT>' , '<STR_LIT>' ) \n return entry [ '<STR_LIT>' ] \n def parse_username ( self , entry ) : \n username = super ( ) . parse_username ( entry ) \n return username . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n class HackerNewsParser ( RSSParser ) : \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url or '<STR_LIT>' in feed_url \n def parse_content_short ( self , entry ) : \n if '<STR_LIT>' in entry [ '<STR_LIT>' ] : \n url = self . parse_content_url ( entry ) \n return self . fetch_meta ( url , '<STR_LIT>' , '<STR_LIT>' ) \n return entry [ '<STR_LIT>' ] \n class GithubFeedParser ( RSSParser ) : \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url and '<STR_LIT>' in feed_url \n def parse_content_short ( self , entry ) : \n return entry [ '<STR_LIT>' ] \n def parse_username ( self , entry ) : \n return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] \n def parse_title ( self , _entry ) : \n return None \n def parse_avatar_url ( self , entry ) : \n return entry [ '<STR_LIT>' ] [ <NUM_LIT> ] [ '<STR_LIT>' ] \n def parse_media_url ( self , _entry ) : \n return None \n def parse_content_url ( self , _entry ) : \n return None \n def parse_target_url ( self , _entry ) : \n return None \n class GoodreadsFeedParser ( RSSParser ) : \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url and '<STR_LIT>' in feed_url \n def parse_content_short ( self , entry ) : \n summary = html . unescape ( entry [ '<STR_LIT>' ] ) \n soup = BeautifulSoup ( summary , '<STR_LIT>' ) \n for img in soup ( '<STR_LIT>' ) : \n img . decompose ( ) \n for a in soup ( '<STR_LIT>' ) : \n a [ '<STR_LIT>' ] = urllib . parse . urljoin ( '<STR_LIT>' , a [ '<STR_LIT>' ] ) \n return str ( soup ) \n def parse_title ( self , _entry ) : \n return None \n def parse_media_url ( self , _entry ) : \n return None \n def parse_target_url ( self , entry ) : \n return entry [ '<STR_LIT>' ] \n def parse_content_url ( self , _entry ) : \n return None \n class RevistaCrisisParser ( RSSParser ) : \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url \n @ staticmethod \n def should_skip ( entry ) : \n return '<STR_LIT>' in entry [ '<STR_LIT>' ] or entry [ '<STR_LIT>' ] . lower ( ) . startswith ( '<STR_LIT>' ) \n def parse_content_short ( self , entry ) : \n return self . fetch_meta ( entry [ '<STR_LIT>' ] , '<STR_LIT>' , '<STR_LIT>' ) \n class ACMQueueParser ( RSSParser ) : \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url \n def parse_content_short ( self , entry ) : \n content = self . request ( entry [ '<STR_LIT>' ] ) \n soup = BeautifulSoup ( content , '<STR_LIT>' ) \n title = soup . find ( '<STR_LIT>' ) \n return str ( title . find_next ( '<STR_LIT>' ) ) \n def parse_username ( self , entry ) : \n content = self . request ( entry [ '<STR_LIT>' ] ) \n soup = BeautifulSoup ( content , '<STR_LIT>' ) \n title = soup . find ( '<STR_LIT>' ) \n author = title . find_next ( '<STR_LIT>' ) \n if author : \n return author . text . split ( '<STR_LIT>' ) [ <NUM_LIT> ] \n class WikiFeaturedParser ( RSSParser ) : \n @ staticmethod \n def is_compatible ( feed_url ) : \n return '<STR_LIT>' in feed_url and '<STR_LIT>' in feed_url \n def parse_content_short ( self , entry ) : \n soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) \n return str ( soup . find ( '<STR_LIT>' ) ) \n def parse_title ( self , entry ) : \n soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) \n return soup . find ( '<STR_LIT>' ) . find ( '<STR_LIT>' ) . text \n class IndieBlogParser ( RSSParser ) : \n @ staticmethod \n def is_compatible ( _feed_url ) : \n return '<STR_LIT>' in _feed_url \n def parse_content_short ( self , entry ) : \n soup = BeautifulSoup ( entry [ '<STR_LIT>' ] , '<STR_LIT>' ) \n body = soup . blockquote \n body . name = '<STR_LIT>' \n return str ( body )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>'", "output": "down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . alter_column ( '<STR_LIT>' , new_column_name = '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None :", "output": "op . create_table ( '<STR_LIT>' , \n sa . Column ( '<STR_LIT>' , sa . INTEGER ( ) , nullable = False ) , \n sa . Column ( '<STR_LIT>' , sa . INTEGER ( ) , nullable = False ) , \n sa . Column ( '<STR_LIT>' , sa . VARCHAR ( ) , nullable = False ) , \n sa . ForeignKeyConstraint ( [ '<STR_LIT>' ] , [ '<STR_LIT>' ] , ) , \n sa . PrimaryKeyConstraint ( '<STR_LIT>' ) , \n sa . UniqueConstraint ( '<STR_LIT>' ) \n ) \n def downgrade ( ) -> None : \n op . drop_table ( '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) \n def downgrade ( ) -> None :", "output": "op . drop_column ( '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op", "output": "revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . drop_index ( '<STR_LIT>' , table_name = '<STR_LIT>' ) \n with op . batch_alter_table ( \"<STR_LIT>\" ) as batch_op : \n batch_op . drop_column ( '<STR_LIT>' ) \n def downgrade ( ) -> None : \n op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . TIMESTAMP ( ) , nullable = True ) ) \n op . create_index ( '<STR_LIT>' , '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False )"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>'", "output": "branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . alter_column ( '<STR_LIT>' , \n existing_type = sa . INTEGER ( ) , \n nullable = False ) \n batch_op . drop_index ( '<STR_LIT>' ) \n batch_op . create_index ( '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' ] , unique = False ) \n batch_op . create_unique_constraint ( '<STR_LIT>' , [ '<STR_LIT>' , '<STR_LIT>' ] ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_constraint ( '<STR_LIT>' , type_ = '<STR_LIT>' ) \n batch_op . drop_index ( '<STR_LIT>' ) \n batch_op . create_index ( '<STR_LIT>' , [ '<STR_LIT>' ] , unique = False ) \n batch_op . alter_column ( '<STR_LIT>' , \n existing_type = sa . INTEGER ( ) , \n nullable = True )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>'", "output": "down_revision : Union [ str , None ] = None \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) \n def downgrade ( ) -> None : \n op . drop_column ( '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "import os \n import re \n import uuid \n import feedgen . feed as feedgen \n import feedi . app as feedi_app \n import httpretty \n import pytest \n from feedi . models import db \n @ pytest . fixture ( scope = '<STR_LIT>' ) \n def app ( ) : \n assert os . getenv ( '<STR_LIT>' ) == '<STR_LIT>' , \"<STR_LIT>\" \n app = feedi_app . create_app ( ) \n httpretty . enable ( allow_net_connect = False , verbose = True ) \n yield app \n httpretty . disable ( ) \n with app . app_context ( ) : \n db . drop_all ( ) \n @ pytest . fixture \n def client ( app ) : \n \"<STR_LIT>\" \n email = f'<STR_LIT>' \n with app . app_context ( ) : \n from feedi import models \n user = models . User ( email = email ) \n user . set_password ( '<STR_LIT>' ) \n db . session . add ( user ) \n db . session . commit ( ) \n client = app . test_client ( ) \n response = client . post ( \n '<STR_LIT>' , data = { '<STR_LIT>' : email , '<STR_LIT>' : '<STR_LIT>' } , follow_redirects = True ) \n assert response . status_code == <NUM_LIT> \n httpretty . reset ( ) \n return client \n def create_feed ( client , domain , items , folder = None ) : \n feed_url = mock_feed ( domain , items ) \n return client . post ( '<STR_LIT>' , data = { \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : domain , \n '<STR_LIT>' : feed_url , \n '<STR_LIT>' : folder \n } , follow_redirects = True ) \n def mock_feed ( domain , items ) : \n base_url = f'<STR_LIT>' \n feed_url = f'<STR_LIT>' \n fg = feedgen . FeedGenerator ( ) \n fg . id ( base_url ) \n fg . link ( href = feed_url ) \n fg . title ( f'<STR_LIT>' )", "output": "fg . description ( f'<STR_LIT>' ) \n for item in items : \n entry_url = f'<STR_LIT>' \n entry = fg . add_entry ( ) \n entry . id ( ) \n entry . link ( href = entry_url ) \n entry . title ( item [ '<STR_LIT>' ] ) \n entry . author ( { \"<STR_LIT>\" : item . get ( '<STR_LIT>' , '<STR_LIT>' ) } ) \n entry . published ( item [ '<STR_LIT>' ] ) \n entry . updated ( item [ '<STR_LIT>' ] ) \n entry . description ( item . get ( '<STR_LIT>' , '<STR_LIT>' ) ) \n mock_request ( entry_url , body = item . get ( '<STR_LIT>' , '<STR_LIT>' ) ) \n rssfeed = fg . rss_str ( ) \n mock_request ( base_url ) \n mock_request ( f'<STR_LIT>' , ctype = '<STR_LIT>' ) \n mock_request ( feed_url , body = rssfeed , ctype = '<STR_LIT>' ) \n return feed_url \n def mock_request ( url , body = '<STR_LIT>' , ctype = '<STR_LIT>' ) : \n httpretty . register_uri ( httpretty . HEAD , url , adding_headers = { \n '<STR_LIT>' : ctype } , priority = <NUM_LIT> ) \n httpretty . register_uri ( httpretty . GET , url , body = body , adding_headers = { \n '<STR_LIT>' : ctype } , priority = <NUM_LIT> ) \n def extract_entry_ids ( response ) : \n entry_ids_with_duplicates = re . findall ( r'<STR_LIT>' , response . text ) \n entry_ids = [ ] \n for e in entry_ids_with_duplicates : \n if e not in entry_ids : \n entry_ids . append ( e ) \n return entry_ids"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa", "output": "revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_column ( '<STR_LIT>' ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . VARCHAR ( ) , nullable = True ) )"}, {"input": "import datetime \n import pathlib \n import tempfile \n import flask \n import sqlalchemy as sa \n from flask import current_app as app \n from flask_login import current_user , login_required \n import feedi . models as models \n import feedi . tasks as tasks \n from feedi import scraping \n from feedi . models import db \n from feedi . parsers import mastodon , rss \n @ app . route ( \"<STR_LIT>\" ) \n @ app . route ( \"<STR_LIT>\" , defaults = { '<STR_LIT>' : True } , endpoint = '<STR_LIT>' ) \n @ app . route ( \"<STR_LIT>\" , defaults = { '<STR_LIT>' : True } , endpoint = '<STR_LIT>' ) \n @ app . route ( \"<STR_LIT>\" ) \n @ app . route ( \"<STR_LIT>\" ) \n @ app . route ( \"<STR_LIT>\" ) \n @ login_required \n def entry_list ( ** filters ) : \n page = flask . request . args . get ( '<STR_LIT>' ) \n hide_seen = flask . session . get ( '<STR_LIT>' , True ) \n ordering = flask . session . get ( '<STR_LIT>' , models . Entry . ORDER_FREQUENCY ) \n filters = dict ( ** filters ) \n text = flask . request . args . get ( '<STR_LIT>' , '<STR_LIT>' ) . strip ( ) \n if text : \n filters [ '<STR_LIT>' ] = text \n is_mixed_feed_list = filters . get ( '<STR_LIT>' ) or ( \n flask . request . path == '<STR_LIT>' and not filters . get ( '<STR_LIT>' ) ) \n ( entries , next_page ) = fetch_entries_page ( page , current_user . id , ordering , hide_seen , is_mixed_feed_list , \n ** filters ) \n if page : \n return flask . render_template ( '<STR_LIT>' , \n entries = entries , \n filters = filters , \n next_page = next_page ) \n return flask . render_template ( '<STR_LIT>' , \n pinned = models . Entry . select_pinned ( current_user . id , ** filters ) , \n entries = entries , \n next_page = next_page , \n is_mixed_feed_view = is_mixed_feed_list , \n filters = filters ) \n def fetch_entries_page ( page_arg , \n user_id , \n ordering_setting , \n hide_seen_setting , \n is_mixed_feed_list , ** filters ) : \n filters [ '<STR_LIT>' ] = is_mixed_feed_list and hide_seen_setting \n ordering = ordering_setting if is_mixed_feed_list else models . Entry . ORDER_RECENCY \n if page_arg : \n start_at , page_num = page_arg . split ( '<STR_LIT>' ) \n page_num = int ( page_num ) \n start_at = datetime . datetime . fromtimestamp ( float ( start_at ) ) \n else : \n start_at = datetime . datetime . utcnow ( ) \n page_num = <NUM_LIT> \n query = models . Entry . sorted_by ( user_id , ordering , start_at , ** filters ) \n entry_page = db . paginate ( query , per_page = app . config [ '<STR_LIT>' ] , page = page_num ) \n next_page = f'<STR_LIT>' if entry_page . has_next else None \n if entry_page . has_prev : \n previous_ids = [ e . id for e in entry_page . prev ( ) . items ] \n update = db . update ( models . Entry ) . where ( models . Entry . id . in_ ( previous_ids ) ) . values ( viewed = datetime . datetime . utcnow ( ) ) \n db . session . execute ( update ) \n db . session . commit ( ) \n return entry_page , next_page \n @ app . get ( \"<STR_LIT>\" ) \n @ login_required \n def autocomplete ( ) : \n term = flask . request . args [ '<STR_LIT>' ] . strip ( ) \n options = [ ] \n if term . startswith ( '<STR_LIT>' ) or term . startswith ( '<STR_LIT>' ) : \n options += [ \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , url = term ) , '<STR_LIT>' , '<STR_LIT>' ) , \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , url = term , redirect = <NUM_LIT> ) , '<STR_LIT>' , '<STR_LIT>' ) , \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , url = term ) , '<STR_LIT>' ) , \n ] \n if current_user . has_kindle : \n options += [ ( '<STR_LIT>' , \n flask . url_for ( '<STR_LIT>' , url = term ) , '<STR_LIT>' , \n '<STR_LIT>' ) ] \n else : \n folders = db . session . scalars ( \n db . select ( models . Feed . folder ) \n . filter ( models . Feed . folder . icontains ( term ) , \n models . Feed . user_id == current_user . id ) . distinct ( ) \n ) . all ( ) \n options += [ ( f , flask . url_for ( '<STR_LIT>' , folder = f ) , '<STR_LIT>' ) \n for f in folders ] \n feed_names = db . session . scalars ( \n db . select ( models . Feed . name ) \n . filter ( models . Feed . name . icontains ( term ) , \n models . Feed . user_id == current_user . id \n ) . distinct ( ) \n ) . all ( ) \n options += [ ( f , flask . url_for ( '<STR_LIT>' , feed_name = f ) , '<STR_LIT>' ) \n for f in feed_names ] \n options . append ( ( '<STR_LIT>' + term , flask . url_for ( '<STR_LIT>' , q = term ) , '<STR_LIT>' ) ) \n options += [ ( '<STR_LIT>' + f , flask . url_for ( '<STR_LIT>' , feed_name = f ) , '<STR_LIT>' ) \n for f in feed_names ] \n static_options = [ \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) , \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , favorited = True ) , '<STR_LIT>' ) , \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' , favorited = True ) , '<STR_LIT>' ) , \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) , \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) , \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) , \n ( '<STR_LIT>' , flask . url_for ( '<STR_LIT>' ) , '<STR_LIT>' ) \n ] \n for so in static_options : \n if term . lower ( ) in so [ <NUM_LIT> ] . lower ( ) : \n options . append ( so ) \n return flask . render_template ( \"<STR_LIT>\" , options = options ) \n @ app . put ( \"<STR_LIT>\" ) \n @ login_required \n def entry_pin ( id ) : \n entry = db . get_or_404 ( models . Entry , id ) \n if entry . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n if entry . pinned : \n entry . pinned = None \n else : \n entry . fetch_content ( ) \n entry . pinned = datetime . datetime . utcnow ( ) \n entry . backlogged = None \n db . session . commit ( ) \n filters = dict ( ** flask . request . args ) \n pinned = models . Entry . select_pinned ( current_user . id , ** filters ) \n return flask . render_template ( \"<STR_LIT>\" , \n is_pinned_list = True , \n filters = filters , \n entries = pinned ) \n @ app . put ( \"<STR_LIT>\" ) \n @ login_required \n def entry_favorite ( id ) : \n \"<STR_LIT>\" \n entry = db . get_or_404 ( models . Entry , id ) \n if entry . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n if entry . favorited : \n entry . favorited = None \n else : \n entry . favorited = datetime . datetime . utcnow ( ) \n db . session . commit ( ) \n return '<STR_LIT>' , <NUM_LIT> \n @ app . put ( \"<STR_LIT>\" ) \n @ login_required \n def entry_backlog_push ( id ) : \n \"<STR_LIT>\" \n entry = db . get_or_404 ( models . Entry , id ) \n if entry . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n entry . backlog ( ) \n db . session . commit ( ) \n return '<STR_LIT>' , <NUM_LIT> \n @ app . delete ( \"<STR_LIT>\" ) \n @ login_required \n def entry_backlog_pop ( id ) : \n \"<STR_LIT>\" \n entry = db . get_or_404 ( models . Entry , id ) \n if entry . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n if entry . backlogged : \n entry . unbacklog ( ) \n db . session . commit ( ) \n return '<STR_LIT>' , <NUM_LIT> \n @ app . put ( \"<STR_LIT>\" ) \n @ login_required \n def mastodon_favorite ( id ) : \n entry = db . get_or_404 ( models . Entry , id ) \n if entry . feed . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n if not entry . feed . is_mastodon : \n flask . abort ( <NUM_LIT> ) \n masto_acct = entry . feed . account \n mastodon . favorite ( masto_acct . app . api_base_url , \n masto_acct . access_token , \n entry . remote_id ) \n return '<STR_LIT>' , <NUM_LIT> \n @ app . put ( \"<STR_LIT>\" ) \n @ login_required \n def mastodon_boost ( id ) : \n entry = db . get_or_404 ( models . Entry , id ) \n if entry . feed . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n if not entry . feed . is_mastodon : \n flask . abort ( <NUM_LIT> ) \n masto_acct = entry . feed . account \n mastodon . boost ( masto_acct . app . api_base_url , \n masto_acct . access_token ,", "output": "entry . remote_id ) \n return '<STR_LIT>' , <NUM_LIT> \n @ app . route ( \"<STR_LIT>\" ) \n @ login_required \n def feed_list ( ) : \n subquery = models . Feed . frequency_rank_query ( ) \n feeds = db . session . execute ( db . select ( models . Feed , subquery . c . rank , sa . func . count ( <NUM_LIT> ) , \n sa . func . max ( models . Entry . sort_date ) . label ( '<STR_LIT>' ) ) \n . filter ( models . Feed . user_id == current_user . id ) \n . join ( subquery , models . Feed . id == subquery . c . id , isouter = True ) \n . join ( models . Entry , models . Feed . id == models . Entry . feed_id , isouter = True ) \n . group_by ( models . Feed ) \n . order_by ( sa . text ( '<STR_LIT>' ) , sa . text ( '<STR_LIT>' ) ) ) \n return flask . render_template ( '<STR_LIT>' , feeds = feeds ) \n @ app . get ( \"<STR_LIT>\" ) \n @ login_required \n def feed_add ( ) : \n url = flask . request . args . get ( '<STR_LIT>' ) \n name = None \n error_msg = None \n if url : \n result = rss . discover_feed ( url ) \n if result : \n ( url , name ) = result \n if not result or not url : \n error_msg = \"<STR_LIT>\" \n folders = db . session . scalars ( \n db . select ( models . Feed . folder ) \n . filter ( models . Feed . folder . isnot ( None ) , \n models . Feed . folder . isnot ( '<STR_LIT>' ) ) \n . filter_by ( user_id = current_user . id ) . distinct ( ) ) \n return flask . render_template ( '<STR_LIT>' , \n url = url , \n name = name , \n folders = folders , \n error_msg = error_msg ) \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def feed_add_submit ( ) : \n values = { k : v . strip ( ) for k , v in flask . request . form . items ( ) if v } \n if not values . get ( '<STR_LIT>' ) : \n return flask . render_template ( '<STR_LIT>' , error_msg = '<STR_LIT>' , ** values ) \n if not values . get ( '<STR_LIT>' ) and not values . get ( '<STR_LIT>' , '<STR_LIT>' ) . startswith ( '<STR_LIT>' ) : \n return flask . render_template ( '<STR_LIT>' , error_msg = '<STR_LIT>' , ** values ) \n name = values . get ( '<STR_LIT>' ) \n feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( \n name = name , user_id = current_user . id ) ) \n if feed : \n return flask . render_template ( '<STR_LIT>' , error_msg = f\"<STR_LIT>\" , ** values ) \n feed_cls = models . Feed . resolve ( values [ '<STR_LIT>' ] ) \n if not values [ '<STR_LIT>' ] . startswith ( '<STR_LIT>' ) and values . get ( '<STR_LIT>' ) : \n del values [ '<STR_LIT>' ] \n feed = feed_cls ( ** values ) \n feed . user_id = current_user . id \n db . session . add ( feed ) \n db . session . flush ( ) \n feed . load_icon ( ) \n db . session . commit ( ) \n tasks . sync_feed ( feed . id , feed . name ) . get ( ) \n return flask . redirect ( flask . url_for ( '<STR_LIT>' , feed_name = feed . name ) ) \n @ app . get ( \"<STR_LIT>\" ) \n @ login_required \n def feed_edit ( feed_name ) : \n feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( \n name = feed_name , user_id = current_user . id ) ) \n if not feed : \n flask . abort ( <NUM_LIT> , \"<STR_LIT>\" ) \n folders = db . session . scalars ( \n db . select ( models . Feed . folder ) \n . filter ( models . Feed . folder . isnot ( None ) , \n models . Feed . folder . isnot ( '<STR_LIT>' ) ) \n . filter_by ( user_id = current_user . id ) . distinct ( ) ) . all ( ) \n return flask . render_template ( '<STR_LIT>' , feed = feed , folders = folders ) \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def feed_edit_submit ( feed_name ) : \n feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( \n name = feed_name , user_id = current_user . id ) ) \n if not feed : \n flask . abort ( <NUM_LIT> , \"<STR_LIT>\" ) \n values = flask . request . form \n if not values . get ( '<STR_LIT>' ) or not values . get ( '<STR_LIT>' ) : \n return flask . render_template ( '<STR_LIT>' , error_msg = '<STR_LIT>' , ** values ) \n for ( attr , value ) in values . items ( ) : \n setattr ( feed , attr , value . strip ( ) ) \n db . session . commit ( ) \n return flask . redirect ( flask . url_for ( '<STR_LIT>' ) ) \n @ app . delete ( \"<STR_LIT>\" ) \n @ login_required \n def feed_delete ( feed_name ) : \n \"<STR_LIT>\" \n feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( \n name = feed_name , user_id = current_user . id ) ) \n if not feed : \n flask . abort ( <NUM_LIT> , \"<STR_LIT>\" ) \n update = db . update ( models . Entry ) . where ( ( models . Entry . feed_id == feed . id ) & ( \n models . Entry . favorited . isnot ( None ) | \n models . Entry . backlogged . isnot ( None ) | \n models . Entry . pinned . isnot ( None ) ) ) . values ( feed_id = None ) \n db . session . execute ( update ) \n db . session . delete ( feed ) \n db . session . commit ( ) \n return '<STR_LIT>' , <NUM_LIT> \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def feed_sync ( feed_name ) : \n \"<STR_LIT>\" \n feed = db . session . scalar ( db . select ( models . Feed ) . filter_by ( \n name = feed_name , user_id = current_user . id ) ) \n if not feed : \n flask . abort ( <NUM_LIT> , \"<STR_LIT>\" ) \n task = tasks . sync_feed ( feed . id , feed . name , force = True ) \n task . get ( ) \n response = flask . make_response ( ) \n response . headers [ '<STR_LIT>' ] = flask . url_for ( '<STR_LIT>' , feed_name = feed . name ) \n return response \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def entry_add ( ) : \n url = flask . request . args [ '<STR_LIT>' ] \n redirect = flask . request . args . get ( '<STR_LIT>' ) \n try : \n entry = models . Entry . from_url ( current_user . id , url ) \n except Exception : \n if redirect : \n return redirect_response ( url ) \n else : \n return '<STR_LIT>' , <NUM_LIT> \n db . session . add ( entry ) \n db . session . commit ( ) \n if redirect : \n return redirect_response ( flask . url_for ( '<STR_LIT>' , id = entry . id ) ) \n else : \n return '<STR_LIT>' , <NUM_LIT> \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def entry_unwrap ( id ) : \n \"<STR_LIT>\" \n entry = db . get_or_404 ( models . Entry , id ) \n if entry . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n if entry . content_short : \n for link in entry . embedded_links ( ) : \n try : \n subentry = models . Entry . from_url ( current_user . id , link ) \n entry . viewed = datetime . datetime . now ( ) \n db . session . add ( subentry ) \n db . session . commit ( ) \n return flask . render_template ( '<STR_LIT>' , \n entries = [ subentry ] ) \n except Exception : \n continue \n return \"<STR_LIT>\" , <NUM_LIT> \n @ app . get ( \"<STR_LIT>\" ) \n @ login_required \n def entry_view ( id ) : \n entry = db . get_or_404 ( models . Entry , id ) \n if entry . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n if '<STR_LIT>' in flask . request . headers and '<STR_LIT>' not in flask . request . args and not entry . content_full : \n return flask . render_template ( \"<STR_LIT>\" , entry = entry , content = None ) \n else : \n if not entry . content_url and not entry . target_url : \n return \"<STR_LIT>\" , <NUM_LIT> \n if '<STR_LIT>' in entry . content_url or '<STR_LIT>' in entry . content_url : \n return redirect_response ( entry . target_url ) \n entry . fetch_content ( ) \n if entry . content_full : \n entry . viewed = entry . viewed or datetime . datetime . utcnow ( ) \n db . session . commit ( ) \n return flask . render_template ( \"<STR_LIT>\" , entry = entry , content = entry . content_full ) \n return redirect_response ( entry . target_url ) \n def redirect_response ( url ) : \n if '<STR_LIT>' in flask . request . headers : \n response = flask . make_response ( ) \n response . headers [ '<STR_LIT>' ] = url \n return response \n else : \n return flask . redirect ( url ) \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def send_to_kindle ( ) : \n if not current_user . has_kindle : \n return '<STR_LIT>' , <NUM_LIT> \n kindle = db . session . scalar ( db . select ( models . KindleDevice ) . filter_by ( \n user_id = current_user . id ) ) \n url = flask . request . args [ '<STR_LIT>' ] \n article = scraping . extract ( url ) \n with tempfile . NamedTemporaryFile ( mode = '<STR_LIT>' , delete = False ) as fp : \n scraping . compress ( fp . name , article ) \n kindle . send ( pathlib . Path ( fp . name ) , \n author = article [ '<STR_LIT>' ] , \n title = article [ '<STR_LIT>' ] ) \n return '<STR_LIT>' , <NUM_LIT> \n @ app . route ( \"<STR_LIT>\" ) \n @ login_required \n def raw_feed ( feed_name ) : \n feed = db . session . scalar ( \n db . select ( models . Feed ) \n . filter_by ( name = feed_name , user_id = current_user . id ) \n . options ( sa . orm . undefer ( models . Feed . raw_data ) ) \n ) \n if not feed : \n flask . abort ( <NUM_LIT> , \"<STR_LIT>\" ) \n return app . response_class ( \n response = feed . raw_data , \n status = <NUM_LIT> , \n mimetype = '<STR_LIT>' \n ) \n @ app . route ( \"<STR_LIT>\" ) \n @ login_required \n def raw_entry ( id ) : \n entry = db . get_or_404 ( models . Entry , id , \n options = [ sa . orm . undefer ( models . Entry . raw_data ) ] ) \n if entry . user_id != current_user . id : \n flask . abort ( <NUM_LIT> ) \n return app . response_class ( \n response = entry . raw_data , \n status = <NUM_LIT> , \n mimetype = '<STR_LIT>' \n ) \n @ app . put ( \"<STR_LIT>\" ) \n @ login_required \n def update_setting ( setting , value ) : \n flask . session [ setting ] = value \n return '<STR_LIT>' , <NUM_LIT> \n @ app . post ( \"<STR_LIT>\" ) \n @ login_required \n def toggle_setting ( setting ) : \n flask . session [ setting ] = not flask . session . get ( setting , True ) \n return '<STR_LIT>' , <NUM_LIT> \n @ app . context_processor \n def sidebar_feeds ( ) : \n if current_user . is_authenticated : \n folders = db . session . scalars ( db . select ( models . Feed . folder ) \n . filter_by ( user_id = current_user . id ) \n . filter ( models . Feed . folder . isnot ( None ) , \n models . Feed . folder . isnot ( '<STR_LIT>' ) ) \n . group_by ( models . Feed . folder ) \n . order_by ( sa . func . count ( models . Feed . folder ) . desc ( ) ) ) . all ( ) \n return dict ( shortcut_folders = folders , filters = { } ) \n return { }"}, {"input": "import datetime as dt \n import re \n from tests . conftest import ( create_feed , extract_entry_ids , mock_feed , \n mock_request ) \n def test_feed_add ( client ) : \n feed_domain = '<STR_LIT>' \n response = create_feed ( client , feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) \n assert response . status_code == <NUM_LIT> \n assert response . request . path == f'<STR_LIT>' , '<STR_LIT>' \n assert '<STR_LIT>' in response . text , '<STR_LIT>' \n assert '<STR_LIT>' in response . text , '<STR_LIT>' \n assert response . text . find ( \n '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) , '<STR_LIT>' \n response = client . get ( '<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n assert '<STR_LIT>' in response . text , '<STR_LIT>' \n assert '<STR_LIT>' in response . text , '<STR_LIT>' \n assert response . text . find ( \n '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) , '<STR_LIT>' \n def test_folders ( client ) : \n create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] , \n folder = '<STR_LIT>' ) \n create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] , \n folder = '<STR_LIT>' ) \n create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] , \n folder = '<STR_LIT>' ) \n create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) \n response = client . get ( '<STR_LIT>' ) \n assert all ( [ feed in response . text for feed in [ '<STR_LIT>' , '<STR_LIT>' , \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] ) \n response = client . get ( '<STR_LIT>' ) \n assert all ( [ feed in response . text for feed in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] ) \n assert all ( [ feed not in response . text for feed in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] ) \n response = client . get ( '<STR_LIT>' ) \n assert all ( [ feed in response . text for feed in [ '<STR_LIT>' , '<STR_LIT>' ] ] ) \n assert all ( [ feed not in response . text for feed in [ \n '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ] ) \n def test_home_sorting ( client ) : \n date12h = dt . datetime . now ( dt . timezone . utc ) - dt . timedelta ( hours = <NUM_LIT> ) \n create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : date12h } ] ) \n items = [ ] \n for i in range ( <NUM_LIT> , <NUM_LIT> ) : \n items . append ( { '<STR_LIT>' : f'<STR_LIT>' , '<STR_LIT>' : date12h + dt . timedelta ( hours = <NUM_LIT> , minutes = i ) } ) \n create_feed ( client , '<STR_LIT>' , items ) \n response = client . get ( '<STR_LIT>' ) \n assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) \n assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) \n date13h = date12h - dt . timedelta ( hours = <NUM_LIT> ) \n create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : date13h } ] ) \n response = client . get ( '<STR_LIT>' ) \n assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) \n assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) \n client . put ( '<STR_LIT>' ) \n response = client . get ( '<STR_LIT>' ) \n assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' not in response . text \n def test_home_pagination ( app , client ) : \n now = dt . datetime . now ( dt . timezone . utc ) \n items = [ ] \n per_page = app . config [ '<STR_LIT>' ] \n for i in range ( <NUM_LIT> , per_page * <NUM_LIT> ) : \n items . append ( { '<STR_LIT>' : f'<STR_LIT>' , '<STR_LIT>' : now - dt . timedelta ( hours = <NUM_LIT> , minutes = i ) } ) \n create_feed ( client , '<STR_LIT>' , items ) \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert f'<STR_LIT>' in response . text \n assert f'<STR_LIT>' not in response . text \n assert response . text . find ( '<STR_LIT>' ) < response . text . find ( f'<STR_LIT>' ) \n next_page = re . search ( r'<STR_LIT>' , response . text ) . group ( <NUM_LIT> ) \n response = client . get ( f'<STR_LIT>' ) \n assert f'<STR_LIT>' not in response . text \n assert f'<STR_LIT>' in response . text \n assert f'<STR_LIT>' in response . text \n assert f'<STR_LIT>' not in response . text \n response = client . get ( '<STR_LIT>' ) \n assert f'<STR_LIT>' not in response . text \n assert f'<STR_LIT>' in response . text \n assert f'<STR_LIT>' in response . text \n assert f'<STR_LIT>' not in response . text \n response = client . post ( '<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert f'<STR_LIT>' in response . text \n assert f'<STR_LIT>' not in response . text \n def test_sync_old_entries ( client ) : \n pass \n def test_sync_updates ( client ) : \n feed_domain = '<STR_LIT>' \n response = create_feed ( client , feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n mock_feed ( feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) \n response = client . post ( f'<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n def test_sync_between_pages ( client ) : \n pass \n def test_favorites ( client ) : \n feed_domain = '<STR_LIT>' \n response = create_feed ( client , feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) \n entry_ids = extract_entry_ids ( response ) \n response = client . put ( f'<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n response = client . put ( f'<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n assert response . text . find ( '<STR_LIT>' ) < response . text . find ( '<STR_LIT>' ) \n def test_backlog ( client ) : \n feed_domain = '<STR_LIT>' \n response = create_feed ( client , feed_domain , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) \n entry_ids = extract_entry_ids ( response ) \n response = client . put ( f'<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n response = client . put ( f'<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' not in response . text \n response = client . delete ( f'<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' not in response . text \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' in response . text \n def test_pinned ( client ) : \n response = create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] , \n folder = '<STR_LIT>' ) \n f1a2_pin_url = re . search ( r'<STR_LIT>' , response . text ) . group ( <NUM_LIT> ) \n response = create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) \n f2_a2_pin_url = re . search ( r'<STR_LIT>' , response . text ) . group ( <NUM_LIT> ) \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' not in response . text \n now = dt . datetime . now ( dt . timezone . utc ) \n for i in range ( <NUM_LIT> , <NUM_LIT> ) : \n date = now - dt . timedelta ( hours = <NUM_LIT> , minutes = <NUM_LIT> )", "output": "create_feed ( client , f'<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : date } ] , \n folder = '<STR_LIT>' ) \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' not in response . text \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' not in response . text \n response = client . put ( f1a2_pin_url ) \n assert response . status_code == <NUM_LIT> \n response = client . put ( f2_a2_pin_url ) \n assert response . status_code == <NUM_LIT> \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' not in response . text \n def test_entries_not_mixed_between_users ( client ) : \n pass \n def test_view_entry_content ( client ) : \n with open ( '<STR_LIT>' ) as sample : \n body = sample . read ( ) \n response = create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : '<STR_LIT>' , \n '<STR_LIT>' : body } ] ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n entry_url = re . search ( r'<STR_LIT>' , response . text ) . group ( <NUM_LIT> ) \n response = client . get ( entry_url ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n def test_add_external_entry ( client ) : \n with open ( '<STR_LIT>' ) as sample : \n body = sample . read ( ) \n content_url = '<STR_LIT>' \n mock_request ( content_url , body = body ) \n response = client . post ( \n '<STR_LIT>' , query_string = { '<STR_LIT>' : content_url , '<STR_LIT>' : <NUM_LIT> } , follow_redirects = True ) \n assert response . status_code == <NUM_LIT> \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n previous_entry_url = response . request . path \n response = client . post ( \n '<STR_LIT>' , query_string = { '<STR_LIT>' : content_url , '<STR_LIT>' : <NUM_LIT> } , follow_redirects = True ) \n assert response . status_code == <NUM_LIT> \n assert response . request . path == previous_entry_url \n client . post ( '<STR_LIT>' ) \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n def test_discover_feed ( client ) : \n pass \n def test_feed_list ( client ) : \n pass \n def test_feed_edit ( client ) : \n pass \n def test_feed_delete ( client ) : \n response = create_feed ( client , '<STR_LIT>' , [ { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } , \n { '<STR_LIT>' : '<STR_LIT>' , '<STR_LIT>' : '<STR_LIT>' } ] ) \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n entry_ids = extract_entry_ids ( response ) \n response = client . put ( '<STR_LIT>' + entry_ids [ <NUM_LIT> ] ) \n assert response . status_code == <NUM_LIT> \n response = client . put ( '<STR_LIT>' + entry_ids [ <NUM_LIT> ] ) \n assert response . status_code == <NUM_LIT> \n response = client . delete ( '<STR_LIT>' ) \n assert response . status_code == <NUM_LIT> \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' in response . text \n assert '<STR_LIT>' not in response . text \n response = client . get ( '<STR_LIT>' ) \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' not in response . text \n assert '<STR_LIT>' not in response . text \n def test_mastodon_feed ( client ) : \n pass"}, {"input": "from typing import Sequence , Union \n import sqlalchemy as sa \n from alembic import op \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None :", "output": "op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . Integer ( ) , nullable = False , server_default = \"<STR_LIT>\" ) ) \n def downgrade ( ) -> None : \n op . drop_column ( '<STR_LIT>' , '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>' \n branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) )", "output": "batch_op . add_column ( sa . Column ( '<STR_LIT>' , sa . String ( ) , nullable = True ) ) \n def downgrade ( ) -> None : \n with op . batch_alter_table ( '<STR_LIT>' , schema = None ) as batch_op : \n batch_op . drop_column ( '<STR_LIT>' ) \n batch_op . drop_column ( '<STR_LIT>' )"}, {"input": "from typing import Sequence , Union \n from alembic import op \n import sqlalchemy as sa \n revision : str = '<STR_LIT>' \n down_revision : Union [ str , None ] = '<STR_LIT>'", "output": "branch_labels : Union [ str , Sequence [ str ] , None ] = None \n depends_on : Union [ str , Sequence [ str ] , None ] = None \n def upgrade ( ) -> None : \n op . add_column ( '<STR_LIT>' , sa . Column ( '<STR_LIT>' , sa . Boolean ( ) , nullable = True ) ) \n def downgrade ( ) -> None : \n op . drop_column ( '<STR_LIT>' , '<STR_LIT>' )"}]